<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# Thought Reasoning의 체인 조사: 발전, 프런티어 및 미래\n' +
      '\n' +
      ' 정추\\({}^{1}\\), 징창천\\({}^{1}\\), 장롱천\\({}^{2}\\), 위장유\\({}^{2}\\), 도허\\({}^{1}\\)\n' +
      '\n' +
      '**Haotian Wang\\({}^{1}\\), Weihua Peng\\({}^{2}\\), Ming Liu\\({}^{1\\dagger}\\), Bing Qin\\({}^{1}\\), Ting Liu\\({}^{1}\\)**\n' +
      '\n' +
      '\\({}^{1}\\)중국 하얼빈 하얼빈공과대학\n' +
      '\n' +
      '(주)화웨이\n' +
      '\n' +
      '{zchu, jcchen, the, mliu\\({}^{\\dagger}\\), qinb, tliu}@ir.hit.edu.cn\n' +
      '\n' +
      '{chenqianglong.ai, wangt1998, Weijiangyu8, pengwh.hit}@gmail.com\n' +
      '\n' +
      ' 해당 작성자입니다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '인간의 지능에 근본적인 인지 과정인 사상 사슬 추론은 인공 지능과 자연어 처리의 영역에서 상당한 주목을 받았다. 그러나 이 분야에 대한 포괄적인 조사가 아직 부족하다. 이를 위해 먼저 이 연구 분야에 대한 철저한 조사를 신중하고 광범위하게 제시한다. 우리는 넓은 의미에서 연쇄 사고를 지칭하기 위해 X-사상(X-of-Thinking)을 사용한다. 세부적으로, 우리는 XoT 구축, XoT 구조 변형, 향상된 XoT를 포함한 방법의 분류에 따라 현재 연구를 체계적으로 정리한다. 또한 프론티어 애플리케이션, 계획, 도구 사용 및 증류를 포함하는 XoT를 설명한다. 또한, 우리는 도전 과제를 해결하고 충실성, 다중 모드 및 이론을 포함한 몇 가지 미래 방향에 대해 논의한다. 우리는 이 조사가 연쇄 사고 추론 1의 영역 내에서 혁신을 추구하는 연구자들에게 귀중한 자원이 되기를 바란다.\n' +
      '\n' +
      '각주 1: 리소스는 [https://github.com/zchuz/CoT-Reasoning-Survey](https://github.com/zchuz/CoT-Reasoning-Survey)에서 사용할 수 있습니다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '사전 훈련된 언어 모델(PLMs)은 레이블이 지정되지 않은 텍스트로부터 일반 표현을 자동으로 학습하고 다운스트림 작업에 대한 미세 조정을 통해 우수한 성능을 달성할 수 있다. Devlin 등(2019); Raffel 등(2020); Radford and Narasimhan(2018). 최근에, 언어 모델을 스케일링하는 것은 성능을 상당히 향상시키고 많은 놀라움들을 가져온다, 예를 들어, 응급 능력 Wei 등(2022); Schaeffer 등(2023). 따라서 자연어 처리의 패러다임은 미세 조정을 통한 사전 학습에서 문맥 내 학습을 통한 사전 학습으로 전환되고 있다. 그러나, 현재, 대규모 언어 모델(LLMs)은 수학적 추론 Cobbe et al.(2021), Patel et al.(2021), 상식 추론 Talmor et al.(2021), Mihaylov et al.(2018) 등과 같은 복잡한 추론 작업에 대해 여전히 상당한 개선의 여지가 있다.\n' +
      '\n' +
      '복잡한 추론 작업을 다루기 위해 LLM을 활용하기 위해 Wei et al.(2022)은 단계적인 추론 과정을 통해 맥락 내 학습을 확장하며, 먼저 CoT(chain-of-thought) 프롬프트 개념을 도입한다. Kojima 등(2022)은 프롬프트에서 단순히 매직 프레이즈 _단계별로 생각하자_ 를 추가하면 LLM들이 어떠한 인간 주석도 없이 제로 샷 체인-오브-생각 추론을 수행할 수 있다는 것을 발견한다. 이러한 연구는 복잡한 추론에 대한 모델의 능력을 향상시키고 추론 및 계획 능력을 향상시키는 데 연쇄 사유의 중요성을 강조했다.\n' +
      '\n' +
      '그 후, XoT(X-of-thought)에 관한 많은 작품들이 NLP 커뮤니티에서 비가 내린 후에 버섯처럼 나타난다. 예를 들어, 자동 XoT 구축 Kojima et al.(2022); Zhang et al.(2023); Xu et al.(2023), XoT 구조 변형 Chen et al.(2022); Ning et al.(2023); Lei et al.(2023); Yao et al.(2023) 등이 있다. 원시 CoT와 구별하기 위해 XoT를 사용하여 광범위한 의미에서 CoT를 지칭하는데, 이는 단계별 추론 방법의 사용을 위한 집합 용어이다.\n' +
      '\n' +
      '그러나 이러한 방법 및 데이터 세트는 아직 체계적인 검토 및 분석을 거치지 않았다. 이 공백을 메우기 위해 우리는 XoT 패밀리에 대한 포괄적이고 상세한 분석을 수행하기 위해 이 작업을 제안한다. 사슬-생각을 논의하는 일부 조사가 있었지만 프롬프트 Qiao 등(2023)과 사슬-생각 프롬프트 전략 Yu 등(2023)과 같은 특정 측면에 국한된다. 대조적으로, 우리의 조사는 그들이 이미 다루었던 주제에 대한 보다 철저하고 포괄적인 토론을 제공할 뿐만 아니라 XoT 구축, XoT 구조적 변형 및 프론티어 적용 등과 같은 추가 주제 및 토론을 포함한다. 구체적으로, 본 논문에서는 먼저 관련 배경과 예비(SS2)를 소개한다. 또한, XoT 구축 방법(SS4.1), XoT 구조 변형 방법(SS4.2), XoT 향상 방법(SS4.3)을 포함한 심층 분석(SS4)을 여러 관점에서 신중하게 분류하고 완료한다. 그런 다음 프론티어 필드(SS5)에서 XoT의 실제 응용 프로그램을 제공한다. XoT의 후속 작업에 영감을 주기 위해 이 분야의 향후 연구를 위한 잠재적인 방법에 대한 통찰력을 제공한다. 마지막으로, 기존의 방법(SS7)을 비교 및 논의한다.\n' +
      '\n' +
      '## 2 배경 및 예비\n' +
      '\n' +
      '### Background\n' +
      '\n' +
      '최근, 컴퓨팅 파워의 지속적인 확장과 함께, 대규모 언어 모델들이 Brown et al. (2020); OpenAI (2023); Touvron et al. (2023); Scao et al. (2022); Touvron et al. (2023); Zhao et al. (2023) 및 모델 사이즈가 계속 성장함에 따라, 많은 새로운 능력들이 출현하였다, 예를 들어, In-context learning 및 chain-of-thought reasoning Brown et al. (2020); Wei et al. (2022); Baa; Schaefer et al. (2023).\n' +
      '\n' +
      'Brown 등(2020)은 대규모 언어 모델들이 우수한 인-컨텍스트 학습(ICL) 능력을 갖는다는 것을 발견한다. ICL은 입력-출력 데모를 프롬프트 텍스트에 통합한다. ICL을 사용하면 유사한 성능을 달성하면서 추가 미세 조정 없이 기성 LLM을 사용할 수 있다. 그럼에도 불구하고 이러한 종단 간 접근은 복잡한 추론 과제에 직면했을 때 과소 수행하는 경향이 있다.\n' +
      '\n' +
      'Wei et al.(2022)은 LMM의 추론 능력을 향상시키기 위해 단계별 추론 과정을 추가하는데, 이를 chain-of-thought prompting이라고 한다. CoT 프롬프팅은 모델이 질문의 복잡성과 추론 과정 모두에 대한 보다 정확한 이해를 얻을 수 있게 한다. 또한, 모델은 일련의 추론 단계를 생성하며, 이는 모델의 인지 과정에 대한 투명한 관점을 제공하여 해석 가능성을 더욱 향상시킨다.\n' +
      '\n' +
      '### Preliminary\n' +
      '\n' +
      '이 절에서는 LLM을 사용한 예비 연쇄 사고 추론을 소개하고 Qiao et al.(2023)의 공식 정의를 참조한다. 질문 \\(\\mathcal{Q}\\), 프롬프트 \\(\\mathcal{T}\\) 및 확률 언어 모델 \\(P_{LM}\\)이 있다고 가정합니다. 이 모델은 질문과 프롬프트를 입력으로 하여 이론 \\(\\mathcal{R}\\)과 대답 \\(\\mathcal{A}\\)을 제공한다. 우리는 먼저 시연이 추론 사슬을 포함하지 않는 맥락 내 시나리오를 고려한다. 우리는 Equ (1,2)와 같이 답\\(\\mathcal{A}\\)의 가능성을 최대화해야 한다.\n' +
      '\n' +
      '\\[p(\\mathcal{A}\\mid\\mathcal{T},\\mathcal{Q})=\\prod_{i=1}^{| \\mathcal{A}|}p_{LM}(a_{i}\\mid\\mathcal{T},\\mathcal{Q},a_{<i}) \\tag{1}\\] \\[\\mathcal{T}_{ICL}=\\{I,(x_{1},y_{1}),\\cdots,(x_{n},y_{n})\\} \\tag{2}\\]\n' +
      '\n' +
      '시연이 추론과정을 담고 있는 연쇄추론 시나리오에서는 Equ(3,4,5,6)와 같이 답의 가능성 \\(\\mathcal{A}\\)과 논리의 가능성 \\(\\mathcal{R}\\)을 극대화해야 한다.\n' +
      '\n' +
      '\\[p(\\mathcal{A}\\mid\\mathcal{T},\\mathcal{Q})=p(\\mathcal{A}\\mid\\mathcal{T},\\mathcal{R}\\mid\\mathcal{T},\\mathcal{Q}) \\tag{3}\\] \\[p(\\mathcal{R}\\mid\\mathcal{T},\\mathcal{Q})=\\prod_{i=1}^{| \\mathcal{R}|\\mathcal{T},\\mathcal{Q},r_{<i})\\] (4) \\[p(\\mathcal{A}|\\mathcal{T},\\mathcal{Q},\\mathcal{R})=\\prod_{j=1}^{ |\\mathcal{A}|}p_{LM}(a_{i}|\\mathcal{T},\\mathcal{Q},\\mathcal{R},a_{<j})\\] (5) \\[\\mathcal{T}_{\\text{CoT}}=\\{\n' +
      '\n' +
      '## 3 Benchmarks\n' +
      '\n' +
      '### Mathematical Reasoning\n' +
      '\n' +
      '수학적 추론은 종종 모델의 추론력을 측정하는 데 사용된다. 초기 벤치마크들은 간단한 산술 연산들 Hosseini 등(2014); Koncel-Kedziorski 등(2015); Roy and Roth(2015); Koncel-Kedziorski 등(2016)을 포함한다. Ling 등(2017)은 추론 과정을 자연어 형태로 레이블링하고, Amini 등(2019)은 추론 과정을 프로그램 형태로 레이블링하여 AQUA를 기반으로 한다. 나중의 벤치마크들 Miao et al.(2020); Patel et al.(2021); Cobbe et al.(2021); Gao et al.(2023)은 보다 복잡하고 다양한 질문들을 포함한다. Zhu 등(2021); Chen 등(2021); Chen 등(2022)은 테이블 내용에 기초한 추론을 요구한다. 또한 일반적인 벤치마크인 Hendrycks 등(2021); Mishra 등(2022); Baa 등(2022) 및 독해 양식 벤치마크인 Dua 등(2019); Chen 등(2023)이 있다. 최근 Yu et al.(2021)은 계층적 추론과 지식을 활용하여 수학적 추론 능력을 사전 훈련된 모델에 부여하였다.\n' +
      '\n' +
      '### Commonsense Reasoning\n' +
      '\n' +
      '상식 추론은 일상 세계에서 일반적으로 알려지고 일반적으로 인식되는 지식을 바탕으로 추론, 판단, 이해를 하는 과정이다. 상식적 지식을 습득하고 이해하는 방법\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:3]\n' +
      '\n' +
      '2020; Wu et al., 2021; Xiao et al., 2021; Li et al., 2022; Gupta and Gupta, 2022)는 시각적 멀티모달 추론에 비해 추가적인 시간적 정보를 도입하기 때문에 더 어렵다.\n' +
      '\n' +
      '### Metrics\n' +
      '\n' +
      '정확도 정확도는 분류 작업에 대한 모델의 능력을 평가하는 데 사용되며 다중 선택 Ling et al.(2017); Mihaylov et al.(2018); Liu et al.(2020); Lu et al.(2022) 및 yes/no Talmor et al.(2021); Geva et al.(2021); Han et al.(2022) 작업에 일반적으로 사용된다.\n' +
      '\n' +
      '\\[\\mathrm{Accuracy}=\\frac{\\mathrm{N}_{\\mathrm{correct}}}{\\mathrm{N}_{\\mathrm{ total}}} \\tag{7}\\]\n' +
      '\n' +
      'EM 및 F1EM 및 F1은 자유 형태 Mishra et al. (2022); Wang et al. (2019); Yi et al. (2020) 및 span extraction Dua et al. (2019); Zhu et al. (2021); Mishra et al. (2022) 태스크를 평가하는 데 사용되는 메트릭이다. 둘 다 토큰 수준에서 계산됩니다.\n' +
      '\n' +
      '\\[\\mathrm{F1}=\\frac{2\\cdot\\mathrm{P}\\cdot\\mathrm{R}}{\\mathrm{P}+\\mathrm{R}} \\tag{8}\\] \\[\\mathrm{EM}=\\frac{\\sum\\mathbb{I}[A=A^{\\prime}]}{\\mathrm{N}_{ \\mathrm{total}}} \\tag{9}\\]\n' +
      '\n' +
      '여기서 P와 R은 정밀도와 재현율을 나타내며 EM은 정확히 동일한 예측과 답변의 비율을 계산한다.\n' +
      '\n' +
      '## 4 Methods\n' +
      '\n' +
      '이 절에서는 X-of-thought의 구성(SS4.1), X-of-thought의 구조적 변형(SS4.2), 그리고 X-of-thought의 향상된 방법(SS4.3)의 세 가지 다른 분류를 통해 X-of-thought 추론을 탐구한다.\n' +
      '\n' +
      '### Construction Approach\n' +
      '\n' +
      '철저한 분석을 통해 X-of-thought의 구성을 1) 수동 XoT, 2) 자동 XoT, 3) 반자동 XoT의 세 가지 범주로 나누어 설명하면 다음과 같다.\n' +
      '\n' +
      '#### 4.1.1 Manual XoT\n' +
      '\n' +
      '대형 언어 모델은 프롬프팅을 통해 적은 수의 샷 인-컨텍스트 학습을 수행하지만, 여전히 추론 작업에 한계가 있다. 대형 언어 모델의 잠재적인 추론 능력을 탐구하기 위해 한 가지 표준 접근법은 시연에서 다양한 형태의 생각을 제공하는 것이다.\n' +
      '\n' +
      'Wei 등(2022)은 먼저 시연에 자연어 형태의 근거를 수동으로 제공함으로써 연쇄 사고 프롬프트(Few-shot CoT)를 제안한다. 추론 과정의 확실성을 더욱 보장하고 추론 경로와 답변 사이의 불일치를 줄이기 위해 PAL Gao et al.(2023), PoT Chen et al.(2022) 및 NLEP Zhang et al.(2023)은 프로그래밍 언어를 주석이 달린 논리로 활용하여 문제 해결을 실행 가능한 파이썬 프로그램으로 변환한다. 한편, 자연어와 프로그래밍 언어의 장점을 모두 취하고 추론 결과의 신뢰도를 높이기 위해 MathPromter Imani et al.(2023)은 zero-shot chain-of-thought prompting을 이용하여 다중 대수식이나 파이썬 함수를 생성함으로써 서로 검증하고 결과의 신뢰도를 향상시킬 수 있다. 더 나아가, 더 많은 추론 단계들을 갖는 체인들과 같은 데모들에서 샘플들의 추론 복잡성 때문에, 성능 개선 Fu 등(2023)은 복잡성 기반 프롬프팅을 제안하며, 여기서 최종 답변을 얻기 위해 고복잡성 근거들 간의 투표가 수행된다.\n' +
      '\n' +
      '수동으로 구성된 X-of-thought 방법은 다양한 유형의 단계별 중간 추론 과정을 시연에 추가하여 맥락 내 학습을 확장한다. LLM이 추론 경로를 모방하고 생성할 수 있도록 한다. 수동 XoT 방법은 인간의 이해에 대한 신뢰뿐만 아니라 더 큰 해석 가능성을 제공하고 복잡한 작업, 즉 수학적 추론, 상식 추론, 상징 추론 등을 능가하지만, 유리체의 수동 주석은 상당한 비용을 수반하고 시연 선택 및 작업 일반화의 어려움과 같은 단점을 겪는다. 특히, 다른 작업은 다른 방식의 시연을 요구합니다. 따라서 다른 연구는 SS4.1.2에서 논의된 바와 같이 추론 경로를 자동으로 구성하려고 시도한다.\n' +
      '\n' +
      '#### 4.1.2 자동 XoT\n' +
      '\n' +
      'Chain-of-thought prompting Wei et al.(2022)은 몇 번의 샷 설정에서 태스크별 예시와 함께 LLM의 복잡한 추론 능력을 이끌어내므로 확장성과 일반화에 한계가 있다. 수작업으로 만들어진 few-shot 예시들의 비용을 감소시키기 위해, Kojima 등(2022)은 질문 후에 매직 프레이즈 _단계별로 생각하자_ 를 도입함으로써 제로-shot CoT를 제안하며, 이는 LLM들이 제로-shot 방식으로 추론 체인들을 생성할 수 있게 한다. 그러나 제로샷 CoT는 많은 실수를 수반하는 질 나쁜 추론 경로를 겪는다. Auto-CoT Zhang et al.(2023)2023f)는 추론 체인 생성에서 데모의 다양성이 중요한 역할을 하기 때문에 클러스터링과 대표 예시 선택을 통해 데모를 자동으로 생성함으로써 다양성을 향상시키고 Few-shot CoT의 성능을 일관되게 일치시키거나 능가한다. COSP(Wan et al., 2023)는 실증 선택을 돕기 위해 질문의 결과 엔트로피를 소개한다. Xu 등(2023)은 Gibbs 샘플링을 반복적으로 채용함으로써 효과적인 CoT 프롬프트를 찾기 위한 Repropting을 제안한다. 한편, 추론 체인의 일부 오류는 누락된 단계의 오류에서 비롯된다. Wang et al.(2023f)은 Zero-shot CoT를 Plan-and-Solve (PS) Prompting으로 확장하여 전체 태스크를 더 작은 서브 태스크로 분할하고 더 자세한 지침을 통해 계획에 따라 서브 태스크를 수행하는 계획을 고안한다. LogCoT(Zhao et al., 2023c)는 심볼릭 로직을 사용하여 제로 샷 추론 프로세스를 검증하고, 따라서 추론에서의 오류를 감소시킨다. 또한, PoT(Chen et al., 2022a)는 코덱스와 같은 언어 모델을 탐색하여 실행 가능한 파이썬 프로그램을 생성하여 _Python 프로그램을 단계적으로 작성하자..._를 추가하여 제로샷 설정에서 수학 문제를 해결하는 실행 가능한 파이썬 프로그램을 생성한다. 이는 중간 추론 단계의 오류를 완화한다. 일부 연구에서는 추론 문제를 해결하기 위해 에이전트를 소개한다. 예를 들어, 에이전트 인스트럭션(Agent Instruct, Crispino 등, 2023a)은 태스크 관련, 정보적 명령어를 생성하기 위해 에이전트를 활용하며, 이는 LLM이 제로 샷 추론을 수행하도록 안내한다.\n' +
      '\n' +
      '수동 XoT와 달리 제로샷 프롬프트 엔지니어링 또는 샘플링을 사용하는 자동 XoT는 확장 가능하고 인간의 개입 없이 도메인 간에 일반화될 수 있다. 그러나 인간 정렬의 부족으로 인해 자동으로 생성된 연쇄 사고는 열악한 품질, 환각 및 사실적 불일치와 같은 문제에 직면한다. 따라서 XoT를 반자동 방식으로 구성하는 것이 필요하며, 이는 SS4.1.3에 소개되어 있다.\n' +
      '\n' +
      '#### 4.1.3 반자동 XoT\n' +
      '\n' +
      '반자동 XoT 방식은 수동 및 자동 시공 방식의 장점을 모두 통합합니다. Shao et al.(2023)은 합성 프롬프팅(Synthetic Prompting)을 제안하는데, 이는 몇 개의 인간 주석이 달린 예들을 활용하여 모델이 교번된 전후진 프로세스를 통해 더 많은 예들을 생성하도록 프롬프트하고 더 나은 추론을 이끌어내기 위해 효과적인 데모를 선택하여 부족을 완화한다.\n' +
      '\n' +
      '그림 1: XoT 방법, 프론티어 적용, 미래 방향 및 벤치마크.\n' +
      '\n' +
      '를 포함하는 것을 특징으로 하는 AutoCoT에서의 인간 정렬 방법. 이전 작업은 수동 주석의 문제를 해결하지만 시연 선택도 성능에 상당한 영향을 미칠 수 있다. Automate-CoT(Shum et al., 2023)는 블랙박스 언어 모델에서 각 예의 유의성을 추정하기 위해 분산-감소된 정책 구배 전략을 갖는 강화 학습을 채용하여, 더 나은 시연 선택을 유도한다. 유사하게, Lu 등(2023)은 표 추론에서 데모를 선택하는 것을 학습하기 위해 정책 그래디언트를 활용하는 PromptPG를 제안한다. Ye와 Durrett(2023)은 처음에 두 개의 프록시 메트릭을 사용하여 각 예를 평가한 다음 예를 검색하여 은 라벨이 붙은 개발 세트에서 최상의 성능을 산출하는 데모를 찾는다. 한편, Pitis 등(2023)은 성능을 향상시키기 위한 신속한 앙상블 방법인 Boosted Promptg를 제안하며, 이는 현재 시연이 다루기 어려운 문제에 직면할 때 예를 반복적으로 확장한다. Zou 등(2023)은 질문 카테고리를 기반으로 데모를 자동으로 선택하는 Meta-CoT를 도입하여 태스크별 프롬프트 설계가 불필요하다.\n' +
      '\n' +
      '반자동 XoT 방법은 추론 능력과 안정성을 높이기 위해 인간 정렬 신호와 시연 선택 전략을 도입하면서 수동 레이블링의 작업량을 줄인다. 또한 비용 효율적인 도메인 일반화를 가능하게 합니다. 그러나 시범 선정 문제는 완전히 해결되지 않았으며 더 많은 노력과 연구가 필요하다.\n' +
      '\n' +
      '### XoT 구조 변형\n' +
      '\n' +
      '가장 원시적인 연쇄 사고는 중간 추론 단계를 자연어로 기술하는 연쇄 구조이다. 본 절에서는 체인 구조 변이체, 트리 구조 변이체, 그래프 구조 변이체를 포함하여 원래의 체인 구조를 수정하는 구조 변이체를 소개한다.\n' +
      '\n' +
      'Chain StructurePAL(Gao et al., 2023) 및 PoT(Chen et al., 2022)는 추론 과정을 설명하기 위해 프로그래밍 언어를 도입함으로써, 추론 문제를 실행 프로그램의 구현으로 변환하여 최종 답변을 얻는다. 프로그램 실행은 결정론적이고 산술 계산을 정확하게 수행하기 때문에 이 접근법은 수학적 추론에서 우수한 성능을 보여준다. 게다가, 기호 시퀀스는 사고 표현의 또 다른 유형이다. Chain-of-Symbol(Hu et al., 2023)은 계획 중에 응축된 심볼 체인 표현으로 복잡한 환경을 나타내며, 이는 시뮬레이션 환경의 복잡성을 감소시킨다. 체인 구조 변형은 그림 2(c,d) Thought의 알고리즘(Sel et al., 2023)에 알고리즘 능력을 모델에 주입하여 알고리즘에 기반한 예제를 추가하여 모델의 추론을 보다 논리적으로 만든다. 트리 탐색이라는 거대한 탐색 공간의 부재(Long, 2023; Yao et al., 2023)는 계산 자원을 절약하고 우수한 성능을 달성한다.\n' +
      '\n' +
      '트리 구조 원래 사슬 구조는 본질적으로 탐색 범위를 제한한다. 트리 구조들 및 트리 탐색 알고리즘들의 통합을 통해, 모델들은 추론 프로세스 동안 효율적으로 탐색하고 역추적하는 능력을 획득한다(Long, 2023; Yao et al., 2023). 중간 사고의 자체 평가와 결합하여 모델은 글로벌 최적 솔루션을 달성할 수 있습니다. ToT의 추론 과정은 불확실성을 포함하고, 이는 잠재적으로 연쇄적인 오류로 이어질 수 있다. TouT(Mo and Xin, 2023)는 불확실성을 고려하여 몬테카를로 드롭아웃을 추론에 도입한다. 유 등(2023)은 LLM의 복잡한 추론 능력을 높이기 위해 그들의 해결책을 활용하여 유사한 문제를 탐구한다. 이러한 유사 문제는 나무와 같은 구조를 나타내어 궁극적으로 주요 문제를 해결하기 위해 수렴한다. 그러나 현재의 트리-오브-사상(tree-of-thought)은 작업 선택에 상당한 한계를 가지고 있으며, 각 작업에 대한 구체적인 신속한 설계가 요구되어 광범위한 적용을 방해하고 있다. SoT(Ning et al., 2023)는 트리 구조의 또 다른 변형으로, 문제를 병렬로 처리하고 동시에 해결하여 추론을 빠르게 할 수 있는 하위 문제로 분해한다. 그러나 그 유용성은 병렬 분해 가능한 문제로 제한되며 복잡한 추론 작업에는 적합하지 않다.\n' +
      '\n' +
      '그래프 구조는 트리에 비해 그래프는 루프와 고리를 도입하여 그림 2(f)와 같이 더 복잡한 위상 관계를 가져오고 더 복잡한 추론을 모델링할 수 있다. GoT(Besta et al., 2023; Lei et al., 2023)는 탐색 및 역추적 연산을 결합하여 중간 사상을 그래프 내의 노드로 간주하고, 추가적으로 트리-오브-사상 대비 집계 및 정제 연산을 도입한다. 추가 연산, 집계 및 개선은 복잡한 작업에서 더 나은 추론을 이끌어낸다. 그럼에도 불구하고, 그것은 생각의 나무와 동일한 딜레마, 즉 과제 제한과 낮은 일반화 가능성에 직면해 있다. 게다가, 그것은 추론 비용을 증가시켰습니다. 생각 그래프를 명시적으로 구성하는 GoT와 달리, ResPrompt Jiang 등(2023)은 프롬프트 텍스트에서 생각들 사이의 잔여 연결들을 도입하여, 상이한 단계들의 추론이 서로 상호작용할 수 있게 한다.\n' +
      '\n' +
      '모델이 선형 사슬에서 계층적 트리 및 복잡한 그래프로 전환함에 따라 사고의 상호 작용이 점진적으로 더 복잡해져 복잡한 문제를 해결할 수 있는 능력이 점차 향상된다. 그러나, 토폴로지의 복잡성이 증가함에 따라, 연관된 방법들은 태스크 선택에 더 많은 제약들을 부과하여, 그들의 일반화 가능성의 현저한 감소를 초래하고 그들의 적용을 어렵게 한다. 복잡한 토폴로지 구조 기반 방법을 일반 도메인으로 확장하는 것은 향후 연구의 주요 과제이다.\n' +
      '\n' +
      '### XoT Enhancement Methods\n' +
      '\n' +
      '이 섹션에서는 XoT 향상 방법을 제시한다. 검증 및 정제 추가(SS4.3.1), 질문 분해(SS4.3.2), 외부 지식 활용(SS4.3.3), 투표 및 순위(SS4.3.4), 효율성 향상(SS4.3.5)의 5가지 범주에 대한 개요를 제공한다.\n' +
      '\n' +
      '#### 4.3.1 Verify and Refine\n' +
      '\n' +
      '생각의 사슬 추론은 종종 환각적인 경향이 있어 잘못된 추론 단계를 생성한다. 중간 추론 단계의 오류는 차례로 일련의 오류를 유발할 수 있다. 피드백을 얻기 위해 검증을 통합하고 이 피드백을 기반으로 추론 과정을 정교화하는 것은 인간의 성찰 과정과 유사한 이 현상을 완화하기 위한 매우 효과적인 전략이 될 수 있다. 그림 3은 검증 및 개선 개요를 보여준다.\n' +
      '\n' +
      'VerifyCoT Ling 등(2023)은 모델들이 정확한 추론 단계들을 생성할 수 있게 하는 연역적 추론 형태인 Natural Program을 고안하고, 각각의 후속 단계들은 이전 단계들을 엄격하게 기반으로 한다. DiVeRSe Li 등(2022)은 오답을 제거하기 위해 투표 메커니즘을 이용하고, 이어서 각 추론 단계의 세밀한 검증을 독립적으로 수행한다. SCREWSShridhar 등(2023)은 수정 후 결과가 반드시 원점보다 우월하지 않을 수 있다고 생각하므로, 원점과 수정 사이에 더 나은 결과를 선택하기 위한 선택 모듈을 도입한다. 지식 집약적 태스크를 용이하게 하기 위해, Verify-and-Edit Zhao 등(2023)은 불확실한 예들을 재 추론하기 위해 외부 지식을 통합하고, 추론의 사실적 실수들을 감소시킨다. 일부 연구 노력은 모델의 내부 지식을 발굴하려고 시도한다. 일부 연구 노력은 모델의 내부 지식을 발굴하려고 시도한다. 사실적 오류를 해결하기 위해 일부\n' +
      '\n' +
      '그림 3: 검증과 정제는 추론에서 계단식 오류를 줄인다.\n' +
      '\n' +
      '그림 2: 직접 I/O에서 체인 구조, 트리 및 그래프 구조로 추론의 진화.\n' +
      '\n' +
      '연구는 LLM의 본질적인 지식을 발굴하려고 시도한다. 그들은 질문에 대답하기 전에 모델로부터 지식을 획득한다(Dhuliawala et al., 2023; Zheng et al., 2023). Ji 등(2023)은 내재된 지식의 정확성을 더 검증하고, Liu 등(2023)은 강화학습을 통해 내재된 지식 획득의 정확도를 높인다.\n' +
      '\n' +
      '비일관성은 추론의 또 다른 주요 과제이며, Dua 등(2022)은 모델이 일관된 답변을 제공할 때까지 이전의 추론 결과를 프롬프트로서 반복적으로 사용한다. Paul 등(2023)은 비평가 모델을 훈련시켜 추론 과정에 대한 구조화된 피드백을 제공한다. Self-Refine(Madaan et al., 2023)은 추론의 오류를 완화하기 위해 반복적 self-feedback과 refinement를 수행한다. Self-Refine과 비교하여 Reflexion(Shinn et al., 2023)은 성찰을 위한 강화학습을 도입하며, 이는 의사결정 능력을 추가적으로 가져온다. 한편, 일부 연구에서는 검증을 위해 백워드 추론(Yu et al., 2023)을 소개하고 있다. RCoT(Xue et al., 2023)는 추론 사슬에 따라 질문을 재구성하고, 원래의 질문과의 불일치는 추론 과정의 오류를 노출한다. FOBAR(Jiang et al., 2023) 및 Self Verification(Weng et al., 2022)는 답변으로부터 질문 내의 조건을 도출하여 검증을 수행한다. FOBAR은 질문의 변수를 추론하고, Self Verification은 질문의 조건을 추론한다. 그러나, Huang 등(2023)은 LLM들이 외부 피드백 없이 자기 수정을 위해 고군분투하고, 심지어 성능 저하로 이어질 수 있다는 것을 발견한다.\n' +
      '\n' +
      'LLM 추론은 중간 추론 단계의 피드백 신호가 추론을 개선하는 데 중요한 역할을 하는 감독되지 않은 과정이다. 피드백 신호로부터의 가이던스는 추론에서 환각 현상을 효과적으로 감소시킬 수 있다. 적절한 피드백을 얻고 그 피드백을 바탕으로 정확한 수정을 할 수 있는 중요한 연구 공간이 여전히 존재한다.\n' +
      '\n' +
      '#### 4.3.2 질문 분해\n' +
      '\n' +
      'X-of-thought 추론의 본질은 단계별 문제 해결에 있다. 그러나 기존의 연쇄 추론 방법은 단계별 추론 과정을 명시적으로 제거하지 않고 여전히 1단계 생성을 사용한다. 이 절에서는 명시적으로 질문을 단계별로 해결하는 질문 분해 접근법에 대해 논의한다. 개요는 그림 4에 나와 있다.\n' +
      '\n' +
      'Wang 등(2022)은 반복적으로 모델로부터 지식을 획득하여 멀티홉 QA에서 진전을 이룬다. Zhou 등(2023)은 Least-to-Most Prompting을 제안하는데, 이 Least-to-Most Prompting은 초기에 질문을 하향식 방식으로 하위 질문으로 분해하고, 후속적으로 한 번에 한 번 하위 질문을 해결하고 그들의 솔루션을 활용하여 후속 하위 질문을 용이하게 한다. Successive Prompting(Dua et al., 2022)은 Least-to-Most Prompting과 유사한 접근법을 취하며, 2단계 분해가 아닌 인터리빙된 서브 질문과 답변으로 분해를 취한다는 차이점이 있다. 상기 방법들은 다양한 서브-문제들에 대한 맞춤형 솔루션들을 공식화하지 않는다. 분해된 프롬프팅(Khot 등, 2023)은 모듈식 공유 라이브러리를 설계하는데, 이는 각각 서브 문제들의 클래스에 전용되며, 서브 문제들의 상이한 클래스들에 보다 효과적인 솔루션들을 맞춤화할 수 있다. 일반적인 작업 외에도 일부 작업은 표형 추론에 대한 질문 분해에 중점을 둔다. BINDER(Cheng et al., 2023)은 추론 과정을 신경망 기호 방식으로 프로그램에 매핑하고 파이썬이나 SQL과 같은 프로그램 실행기를 통해 최종 답변을 얻는다. Ye 등(2023)은 DATER를 소개하는데, DATER는 큰 테이블을 작은 테이블로, 복잡한 질문을 간단한 테이블로 분해한다. 전자는 관련 없는 정보를 줄이는 반면 후자는 추론의 복잡성을 줄인다.\n' +
      '\n' +
      '복잡한 질문에 대한 직접적인 답을 제공하는 것은 어려울 수 있다. 질문을 간단한 하위 문항으로 분해하여 단계별로 해결함으로써 난이도가 줄어든다. 또한 각 하위 질문은 특정 추론 단계로 거슬러 올라갈 수 있어 추론 과정을 보다 투명하고 설명할 수 있다. 현재 작업은 대부분 하향식 분해 전략을 사용하는 반면, 역방향 추론에 기반한 상향식 분해 전략은 향후 작업에서 탐구해야 한다.\n' +
      '\n' +
      '그림 4: 질문 분해는 단순한 하위 질문을 해결함으로써 복잡한 질문을 점진적으로 해결한다.\n' +
      '\n' +
      '#### 4.3.3 외부 지식\n' +
      '\n' +
      '모델 내에서 매개변수화된 지식은 제한적이고 구식이다. 따라서 지식 집약적 과제에 직면할 때 사실적 실수가 종종 발생한다. 외부 지식을 도입하는 것은 그림 5와 같이 이러한 현상을 완화할 수 있다.\n' +
      '\n' +
      'Lu 등(2023)은 기계 번역을 향상시키기 위해 프롬프트에서 다국어 사전을 소개한다. Li 등(2023)은 지식-유도 추론을 수행하기 위해 질의 생성기를 통해 지식 베이스로부터 구조화된 지식을 획득하는 CoK-Li(chain-of-knowledge)를 제안한다. Wang 등(2023)(CoK-Wang)은 또한 KB로부터 구조화된 지식을 검색한다. 또한, 추론 사슬을 사실성과 충실성 측면에서 추정하고 신뢰할 수 없는 추론에 대해 재고하도록 유도하여 CoK-Li의 지식 검색 오류를 완화한다. KD-CoT Wang 등(2023)은 다중 턴 QA 접근법을 통해 사실 추론 문제를 다룬다. 그들은 추론 프로세스를 보정하기 위해 QA의 각 라운드에서 관련 외부 지식을 검색하기 위한 피드백 증강 검색기를 설계한다. 다른 연구들은 모델 자신의 기억을 외부 지식으로 활용한다. 예를 들어, Memory-of-Thinking Li and Qiu(2023)는 먼저, 높은 신뢰도의 생각들을 외부 메모리에 저장하기 위해 사전 사고를 수행하고, 추론 동안, LLM이 추론에 도움을 주기 위해 관련 기억을 회상하도록 한다.\n' +
      '\n' +
      '모델에서 매개변수화된 지식은 사전 훈련이 끝날 때 고정되며, 이는 지식 용량 및 지식 업데이트 측면에서 단점으로 이어진다. 외부 지식을 도입하면 이를 어느 정도 완화할 수 있지만 불완전한 해결책으로 남아 있다. 이 문제를 근본적으로 해결하기 위해 지속적인 학습 Lange et al.(2022); Wang et al.(2023)은 미래의 연구 노력을 위한 유망한 길이다.\n' +
      '\n' +
      '#### 4.3.4 Vote and Rank\n' +
      '\n' +
      '생성 과정에서 내재된 확률성으로 인해 LLM 추론은 무작위성과 불확실성의 요소를 나타낸다. 이 문제는 그림 6과 같이 다중 샘플링 전략을 통해 효과적으로 완화될 수 있다.\n' +
      '\n' +
      '일부 방법은 랭킹을 채택하는데, 예를 들어 Cobbe 등(2021)은 랭킹을 통해 높은 신뢰도의 추론 체인을 선택하기 위해 검증자를 훈련시킨다. 한편, 다른 방법은 투표 메커니즘을 통해 추론 체인을 선택한다. Self-consistency Wang 등(2023)은 최종 답변에 기초하여 샘플링된 추론 체인 중에서 다수 투표에 의해 가장 일관된 답변을 선택한다. 나아가 Fu 등(2023)은 보다 복잡한 추론 체인에 의해 생성된 답변을 선택하는 쪽으로 기울어지는 복잡도 기반 투표 전략을 활용하는 Complex CoT를 제안한다. 그러나 답변 기반 투표 메커니즘은 추론 사슬의 정확성을 고려하지 않는다. Miao 등(2023)은 투표할 때 추론 단계를 고려하며, 이는 일관된 답변과 신뢰할 수 있는 추론 프로세스를 동시에 얻을 수 있다. 더욱이, 체인들에 걸친 중간 단계들 사이의 관계들을 고려하기 위해, Yoran 등(2023)은 추론 체인들 사이에 정보를 혼합하고, 다중 추론 체인들에 걸쳐 메타-추론을 수행하기 위해 가장 관련된 사실들을 선택한다. GRACE Khalifa 등(2023)은 대조적 학습을 통해 판별기를 훈련시키고, 이 판별기를 사용하여 각각의 중간 추론 단계의 순위를 매긴다. 기존의 방법들은 확률 분포를 기반으로 표본을 추출하지만, Diversity-of-Thought Naik et al.(2023)은 서로 다른 명령어로 프롬프트하여 여러 추론 경로를 얻는다.\n' +
      '\n' +
      '앙상블 학습에서 영감을 끌어내고, 다중 샘플링으로 투표하고 순위를 매기는 연습은 불확실성을 줄이는 역할을 한다. 게다가, 그것은 실질적인 성능을 보여주었다.\n' +
      '\n' +
      '그림 5: 외부 지식을 도입하면 추론의 사실적 오류가 줄어든다.\n' +
      '\n' +
      '도 6: 투표 및 랭킹은 다수의 샘플링으로부터 최종 답변을 선택함으로써 불일치를 감소시킨다.\n' +
      '\n' +
      '단일 표본 접근법에 비해 개선됩니다. 투표를 통한 다중 샘플링은 현재 X-of-thought 연구에서 일반적인 기술이 되었다. 추론 사슬을 투표에 통합하는 것은 미래를 위한 중요한 연구 영역으로 남아 있다.\n' +
      '\n' +
      '#### 4.3.5 Efficiency\n' +
      '\n' +
      'LLM 추론과 수동으로 주석이 달린 추론 체인은 값비싼 오버헤드를 부과한다. Aggarwal et al.(2023)은 샘플 수를 동적으로 조정함으로써 자기 일관성을 향상시켜 한계 성능 저하로 추론 비용을 크게 줄일 수 있다. Ning et al.(2023)은 문제를 병렬적으로 분해하여 동시에 처리함으로써 추론 시간 오버헤드를 줄였다. 하지만 그것은 복잡한 질문들을 처리할 수 없다. Zhang 등(2023)은 일부 중간 계층을 선택적으로 건너뛰어 추론을 가속화한 다음 다른 전진 패스에서 드래프트를 검증한다. Diao et al.(2023)은 능동적 학습으로부터 아이디어를 차용하여 불확실성이 높은 예제에 주석을 달기 때문에 인간의 주석 비용을 줄일 수 있다.\n' +
      '\n' +
      '대규모 언어 모델은 엄청난 능력을 보여주었지만 상당한 오버헤드를 수반한다. 성능과 오버헤드 간의 균형을 맞추는 것은 향후 연구 노력에서 상당한 주의를 필요로 할 수 있다.\n' +
      '\n' +
      '## 5 Frontier 애플리케이션\n' +
      '\n' +
      '### Tool Use\n' +
      '\n' +
      'LLM이 보여주는 광범위한 지식에도 불구하고 몇 가지 문제가 수반된다. 여기에는 최신 뉴스에 접근할 수 없는 능력, 영역 밖의 지식과 관련된 질문에 응답할 때 환각에 대한 성향, 수학적 계산이나 상징 추론과 같은 정교한 추론 능력의 부재가 포함된다. LLM에 외부 도구를 사용할 수 있는 능력을 부여함으로써 모델의 추론 능력을 증강하고 외부 지식을 동화시켜 정보 검색 및 환경 상호 작용에 참여할 수 있게 된다.\n' +
      '\n' +
      'MRKL Karpas 등(2022)은 확장 가능한 모듈(전문가라고 함) 및 라우터를 포함하는 새로운 프레임워크를 소개한다. 이러한 전문가들은 신경망이나 기호의 형태를 취할 수 있다. 그러나 본 연구는 수학적 계산을 위해 LLM을 개념화하고 훈련하는 데 중점을 두고 다른 모듈 콘텐츠를 구현하는 데 중점을 두지 않는다. TALM Parisi 등(2022) 및 Toolformer Schick 등(2023)은 언어 모델의 능력을 향상시키기 위해 보충 도구와 텍스트 중심 방법론을 통합한다. 그들은 제한된 툴팁 세트로 시작하여 성능 향상을 시작하기 위해 자체 감독 메커니즘을 사용한다. 유사한 맥락에서, HuggingGPT Shen 등(2023)은 시각적 및 음성 모델을 활용하여 다양한 모달리티로부터의 정보를 처리함으로써, LLM들에게 멀티모달 이해 및 생성을 위한 능력을 부여한다. 또 다른 질문은 적절한 도구를 선택하는 방법이다. LATM Cai et al. (2023)은 LLM의 도구 생성 능력이 다양한 작업에 걸쳐 일반화된 API를 만들 수 있도록 하고 GEAR Lu et al. (2023)은 더 작은 모델을 사용하여 도구 접지와 실행을 위임함으로써 도구 사용의 효율성을 고려한다.\n' +
      '\n' +
      '그러나, 사용자 요청을 API 포맷으로 변환하는 것은 종종 간단하지 않다. 위에서 언급된 기존의 접근법들은 툴의 다수의 호출들을 용이하게 하고 질의 에러들을 정정하는 데 한계가 있다. 이 문제를 해결하기 위해 ReAct Yao et al.(2023)은 추론과 행동의 장점을 통합하여 서로를 강화하고 보완하여 문제 해결 능력을 상호 보완한다. ART Paranjape 등(2023)은 태스크 라이브러리를 사용하여 관련 툴 사용 및 추론 체인을 선택한다. MM-REACT Yang 등(2023)은 멀티모달 추론 및 액션을 가능하게 하기 위해 비전 전문가를 추가로 활용한다.\n' +
      '\n' +
      '앞서 언급한 연구는 다양한 도메인에서 LLM의 기능을 향상시키기 위한 도구(또는 API)를 설계하는 데 중점을 둔다. XoT와 도구를 결합하면 LLM이 직면한 문제를 효과적으로 해결할 수 있다. X-of-thought 추론은 모델이 예외를 관리하면서 액션 계획을 효과적으로 도출, 추적 및 업데이트할 수 있게 한다. 동시에, 액션 연산은 모델이 지식 베이스 및 환경과 같은 외부 소스와의 상호 작용을 용이하게 하여 추가 정보를 수집할 수 있게 한다. 도구의 숙련도를 평가하기 위해 APIBank Li et al.(2023)과 MetaTool Huang et al.(2023)은 포괄적인 벤치마크를 도입하여 도구 증강 LLM의 성능과 효과를 평가할 수 있는 강력한 기반을 제공한다.\n' +
      '\n' +
      '### Planning\n' +
      '\n' +
      'LLM은 복잡한 문제에 대해 정확한 응답을 직접 제공하는 데 어려움을 겪으며, 이를 순차적 단계와 하위 작업으로 분해해야 한다. CoT는 계획에 대한 간단한 접근법을 제공하지만 매우 복잡한 문제를 해결하는 데 부족하고 역추적을 통해 오류를 평가하고 수정하는 능력이 부족하다.\n' +
      '\n' +
      '수많은 연구는 계획 능력을 더 향상시키기 위해 연쇄 사상의 틀을 다양한 형식으로 확장했다. Tree-of-Thought(Yao et al., 2023)는 LLM들이 트리 내의 다수의 추론 경로들을 고려할 수 있게 하고, 다음 행동 과정을 결정하기 위해 자기-평가할 수 있게 한다. 전역적 결정이 필요한 경우 ToT는 심층 우선 탐색 또는 폭 우선 탐색과 같은 기법을 통해 전진 또는 후진 탐색을 허용한다. RAP(Reasoning via Planning) (Hao et al., 2023) 또한 문제를 트리로 분할하고, LLM을 월드-모델 및 추론 에이전트로 사용하여 몬테 카를로 트리 탐색 알고리즘에 의해 탐색한다. 또 다른 방법인 GoT(Graph of Thought) (Yao et al., 2023)는 그래프 노드를 채용하여 개인의 생각을 표현하고 조직을 위한 외부 그래프 신경망을 사용한다. LLM+P(Liu et al., 2023) 및 LLM+DP(Dagan et al., 2023)는 LLM에 의한 계획 도메인 정의 언어(PDDL)(Gerevini, 2020)의 생성을 용이하게 한다. PDDL은 LLM 처리를 위해 결과를 자연어로 변환하기 전에 복잡한 문제를 분해하고 계획을 위한 특수 모델을 활용하는 데 도움이 된다. 그러나 이러한 방법은 트리/그래프/PDDL 노드를 사용하여 생각을 표현하는데, 이는 표현 형태에 제한이 있고 특정 계획 문제만 처리할 수 있다는 점에 유의해야 한다.\n' +
      '\n' +
      '또 다른 기법은 오류를 수정하고 역사적 경험을 요약하는 모델의 능력을 향상시키는 것이다. Self-Refine(Madaan et al., 2023)은 모델에 의해 생성된 출력이 동일한 모델을 사용하여 평가되고 피드백과 함께 제공되는 독특한 접근법을 채용한다. 반사(Shinn et al., 2023)는 모델이 이전 동작에서 이루어진 오류를 반성하고 수정하는 것을 가능하게 하고, 텍스트 형식의 강화 학습과 유사하며, 메모리를 장단기 컴포넌트로 분할하는 것을 포함한다. 그러나 계획 외 오류가 발생하면 계획을 업데이트할 수 없습니다. AdaPlanner(Sun et al., 2023)는 환경의 피드백을 기반으로 태스크 계획을 반복적으로 정제하는 적응형 폐루프 계획 정제법을 소개한다. ISR-LLM(Zhou et al., 2023)은 Self-Refine과 PDDL을 결합하여 long-horizon 순차 태스크에서 더 나은 성공률을 달성한다. 한편, LATS(Zhou et al., 2023)는 보다 유연한 계획 절차를 위해 LM 기반 몬테 카를로 트리 탐색을 활용한다.\n' +
      '\n' +
      '계획은 추론 능력을 풍부하게 하기 위해 도구(Ruan et al., 2023) 또는 에이전트(Crispino et al., 2023)와 유연하게 결합될 수 있다. ToRA(Gou et al., 2023)는 외부 도구를 사용하여 수학적 특수 에이전트를 설계하고 AutoUI(Zhang and Zhang, 2023)는 시각적 입력을 텍스트로 변환하는 대신 멀티모달 환경과 직접 상호작용하여 추론 효율성을 높이고 오류 전파를 줄인다.\n' +
      '\n' +
      '계획 증강 접근법은 검색 기반, 그래프 기반 및 정의 언어 기반 방법을 도입하여 기존의 순차 계획을 발전시켰다. 반면에, 일부 방법은 LLM의 장기 계획 및 오류 복원 능력을 향상시키는 것을 목표로 하는 행동, 계획, 반영 또는 도구를 통합한다.\n' +
      '\n' +
      '### CoT Distillation\n' +
      '\n' +
      'LLM은 복잡한 문제를 해결하기 위해 추론 단계를 증류함으로써 자체 개선될 수 있다. Huang 등(2022)은 라벨링되지 않은 데이터로부터 추론 체인을 생성하기 위해 자기-일관성을 갖는 LLM을 채용한다. 이러한 사슬은 이후에 모델을 미세 조정하여 일반화된 추론 능력을 향상시키는 데 사용된다. Zelikman 등(2022)은 셀프-루프 부트스트랩 전략을 사용하여 LM 의 추론 능력을 향상시키기 위한 수샷 학습 접근법인 STaR을 제안한다. SECToR(Zhang and Parkes, 2023)은 chain-of-thought를 사용하여 산술적 답변을 얻은 다음, 모델을 미세 조정하여 CoT 없이 직접 답변을 생성한다.\n' +
      '\n' +
      '생각 CoT는 LLM에서 주로 관찰되는 새로운 능력이며 소형 모델의 발전은 제한적이다. 그러나 증류와 같은 기술을 통해 소형 모델의 CoT 능력을 향상시키는 것을 생각할 수 있다. Magister et al.(2023)은 더 큰 교사 모델에 의해 생성된 추론 체인으로 T5를 미세 조정하고 답변 해결을 위해 외부 계산기를 활용하는 것이 다양한 데이터 세트에 걸쳐 태스크 성능을 실질적으로 향상시킬 수 있음을 보여준다. Ho 등(2023)은 다양성을 풍부하게 하기 위해 다수의 추론 경로를 생성하고 필터링한다.\n' +
      '\n' +
      '자기 일관성을 활용하여 주석이 없는(또는 주석이 없는) 데이터를 사용하여 인적 비용을 줄이기 위한 수많은 노력이 수행될 수 있다(Wang et al., 2023). Hsieh 등(2023)은 훨씬 적은 라벨링된/라벨링되지 않은 데이터로부터 답변들을 생성하기 위한 프롬프트를 채용하고, 이어서 주어진 답변에 대한 추론을 제공하기 위해 언어 모델을 프롬프트하는 근거들의 생성을 수행한다. SCoTD(Li et al., 2023)는 교사의 인스턴스당 다수의 추론 체인을 샘플링하는 것이 학생들의 능력을 향상시키는 데 가장 중요하다는 것을 발견한다. SCOTT Wang 등(2023)은 교사 모델들에 대한 근거 생성 동안 대조적 디코딩 Li 등(2022); O\'Brien and Lewis(2023)을 이용한다. 또한, 바로 가기 문제를 해결하기 위해 학생 모델을 훈련하는 동안 반사실적 추론 목표를 사용한다. DialCoT Han 등(2023)은 추론 단계들을 다라운드 대화로 분해하고 PPO 알고리즘을 사용하여 올바른 경로를 선택한다. Jie 등(2023); Wang 등(2023)은 수학 문제에 대한 특별한 토큰을 추가한다. 이 높은 수준의 정보는 추론 단계의 일관성을 향상시킨다.\n' +
      '\n' +
      '위의 연구들은 추론 사슬이 우수한 추론 능력을 가진 LLM을 통해 생성되는 공유 패러다임을 채택한다. 그런 다음 이러한 추론 사슬을 더 작은 모델로 증류한다. 증류 공정의 효과는 예를 들어 다중 샘플링 경로, 일관성 또는 대조적 디코딩의 활용을 통해 더 큰 모델에서 샘플링 전략을 강화함으로써 향상되며, 이는 생성된 추론 사슬에서 다양성과 정확도를 향상시켜 궁극적으로 증류 공정을 더 작은 모델로 이롭게 한다. 언어 모델은 다차원 능력과 관련된 복잡한 절충과 복잡한 균형을 가지고 있다는 점은 주목할 만하다. Fu et al.(2023)은 증류를 통한 과제별 연쇄 사고 능력의 증가는 일반화된 문제를 해결하는 데 있어서도 모델의 성능에 부정적인 영향을 미칠 수 있음을 강조한다.\n' +
      '\n' +
      '## 6 Future Direction\n' +
      '\n' +
      '사슬 사고 추론은 수많은 작업에서 놀라운 성능을 보여주었지만 일부 과제는 여전히 추가 탐색을 필요로 한다. 이 섹션에서는 향후 연구를 위한 세 가지 유망한 방법, 즉 다중 모드 사고 추론(SS6.1), 충실한 사고 추론(SS6.2) 및 사고 추론 이론(SS6.3)에 대한 간략한 개요를 제공한다.\n' +
      '\n' +
      '### Multi-modal CoT\n' +
      '\n' +
      '텍스트 유니모달에서 비전-텍스트 멀티모달로의 전환은 더 풍부한 정보를 도입하는 동시에 더 많은 도전을 가져온다. 일부 연구는 고품질의 사고 사슬을 생성하기 위해 멀티 모달 모델을 미세 조정하여 멀티 모달 시나리오에서 사고 X-추론을 탐구하려고 시도했다.\n' +
      '\n' +
      '멀티모달-CoT Zhang et al.(2023)은 먼저 멀티모달 모델을 미세 조정하여 체인-오브-사유(chain-of-thoughts)를 생성한 후 최종 답변을 얻기 위한 근거에 대한 이유를 도출한다. 그러나 이는 추론 과정의 선형성의 한계를 가지며 서로 다른 양식의 상호 작용에 어려움을 겪는다. Multimodal-CoT가 직면하는 도전들을 완화하기 위해, Yao 등(2023)은 사고 프로세스들을 그래프로 모델링하는 GoT(Graph-of-Thought)를 제안한다. 추론 사슬을 사고 그래프로 파싱하여 비순차적인 정보 상호 작용을 포착하여 사고 과정을 보다 사실적으로 표현할 수 있게 한다. 이 측정은 그래픽 구조를 통해 선형 구조의 한계를 깨고 성능을 더욱 향상시킨다. 또한 Yao et al.(2023)은 하이퍼그래프(Hypergraph-of-Thought, HoT)를 제안하여 사고 그래프를 하이퍼그래프로 대체하여 고차 멀티홉 추론 및 멀티모달 비교 판단 능력이 향상된 모델을 가능하게 한다. 한편, 일부 작업은 지식 증류를 기반으로 한 접근법을 취한다. T-SciQ Wang 등(2023)은 미세 조정 신호로서 LLM으로부터 고품질 CoT 근거를 생성하고 다양한 질문에 대한 효과적인 샘플을 생성하기 위해 새로운 데이터 혼합 전략을 소개한다.\n' +
      '\n' +
      '앞서 언급한 연구는 소형 모델과 미세 조정 시나리오에서 다중 모달 추론을 탐구하며, 이는 다중 모달 연쇄 사고 추론의 영역에서 초기 노력으로 간주한다. 우리는 비디오 멀티모달 추론과 맥락 내 학습을 결합한 연구가 향후 연구의 초점이 되어야 한다고 믿는다. 한편, 비디오는 이미지와 비교하여 선천적인 연쇄 관계를 갖는 추가적인 시간적 정보를 도입한다. 체인-사상 추론을 통해 서로 다른 프레임의 정보를 자연스럽게 연결하여 시간적 관계를 명시적으로 모델링할 수 있으며, 이는 비디오 멀티모달 추론에 적합하다. 반면에, 소형 모델은 용량이 제한적이며, 연쇄 사고 능력을 얻기 위해 미세 조정이 필요하다. 더 나쁜 것은, 멀티모달 추론 사슬을 얻기 어렵고, 이는 도전을 더욱 악화시킨다. 이에 비해, 컨템포러리 비전-언어 기초 모델들(VLMs) Alayrac et al.(2022); Li et al.(2023); Wang et al.(2022); Huang et al.(2023); Peng et al.(2023); Yu et al.(2021)은 강한 비전-언어 이해를 가지며, 인터리빙된 텍스트 및 이미지를 갖는 인-컨텍스트 학습이 이미 가능하다. 그들은 맥락 내 학습과 함께 연쇄 사고 추론을 위한 견고한 기초를 제공한다. 비디오 추론을 위해 사상 사슬을 활용하는 것은 소수의 연구만으로 미개척 영역으로 남아 있다. CoMT(Hu et al., 2023)는 비디오 추론에서 빠른 사고와 느린 사고를 결합하고 계획을 위한 트리 탐색 전략을 도입하는데, 이 전략은 먼저 비디오 멀티모달 추론에서 CoT를 적용한다.\n' +
      '\n' +
      '사슬 추론(chain-of-thought reasoning)을 활용하여 멀티모달 추론(multi-modal reasoning) 과제를 해결하기 시작한 연구들이 있지만, 이전 연구들은 고품질의 미세 조정 데이터(fine-tuned data)를 구축하는 방법에만 초점을 맞추고 있으며, 여전히 몇 가지 과제가 남아 있다.\n' +
      '\n' +
      '* 더 나은 멀티 모달 이해를 이끌어내기 위해 시각적 및 언어 기능을 통합하는 방법입니다.\n' +
      '* 미세 조정 없이 VLM을 사용 하 여 생각 체인 추론을 수행 하는 방법입니다.\n' +
      '* 이미지 멀티모달 추론을 비디오 멀티모달 추론에 적응시키는 방법.\n' +
      '\n' +
      '### Faithfulness\n' +
      '\n' +
      '광범위한 연구에 따르면 연쇄 사고 추론은 사실적 실수 및 맥락적 불일치와 같은 환각 현상으로 이어질 수 있다. 언어 모델은 근본적으로 통계 모델에 속하고, 데이터 잡음, 지식 망각 등의 요인으로 인해 환각 현상이 불가피하다는 점을 고려하면 말이다.\n' +
      '\n' +
      '일부 작품들은 사실상의 실수를 완화하는 데 초점을 맞춘다. 그 외(2023)는 추론 체인을 평가하기 위해 외부 지식을 도입하고, 사실적 오류가 포함된 체인을 걸러내기 위해 투표를 도입하지만 수정하지 않고 Wang 외(2023)는 유사한 방식을 채택하며, 저득점 추론을 수정하기 위해 반영 메커니즘을 추가로 도입한다는 차이점이 있다. Zhao et al.(2023)은 일관성에 의한 저신뢰 추론을 필터링하고 관련 외부 지식을 기반으로 모델을 재추론하도록 안내한다. 앞서 언급한 방법은 지식 집약적 작업에서 잘 작동하지만 맥락적 불일치의 문제를 해결하는 데 부족하다. Zhang 등(2023)은 추론 과정에서 환각 눈덩이 현상을 탐구한다. 다른 사람들은 불일치 문제를 해결하는 것을 목표로 합니다. Radhakrishnan 등(2023)은 단순한 질문을 다룰 때 모델이 더 충실하다는 것을 관찰한다. 따라서 질문 분해를 통해 충실성을 향상시킵니다. Fithful CoT(Lyu et al., 2023)는 처음에 심볼 추론 체인을 생성하고 나중에 결정론적으로 심볼 함수를 실행하여 추론 불일치를 완화한다. Lanham et al.(2023)은 경험적 관점을 제공하는 충실성에 영향을 미치는 요인을 탐구한다. 충실성은 다른 작업에 따라 다르며 모델 크기가 증가함에 따라 감소한다는 것을 발견한다. CoNLI(Lei et al., 2023)는 환각을 줄이기 위한 사후 편집 전략을 제안한다. SynTra(Jones et al., 2023)는 쉽게 환각을 유발하도록 설계된 합성 데이터세트에 대해 프리픽스-튜닝을 수행한 후, 이 능력을 실제 작업에 전달한다.\n' +
      '\n' +
      '대형 언어 모델에서 환각 문제를 해결하기 위한 수많은 노력에도 불구하고 이러한 작업은 문제를 어느 정도 완화했을 뿐이다. 대형 언어 모델의 충실성을 완전히 제고하기 위해서는 아직 갈 길이 멀다. 향후 방향을 정리하면 다음과 같습니다.\n' +
      '\n' +
      '* 추론 과정에서 환각 현상을 인식하는 능력 향상.\n' +
      '* 외부 지식 검색 및 활용의 정확도를 향상시켜 사실적 오류를 줄입니다.\n' +
      '* 컨텍스트 불일치 및 논리적 오류를 인식하고 수정하는 기능을 향상시키므로 더 어렵습니다.\n' +
      '* 특정 사전 훈련과 같은 대체 접근 방식에서 환각 현상을 근본적으로 제거하는 방법입니다.\n' +
      '\n' +
      '### CoT Theory\n' +
      '\n' +
      '사슬 사고 추론의 인상적인 능력에도 불구하고 지시를 따르는 사슬 사고 생성 능력은 아직 포괄적인 설명이 부족하다.\n' +
      '\n' +
      '일부 작업은 경험적 관점에서 다루며 실용적인 가이드 역할을 할 수 있다. Madaan과 Yazdanbakhsh(2022)는 프롬프트를 기호, 패턴, 텍스트의 세 가지 구성 요소로 분해하여 반사실적 프롬프팅을 통해 CoT의 영향을 탐구한다. Wang et al.(2023)은 시연 선택의 영향을 분석한다. 그들은 추론 사슬의 정확성이 무시할 수 있는 영향을 미치는 반면 질문과 올바른 추론 순서와의 관련성이 중요하다는 것을 발견했다. Tang 등(2023)은 의미론의 역할을 탐구한다. 그들은 연쇄 사고 추론이 사전 훈련 중에 도입된 의미적 지식에 크게 의존하고 상징 추론에서 제대로 작동하지 않는다는 것을 발견했다.\n' +
      '\n' +
      '다른 사람들은 근본적인 원리와 내부 메커니즘을 탐구하면서 이론적으로 분석한다. Li 등(2023)은 연쇄-사상 추론을 다단계 조합 함수로서 재구성한다. 그들은 연쇄 사상이 복잡한 문제를 해결하기 위해 맥락 내 학습의 복잡성을 감소시킨다는 것을 입증한다. Feng et al.(2023)은 고정된 크기의 Transformer가 chain-of-thought를 이용한 동적계획과 계산작업에 충분하다는 것을 이론적으로 증명한다. 메릴과 사바왈(2023)은 중간 추론 단계의 수가 증가함에 따라 향상 정도가 증가하는 연쇄 사상이 추론 능력을 향상시킬 수 있음을 관찰한다. Wu et al.(2023)은 기울기 기반 특징 속성 방법을 활용하여 연쇄 사상이 출력에 미치는 영향을 탐구한다. 결과는 연쇄 사상이 문제의 섭동과 변동에 대한 견고성을 나타냄을 나타낸다. 또한, 훈련 전 단계(Madaan et al., 2022; Zhang et al., 2023c) 동안 연쇄적 사고 능력이 코드 데이터에서 비롯되었다는 주장도 있지만, 현재 이러한 의견을 입증하기 위한 체계적인 작업은 없다.\n' +
      '\n' +
      '사슬사상 이론에 대한 현재 연구는 아직 초기 탐색 단계에 있다. 향후 연구방향을 요약하면 다음과 같다.\n' +
      '\n' +
      '* CoT 추론에서 목표 된 개선을 달성 하는 체인 사고 능력의 출처를 탐색 합니다.\n' +
      '* 맥락 내 학습에 대 한 연쇄 사상의 이점을 이론적으로 분석 하 고 기능의 경계를 탐색 합니다.\n' +
      '\n' +
      '## 7 Discussion\n' +
      '\n' +
      '### XoT 구성 비교\n' +
      '\n' +
      '기존 방법에 대 한 생각 X를 구성 하는 방법에는 세 가지 주요 방법이 있습니다. (1) **수동** 레이블링 추론 체인입니다. (2) 모델에 의해 추론 체인을 **자동** 생성합니다. (3) 소수의 수동으로 레이블이 지정된 추론 체인에서 자동 확장을 사용하는 **반자동** 생성입니다.\n' +
      '\n' +
      '수작업 구축 방법(Wei et al., 2022b; Gao et al., 2023)은 인-컨텍스트 학습, 즉 시연 선택, 명령어 포맷팅 등과 유사한 문제에 직면해 있음을 관찰한다(Dong et al., 2023). 이는 적용에 많은 어려움을 초래하고 다양한 업무 전반에 걸친 전이 능력을 저해한다. 자동 구축 방법들(Zhang et al., 2023f; Chen et al., 2022a; Xu et al., 2023)은 고품질의 주석들의 안내가 부족하여, 성능 결함들을 초래한다. 수동 주석에 의해 가져온 신호로부터 이익을 얻는, 반자동 방법(Shum et al., 2023; Shao et al., 2023)은 셀프 부트스트래핑 및 유사한 기술을 통해 고품질 추론 체인을 생성할 수 있어, 이전 접근법이 직면한 과제를 효과적으로 해결할 수 있다. 뛰어난 성능을 달성하면서도 다양한 작업에 걸쳐 쉽게 이동할 수 있습니다.\n' +
      '\n' +
      '### 인증/정제 및 계획 비교\n' +
      '\n' +
      '계획 방법과 검증/정제 기반 방법 사이에는 수많은 병렬이 존재하는데, 둘 다 행동을 조정하고 정제하기 위해 중간 프로세스의 피드백에 의존하기 때문이다. 차이점은 계획 방법이 의사 결정을 포괄하는 반면 검증/정제 기반 방법은 더 높은 수준의 인지 과정을 조사하지 않고 중간 오류만 해결한다는 사실에 있다.\n' +
      '\n' +
      'LLM 추론 과정은 종종 환각적이어서 사실적이고 논리적인 실수를 일으킨다. 검증 및 편집 기반 방법들(Ling et al., 2023; Zhao et al., 2023a; Madaan et al., 2023; Shinn et al., 2023)은 환각을 유발할 수 있는 추론 프로세스 및 정제 추론 단계의 정확성을 검증한다. 검증 및 정제를 통해 추론 과정에서의 계단식 오류와 환각 현상을 현저히 감소시킨다.\n' +
      '\n' +
      '계획 방법들(Long, 2023; Yao et al., 2023b,c; Liu et al., 2023a; Shinn et al., 2023)은 추론에서 의사결정 프로세스를 도입한다. 그들은 피드백을 얻기 위해 중간 추론 단계를 평가하고 피드백을 기반으로 글로벌 수준에서 우수한 솔루션을 달성하기 위해 탐색 및 역추적에 참여한다. 그들의 전문화는 복잡한 문제를 처리하는 데 있어 특히 복잡한 멀티홉 추론 및 계획 작업에 직면할 때 놀라운 성능을 달성할 수 있도록 한다.\n' +
      '\n' +
      '### Innate Weakness 보상\n' +
      '\n' +
      'LLM은 추론에 있어서 외부 정보에 접근할 수 없는 한계, 산술 오류, 일관성 없는 추론 등 많은 내재적 한계를 가지고 있다. 이러한 문제는 특정 책임을 전용 모듈이나 모델에 맡김으로써 교묘하게 우회할 수 있다.\n' +
      '\n' +
      '외부 정보에 액세스하는 모델들의 한계에 응답하여, (Li et al., 2023d; Wang et al., 2023b; Lu et al., 2023a; Schick et al., 2023; Karpas et al., 2022; Yoran et al., 2023)는 지식 베이스, 검색 엔진, 및 개방형 질문-응답 시스템과 같은 외부 지식 자원을 활용한다. 일부 작업은 산술 오류를 해결하기 위해 계산기를 도입한다(Schick et al.,2023; Karpas et al., 2022; Parisi et al., 2022). 코드 실행은 결정론적이며, 특정 작업은 코드 실행기 Gao 등(2023); Chen 등(2022); Bi 등(2023); Imani 등(2023)을 도입함으로써 추론 프로세스의 일관성을 향상시킨다. 본 논문에서는 중앙계획 및 추론을 위한 에이전트로 LLMs를 사용하여 특정 서브 태스크를 전용 서브 모델에 위임하는 것이 향후 Wang 등(2023)과 Xi 등(2023)의 복잡한 시나리오에서 대형 모델을 적용할 수 있는 잠재적인 방법이라고 믿는다.\n' +
      '\n' +
      '### Other Work\n' +
      '\n' +
      '이 장에서는 연쇄 사고 추론의 초기 시도를 나타내거나 특정 영역을 위해 설계된 다른 작품을 나열할 것이다.\n' +
      '\n' +
      'Katz 등(2022); Zhang 등(2022)은 벤치마크 및 리소스를 제공한다. Lampinen et al. (2022); Ye and Durrett et al. (2022); Arora et al. (2023) and Shi et al. (2023)은 다국어 CoT 추론을 탐구한다. 다른 작업은 기계 번역 He et al.(2023), 감정 분석 Fei et al.(2023), 문장 임베딩 Zhang et al.(2023), 요약 Wang et al.(2023), 산술 Lee and Kim (2023), 표 추론 Chen (2023), Jin and Lu (2023) 등과 같은 특정 도메인에 초점을 맞춘다. 또한, 수학적 추론 Lewkowycz 등(2022); Zhao 등(2022)과 같은 특정 능력을 향상시키기 위해 특정 사전 훈련을 활용하는 연구도 있다.\n' +
      '\n' +
      '## 8 Conclusion\n' +
      '\n' +
      '본 논문에서는 X-of-thought 추론에 대한 기존 연구에 대한 광범위한 조사를 수행하여 해당 분야에 대한 포괄적인 검토를 제공한다. 일반화된 연쇄사상(X-of-thought, X-of-thought)의 개념을 소개하고 다양한 각도에서 X-of-thought 추론의 발전을 살펴본다. 또한, 최첨단의 도메인에서 X-of-thought의 적용을 조사한다. 나아가 본 연구가 당면한 당면 과제를 조명하고 향후 전망을 제시하고자 한다. 우리가 아는 한, 이 조사는 연쇄 사고 추론의 첫 번째 체계적인 탐구를 나타낸다. 우리의 목표는 이 조사가 이 분야의 추가 연구를 촉진할 것이라는 희망과 함께 철저한 개요를 통해 연쇄 사고 추론에 관심이 있는 연구자에게 제공하는 것이다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* A. A. Aggarwal, A. Madaan, Y. 양민 (2023) step by sample: adaptive-consistency for efficient reasoning with lms. CoRRabs/2305.11860. 인용: SS1.\n' +
      '* J. A. Alayrac, J. Donahue, P. Luc, A. M. Miesch, I. Barr, Y. 하슨 아멘쉬 렌치 밀리칸 레이놀즈 링러더포드 카비티 한진 공성훈 사망구에이 원테이로 J. L. 메닉 보르헤오, A. 브록, A. 네마차데, S. 샤리프자데 빈코스키 오바레이라 Vinyals, A. Zisserman, K. Simonyan(2022)Flamingo: few-shot learning을 위한 시각 언어 모델. NeurIPS에서, 인용: SS1.\n' +
      '* A. Amini, S. 가브리엘 린래 곤셀케지레스키 Choi, and H. Hajishirzi (2019)MathQA: towards interpretedable math word problem solving with operation-based formalisms. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1(Long and Short Papers), pp. 2357-2367. External Links: Link, Document Cited by: SS1.\n' +
      '*S. Arora, A. Narayan, M. F. Chen, L. J. Orr, N. 구하경 Bhatia, I. Chami, 그리고 C. Re (2023)는 저에게 무엇이든 물어보세요: 언어 모델을 프롬프트하기 위한 간단한 전략입니다. The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023, pp. 외부 링크: 링크, 문서 인용: SS1입니다.\n' +
      '*M. 베스타 블래치 거스텐버거 지아나찌 J. 가즈다 리만 Podstawski, H. Niewiadomski, P. Nyczyk, T. Hoefler(2023)Graph of thoughts: The elaborate problems with large language models. CoRRabs/2308.09687. External Links: Link, 2308.09687 Cited by: SS1.\n' +
      '*S. 박타바살람 핫, B 달비 미슈라, K Richardson, A. Sabharwal, C. Schoenick, O. Tafjord, 그리고 P. Clark (2021) 직접 답변 질문을 해결했다고 생각하십니까? 직접 답변 AI2 추론 도전인 arc-da를 시도하십시오. CoRRabs/2102.03315. External Links: Link, 2102.03315 Cited by: SS1.\n' +
      '*Z. 비남 장영 장성훈 Deng, G. Zheng, H. Chen (2023)은 언제 추론에 대한 생각을 하는가? External Links: Link, 2308.09687 Cited by: SS1.\n' +
      '*Y. 비스크 Zellers, R. L. Bras, J. Gao, and Y. 최(2020)PIQA: 자연어에서의 물리적 상식에 대한 추론. The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020_, pages 7432-7439. AAAI Press.\n' +
      '* Brown 등(2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. 지글러, 제프리 우, 클레멘스 윈터, 크리스토퍼 헤세, 마크 첸, 에릭 시글러, 마테우스 리트윈, 스콧 그레이, 벤자민 체스, 잭 클라크, 크리스토퍼 베르너, 샘 맥캔들리시, 알렉 래드포드, 일야 서츠케버, 다리오 아모데이. 2020. 언어 모델은 적은 수의 학습자입니다. _Neural Information Processing Systems의 발전 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_.\n' +
      '* Cai 등(2023) Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. 2023. 툴 메이커로서의 대형 언어 모델.\n' +
      '* Chen(2023) Wenhu Chen. 2023. 대용량 언어 모델은 (1)-shot table 추론기가 적다. _Findings of the Association for Computational Linguistics: EACL 2023, Dubrovnik, Croatia, May 2-6, 2023_ 페이지 1090-1100. Association for Computational Linguistics.\n' +
      '* Chen 등(2022a) Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. 세스 2022a. 생각 프롬프트 프로그램: 숫자 추론 작업에 대 한 추론에서 계산을 분리 합니다. _ CoRR_, abs/2211.12588.\n' +
      '* Chen 등(2023) Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and Tony Xia. 2023. Theoremqa: A theorem-driven question answer dataset. _ CoRR_, abs/2305.12524.\n' +
      '* Chen 등(2021) Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan R. 루틀리지, 윌리엄 양 왕 2021. Finqa: 재무 데이터에 대한 수치 추론의 데이터세트. _Proceedings of 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event/ Punta Cana, Dominican Republic, 7-11 November, 2021_, pages 3697-3711. Association for Computational Linguistics.\n' +
      '* Chen 등(2022) Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and William Yang. 2022b. Convfnqa: 대화형 금융 질의 응답에서 수치적 추론의 연쇄를 탐구한다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 6279-6292. Association for Computational Linguistics.\n' +
      '* Cheng 등(2023) Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2023. Binding language models in symbol languages. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Cobbe et al.(2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve mathematics word problems. _ CoRR_, abs/2110.14168.\n' +
      '* Crispino 등(2023a) Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023a. 에이전트는 대규모 언어 모델에 일반 제로 샷 추론기가 되도록 지시합니다. _ arXiv preprint arXiv:2310.03710_.\n' +
      '* Crispino 등(2023b) Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023b. 에이전트는 대규모 언어 모델에 일반 제로 샷 추론기가 되도록 지시합니다. _ arXiv preprint arXiv:2310.03710_.\n' +
      '* Crispino 등(2023b) Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023b. 에이전트는 대형 언어 모델에 일반 제로 샷 추론기가 되도록 지시합니다.\n' +
      '* Dagan 등(2023) Gautier Dagan, Frank Keller, Alex Lascarides. 2023. Dynamic planning with a llm. _ ArXiv_, abs/2308.06391.\n' +
      '* Devlin 등(2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: 언어 이해를 위한 심층 양방향 변압기 사전 훈련. _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1(Long and Short Papers)_, pages 4171-4186. Association for Computational Linguistics.\n' +
      '* Dhuliawala 등(2023) Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023. 체인 오브 검증은 대형 언어 모델에서의 환각을 감소시킨다. _ arXiv preprint arXiv:2309.11495_.\n' +
      '* Diao et al.(2023) Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. 2023. Active prompting with chain-of-thought for large language models. _ CoRR_, abs/2302.12246.\n' +
      '* Dong et al.(2023) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023. a survey for in-context learning. _ CoRR_, abs/2301.00234.\n' +
      '* Dong et al.(2022) Qingxiu Dong, Ziwei Qin, Heming Xia, Tian Feng, Shoujie Tong, Haoran Meng, Lin Xu, Zhongyu Wei, Weidong Zhan, Baobao Chang, Sujian Li, Tianyu Liu, and Zhifang Sui. 2022. 전제 기반 멀티모달 추론: 공동 텍스트 및 시각적 단서에 대한 조건부 추론. _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022_, pages 932-946. Association for Computational Linguistics.\n' +
      '\n' +
      '디에루 두아, 시반슈 굽타, 사미어 싱, 맷 가드너 2022. 복잡한 질문들을 분해하기 위한 연속적인 프롬프트. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_ 페이지 1251-1265. Association for Computational Linguistics.\n' +
      '* Dua 등(2019) Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: 단락에 대한 이산 추론이 필요한 읽기 이해 벤치마크. _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long and Short Papers)_, pages 2368-2378, Minneapolis, Minnesota. 계산 언어학을 위한 연관성.\n' +
      '* Fei 등(2023) Hao Fei, Bobo Li, Qian Liu, Lidong Bing, Fei Li, and Tat-Seng Chua. 2023. Reasoning implicit sentiment with chain-of-thought prompting. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 1171-1182. Association for Computational Linguistics.\n' +
      '* Feng 등(2023) Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, and Liwei Wang. 2023. The mystery behind the chain of thoughts: a theoretical perspective. _ CoRR_, abs/2305.15408.\n' +
      '* Fu et al.(2023a) Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2023a. 다단계 추론을 위한 복잡성 기반 프롬프트 _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Fu et al.(2023b) Yao Fu, Hao-Chun Peng, Litu Ou, Ashish Sabharwal, and Tushar Khot. 2023b. 다단계 추론을 위한 더 작은 언어 모델 전문화 _Machine Learning에 대 한 국제 회의_ 에서입니다.\n' +
      '* Gao 등(2023) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023. PAL: 프로그램 지원 언어 모델. 「제40회 기계 학습에 관한 국제 회의 회의」 _Proceedings of the 40th International Conference on Machine Learning_, _Proceedings of Machine Learning Research_의 202 권 10764-10799 페이지. PMLR.\n' +
      '* Gerevini (2020) Alfonso Emilio Gerevini. 2020. An introduction to planning domain definition language (PDDL): book review. _ 아티프 Intell._ , 280:103221.\n' +
      '* Geva 등(2021) Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021년. 아리스토텔레스가 노트북을 사용했나요? 암묵적 추론 전략을 사용 하는 질문 응답 벤치마크입니다. _ 트랜스 Assoc. 컴퓨팅. 언어학_, 9:346-361\n' +
      '* Gou 등(2023) Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. Tora: 수학적 문제 해결을 위한 도구 통합 추론 에이전트.\n' +
      '* 26th Pacific-Asia Conference, PAKDD 2022, Chengdu, China, May 16-19, 2022, Proceedings, Part III_, Volume 13282 of _Lecture Notes in Computer Science_, pages 3-15. Springer.\n' +
      '* Han 등(2023) Chengheng Han, Xiaowei Du, Che Zhang, Yixin Lian, Xiang Li, Ming Gao, and Baoyuan Wang. 2023. Dialoc meets ppo: Decomposing and exploring reasoning path in smaller language models.\n' +
      '* Han 등(2022) Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell, David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq R. 알렉산더 조티 파브리, 워지엑 크리신스키, 시 빅토리아 린, 카이밍 시옹, 그리고 드라고미르 라데프. 2022. FOLO: 1차 논리로 자연어 추론. _ CoRR_, abs/2209.00840.\n' +
      '* Hao 등(2023) Shibo Hao, Yilan Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023. Reasoning with language model is planning with world model. _ ArXiv_, abs/2305.14992.\n' +
      '*He et al.(2023a) Hangfeng He, Hongming Zhang, and Dan Roth. 2023a. 검색에 대한 재고: 신뢰할 수 있는 대형 언어 모델 추론입니다. _ CoRR_, abs/2301.00303.\n' +
      '*He 등(2023b) Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. 2023b. 큰 언어 모델을 사용 하 여 인간 유사 번역 전략을 탐색 합니다. _ CoRR_, abs/2305.04118.\n' +
      '* Hendrycks 등(2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the MATH dataset. _Proceedings of Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual_.\n' +
      '* Ho et al.(2023) Namgyu Ho, Laura Schmid, and Se-Young Yun. 2023. 대형 언어 모델은 추론 교사이다. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 14852-14882. Association for Computational Linguistics.\n' +
      '* Hosseini 등(2014) Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning to solve arithmetic word problems with verb categorization. _Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, 카타르, A meeting of SIGDAT, a Special Interest Group of the ACL_, pages 523-533. ACL.\n' +
      '* Hosseini 등(2015)Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhias Fujii, Alexander J. Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023. 단계별 증류! 더 적은 학습 데이터와 더 작은 모델 크기로 더 큰 언어 모델을 수행할 수 없습니다. _ ArXiv_, abs/2305.02301.\n' +
      '* Hu 등(2023a) Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, and Yue Zhang. 2023a. 기호의 사슬 프롬프트는 대형 랑게이지 모델에서 계획을 이끌어냅니다. _ CoRR_, abs/2305.10276.\n' +
      '* Hu 등(2023b) Pengbo Hu, Ji Qi, Xingyu Li, Hong Li, Xinqi Wang, Bing Quan, Ruiyu Wang, and Yi Zhou. 2023b. Tree-of-mixed-thought: 멀티 홉 시각적 추론을 위한 빠른 사고와 느린 사고를 결합합니다. _ CoRR_, abs/2308.09658.\n' +
      '* Huang 등(2022) Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022. 대용량 언어 모델은 자체 개선할 수 있습니다. _ CoRR_, abs/2210.11610.\n' +
      '* Huang 등(2023a) Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. 2023a. 큰 언어 모델은 아직 자기 수정 추론을 수행할 수 없습니다. _ arXiv preprint arXiv:2310.01798_.\n' +
      '* Huang 등(2019) Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019. Cosmos QA: 문맥 상식 추론에 의한 기계 독해력. _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019_, pages 2391-2401. Association for Computational Linguistics.\n' +
      '* Huang 등(2023b) Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Barun Patra, Qiang Liu, Kritit Aggarwal, Zewen Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, and Furu Wei. 2023b. 언어만 필요한 것은 아닙니다. 인식을 언어 모델과 정렬합니다. _ CoRR_, abs/2302.14045.\n' +
      '* Huang 등(2023c) Yue Huang, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu, Pan Zhou, Yao Wan, Neil Zhenqiang Gong, and Lichao Sun. 2023c. 메타툴 벤치마크: 도구를 사용할지 여부와 사용할 항목을 결정합니다.\n' +
      '* Imani 등(2023) Shima Imani, Liang Du, and Harsh Shrivastava. 2023. Mathprompter: Large Language Model을 이용한 수학적 추론. _Proceedings of the 61th Annual Meeting of the Association of Computational Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 37-42. Association for Computational Linguistics.\n' +
      '* Ji 등(2023) Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, and Pascale Fung. 2023. 자기반성을 통한 대형 언어 모델에서의 환각 완화를 향하여. _ arXiv preprint arXiv:2310.06271_.\n' +
      '* Jiang et al.(2023a) Song Jiang, Zahra Shakeri, Aaron Chan, Maziar Sanjabi, Hamed Firooz, Yinglong Xia, Bugra Akyildiz, Yizhou Sun, Jinchao Li, Qifan Wang, et al. 2023a. Resprorupt: 잔차 연결 프롬프트는 대규모 언어 모델에서 다단계 추론을 발전시킵니다. _ arXiv preprint arXiv:2310.04743_.\n' +
      '* Jiang 등(2023b) Weisen Jiang, Han Shi, Longhui Yu, Zhengying Liu, Yu Zhang, Zhenguo Li, and James T. 곽이 형. 2023b. 확인을 위해 대규모 언어 모델에서 전후방 추론을 수행합니다. _ CoRR_, abs/2308.07758.\n' +
      '* Jie 등(2023) Zhanming Jie, Trung Quoc Luong, Xinbo Zhang, Xiaoran Jin, and Hang Li. 2023. Design of chain-of-thought in math problem solving.\n' +
      '* Jin and Lu(2023) Ziqi Jin and Wei Lu. 2023. Tab-cot: Zero-shot tabular chain of thought. _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_ 페이지 10259-10277. Association for Computational Linguistics.\n' +
      '* Jones 등(2023) Erik Jones, Hamid Palangi, Clarisse Simoes, Varun Chandrasekaran, Subhabrata Mukherjee, Arindam Mitra, Ahmed Awadallah, and Ece Kamar. 2023. 합성 작업으로 환각을 적게 하도록 언어 모델을 가르친다. _ arXiv preprint arXiv:2310.06827_.\n' +
      '* Karpas et al.(2022) Ehud D. Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhl-gay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, and Moshe Tenenholtz. 2022, 미스터크! 시스템: 큰 언어 모델, 외부 지식 소스 및 이산 추론을 결합한 모듈식, 신경-상징 구조. _ ArXiv_, abs/2205.00445.\n' +
      '* Katz 등(2022) Uri Katz, Mor Geva, and Jonathan Berant. 2022. Infering implicit relations in complex questions with language model. _Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_ 페이지 2548-2566. Association for Computational Linguistics.\n' +
      '* Khalifa 등(2023) Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang. 2023. Discriminator-guided multi-step reasoning with language models. _ arXiv preprint arXiv:2305.14934_.\n' +
      '* Khot 등(2023) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2023. 분해 프롬프트: 복잡한 태스크를 해결하기 위한 모듈식 접근법. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Kojima 등(2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. 대형 언어 모델은 제로 샷 추론기이다. _NeurIPS_에서입니다.\n' +
      '* Koncel-Kedziorski 등(2021) Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang.\n' +
      '\n' +
      '2015) 대수적 단어 문제를 방정식으로 구문 분석. _ Transactions of the Association for Computational Linguistics_, 3:585-597.\n' +
      '* Koncel-Kedziorski 등(2016) Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. MAWPS: A math word problem repository. _NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, June 12-17, 2016_, pages 1152-1157. The Association for Computational Linguistics.\n' +
      '* Lampinen 등(2022) Andrew K. 람피넨, 이시타 다스굽타, 스테파니 C. Y. 찬, 코리 W. 매튜슨, 음 테슬러, 안토니아 크레스웰, 제임스 L. 맥클랜드, 제인 왕, 펠릭스 힐 2022. 언어 모델이 문맥에서 설명으로부터 학습할 수 있는가? _Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_ 페이지 537-563. Association for Computational Linguistics.\n' +
      '* De Lange 등(2022) Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory G. Slabaugh, and Tinne Tuytelaars. 2022. 지속적인 학습 조사: 분류 작업에서의 망각을 거부함_ IEEE Trans. Pattern Anal. 마케터 Intell._ , 44(7):3366-3385.\n' +
      '* Lanham 등(2023)은 Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamile Lukositte, Karina Nguyen, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam McCandlish, Sandipan Kundu, Saurav Kadavath, Shannon Yang, Thomas Henighan, Timothy Maxwell, Timothy Telleleen-Lawton, Tristan Hume, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. 보우먼과 이든 페레즈 2023. Measuring faith of the chain-of-thought reasoning. _ CoRR_, abs/2307.13702.\n' +
      '* Lee and Kim (2023) Soochan Lee and Gunhee Kim. 2023. Recursion of thought: A divide-and-conquer approach to multi-context reasoning with language models. _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_, pages 623-658. Association for Computational Linguistics.\n' +
      '* Lei 등(2023a) Bin Lei, Pei-Hung Lin, Chunhua Liao, and Caiwen Ding. 2023a. 새로운 프레임워크를 통해 대규모 언어 모델에서 논리적 추론을 강화합니다: 사고의 그래프입니다. _ CoRR_, abs/2308.08614.\n' +
      '* Lei 등(2023b) Deren Lei, Yaxi Li, Mingyu Wang, Vincent Yun, Emily Ching, Eslam Kamal, 등 2023b. 대용량 언어 모델 비접지 환각을 감소시키기 위한 자연 언어 추론의 사슬. _ arXiv preprint arXiv:2310.03951_.\n' +
      '* Lei 등(2020) Jie Lei, Licheng Yu, Tamara L. 버그와 모히트 밴살 2020년. 다음에 어떤 일이 일어날 것 같습니까? 비디오 및 언어 미래 이벤트 예측. _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020_, pages 8769-8784. Association for Computational Linguistics.\n' +
      '* Lewkowycz 등(2022) Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay V. 라마제시, 암브로즈 슬론, 켐 아닐, 이마놀 슐래그, 테오 구트만-솔로, 유화이 우, 베남 니하부르, 가이 구르-아리, 베단트 미스라. 2022. Solving quantitative reasoning problems with language models. _NeurIPS_에서입니다.\n' +
      '* Li 등(2022a) Jiangtong Li, Li Niu, 및 Liqing Zhang. 2022a. 표현에서 추론에 이르기까지: 비디오 질문-답변을 위한 증거와 상식 추론 모두를 향한다. _IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022_, pages 21241-21250. IEEE.\n' +
      '* Li 등(2023a) Junnan Li, Dongxu Li, Silvio Savarese, and Steven C. H. Hoi. 2023a. BLIP-2: 동결된 이미지 인코더 및 대형 언어 모델을 사용한 부트스트래핑 언어-이미지 사전 트레이닝. _International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA_, Volume 202 of _Proceedings of Machine Learning Research_, pages 19730-19742. PMLR.\n' +
      '* Li 등(2023b) Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 2023b. 상징적 사상 사슬 증류: 작은 모델도 단계별로 "생각"할 수 있습니다. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 2665-2679. Association for Computational Linguistics.\n' +
      '* Li 등(2023c) Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. 2023c. Apibank: 도구 확장 llms의 벤치마크입니다. _ ArXiv_, abs/2304.08244.\n' +
      '* Li 등(2022b) Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022b. 대비 디코딩: 최적화로서 개방형 텍스트 생성. _계산 언어 학회 연례 회의_ 에서입니다.\n' +
      '* Li 및 Qiu (2023) Xiaonan Li 및 Xipeng Qiu. 2023. Mot: Pre-thinking and recalling enable chatgpt to self-improve with memory-of-thoughts. _ CoRR_, abs/2305.05181.\n' +
      '* Li 등(2023d) Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Lidong Bing, Shafiq R. 조티, 소잔야 포리아 2023d. 지식의 사슬: 구조화된 지식 베이스를 갖는 대형 언어 모델들을 접지시키기 위한 프레임워크. _ CoRR_, abs/2305.13269.\n' +
      '* Li 등(2022c) Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, B. Chen, Jian-Guang Lou, and Weizhu Chen. 2022c. 단계 인식 검증기를 사용하여 언어 모델을 더 나은 추론기로 만들 수 있습니다. _계산 언어 학회 연례 회의_ 에서입니다.\n' +
      '\n' +
      '* Li 등(2023) Yingcong Li, Kartik Sreenivasan, Angeliki Giannou, Dimitris S. 파파일리오풀로스와 사메 오이막 2023e. 분열 사슬 사고: mlps의 구성적 맥락 내 학습에 관한 연구 CoRR_, abs/2305.18869.\n' +
      '* 8월 4일, 볼륨 1: 긴 페이퍼_, 페이지 158-167. 계산 언어학에 대한 연합.\n' +
      '* Ling 등(2023) Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, and Hao Su. 2023. 연쇄사상추론의 연역적 검증. _ CoRR_, abs/2306.03872.\n' +
      '* Liu 등(2023a) Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. 2023a. Llm+p: 최적의 계획 숙련도를 갖춘 대형 언어 모델을 강화합니다.\n' +
      '* Liu 등(2023b) Jiacheng Liu, Ramakanth Pasunuru, Hannaneh Hajishirzi, Yejin Choi, and Asli Celikyilmaz. 2023b. 결정: 자기 피드백으로 강화된 내성 추론기. _ arXiv preprint arXiv:2310.04921_.\n' +
      '* Liu 등(2020) Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2020. Logiqa: 논리적 추론을 이용한 기계 독해력 챌린지 데이터셋. _Proceedings of the Twenty-Nineth International Joint Conference on Artificial Intelligence, IJCAI 2020_, pages 3622-3628. ijcai.org.\n' +
      '* Long(2023) Jieyi Long. 2023. Large language model guided tree-of-thought. _ CoRR_, abs/2305.08291.\n' +
      '* Lu 등(2023a) Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei. 2023a. 사전 연결 프롬프트는 대규모 언어 모델에서 번역을 유도합니다. _ CoRR_, abs/2305.06575.\n' +
      '* Lu 등(2022) Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022. 설명에 대해 배움: 과학 질문 응답을 위한 사고 사슬을 통한 멀티모달 추론. _NeurIPS_에서입니다.\n' +
      '* Lu 등(2023b) Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, and Ashwin Kalyan. 2023b. 반구조화된 수학적 추론을 위한 정책 그래디언트를 통한 동적 프롬프트 학습 _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Lu 등(2023c) Yining Lu, Haoping Yu, Daniel Khashabi. 2023c. 기어: 일반화 가능하고 효율적인 도구 해상도로 언어 모델을 확장합니다.\n' +
      '* Lyu 등(2023) Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023. Faithful chain-of-thought reasoning. _ CoRR_, abs/2301.13379.\n' +
      '* Madaan 등(2022) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhiswa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, and Peter Clark. 2023. Self-refine: Self-feedback을 이용한 반복적 정제. _ CoRR_, abs/2303.17651.\n' +
      '* Madaan and Yazdanbakhsh (2022) Aman Madaan and Amir Yazdanbakhsh. 2022. 텍스트 및 패턴: 효과적인 사고 사슬을 위해 탱고에 두 개가 필요합니다. _ CoRR_, abs/2209.07686.\n' +
      '* Madaan 등(2022) Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, and Graham Neubig. 2022. 코드의 언어 모델은 소수의 상식적인 학습자들이다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 1384-1403. Association for Computational Linguistics.\n' +
      '* Magister 등(2023) Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and Aliaksei Severyn. 2023. Teaching small language models to reason. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 1773-1781. Association for Computational Linguistics.\n' +
      '* Merrill and Sabharwal (2023) William Merrill and Ashish Sabharwal. 2023. 사유의 사슬을 가진 변압기의 표현력.\n' +
      '* Miao 등(2023) Ning Miao, Yee Whye Teh, and Tom Rainforth. 2023. 셀프 체크: lms를 사용하여 제로 샷 체크는 자신의 단계별 추론을 체크한다. _ arXiv preprint arXiv:2308.00436_.\n' +
      '* Miao et al.(2020) Shen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2020. 영어 수학 단어 문제 해결사 평가 및 개발을 위한 다양한 말뭉치. _Computational Linguistics Association of 58th Annual Meeting Proceedings_, pages 975-984, Online. 계산 언어학을 위한 연관성.\n' +
      '* Mihaylov et al.(2018) Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 2018. 갑옷이 전기를 전도할 수 있나요? 열린 책 질문 답변을 위한 새로운 데이터 세트 _2018년 자연어 처리에서의 경험적 방법에 관한 회의의 진행문_ 에서, 벨기에 브뤼셀의 2381-2391 페이지이다. 계산 언어학을 위한 연관성.\n' +
      '* Mishra 등(2022a) Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan. 2022a. LILA: 수학적 추론을 위한 통합된 벤치마크입니다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 5807-5832. Association for Computational Linguistics.\n' +
      '* Madaan 등(2022b)Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavedeep Singh Sachdeva, Peter Clark, Chitta Baral, and Ashwin Kalyan. 2022b. 넘글루: 기본적이면서도 도전적인 수학적 추론 과제의 집합입니다. _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022_ 페이지 3505-3523. Association for Computational Linguistics.\n' +
      '* Mo and Xin (2023) Shentong Mo and Miao Xin. 2023. Tree of uncertain thoughts reasoning for large language models. _ CoRR_, abs/2309.07694.\n' +
      '* Naik 등(2023) Ranjita Naik, Varun Chandrasekaran, Mert Yuksekgonul, Hamid Palangi, and Besmira Nushi. 2023. 사유의 다양성은 대형 언어 모델의 추론 능력을 향상시킨다. _ arXiv preprint arXiv:2310.07088_.\n' +
      '* Ning 등(2023) Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu Wang. 2023. Skeleton-of-thought: Large language models can do parallel decoding. _ CoRR_, abs/2307.15337.\n' +
      '* O\'Brien and Lewis (2023) Sean O\'Brien and Mike Lewis. 2023. 대조적 디코딩은 대형 언어 모델에서의 추론을 향상시킨다. _ ArXiv_, abs/2309.09117.\n' +
      '* OpenAI(2023) OpenAI. 2023. GPT-4 기술보고서. _ CoRR_, abs/2303.08774.\n' +
      '* Paranjape 등(2023) Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. 2023. 아트: 대용량 언어 모델에 대한 자동 다단계 추론 및 도구 사용.\n' +
      '* Parisi 등(2022a) Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022a. Talm: 툴 증강 언어 모델. _ ArXiv_, abs/2205.12255.\n' +
      '* Parisi 등(2022b) Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022b. TALM: 도구 증강 언어 모델입니다. _ CoRR_, abs/2205.12255.\n' +
      '* ECCV 2020\n' +
      '- 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V_, Volume 12350 of _Lecture Notes in Computer Science_, pages 508-524. Springer.\n' +
      '* Patel 등(2021) Arkil Patel, Satwik Bhattacharya, Navin Goyal. 2021. NLP 모델이 정말 간단한 수학 단어 문제를 해결할 수 있나요? _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021_, pages 2080-2094. Association for Computational Linguistics.\n' +
      '* Paul 등(2023) Debjit Paul, Mete Ismayilkada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, and Boi Faltings. 2023. REFINER: 중간 표현들에 대한 추론 피드백. _ CoRR_, abs/2304.01904.\n' +
      '* Peng 등(2023) Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. 2023. Kosmos-2: Grounding multimodal large language models to the world. _ CoRR_, abs/2306.14824.\n' +
      '* Pitis 등(2023) Silviu Pitis, Michael R. 장, 앤드류 왕, 지미 바 2023. 대형 언어 모델에 대 한 추가 프롬프트 앙상블입니다. _ CoRR_, abs/2304.05970.\n' +
      '* Qiao 등(2023) Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. 2023. Reasoning with language model prompting: survey. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 5368-5393. Association for Computational Linguistics.\n' +
      '* Radford and Narasimhan (2018) Alec Radford and Karthik Narasimhan. 2018. Generative Preraining에 의한 언어 이해력 향상.\n' +
      '*Radhakrishnan 등(2023) Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamille Lukositute, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Sam McCandlish, Sheer El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. 보우먼과 이든 페레즈 2023. 질문 분해는 모델 생성 추론의 충실성을 향상시킨다. _ CoRR_, abs/2307.11768.\n' +
      '* Raffel 등(2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. 통합 텍스트-텍스트 변환기를 이용한 전이 학습의 한계 탐색. _ 제이 마케터 배워 Res._ , 21(1).\n' +
      '* Rashkin 등(2018) Hannah Rashkin, Maarten Sap, Emily Allaway, Noah A. Smith, and Yejin Choi. 2018. EventZmind: 이벤트, 의도 및 반응에 대한 상식 추론. _Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers_, pages 463-473. Association for Computational Linguistics.\n' +
      '* Roy and Roth (2015) Subhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. _2015 자연어 처리에서의 경험적 방법에 관한 회의의 진행문_ 에서, 1743-1752 페이지, 포르투갈 리스본. 계산 언어학을 위한 연관성.\n' +
      '* Ruan 등(2023) Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao. 2023. Tptu: 대용량 언어 모델 기반 ai 에이전트의 태스크 계획 및 툴 사용.\n' +
      '* Saparov and He (2023) Aulhair Saparov and He He. 2023. 언어 모델은 탐욕적인 추론자이다: 연쇄 사상의 체계적인 형식 분석. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Raffel 등(2020)* Le Scao 등(2023) Teven Le Scao, Angela Fan, Christopher Akiki, Elie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, Francois Yvon, Matthias Galle, Jonathan Tow, Alexander M. Rush, Stella Biderman, Albert Webson, Pawan Sasanka Ammanmananchi, Thomas Wang, Benoit Sagot, Niklas Muennighoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurencon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David Ifeoluwa Adelani, et al. 2022. BLOOM: 176b CoRR_, abs/2211.05100.\n' +
      '* Schaeffer 등(2023) Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. 2023. 대형 언어 모델의 비상한 능력은 신기루입니까? _ CoRR_, abs/2304.15004.\n' +
      '* Schick 등(2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: 언어 모델은 스스로 도구를 사용하는 방법을 가르칠 수 있습니다. _ CoRR_, abs/2302.04761.\n' +
      '* Sel 등(2023) Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Lu Wang, Ruoxi Jia, and Ming Jin. 2023. 생각의 알고리즘: 대용량 언어 모델에서 아이디어의 탐색을 강화함_ CoRR_, abs/2308.10379.\n' +
      '* Shao 등(2023) Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. 합성 프롬프트: 대형 언어 모델에 대한 사상 체인 데모를 생성함_ CoRR_, abs/2302.00618.\n' +
      '* Shen 등(2023) Yongliang Shen, Kaitao Song, Xu Tan, Dong Sheng Li, Weiming Lu, and Yue Ting Zhuang. 2023. 포옹: 포옹하는 얼굴에서 채팅과 그 친구들과 함께 ai 태스크를 해결하는 것_ ArXiv_, abs/2303.17580.\n' +
      '* Shi et al.(2023) Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. 2023. 언어 모델은 다국어 연쇄 사상 추론기이다. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '*Shinn 등(2023) Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023. 반사: 언어 강화 학습을 갖는 언어 에이전트.\n' +
      '* Shridhar 등(2023) Kumar Shridhar, Harsh Jhamtani, Hao Fang, Benjamin Van Durme, Jason Eisner, and Patrick Xia. 2023. 스크류: 수정들을 갖는 추론을 위한 모듈식 프레임워크. _ arXiv preprint arXiv:2309.13075_.\n' +
      '* Shum et al.(2023) Kashun Shum, Shizhe Diao, and Tong Zhang. 2023. 라벨링된 데이터로부터 체인-오브-생각을 갖는 자동 프롬프트 증강 및 선택. _ CoRR_, abs/2302.12822.\n' +
      '* Srivastava 등(2019) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, Agnieszka Kluka, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tzarav, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Ananthharaman S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlmuller, Andrew M. 다이 앤드루 라 앤드루 케이 Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and et al. 2022. Beyond the mimitation game: 언어 모델의 능력을 정량화하고 외삽한다. _ CoRR_, abs/2206.04615.\n' +
      '* Sun 등(2023) Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and Chao Zhang. 2023. Adaplanner: Adaptive planning from feedback with language models. _ ArXiv_, abs/2305.16653.\n' +
      '* Suzgun 등(2023) Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. 르, 에드치, 데니 저우 제이슨 웨이 2023. Challing big-bench tasks and whether the chain-of-thought can solve them. _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_, pages 13003-13051. Association for Computational Linguistics.\n' +
      '* Tafjord 등(2021) Oyvind Tafjord, Bhavana Dalvi, Peter Clark. 2021. Proofwriter: 자연어에 대한 시사점, 증명 및 귀납적 진술 생성. _Findings of Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021_, Volume ACL/IJCNLP 2021 of _Findings of ACL_, pages 3621-3634. Association for Computational Linguistics.\n' +
      '* Talmor 등(2019) Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. Commonsenseqa: 상식 지식을 대상으로 하는 질문 응답 도전. _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1(Long and Short Papers)_, pages 4149-4158. Association for Computational Linguistics.\n' +
      '* Talmor 등(2021) Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and Jonathan Berant. 2021. Commonsenseqa 2.0: 게이미피케이션을 통한 AI의 한계 노출. _Proceedings of Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual_.\n' +
      '* Tang 등(2023) Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. 2023. 대형 언어 모델들은 기호 추론기들이 아닌 문맥 내 의미 추론기들이다. _ CoRR_, abs/2305.14825.\n' +
      '* Touvron 등(2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothete Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. Llama: 오픈하고 효율적인 기초 언어 모델입니다. _ CoRR_, abs/2302.13971.\n' +
      '* Touvron 등(2023a) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kolumann, Artem Korenecy, Punit Singh Koura, Marie-Anne Lachau, Thibaut Lavril, Jenya Lee, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rung 2023b. 라마 2: 기반 및 미세 조정 채팅 모델을 엽니다. _ CoRR_, abs/2307.09288.\n' +
      '* Wan 등(2023) Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. 아리크, 토마스 화이스터 2023. 자가 적응 프롬프팅으로 더 나은 제로 샷 추론. _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_, pages 3493-3514. Association for Computational Linguistics.\n' +
      '* Wang 등(2022a) Boshi Wang, Xiang Deng, and Huan Sun. 2022a. 사상의 사슬을 위해 사전 훈련된 언어 모델을 반복적으로 재촉합니다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 2714-2730. Association for Computational Linguistics.\n' +
      '* Wang 등(2023a) Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun. 2023a. 사상의 사슬을 이해하기 위한 연구: 무엇이 중요한지에 대한 실증적 연구 _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 2717-2739. Association for Computational Linguistics.\n' +
      '* Wang 등(2019) Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li, and Tian Gao. 2019년 말이 돼? 왜? 감각 만들기 및 설명을 위한 예비 연구 _Computational Linguistics Association의 제57차 연차총회 회보_에서, 이탈리아 플로렌스 4020-4026 페이지. 계산 언어학을 위한 연관성.\n' +
      '* Wang 등(2023b) Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, and Ming Gao. 2023b. 체인 지식 프롬프팅으로 언어 모델 추론을 향상시킵니다. _ CoRR_, abs/2306.06427.\n' +
      '* Wang 등(2022c) Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and Zhang Xiong. 2023c. 지식주도형 간이침대: 지식집약형 질의응답을 위한 충실한 추론 탐구\n' +
      '* Wang 등(2023d) Lei Wang, Yi Hu, Jiabang He, Xing Xu, Ning Liu, Hui Liu, and Heng Tao Shen. 2023d. T-sciq: 과학 질의응답을 위한 대형 언어 모델 신호를 통해 멀티모달 체인 오브 사고 추론을 가르치는 것. _ CoRR_, abs/2305.03453.\n' +
      '* Wang 등(2023e) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Ji-Rong Wen. 2023e. 대용량 언어 모델 기반 자율 에이전트에 대 한 설문 조사 _ CoRR_, abs/2308.11432.\n' +
      '* Wang 등(2023f) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023f. 계획 및 해결 프롬프트: 대규모 언어 모델에 의한 제로 샷 체인 사고 추론 개선 _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers), ACL 2023, Toronto, July 9-14, 2023_, pages 2609-2634. Association for Computational Linguistics.\n' +
      '* Wang 등(2023g) Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu. 2023g. 연속학습에 대한 종합적인 조사: 이론, 방법 및 적용. _ CoRR_, abs/2302.00487.\n' +
      '* Wang 등(2023h) Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, and Xiang Ren. 2023h. 스콧: 자기 일관성 있는 사상체인의 증류. _계산 언어 학회 연례 회의_ 에서입니다.\n' +
      '* Wang 등(2022b) Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, and Furu Wei. 2022b. 외국어로 이미지: 모든 비전 및 비전 언어 작업에 대 한 사전 교육을 수행 합니다. _ CoRR_, abs/2208.10442.\n' +
      '* Wang 등(2023i) Xinyi Wang, Lucas Caccia, Oleksiy Ostapenko, Xingdi Yuan, and Alessandro Sordoni. 2023i. 계획 토큰으로 언어 모델 추론을 안내합니다.\n' +
      '\n' +
      '쉐지 왕, 제이슨 웨이, 데일 슈어맨스, 퀵 V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou 2023j. 자기일관성은 언어 모델에서 사고 추론의 사슬을 향상시킨다. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Wang 등(2023) Yiming Wang, Zhuosheng Zhang, and Rui Wang. 2023k. 대용량 언어 모델을 이용한 요소 인식 요약: 전문가 정렬 평가 및 체인 사상 방법. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 8640-8665. Association for Computational Linguistics.\n' +
      '* Wei 등(2022a) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. 대형 언어 모델의 최신 기능입니다. _ 트랜스 마케터 배워 Res._ , 2022.\n' +
      '* Wei 등(2022b) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. 르와 데니 저우 2022b. 생각의 사슬은 큰 언어 모델에서 추론을 이끌어낸다. _NeurIPS_에서입니다.\n' +
      '* Weng 등(2022) Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao. 2022. 대형 언어 모델은 자체 검증을 사용하는 추론기입니다. _ arXiv preprint arXiv:2212.09561_.\n' +
      '* Wu 등(2021) Bo Wu, Shoubin Yu, Zhenfang Chen, Josh Tenenbaum, and Chuang Gan. 2021. STAR: 실세계 비디오에서 상황 추론을 위한 벤치마크. _Proceedings of Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual_.\n' +
      '* Wu 등(2023) Skyler Wu, Eric Meng Shen, Charumathi Badrinath, Jiaqi Ma, and Himabidu Lakkaraju. 2023. 그래디언트-기반 특징 속성들을 통해 대형 언어 모델들에서 프롬프팅의 체인-생각을 분석하는 것 _ CoRR_, abs/2307.13339.\n' +
      '* Xi 등(2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huan, and Tao Gui. 2023. 대형 언어 모델 기반 에이전트의 상승과 잠재력: 설문조사. _ CoRR_, abs/2309.07864.\n' +
      '* Xiao 등(2021) Junbin Xiao, Xindi Shang, Angela Yao, and Tat-Seng Chua. 2021. Next-qa: 시간적 동작을 설명하기 위한 질문-응답의 다음 단계. _IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021_, pages 9777-9786. Computer Vision Foundation/IEEE.\n' +
      '* Xu 등(2023) Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. 2023. Reprompting: gibbs sampling을 통한 자동화된 Chain-of-thought prompt inference.\n' +
      '* Xue 등(2023) Tianc Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. 2023. RCOT: chain-of-thought를 역전시킴으로써 추론에서 사실적 불일치를 검출하고 교정한다. _ CoRR_, abs/2305.11499.\n' +
      '* Yang 등(2023) Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang. 2023. MMEAACT: prompting chatgpt for multimodal reasoning and action. _ CoRR_, abs/2303.11381.\n' +
      '* Yang 등(2022) Zonglin Yang, Li Dong, Xinya Du, Hao Cheng, Erik Cambria, Xiaodong Liu, Jianfeng Gao, and Furu Wei. 2022. Language models as inductive reasoners. _ CoRR_, abs/2212.10923.\n' +
      '*Yao 등(2023a) Fanglong Yao, Changyuan Tian, Jintao Liu, Zequn Zhang, Qing Liu, Li Jin, Shuchao Li, Xiaoyu Li, and Xian Sun. 2023a. 전문가처럼 생각하는 것: 기초 양식을 향상시키기 위한 다중 모드 하이퍼그래프-사상(핫) 추론입니다.\n' +
      '*Yao 등(2023b) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. 그리피스, 위안 카오, 카르틱 나라심한. 2023b. 생각의 나무: 큰 언어 모델을 사용 하 여 문제 해결을 검토 합니다. _ CoRR_, abs/2305.10601.\n' +
      '*Yao 등(2023c) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. 나라심한과 위안 조 2023c. 반응: 언어 모델에서 추론과 행동을 동기화합니다. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Yao 등(2023d) Yao Yao, Zuchao Li, 및 Hai Zhao. 2023d. 체인 사고를 넘어 대용량 언어 모델에서 효과적인 그래프 사고 추론입니다. _ CoRR_, abs/2305.16582.\n' +
      '* Ye and Durrett (2022) Xi Ye and Greg Durrett. 2022. few-shot in-context learning에서의 설명의 비신뢰성_ CoRR_, abs/2205.03401.\n' +
      '* Ye and Durrett (2023) Xi Ye and Greg Durrett. 2023. In-context 학습을 위해 레이블이 지정되지 않은 데이터를 이용한 설명 선택. _ CoRR_, abs/2302.04813.\n' +
      '* Ye 등(2023) Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, and Yongbin Li. 2023. 대용량 언어 모델은 다용도 분해자: 표 기반 추론을 위한 증거와 질문을 분해한다. _Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023_, pages 174-184. ACM.\n' +
      '* Yi 등(2020) Kexin Yi, Chang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua B. Tenenbaum. 2020. CLEVRER: 충돌 이벤트 for video representation and reasoning. _8th International Conference on Learning Representations, ICLR 2020,Addis Ababa, Ethiopia, April 26-30, 2020_. OpenReview.net.\n' +
      '*Yoran 등(2023) Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, and Jonathan Berant. 2023. response questions by meta-reasoning over multiple chain of thought. _ CoRR_, abs/2304.13007.\n' +
      '* Yu 등(2023a) Fei Yu, Hongbo Zhang, Benyou Wang. 2023a. Nature Language reasoning, A survey. _ CoRR_, abs/2303.14725.\n' +
      '* Yu 등(2023b) Junchi Yu, Ran He, and Rex Ying. 2023b. 생각 전파: 큰 언어 모델을 사용 하 여 복잡 한 추론에 대 한 유추적 접근입니다. _ arXiv preprint arXiv:2310.03965_.\n' +
      '* Yu 등(2020) Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng. 2020. Reclor: 논리적 추론이 필요한 읽기 이해 데이터셋. _8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020_. OpenReview.net.\n' +
      '* Yu 등(2021a) Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong Xiao. 2021a. 사전 훈련된 지식과 계층적 추론으로 수학 단어 문제를 개선합니다. _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 3384-3394, Online and Punta Cana, Dominican Republic. 계산 언어학을 위한 연관성.\n' +
      '* Yu 등(2021b) Weijiang Yu, Haoteng Zheng, Mengfei Li, Lei Ji, Lijun Wu, Nong Xiao, and Nan Duan. 2021b. 내부로부터의 학습: 비디오 질문 응답에 대한 자기 주도적 샴즈 샘플링 및 추론. _ Advances in Neural Information Processing Systems_, 34:26462-26474.\n' +
      '* Yu 등(2023c) Zihan Yu, Liang He, Zhen Wu, Xinyu Dai, and Jiajun Chen. 2023c. 더 나은 사상 사슬 촉진 전략: 설문 조사.\n' +
      '* Zelikman 등(2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. 2022. Star: Bootstraping reasoning with reasoning. _NeurIPS_에서입니다.\n' +
      '* Zellers 등(2019) Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. 인식에서 인지: 시각적 상식 추론. _IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019_, pages 6720-6731. Computer Vision Foundation/IEEE.\n' +
      '* Zhang et al.(2023a) Bowen Zhang, Kehua Chang, and Chunping Li. 2023a. Cot-bert: Chain-of-thought를 통해 비감독 문장 표현을 향상시킵니다. _ CoRR_, abs/2309.11143.\n' +
      '* Jang and Parkes (2023) Hugh Zhang and David C. Parkes. 2023. Chain-of-thought reasoning은 정책 개선 연산자이다.\n' +
      '* Zhang 등(2023b) Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, and Sharad Mehrotra. 2023b. 초안 & 검증: 자체 추측 디코딩을 통한 무손실 대형 언어 모델 가속입니다. _ arXiv preprint arXiv:2309.08168_.\n' +
      '* Zhang et al.(2023c) Li Zhang, Liam Dugan, Hainiu Xu, and Chris Callison-Burch. 2023c. 호기심 많은 코드 프롬프트 사례를 탐색합니다. _ CoRR_, abs/2304.13250.\n' +
      '* Zhang 등(2023d) Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah A. Smith. 2023d. 언어 모델 환각이 눈덩이처럼 불어나는 방법 _ CoRR_, abs/2305.13534.\n' +
      '* Zhang 등(2022) Sarah J. Zhang, Reece Shuttleworth, Derek Austin, Yann Hicke, Leonard Tang, Sathwik Karnik, Darnell Granberry, and Iddo Drori. 2022. 기계 학습 기말고사 자동응답 및 생성을 위한 데이터셋 및 벤치마크. _ CoRR_, abs/2206.05442.\n' +
      '* Zhang et al.(2023e) Tianhua Zhang, Jiaxin Ge, Hongyin Luo, Yung-Sung Chuang, Mingye Gao, Yuan Gong, Xixin Wu, Yoon Kim, Helen Meng, and James Glass. 2023e. 하이브리드 언어 기호추론을 위한 자연어 내장 프로그램. _ arXiv preprint arXiv:2309.10814_.\n' +
      '* Zhang and Zhang (2023) Zhuosheng Zhang and Aston Zhang. 2023. 화면만 볼 수 있습니다: 멀티모달 액션 체인 에이전트입니다.\n' +
      '* Zhang et al.(2023) Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023f. 대형 언어 모델에서의 사고 자동 연결 프롬프트 _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* Zhang 등(2023g) Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. 2023g. 언어 모델에서 Multimodal chain-of-thought reasoning. _ CoRR_, abs/2302.00923.\n' +
      '* Zhao et al.(2023a) Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023a. 검증 및 편집: 지식이 강화된 사상 사슬 프레임워크입니다. _Proceedings of 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 5823-5840. Association for Computational Linguistics.\n' +
      '* 18, 2022_, pages 4571-4581. ACM.\n' +
      '* Zhao 등(2023b) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023b. 대형 언어 모델에 대한 설문조사입니다. _ CoRR_, abs/2303.18223.\n' +
      '\n' +
      '수펑 자오, 멍디 리, 원하오 루, 코넬리우스 베버, 이재희, 건추, 스테판 베르메르 등이 있다. 2023c. 로직을 통해 대규모 언어 모델에서 제로 샷 체인 오브 생각 추론을 향상시킵니다. _ CoRR_, abs/2309.13339.\n' +
      '* [정등 2023] Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le, and Denny Zhou. 2023. 한 걸음 물러서기: 대형 언어 모델에서의 추상화를 통한 추론 유발. _ arXiv preprint arXiv:2310.06117_.\n' +
      '* [Zhou et al.2023a] Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. 2023a. 언어 에이전트 트리 검색은 언어 모델에서 추론 행위와 계획을 통합한다.\n' +
      '* [Zhou et al.2019] Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. 2019. "휴가 중"은 "산책 중"보다 시간이 더 오래 걸린다. 시간적 상식 이해에 대한 연구. _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, pages 3361-3367. Association for Computational Linguistics.\n' +
      '* [Zhou et al.2023b] Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le, Ed H. Chi. 2023b. 최소 프롬프트는 대규모 언어 모델에서 복잡한 추론을 가능하게 한다. _The 11번째 International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_. OpenReview.net.\n' +
      '* [Zhou et al.2023c] Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, and Lei Ma. 2023c. Isr-llm: long-horizon 순차 태스크 계획을 위한 반복적 자기 정제 대형 언어 모델.\n' +
      '* [Zhu et al.2021] Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021. TAT-QA: 금융에서 표형 콘텐츠와 텍스트형 콘텐츠의 혼성체에 대한 질의 응답 벤치마크. _Proceedings of the 59th Annual Meeting of the Association of the Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021_, pages 3277-3287. Association for Computational Linguistics.\n' +
      '* [Zou et al.2023] Anni Zou, Zhuosheng Zhang, Hai Zhao, and Xiangru Tang. 2023. Meta-cot: Generalizable chain-of-thought prompting in mixed-task scenarios with large language models. _ arXiv preprint arXiv:2310.06692_.\n' +
      '* [Zhou et al.2023c]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>