{
    "2310.04406": {
        "paper_id": "2310.04406",
        "abs_url": "https://arxiv.org/abs/2310.04406",
        "pdf_url": "https://arxiv.org/pdf/2310.04406.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2310.04406_Language_Agent_Tree_Search_Unifies_Reasoning_Acting_and_Planning_in_Language_Models.pdf",
        "title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Andy Zhou",
            "Kai Yan",
            "Michal Shlapentokh-Rothman",
            "Haohan Wang",
            "Yu-Xiong Wang"
        ],
        "abstract": "While large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness and generality of our method.",
        "comments": "Website and code can be found at this https URL",
        "official_code_urls": [
            "https://github.com/andyz245/LanguageAgentTreeSearch"
        ],
        "pwc_page_url": "https://paperswithcode.com/paper/language-agent-tree-search-unifies-reasoning",
        "bibtex": "@misc{zhou2023language,\n      title={Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models}, \n      author={Andy Zhou and Kai Yan and Michal Shlapentokh-Rothman and Haohan Wang and Yu-Xiong Wang},\n      year={2023},\n      eprint={2310.04406},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}"
    }
}