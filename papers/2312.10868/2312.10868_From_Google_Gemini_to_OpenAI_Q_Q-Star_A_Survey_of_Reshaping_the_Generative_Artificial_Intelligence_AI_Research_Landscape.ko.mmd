Google Gemini에서 OpenAI Q*(Q-Star): 인공지능(AI) 연구경관 재편성 실태조사

티모시 맥킨토시, 테오 수센작, 통류, 폴 와터스, 말카 N. 할가무지

원고는 2023년 12월 19일에 받았다. _(교신저자: Timothy R. McIntosh.)_Timothy McIntosh는 Academyies Australasia Polytechnic, Melbourne, VIC 2000, Australia(e-mail: tmcintosh@aupd.edu.au), Teo Susnjak and Tong Liu는 Massey University, Auckland 0632, 뉴질랜드(e-mail: tliu@massey.ac.nz; tsusnjak@massey.ac.nz), Paul Watters는 Cybersronomy Pty Ltd, Ballarat, VIC 3350, Australia(e-mail: eco@cybersronomy.com).Malka N. Halgamuge는 RMIT University, Melbourne, VIC 3000, Australia와 함께 있다(e-mail: malka.halgamuge@rmit.edu.au).

###### Abstract

이 종합 조사는 혼합 전문가(MoE), 멀티모달 학습 및 인공 지능(AGI)으로의 추측된 진화의 변형 영향에 특정한 초점을 두고 생성 인공 지능(AI)의 진화하는 풍경을 탐구했다. 구글의 제미니(Gemini)와 예상되는 OpenAI Q* 프로젝트와 같은 혁신이 어떻게 생성 AI 연구 분류법에 대한 영향 분석을 포함하여 다양한 영역에 걸쳐 연구 우선 순위 및 애플리케이션을 재편하고 있는지 탐구하면서 생성 AI(AI)의 현재 상태와 미래 궤적을 비판적으로 조사했다. 이 기술은 의료, 금융 및 교육과 같은 분야에서 상당한 발전을 이끌 수 있는 잠재력을 강조하면서 이러한 기술의 계산 문제, 확장성 및 실제 영향을 평가했다. 또한 AI를 주제로 한 사전 인쇄물과 AI 생성 사전 인쇄물의 확산으로 인해 제기되는 새로운 학문적 문제를 해결하여 동료 검토 과정과 학술적 커뮤니케이션에 미치는 영향을 조사했다. 이 연구는 AI 개발에 윤리적, 인간 중심적 방법을 통합하고 사회적 규범 및 복지와의 일치를 보장하는 것의 중요성을 강조했으며, MoE, 다중 모드 및 AGI를 생성 AI에 균형 있고 양심적으로 사용하는 데 초점을 맞춘 향후 AI 연구를 위한 전략을 요약했다.

 AI 윤리, AI(Artificial General Intelligence), AI(Artificial Intelligence), Gemini, Generative AI, Mixture of Experts(MoE), Multimodality, Q*(Q-star), Research Impact Analysis.

## I Introduction

앨런 튜링의 "모방 게임"[1], 초기 계산 이론[2, 3], 최초의 신경망과 기계 학습[4, 5, 6]의 개발로 거슬러 올라가는 AI의 역사적 맥락은 오늘날의 고급 모델의 기초를 마련했다. 딥러닝과 강화학습의 등장과 같은 중요한 순간들에 의해 강조되는 이러한 진화는 이 분야의 역동적이고 지속적으로 진화하는 성격을 보여주는 정교한 혼합 전문가 모델 및 멀티모달 AI 시스템을 포함하여 AI의 현대 트렌드를 형성하는 데 필수적이었다. 이러한 발전은 AI 기술의 역동적이고 끊임없이 진화하는 특성을 보여주는 증거이다. 인공지능(AI)의 진화는 OpenAI가 개발한 대형 언어 모델(LLM), 특히 ChatGPT의 등장, 구글의 제미니[7, 8]의 최근 공개와 함께 결정적인 전환을 목격했다. 이 기술은 산업계와 학계에 혁명을 일으켰을 뿐만 아니라 AI 의식과 인류에 대한 잠재적 위협에 대한 비판적 논의를 재점화했다[9, 10, 11]. 인류학의 클로드와 같은 주목할 만한 경쟁자를 포함한 이러한 첨단 AI 시스템의 개발과 GPT-3, 구글의 자체 LaMDA와 같은 이전 모델에 대한 몇 가지 발전을 보여주는 제미니는 연구 지형을 재구성했다. 쌍방향 대화에서 학습할 수 있는 제미니의 능력과 멀티턴 대화 중에 컨텍스트의 관련 부분에 집중할 수 있는 "스파이크 앤 슬랩" 주의 방법은 다중 도메인 대화 애플리케이션에 더 잘 장착된 모델 개발의 상당한 비약을 나타낸다. 제미니가 사용하는 혼합 전문가 방법을 포함한 LLM의 이러한 혁신은 다양한 입력을 처리하고 다중 모드 접근법을 촉진할 수 있는 모델을 향한 이동을 나타낸다. 이러한 배경 속에서 LLM의 힘을 Q-러닝, A*(A-Star 알고리즘) 등 정교한 알고리즘과 결합해 역동적인 연구 환경2에 더욱 기여했다는 주장이 제기되면서 Q*(Q-Star)로 알려진 오픈AI 프로젝트에 대한 추측이 수면 위로 떠올랐다.

각주 1: [https://deepmind.google/technologies/gemini/](https://deepmind.google/technologies/gemini/)

각주 2: [https://www.forbes.com/sites/anzoelior/2023/11/26/about-that-mysterious-ai-breakthrough-known-as-q-by-openai-that-allegedly-attains-true-ai-or-is-on-the-path-toward-artificial-general-intelligence-agi](https://www.forbes.com/sites/anzoelior/2023/11/26/about-that-mysterious-ai-breakthrough-known-as-q-by-openai-that-allegedly-attains-true-ai-or-is-on-the-path-toward-artificial-general-intelligence-agi)

### _Changing AI Research Popularity_

제미니 및 Q*와 같은 혁신으로 예시되는 LLM 분야가 계속 진화함에 따라 새로운 추세를 식별하는 것부터 신속한 진전을 위해 준비된 영역을 강조하는 것까지 다양한 미래 연구 경로를 차트화하기 위한 목적으로 많은 연구가 표면화되었다. 제미니에 의해 입증된 바와 같이 LLM 연구의 "핫 주제"가 점점 더 멀티모달 능력과 대화 중심 학습으로 전환되는 등 확립된 방법과 초기 채택의 이분법이 분명하다. 사전 인쇄물의 전파는 지식 공유를 빠르게 하지만 학문적 조사를 줄일 위험도 가져온다. 표절 및 위조에 대한 우려와 함께 철회 워치에 의해 언급된 고유한 편향과 같은 문제는 상당한 장애물을 제시한다[12]. 따라서 학계는 교차로에 서 있어 현장의 빠른 진화에 비추어 연구 방향을 구체화하기 위한 통일된 추진력이 필요하며, 이는 시간이 지남에 따라 다양한 연구 키워드의 변화하는 인기를 통해 부분적으로 추적되는 것으로 판단된다. GPT와 같은 생성 모델의 출시와 ChatGPT의 광범위한 상업적 성공이 영향을 미쳤다. 그림 1에서 볼 수 있듯이 특정 키워드의 상승과 하락은 2017년 [13]의 "트랜스포머" 모델, 2018년 [14]의 GPT 모델, 2022년 12월의 상업용 ChatGPT-3.5와 같은 주요 산업 이정표와 상관관계가 있는 것으로 보인다. 예를 들어, "딥 러닝"과 관련된 검색의 급증은 신경망 애플리케이션의 돌파구와 일치하는 반면 "자연어 처리"에 대한 관심은 GPT 및 LLaMA와 같은 모델로 급증하여 언어 이해 및 생성에서 가능한 것을 재정의한다. AI 연구에서 "윤리/윤리"에 대한 지속적인 관심은 일부 변동에도 불구하고 AI의 도덕적 차원에 대한 지속적이고 뿌리 깊은 우려를 반영하며, 윤리적 고려는 단순히 반동적인 조치가 아니라 AI 토론 내에서 통합적이고 지속적인 대화임을 강조한다[15].

이러한 추세가 기술 발전이 연구 초점을 주도하는 인과 관계를 의미하는지 또는 급성장하는 연구 자체가 기술 개발을 추진하는지를 가정하는 것은 학문적으로 흥미롭다. 이 논문은 또한 AI 발전의 심각한 사회적, 경제적 영향을 탐구한다. AI 기술이 다양한 산업을 재편하고 고용 경관을 변경하며 사회 경제적 구조에 어떻게 영향을 미치고 있는지 살펴본다. 이 분석은 현대 사회에서 AI가 제기하는 기회와 도전을 모두 강조하면서 혁신과 경제 성장을 주도하는 역할을 강조하는 동시에 사회적 혼란에 대한 윤리적 의미와 잠재력을 고려한다. 향후 연구는 더 확실한 통찰력을 얻을 수 있지만 혁신과 학문적 호기심 사이의 동기적 상호 작용은 AI 진행의 특징으로 남아 있다.

한편, 그림 2와 같이 컴퓨터 과학 \(>\) 인공지능(cs.AI) 범주에서 arXiv에 게시된 사전 인쇄물의 수가 기하급수적으로 증가한 것은 AI 커뮤니티 내에서 연구 보급의 패러다임 전환을 의미하는 것으로 보인다. 연구 결과의 빠른 배포는 신속한 지식 교환을 가능하게 하지만 정보의 검증에 대한 우려도 제기한다. 사전 인쇄의 급증은 검증되지 않았거나 편향된 정보의 전파로 이어질 수 있는데, 이러한 연구는 동료 검토 출판물의 전형적인 엄격한 조사 및 잠재적 철회 과정을 거치지 않기 때문이다[16, 17]. 이러한 경향은 특히 이러한 공개 연구가 인용되고 그 결과가 전파될 가능성을 고려할 때 학계에서 신중한 고려와 비판의 필요성을 강조한다.

### _Objectives_

이 조사의 추진력은 제미니의 공식 공개와 Q* 프로젝트를 둘러싼 추측 담론이며, 이는 생성 AI 연구의 일반적인 흐름을 적시에 조사하도록 촉구한다. 이 논문은 특히 MoE, 멀티모달리티, 인공지능(AGI)이 생성적 인공지능 모델에 어떻게 영향을 미치는지 이해하는 데 기여하여 이 세 가지 핵심 영역 각각에 대한 자세한 분석과 향후 방향을 제공한다. 이 연구는 공개되지 않은 Q-Star 이니셔티브에 대한 추측을 영속화하는 것이 아니라 현재 연구 주제에서 진부하거나 중요하지 않을 가능성을 비판적으로 평가하는 동시에 빠르게 변화하는 LLM 파노라마 내에서 급증하는 전망을 탐구하는 것을 목표로 한다. 이 연구는 다양한 공격 벡터를 사용하는 데이터 도용 전략으로 랜섬웨어 수집체의 전환으로 인해 무시된 암호화 중심 또는 파일 엔트로피 기반 랜섬웨어 탐지 방법론의 구태를 연상시키며, 암호 랜섬웨어에 대한 현대 연구를 후발주자의 지위로 끌어올린다[18, 19]. 인공지능의 발전은 언어 분석 및 지식 합성의 능력을 향상시킬 뿐만 아니라 Mixture of Experts(MoE)[20, 21, 22, 23, 24, 25], 멀티모달리티[26, 27, 28, 29, 30], 인공지능(AGI)[31, 32, 10, 11]과 같은 분야에서 개척할 것으로 예상되며 이미 많은 영역에서 통계 기반 자연 언어 처리 기술의 진부화를 예고했다. 그럼에도 불구하고 AI가 인간 윤리와 가치와 일치하기 위한 영원한 명령은 기본 교리[33, 34, 35]로 지속되며 추측 Q-Star 이니셔티브는 이러한 발전이 LLM 연구 지형을 재구성할 수 있는 방법에 대한 담론을 선동할 수 있는 전례 없는 기회를 제공한다. 이러한 환경에서 짐 팬(NVIDIA의 선임 연구 과학자 및 AI 에이전트의 리더)의 Q*에 대한 통찰, 특히 학습 및 검색 알고리즘의 통합에 관한 통찰은 이러한 프로젝트의 예비 기술적 구성 및 효율성에 대한 귀중한 관점을 제공한다. 우리의 연구 방법론은 '대형 언어 모델' 및 '생성 AI'와 같은 주요 용어를 사용하여 구조화된 문헌 검색을 포함했다. IEEE Xplore, Scopus, ACM Digital Library, ScienceDirect, Web of Science, ProQuest Central과 같은 여러 학술 데이터베이스에서 필터를 사용하여 2017년("트랜스포머" 모델 출시)부터 2023년(이 원고의 작성 시간)까지의 기간에 게시된 관련 기사를 식별했다. 이 논문은 제미니와 Q*의 기술적 파급 효과를 분석하고 그들이 어떻게 (그리고 이제 출현이 불가피한 유사한 기술) 연구 궤적을 구성하고 AI 영역에서 새로운 전망을 공개할 수 있는지 조사하고자 한다. 그렇게 함으로써 우리는 생성 AI 연구 지형을 심오하게 재구성할 수 있는 MoE, 다중 모드 및 AGI의 세 가지 초기 연구 영역을 정확하게 지적했다. 이 조사는 조사 방식의 접근법을 채택하여 생성 AI의 현재 및 창발적 추세를 종합하고 분석하는 연구 로드맵을 체계적으로 매핑한다.

각주 4: [https://twitter.com/DrJimFan/status/1728100123862004105](https://twitter.com/DrJimFan/status/1728100123862004105)

본 연구의 주요 공헌점은 다음과 같다.

1. 제미니와 Q*와 같은 기술의 발전과 혁신, 그리고 AI 영역 내에서 광범위한 의미를 강조하는 생성 AI의 진화하는 경관에 대한 자세한 조사.

2. 진보된 생성 AI 시스템이 학술 연구에 미치는 변환 효과의 분석, 이러한 개발이 연구 방법론을 어떻게 변경하고, 새로운 트렌드를 설정하고, 잠재적으로 전통적인 접근법의 진부화로 이어지는지를 탐구한다.
3. 학계에서 생성 AI의 통합으로 인해 발생하는 윤리적, 사회적 및 기술적 문제에 대한 철저한 평가, 이러한 기술을 윤리적 규범과 일치시키고 데이터 프라이버시를 보장하며 포괄적인 거버넌스 프레임워크를 개발해야 하는 중요한 필요성을 강조한다.

이 논문의 나머지 부분은 다음과 같이 정리된다. II절에서는 생성 AI의 역사적 발전을 탐구한다. 섹션 III에서는 현재 생성 AI 연구의 분류법을 제시한다. 섹션 IV에서는 MoE(Mixture of Experts) 모델 아키텍처, 혁신적인 기능 및 변압기 기반 언어 모델에 미치는 영향을 조사합니다. 섹션 V에서는 Q* 프로젝트의 추측된 기능에 대해 설명한다. 섹션 VI에서는 AGI의 예상 기능에 대해 논의한다. 섹션 VII는 최근 발전이 AI 연구 분류법에 미치는 영향을 조사한다. 섹션 VIII는 생성 AI에서 새로운 연구 우선순위를 식별한다. 섹션 X에서는 AI의 사전 인쇄가 급증하는 학문적 문제에 대해 논의한다. 논문은 생성 AI의 이러한 개발의 전반적인 효과를 요약하는 섹션 XI에서 마무리한다.

## II 배경: Generative AI의 진화

생성 AI의 등장은 각 새로운 모델이 다음 진화적 도약의 길을 열어주는 중요한 이정표로 표시되었다. 단일 목적 알고리즘부터 OpenAI의 ChatGPT와 같은 LLM, 최신 멀티모달 시스템까지 AI 풍경은 변모했고, 그 외 수많은 분야는 차질을 빚었다.

### _언어 모델의 진화_

언어 모델은 변형 여정을 거쳤다(도 3). 초보적인 통계 방법에서 출발하여

도 1: 3년차별로 서로 다른 키워드를 가진 구글 학자의 검색 결과 수

도 2: arXiv.org의 cs.AI 카테고리 아래에 게시된 사전 인쇄의 연간 수

오늘날의 LLMs를 뒷받침하는 복잡한 신경망 아키텍처[36, 37]. 이 진화는 인간 언어의 뉘앙스를 더 정확하게 반영하는 모델에 대한 끊임없는 탐구와 기계가 이해하고 생성할 수 있는 것의 경계를 밀어내고자 하는 욕구에 의해 주도되었다[36, 38, 37]. 그러나 이러한 급속한 발전은 그 도전들이 없는 것이 아니었다. 언어 모델이 능력이 증가함에 따라 사용을 둘러싼 윤리적 및 안전 문제도 발생하여 이러한 모델이 어떻게 개발되고 사용되는 목적에 대한 재평가를 촉발한다[36, 39, 40].

#### Ii-B1 언어 모델 as Precursors

언어 모델링의 시작은 자연어 처리(Natural Language Processing; NLP)에서 규칙 기반에서 기계 학습 알고리즘으로의 전환으로 표시된 기간인 1980년대 후반의 통계적 접근법들로 추적될 수 있다[41, 42, 43, 44, 45]. 초기 모델은 주로 \(n\)-gram 기반으로 말뭉치에서 단어열의 확률을 계산하여 언어 구조에 대한 초보적인 이해를 제공한다[41]. 단순하면서도 획기적인 이 모델들은 언어 이해의 미래 진보를 위한 토대를 마련했다. 계산 능력의 증가와 함께 1980년대 후반은 초기 NLP 시스템을 지배했던 경직되고 '자필' 규칙 기반 시스템과 달리 '소프트' 확률적 결정이 가능한 통계 모델로 선회하는 NLP의 혁명을 목격했다[43]. IBM이 이 기간 동안 복잡한 통계 모델을 개발한 것은 이러한 접근법의 중요성과 성공이 증가하고 있음을 의미한다. 이후 10년 동안 통계 모델의 인기와 적용 가능성이 급증하여 디지털 텍스트의 번성 흐름을 관리하는 데 매우 중요했다. 1990년대에는 NLP 연구에서 통계적 방법이 확고하게 확립되었으며 n-그램은 언어 패턴을 수치적으로 포착하는 데 중요한 역할을 했다. 1997년 LSTM(Long Short-Term Memory) 네트워크의 도입과 10년 후 음성 및 텍스트 처리에 대한 적용[47, 48, 49]은 중요한 이정표를 표시하여 신경망 모델이 NLP 연구 개발의 최첨단을 나타내는 현재 시대로 이어졌다.

#### Ii-B2 대용량 언어 모델: 기술 발전과 상업적 성공

딥러닝의 등장은 NLP 분야에 혁명을 일으켜 GPT, BERT, 특히 OpenAI의 ChatGPT와 같은 LLM의 개발로 이어졌다. GPT-4 및 LLaMA와 같은 최근의 모델들은 트랜스포머 아키텍처들 및 진보된 자연 언어 이해와 같은 정교한 기술들을 통합함으로써 경계를 밀어붙였고, 이는 이 분야의 급속한 진화를 예시한다[37]. 이러한 모델은 언어 이해 및 생성에서 새로운 높이를 달성하기 위해 방대한 계산 자원과 광범위한 데이터 세트를 활용하여 NLP 능력의 상당한 도약을 나타낸다[37, 50]. 챗GPT는 출시 직후 1억 명이 넘는 사용자의 빠른 채택을 포함하여 기술 및 상업적 성공으로 입증된 바와 같이 많은 영역에서 광범위한 기능적 사용으로 인상적인 대화 기술과 맥락적 이해를 보여주었으며, 이는 자연어 AI에 대한 강력한 시장 수요를 강조하고 교육, 의료 및 상거래와 같은 분야의 응용 프로그램에 대한 학제 간 연구를 촉진했다. 교육에서 ChatGPT는 개인화된 학습 및 대화식 교육에 대한 혁신적인 접근법을 제공하는 반면(54, 51, 55, 56), 상거래에서는 고객 서비스 및 콘텐츠 생성에 혁명을 일으킨다[57, 58]. 챗GPT, Google Bard, Anthropic Claude 및 이와 유사한 상업용 LLM의 광범위한 사용은 인간과 유사한 상호 작용 능력이 상당한 윤리적 질문을 제기하고 AI 개발에서 강력한 거버넌스 및 안전 조치의 필요성을 강조하기 때문에 AI 분야, 특히 AI 의식과 안전에 관한 중요한 논쟁을 재점화했다. 이러한 영향은 기술적 성과를 넘어 우리 세계에서 AI의 역할과 미래에 대한 문화적, 사회적 논의를 형성하는 것으로 판단된다.

GPT 및 BERT와 같은 모델 개발을 포함한 LLM의 발전은 Q*의 개념화를 위한 길을 열었다. 특히, 확장 가능한 아키텍처와 이러한 모델을 특성화하는 광범위한 훈련 데이터는 Q*의 제안된 기능에 기초한다. 예를 들어 맥락 이해 및 대화형 AI에서 ChatGPT의 성공은 Q*의 설계 원리를 알려 보다 정교하고 상황 인식 및 적응형 언어 처리 능력을 향한 궤적을 제시한다. 마찬가지로 텍스트, 이미지, 오디오 및 비디오를 통합할 수 있는 제미니와 같은 멀티모달 시스템의 출현은 Q*가 확장할 수 있는 진화 경로를 반영하며 LLM의 범용성과 보다 총체적인 AI 솔루션을 위한 고급 학습 및 경로 찾기 알고리즘을 결합한다.

#### Ii-B3 미세 조정, 환각 감소 및 LLMs 정렬

LLM의 발전은 미세 조정[60, 61, 62, 63], 환각 감소[64, 65, 66, 67], 정렬[68, 69, 70, 71, 72]의 중요성을 강조했다. 이러한 측면은 LLM의 기능성과 신뢰성을 향상시키는 데 중요하다. 사전 훈련된 모델을 특정 작업에 적응시키는 것을 포함하는 미세 조정은 상당한 진전을 보였다: 전문 데이터 세트에 대한 감독된 미세 조정과 함께 프롬프트 기반 및 소수의 샷 학습[73, 74, 75, 76]과 같은 기술은 다양한 맥락에서 LLM의 적응성을 향상시켰지만, 특히 편향 완화 및 도전 과제가 남아 있다.

그림 3: 언어모델 진화의 주요 발전 시기

다양한 작업에 걸친 모델의 일반화[60, 80, 72]. 환각 감소는 자신 있지만 사실적으로 잘못된 정보의 생성을 특징으로 하는 LLM의 지속적인 도전이다[36]. 과신감을 완화하고 정확성을 향상시키기 위해 미세 조정 중 신뢰 패널티 정규화와 같은 전략이 실행되었다[81, 82, 83]. 이러한 노력에도 불구하고, 인간 언어의 복잡성과 주제의 폭은 특히 문화적으로 민감한 맥락에서 환각을 완전히 근절하는 것을 어려운 과제로 만든다[36, 9]. LLM 산출물이 인간의 가치 및 윤리와 일치하도록 보장하는 정렬은 진행 중인 연구의 영역이다. 제약된 최적화[84, 85, 86, 87, 88], 다양한 유형의 보상 모델링[89, 90, 91, 92]에 이르기까지 혁신적인 접근법은 AI 시스템 내에 인간의 선호도를 내장하는 것을 목표로 한다. 미세 조정, 환각 감소 및 정렬의 발전은 LLM을 앞으로 추진했지만 이러한 영역은 여전히 상당한 문제를 제시한다. AI를 인간 윤리의 다양한 스펙트럼과 정렬하는 복잡성과 특히 문화적으로 민감한 주제에 대한 환각의 지속성은 LLM의 개발 및 적용에 대한 지속적인 학제 간 연구의 필요성을 강조한다[9].

#### Ii-A4 혼합 Experts: Paradigm Shift

LLM에서 MoE 아키텍처의 채택은 AI 기술의 중요한 진화를 나타낸다. 구글의 스위치 트랜스포머5 및 미스트랄AI의 미스트랄-8x7B6과 같은 고급 모델로 예시된 이 혁신적인 접근법은 동적 토큰 라우팅을 위해 여러 변압기 기반 전문가 모듈을 활용하여 모델링 효율성과 확장성을 향상시킨다. MoE의 주요 이점은 방대한 파라미터 스케일을 처리할 수 있는 능력에 있으며, 메모리 풋프린트 및 계산 비용을 상당히 감소시킨다[93, 94, 95, 96, 97]. 이것은 전문 전문가들에 걸친 모델 병렬화를 통해 달성되어, 수조 개의 파라미터들을 갖는 모델들의 훈련을 허용하고, 다양한 데이터 분포들을 다루는 그것의 전문화는 적은 샷 학습 및 다른 복잡한 태스크들에서의 능력을 향상시킨다[94, 95]. MoE의 실용성을 설명하기 위해 의료 분야에서 MoE의 적용을 고려한다. 예를 들어, MoE 기반 시스템은 유전체학, 의료 영상 및 전자 건강 기록을 포함한 환자 데이터 분석의 다양한 측면을 전문으로 하는 다양한 '전문가' 모듈이 개인화된 의학에 사용될 수 있다. 이 접근법은 진단 정확도와 치료 개인화를 크게 향상시킬 수 있다. 유사하게, 금융에서 MoE 모델은 위험 평가를 위해 배치될 수 있으며, 여기서 전문가는 별개의 재무 지표, 시장 동향 및 규제 준수 요인을 분석한다.

각주 5: [https://huggingface.co/google/switch-c-2048](https://huggingface.co/google/switch-c-2048)

각주 6: [https://huggingface.com/mistralai/Mistral-8x7B-v0.1](https://huggingface.com/mistralai/Mistral-8x7B-v0.1)

이점에도 불구하고 MoE는 동적 라우팅 복잡성[98, 99, 100, 101, 102], 전문가 불균형[103, 104, 105, 106], 확률 희석[107]의 문제에 직면해 있으며 이러한 기술적 장애물은 MoE의 잠재력을 완전히 활용하기 위한 정교한 솔루션을 요구한다. 더욱이, MoE는 성능 이득을 제공할 수 있지만, AI의 윤리적 정렬 문제를 본질적으로 해결하지는 않는다[108, 109, 110]. MoE 모델의 복잡성과 전문화는 의사 결정 프로세스를 모호하게 하여 윤리적 준수 및 인간 가치와의 일치를 보장하기 위한 노력을 복잡하게 할 수 있다[108, 111]. MoE로의 패러다임 전환은 LLM 개발의 주요 도약을 의미하지만 상당한 확장성과 전문화 이점을 제공하며 이러한 모델의 안전, 윤리적 정렬 및 투명성을 보장하는 것이 가장 중요한 관심사이다. MoE 아키텍처는 기술적으로 발전했지만 AI를 광범위한 사회적 가치와 윤리적 기준과 일치시키기 위한 지속적인 학제 간 연구 및 거버넌스를 수반한다.

### _멀티모달 AI 및 상호 작용의 미래_

멀티모달 AI의 출현은 AI 개발의 변혁적 시대를 나타내며 기계가 인간의 다양한 감각 입력 및 컨텍스트 데이터와 해석하고 상호 작용하는 방식을 혁신한다.

#### Ii-B1 Gemini: 다중 모드에서 벤치마크 재정의

선구적인 멀티모달 대화 시스템인 제미니(Gemini)는 GPT-3와 같은 전통적인 텍스트 기반 LLM과 심지어 멀티모달 대응체인 ChatGPT-4를 능가함으로써 AI 기술의 상당한 변화를 나타낸다. 제미니의 아키텍처는 텍스트, 이미지, 오디오, 비디오와 같은 다양한 데이터 유형의 처리, 독특한 멀티모달 인코더, 크로스모달 어텐션 네트워크 및 멀티모달 디코더에 의해 촉진되는 위업을 통합하도록 설계되었다[112]. 제미니의 아키텍처 핵심은 이중-인코더 구조이며, 시각적 및 텍스트 데이터를 위한 별도의 인코더를 구비하여 정교한 멀티모달 상황화를 가능하게 한다[112]. 이 아키텍처는 단일-인코더 시스템의 능력을 능가하는 것으로 여겨지며, 제미니로 하여금 텍스트 개념을 이미지 영역과 연관시키고 장면에 대한 구성적 이해를 달성할 수 있게 한다[112]. 또한, Gemini는 구조화된 지식을 통합하고 교차 모달 지능을 위한 전문화된 훈련 패러다임을 채택하여 AI [112]에서 새로운 벤치마크를 설정한다. [112]에서, 구글은 몇 가지 주요 특징들을 통해 Gemini가 ChatGPT-4와 구별되는 것을 주장 및 입증하였다:

* _모달리티의 폭:_ 텍스트, 문서, 이미지 및 코드에 주로 초점을 맞춘 ChatGPT-4와 달리 Gemini는 오디오 및 비디오를 포함한 광범위한 모달리티를 처리합니다. 이 광범위한 범위를 통해 제미니는 복잡한 작업을 해결하고 실제 상황을 보다 효과적으로 이해할 수 있다.
* _성능:_ Gemini Ultra는 주요 다중 모드 벤치마크, 특히 과학, 법률 및 의학과 같은 다양한 도메인 배열을 포함하는 대규모 다중 작업 언어 이해 (MMLU)에서 ChatGPT-4를 능가하는 우수한 성능을 발휘 합니다.
* Ultra, Pro, Nano
- 데이터 센터에서 온 디바이스 작업에 이르기까지 다양한 응용 프로그램을 제공 합니다. 이는 ChatGPT-4에서 아직 볼 수 없는 유연성 수준입니다.
* _코드 생성:_ 다양한 프로그래밍 언어에 걸쳐 코드를 이해 하 고 생성 하는 Gemini의 숙련도는 ChatGPT-4의 기능을 넘어 실용적인 응용 프로그램을 제공 합니다.
* _투명성 및 설명성:_ 설명성에 중점을 두면 Gemini가 출력에 대 한 정당성을 제공 하 여 사용자 신뢰 및 AI의 추론 프로세스에 대 한 이해도를 향상 시킬 수 있기 때문에 Gemini를 구분 합니다.

이러한 발전에도 불구하고 양식에 걸쳐 상식 지식의 통합을 요구하는 복잡한 추론 작업에서 제미니의 실제 성능은 철저히 평가되어야 한다.

멀티모달 시스템에서의 Ii-B2 기술 과제

멀티모달 AI 시스템의 개발은 강력하고 다양한 데이터 세트를 만들고 확장성을 관리하며 사용자 신뢰 및 시스템 해석 가능성을 높이는 등 여러 기술적 장애물에 직면해 있다[113, 114, 115]. 데이터 획득 및 주석 문제로 인해 데이터 왜곡 및 편향과 같은 문제가 만연하며, 이는 데이터 증강, 능동 학습 및 전이 학습과 같은 전략을 사용하여 효과적인 데이터 세트 관리가 필요하다[113, 116, 80, 115]. 중요한 과제는 다양한 데이터 스트림을 동시에 처리하는 계산 요구로서, 다수의 인코더에 대한 강력한 하드웨어 및 최적화된 모델 아키텍처를 필요로 한다[117, 118]. 상이한 입력 매체들에 걸쳐 주의의 균형을 맞추고, 특히 모순된 정보를 제공할 때 모달리티들 간의 충돌을 해결하기 위해 진보된 알고리즘들 및 멀티모달 주의 메커니즘들이 필요하다[119, 120, 118]. 필요한 광범위한 계산 리소스로 인해 확장성 문제는 제한된 고성능 하드웨어 가용성으로 인해 악화된다[121, 122]. 또한, 작곡 장면 이해 및 데이터 통합을 위한 보정된 멀티모달 인코더에 대한 긴급한 요구가 있다[120]. 이러한 시스템에 대한 평가 메트릭을 정제하는 것은 포괄적인 데이터 세트와 통합된 벤치마크를 요구하는 실제 작업에서 성능을 정확하게 평가하고 멀티모달 컨텍스트에서 설명할 수 있는 AI를 통해 사용자 신뢰 및 시스템 해석 가능성을 향상시키기 위해 필요하다. 이러한 문제를 해결하는 것은 인간의 기대와 일치하는 매끄럽고 지능적인 상호 작용을 가능하게 하는 멀티모달 AI 시스템의 발전에 필수적이다.

#### Ii-B3 Multimodal AI: Beyond Text in Ethical and Social Context

멀티모달 AI 시스템의 확장은 텍스트 기반 AI가 직면한 것 이상으로 확장되는 혜택과 복잡한 윤리적, 사회적 도전을 모두 도입한다. 상거래에서, 멀티모달 AI는 시각적, 텍스트적, 청각적 데이터를 통합함으로써 고객 참여를 변화시킬 수 있다[123, 124, 125]. 자율 주행 차량의 경우, 멀티모달리티는 시각적, 레이더 및 LIDAR(Light Detection and Ranging)을 포함한 다양한 센서로부터의 데이터를 합성함으로써 안전 및 항법을 향상시킬 수 있다[126, 125, 127]. 여전히, 설득력 있게 사실적인 비디오, 오디오 및 이미지를 생성하는 딥페이크 기술의 능력은 여론, 정치 풍경 및 개인 평판에 상당한 영향을 미치는 잘못된 정보 및 조작의 위험을 제기하여 디지털 미디어의 진위를 손상시키고 진품과 AI 생성 콘텐츠를 구별하는 것이 점점 더 어려워지는 사회 공학 및 디지털 포렌식에서 문제를 제기하기 때문에 다중 모드에서 중요한 관심사이다[128, 129]. 프라이버시 우려는 다양한 데이터 소스를 처리하고 상관시키는 능력으로 인해 멀티모달 AI에서 증폭되어 잠재적으로 침입 감시 및 프로파일링으로 이어지며, 이는 특히 개인 미디어가 AI 교육 또는 콘텐츠 생성을 위해 허가 없이 사용될 때 개인의 동의 및 권리에 대한 질문을 제기한다[113, 130, 131]. 또한, 멀티모달 AI는 다양한 양식에 걸쳐 편향과 고정 관념을 전파하고 증폭할 수 있으며, 선택되지 않으면 차별과 사회적 불평등을 영속화할 수 있으므로 알고리즘 편향을 효과적으로 해결하는 것이 필수적이다[132, 133, 134]. 멀티모달 AI 시스템의 윤리적 발전은 투명성, 동의, 데이터 처리 프로토콜 및 대중의 인식에 초점을 맞춘 강력한 거버넌스 프레임워크를 필요로 하며, 윤리적 지침은 데이터 사용에 대한 표준을 설정하고 개인 정보의 비동의적 이용에 대한 보호를 포함하여 이러한 기술이 제기하는 고유한 문제를 해결하기 위해 진화해야 한다[135, 136]. 또한 AI 리터러시 프로그램의 개발은 사회가 멀티모달 AI 기술을 이해하고 책임감 있게 상호 작용할 수 있도록 돕는 데 중요할 것이다[113, 135]. 분야가 진행됨에 따라, 학제간 협업은 이러한 시스템이 사회적 가치 및 윤리적 원칙과 일치하는 방식으로 개발 및 배치되도록 하는 데 핵심이 될 것이다[113].

### _투기적 진전 및 Chronological Trends_

AI의 역동적인 풍경에서 Q* 프로젝트의 투기적 역량인 LLM, Q-러닝, A*(A-Star 알고리즘)의 혼합은 상당한 도약을 구현한다. 이 섹션에서는 게임 중심 AI 시스템에서 Q*로 예상되는 광범위한 응용 프로그램에 이르기까지 진화 궤적을 탐구한다.

#### Ii-C1 From AlphaGo's Groundtruth to QStar's Exploration

게임 중심 AI인 알파고에서 개념적 Q-Star 프로젝트까지의 여정은 AI의 중요한 패러다임 전환을 나타낸다. 바둑 게임에서 알파고의 마스터는 잘 정의된 규칙 기반 환경 내에서 딥 러닝 및 트리 검색 알고리즘의 효과를 강조하여 복잡한 전략과 의사 결정에서 AI의 잠재력을 강조했다[137, 138]. 그러나 Q-Star는 이러한 한계를 넘어 (알파고에서 볼 수 있듯이) 강화 학습의 강점을 지식, NLG, LLM의 창의성과 다양성, A*와 같은 경로 찾기 알고리즘의 전략적 효율성과 융합하는 것을 목표로 하는 것으로 추측된다. 이러한 혼합, 경로 탐색 알고리즘과 LLM을 병합하면 AI 시스템이 보드 게임을 초월하고 Q-Star의 자연어 처리와 인간 언어와 상호 작용하여 미묘한 상호 작용을 가능하게 하고 구조화된 작업과 복잡한 인간 유사 커뮤니케이션 및 추론 모두에서 AI 능숙으로 도약할 수 있다. 또한 Q-학습 및 A* 알고리즘을 통합하면 Q-Star가 의사 결정 경로를 최적화하고 상호 작용에서 학습할 수 있으므로 시간이 지남에 따라 더 적응적이고 지능적이다. 이러한 기술의 결합은 문제 해결에 더 효율적일 뿐만 아니라 접근 방식에 창의적이고 통찰력 있는 AI로 이어질 수 있다. 알파고의 게임 중심 파워에서 Q-Star의 포괄적인 잠재력으로의 이러한 사행적 발전은 AI 연구의 역동적이고 끊임없이 진화하는 특성을 보여주며, 인간의 삶과 더 통합되고 더 큰 자율성과 정교함으로 더 광범위한 작업을 처리할 수 있는 AI 응용 프로그램의 가능성을 열어준다.

#### 창의성을 활용한 Ii-C2 브리징 구조화 학습

Q-러닝과 A* 알고리즘을 LLM의 창의성과 혼합한 예상 Q* 프로젝트는 AI의 획기적인 단계를 구현하며 잠재적으로 제미니와 같은 최근의 혁신을 능가한다. Q*에서 제시한 융합은 기존의 제미니의 성취를 초월할 수 있는 조합인 생성적, 창조적 역량과 구조화된 목표 지향적 학습의 통합을 가리킨다. 제미니(Gemini)는 텍스트, 이미지, 오디오 및 비디오와 같은 다양한 형태의 데이터 입력을 결합하는 멀티모달 AI의 상당한 비약을 나타내지만 Q*는 창의적인 추론과 구조화된 문제 해결의 보다 심오한 통합을 가져올 것으로 추측된다. 이는 A*와 같은 알고리즘의 정밀도와 효율성을 Q-러닝의 학습 적응성과 LLM이 제공하는 인간 언어 및 컨텍스트에 대한 복잡한 이해와 병합함으로써 달성될 것이다. 이러한 통합은 AI 시스템이 복잡한 멀티모달 데이터를 처리하고 분석할 뿐만 아니라 인간의 인지의 다면적 특성을 반영하여 창의적인 문제 해결 및 지식 생성에 참여하면서 구조화된 작업을 자율적으로 탐색할 수 있도록 할 수 있다. 이러한 잠재적 진보의 의미는 방대하며, 제미니와 같은 현재의 복합 시스템의 능력을 넘어서는 응용 프로그램을 제안한다. 전통적인 AI 알고리즘의 결정론적 측면을 LLM의 창의적이고 생성적인 잠재력과 정렬함으로써 Q*는 AI 개발에 대한 보다 총체적인 접근법을 제공할 수 있다. 이는 AI의 논리적, 규칙 기반 처리와 인간 지능의 창의적이고 추상적인 사고 특성 사이의 격차를 해소할 수 있다. Q*의 예상되는 공개, 구조화된 학습 기술과 독창적인 문제 해결을 단수적이고 진보된 프레임워크로 병합하는 것은 제미니와 같은 시스템의 멀티모달 능력을 확장할 뿐만 아니라 크게 능가할 가능성을 가지고 있으며, 따라서 생성 AI 영역에서 또 다른 게임 변경 시대를 예고하여 AI의 지속적인 진화에서 간절히 기다리고 있는 중요한 발전으로서의 잠재력을 보여준다.

## 3. 현재 생성 AI 연구 분류

생성 AI 분야는 빠르게 발전하고 있으며, 이는 이 영역 내에서 연구의 폭과 깊이를 포괄하는 포괄적인 분류법을 필요로 한다. 표 I에 자세히 설명된 이 분류법은 생성 AI의 탐구와 혁신의 핵심 영역을 분류하고 진화하는 모델 아키텍처, 고급 교육 방법론, 다양한 응용 영역, 윤리적 시사점 및 신흥 기술의 한계를 안내하면서 현장의 현재 상태를 이해하는 기초 프레임워크 역할을 한다.

### _Model Architectures_

생성 AI 모델 아키텍처는 4가지 핵심 도메인이 돋보이는 등 상당한 발전을 보였다.

* **트랜스포머 모델:** 트랜스포머 모델은 더 높은 효율성과 확장성으로 인해 특히 NLP에서 AI 분야에 큰 혁명을 일으켰습니다. [139, 140, 141]. 그들은 향상된 컨텍스트 처리를 달성하기 위해 고급 주의 메커니즘을 채용하여, 보다 미묘한 이해와 상호 작용을 허용한다[142, 143, 144]. 이러한 모델들은 또한 EfficientViT[145, 146] 및 YOLOv8[147, 148, 149]과 같은 비전 변압기의 개발에 의해 입증된 바와 같이 컴퓨터 비전에서 주목할 만한 진전을 이루었다. 이러한 혁신은 객체 검출과 같은 영역에서 변압기 모델의 확장된 기능을 상징하여 향상된 성능뿐만 아니라 증가된 계산 효율성을 제공한다.
* **순환 신경망(RNN):** RNN은 시퀀스 모델링 영역에서 탁월하여 언어 및 시간 데이터를 포함하는 작업에 특히 효과적입니다. 그 아키텍처는 텍스트와 같은 데이터 시퀀스를 처리하도록 특별히 설계되어 입력의 컨텍스트 및 순서를 효과적으로 캡처할 수 있기 때문입니다. [150, 151, 152, 153, 154]. 순차적인 정보를 다루는 이러한 숙련도는 자연어 작업 및 시계열 분석과 같은 데이터 내의 시간 역학에 대한 깊은 이해를 필요로 하는 애플리케이션에서 그들을 필수 불가결한 것으로 만든다[155, 156]. 순서에 대한 연속성을 유지하는 RNN의 능력은 AI의 광범위한 분야, 특히 컨텍스트 및 과거 데이터가 중요한 역할을 하는 시나리오에서 중요한 자산이다[157].
* **MoE(Mixture of Experts):** MoE 모델은 여러 전문 전문가 모듈에 모델 병렬성을 배포하여 효율성을 크게 향상시킬 수 있으며, 이를 통해 이러한 모델은 동적 토큰 라우팅을 위해 변압기 기반 모듈을 활용하고 수조 개의 매개 변수로 확장할 수 있으므로 메모리 공간 및 계산 비용을 모두 줄일 수 있습니다. [94, 98]. MoE 모델은 다양한 전문가들 사이에서 계산 부하를 분할하는 능력이 두드러지며, 각각은 데이터의 상이한 양태들을 전문화하고, 이는 방대한 스케일의 파라미터들을 보다 효과적으로 핸들링할 수 있게 하여, 복잡한 태스크들의 보다 효율적이고 전문화된 핸들링을 유도한다[94, 21].
* **멀티모달 모델:** 텍스트, 비전 및 오디오와 같은 다양한 감각 입력을 통합 하는 멀티모달 모델은 복잡한 데이터 세트, 특히 의료 이미징과 같은 분야에서 변환에 대 한 포괄적인 이해를 달성 하는 데 중요 합니다. 이러한 모델들은 멀티뷰 파이프라인들 및 크로스-어텐션 블록들을 채용함으로써 정확하고 데이터 효율적인 분석을 용이하게 한다[158, 159]. 다양한 감각 입력의 이러한 통합은 데이터에 대한 보다 미묘하고 상세한 해석을 가능하게 하여 다양한 유형의 정보를 정확하게 분석하고 이해하는 모델의 능력을 향상시킨다[160]. 동시에 처리되는 상이한 데이터 유형들의 조합은 이러한 모델들이 전체론적 뷰를 제공할 수 있게 하여, 복잡한 시나리오들의 깊고 다면적인 이해를 필요로 하는 애플리케이션들에서 특히 효과적이다[113, 161, 162, 160].

### _Training Techniques_

생성 AI 모델의 훈련은 4가지 핵심 기술을 활용하며, 각각은 해당 분야에 고유하게 기여한다.

* **지도 학습:** AI의 기본 접근 방식인 지도 학습은 레이블이 지정된 데이터 세트를 사용하여 모델을 정확한 예측으로 안내하며 이미지 인식 및 NLP [163, 164, 165]를 비롯한 다양한 애플리케이션에 필수적입니다. 최근의 발전은 지도 학습 모델의 성능 및 일반화 능력을 향상시키는 것을 목표로 하는 정교한 손실 함수 및 정규화 기술을 개발하는 데 초점을 맞추고 있으며, 광범위한 작업 및 데이터 유형에 걸쳐 견고하고 효과적으로 유지되도록 한다[166, 167, 168].

* **비지도 학습:** 비지도 학습은 특징 학습 및 클러스터링과 같은 작업의 중심 프로세스인 레이블이 지정되지 않은 데이터 내에서 패턴을 밝히는 데 AI에서 필수적입니다. 이 방법은 오토인코더[171, 172]와 생성적 적대 신경망[173, 174, 175]의 도입으로 상당한 발전을 보였으며, 이는 비지도 학습의 적용 가능성을 현저하게 확장하여 보다 정교한 데이터 생성 및 표현 학습 능력을 가능하게 했다. 이러한 혁신은 종종 비정형 데이터 세트에 내재된 복잡한 구조를 이해하고 활용하는 데 중요하며, 이는 비지도 학습 기술의 다양성과 깊이를 증가시키는 것을 강조한다.
* **강화 학습:** 적응성 및 최적화 기능을 특징으로 하는 강화 학습은 의사 결정 및 자율 시스템에서 점점 더 중요해지고 있습니다 [176, 177]. 이러한 훈련 기술은 특히 심층 Q-네트워크(Deep Q-Networks; DQN)[178, 179, 180] 및 근접 정책 최적화(Proximal Policy Optimization; PPO) 알고리즘[181, 182, 183]의 개발과 함께 상당한 발전을 겪었다. 이러한 향상은 특히 복잡하고 역동적인 환경에서 강화 학습의 효과와 적용 가능성을 개선하는 데 중요했다. 상호작용 피드백 루프를 통해 의사 결정과 정책을 최적화함으로써 강화 학습은 의사 결정에 높은 수준의 적응성과 정밀도를 요구하는 시나리오에서 AI 시스템을 훈련시키는 중요한 도구로 자리매김했다[184, 185].
* **전이 학습:** 전이 학습은 AI 훈련에서 다양성과 효율성을 강조하므로 모델이 한 작업에서 얻은 지식을 다른 작업에 적용할 수 있습니다.

\begin{table}
\begin{tabular}{|p{56.9pt}|p{56.9pt}|p{113.8pt}|p{113.8pt}|} \hline
**Domain** & **Subdomain** & **Key Focus** & **Description** \\ \hline \multirow{4}{*}{\begin{tabular}{} \end{tabular} } & Transformer Models & Efficiency, Scalability & Optimizing network structures for faster processing and larger datasets. \\ \cline{2-4}  & Recurrent Neural Networks & Sequence Processing & Handling sequences of data, like text, for improved contextual understanding. \\ \cline{2-4}  & Mixture of Experts & Specialization, Efficiency & Leveraging multiple expert modules for enhanced efficiency and task-specific performance. \\ \cline{2-4}  & Multimodal Models & Sensory Integration & Integrating text, vision, and audio inputs for comprehensive understanding. \\ \hline \multirow{2}{*}{\begin{tabular}{} \end{tabular} } & Supervised Learning & Data Labeling, Accuracy & Using labeled datasets to train models for precise predictions. \\ \cline{2-4}  & Unsupervised Learning & Pattern Discovery & Finding patterns and structures from unlabeled data. \\ \cline{2-4}  & Reinforcement Learning & Adaptability, Optimization & Training models through feedback mechanisms for optimal decision-making. \\ \cline{2-4}  & Transfer Learning & Versatility, Generalization & Applying knowledge gained in one task to different but related tasks. \\ \hline \multirow{2}{*}{\begin{tabular}{} \end{tabular} } & Natural Language Understanding & Comprehension, Contextualization & Enhancing the ability to understand and interpret human language in context. \\ \cline{2-4}  & Natural Language Generation & creativity, Coherence & Generating coherent and contextually relevant text responses. \\ \cline{2-4}  & Conversational AI & Interaction, Naturalness & Developing systems for natural and contextually relevant human-computer conversations. \\ \cline{2-4}  & Creative AI & Innovation, Artistic Generation & Generating creative content, including text, art, and music. \\ \hline \multirow{2}{*}{\begin{tabular}{} \end{tabular} } & Bias Mitigation & Fairness, Representation & Addressing and reducing biases in AI outputs. \\ \cline{2-4}  & Data Security & Data Protection, Confidentiality & Ensuring data confidentiality, integrity and availability security in AI models and outputs. \\ \cline{2-4}  & AI Ethics & Fairness, Accountability & Addressing ethical issues such as bias, fairness, and accountability in AI systems. \\ \cline{2-4}  & Privacy Preservation & Privacy Compliance, Anonymization & Protecting data privacy in model training and outputs. \\ \hline \multirow{2}{*}{\begin{tabular}{} \end{tabular} } & Self-supervised Learning & Autonomy, Efficiency & Utilizing unlabeled data for model training, enhancing learning efficiency. \\ \cline{2-4}  & Meta-learning & Rapid Adaptation & Enabling AI models to quickly adapt to new tasks with minimal data. \\ \cline{2-4}  & Fine Tuning & Domain-Specific Tuning, Personalization & Adapting models to specific domains or user preferences for enhanced relevance and accuracy. \\ \cline{2-4}  & Human Value Alignment & Ethical Integration, Societal Alignment & Aligning AI outputs with human ethics and societal norms, ensuring decisions are ethically and socially responsible. \\ \hline \multirow{2}{*}{
\begin{tabular}{} \end{tabular} } & Multimodal Learning & Integration with Vision, Audio & Combining language models with other sensory data types for richer understanding. \\ \cline{2-4}  & Interactive and Cooperative AI & Collaboration, Human-AI & Enhancing AI’s ability to work alongside humans in collaborative tasks. \\ \cline{2-4}  & AGI Development & Holistic Understanding & Pursuing the development of AI systems with comprehensive, human-like understanding. \\ \cline{2-4}  & AGI Containment & Safety Protocols, Control Mechanisms & Developing methods to contain and control AGI systems to prevent unintended consequences. \\ \hline \end{tabular}
\end{table}
표 I: 현재 생성 AI 및 LLM Researchyet 관련 작업의 종합 분류법으로서, 큰 라벨링된 데이터 세트의 필요성을 상당히 감소시킨다[186, 187]. 사전 트레이닝된 네트워크의 사용을 통한 전이 학습은 모델들이 특정 애플리케이션들에 대해 효율적으로 미세 조정될 수 있게 함으로써 트레이닝 프로세스를 간소화하고, 이에 따라 다양한 태스크들에 걸쳐 적응성 및 성능을 향상시키고, 광범위한 라벨링된 데이터를 획득하는 것이 비실용적이거나 실현 가능하지 않은 시나리오들에서 특히 유익함을 증명한다[188, 189].

### _Application Domains_

Generative AI의 응용 영역은 연구 및 응용의 확립된 영역과 새로운 영역을 모두 포괄하여 현저하게 다양하고 진화하고 있다. 이러한 영역은 최근 AI 기술의 발전과 AI 응용 프로그램의 확장 범위에 의해 크게 영향을 받았다.

* **자연어 이해(NLU)**: NLU는 AI 시스템에서 인간 언어의 이해 및 맥락화를 향상시키는 데 중심적이며, 의미 분석, 명명된 개체 인식, 감정 분석, 텍스트 수반 및 기계 읽기 이해 [190, 191, 192, 193]와 같은 주요 기능을 포함합니다. NLU의 발전은 간단한 대화 교환에서 복잡한 텍스트 데이터[190, 192, 193]에 이르기까지 다양한 맥락에서 언어를 해석하고 분석하는 AI의 숙련도를 향상시키는 데 중요했다. NLU는 감성 분석, 언어 번역, 정보 추출 등과 같은 응용에서 기본이다[194, 195, 196]. 최근의 발전들은 BERT 및 GPT-3와 같은 대형 변압기 기반 모델들이 두드러지게 특징지어졌으며, 이는 언어 미묘함에 대한 더 깊고 복잡한 이해를 가능하게 함으로써 그 분야를 상당히 발전시켰다[197, 198].
* **자연어 생성(NLG)**: NLG는 챗봇, 가상 비서 및 자동화된 콘텐츠 만들기 도구에서 중요한 구성 요소인 일관성 있고 맥락적으로 관련되며 창의적인 텍스트 응답을 생성하기 위한 모델의 훈련을 강조합니다. [199, 36, 200, 201]. NLG는 토픽 모델링, 담화 계획, 개념-텍스트 생성, 스타일 전이, 제어가능한 텍스트 생성 등의 과제를 포괄한다[36, 202]. 최근 GPT-3과 같은 고급 모델로 예시된 NLG 기능의 급증은 텍스트 생성의 정교함과 뉘앙스를 크게 향상시켰으며, 이는 AI 시스템이 인간의 필기 스타일을 밀접하게 반영하는 텍스트를 생성할 수 있도록 하여 다양한 대화형 및 창의적 맥락에서 NLG의 범위와 적용 가능성을 넓혔다[203, 55, 51].
* **대화형 AI**: 이 하위 도메인은 대화 모델링, 질문 응답, 사용자 의도 인식 및 다중 회전 컨텍스트 추적에 중점을 두어 원활하고 자연스러운 상황 인식 인간-컴퓨터 상호 작용이 가능한 AI 시스템을 개발하는 데 전념합니다. [204, 205, 206, 207]. 금융 및 사이버 보안에서 AI의 예측 분석은 위험 평가와 사기 탐지를 변형시켜 보다 안전하고 효율적인 운영으로 이어졌다[205, 209]. Meena7 및 BlenderBot8과 같은 대규모 사전 훈련 모델에 의해 입증된 이 분야의 발전은 AI 상호 작용의 공감 및 반응 능력을 크게 향상시켰다. 이러한 시스템들은 사용자 참여 및 만족도를 향상시킬 뿐만 아니라, 다수의 턴들에 걸쳐 대화의 흐름을 유지하여, 일관성 있고, 맥락적으로 관련되고, 매력적인 경험들을 제공한다[208, 209]. 각주 7: [https://neptune.ai/blog/transformer-nlp-models-meena-lamda-chatbots](https://neptune.ai/blog/transformer-nlp-models-meena-lamda-chatbots)
* **창의적 AI**: 이 새로운 하위 도메인은 텍스트, 예술, 음악 등에 걸쳐 있으며 이미지, 오디오 및 비디오를 포함한 다양한 양식에 걸쳐 AI의 창의적이고 혁신적인 잠재력의 경계를 푸시합니다. 아이디어 생성, 스토리텔링, 시, 음악 구성, 시각 예술 및 창의적 작문의 애플리케이션을 포괄하여 예술적 콘텐츠의 생성에 참여함으로써 MidJourney 및 DALL-E [210, 211, 212]와 같은 상업적 성공을 거두었습니다. 이 분야의 과제는 창의성을 효과적으로 평가하고 육성하기 위해 적합한 데이터 표현, 알고리즘 및 평가 메트릭을 찾는 것이다[212, 213]. 창의적 AI는 예술적 프로세스를 자동화하고 향상시키는 도구일 뿐만 아니라 새로운 형태의 예술적 표현을 탐구하는 매개체 역할을 하여 참신하고 다양한 창의적 산출물의 창작을 가능하게 한다[212]. 이 영역은 기술과 예술의 교차점을 재정의하면서 AI의 창의적인 노력에 참여하고 기여할 수 있는 능력의 상당한 비약을 나타낸다.

각주 8: [https://blenderbot.ai](https://blenderbot.ai)

### _Compliance and Ethical Considerations_

AI 기술이 빠르게 발전하고 다양한 분야로 통합됨에 따라 윤리적 고려와 법적 준수가 점점 더 중요해지고 있으며, 이는 생성 AI에서 책임 있는 AI 개발 경향을 반영하는 우리 분류학의 새로운 범주인 '윤리적 AI 프레임워크' 개발에 중점을 두어야 한다[214, 215, 216, 217, 214]. 이러한 프레임워크는 공정성을 위한 편향 완화, 데이터 보호를 위한 개인 정보 보호 및 보안 문제, 책임성을 위한 AI 윤리와 같은 중요한 측면을 다루기 때문에 윤리적 고려 사항, 공정성 및 투명성에 중점을 두고 AI 시스템이 구축되도록 하는 데 중요하며, 따라서 AI의 책임성이 가장 중요한 진화하는 환경에 대응한다[214, 15]. 윤리적 무결성과 법적 적합성을 유지하기 위한 엄격한 접근법의 필요성은 이러한 기술의 채택에 의해 도입된 복잡성과 다각적인 도전을 반영하여 이보다 더 긴급한 적이 없다[15].

* **편향 완화:** AI 시스템의 편향 완화는 공정성과 표현을 보장하기 위한 중요한 시도이며, 편향된 관점을 피하기 위해 균형 잡힌 데이터 수집뿐만 아니라 편향을 최소화하기 위한 알고리즘 조정 및 정규화 기술을 구현하는 것도 포함됩니다. [218, 219]. AI의 예측 패턴에서 나타날 수 있는 모든 편향을 식별하고 해결하기 위해서는 지속적인 모니터링 및 편향 테스트가 필수적이다[210, 220]. 이 영역에서 중요한 과제는 교차 편향[221, 222, 223]을 다루고 이러한 편향[224, 225, 226, 227]에 기여할 수 있는 인과 관계를 이해하는 것이다.
* **데이터 보안:** AI 데이터 보안에서 주요 요구 사항 및 문제에는 데이터 기밀성 보장, 동의 규범 준수, 멤버 자격 추론 공격과 같은 취약성에 대한 보호 등이 포함됩니다. [228, 229]. 일반 데이터 보호 규정(GDPR) 및 캘리포니아 소비자 개인 정보 보호법(CCPA)과 같은 해당 관할 구역 내의 엄격한 법적 표준을 준수하는 것은 필수적이며, 목적 제한 및 데이터 최소화가 필요하다[230, 231, 232]. 또한, 데이터 주권과 저작권 문제는 강력한 암호화, 접근 제어 및 지속적인 보안 평가의 필요성을 강조한다[233, 234]. 이러한 노력은 진화하는 디지털 환경에서 AI 시스템의 무결성을 유지하고 사용자 프라이버시를 보호하는 데 중요하다.
* **AI 윤리:** AI 윤리 분야는 공정성, 책임성 및 사회적 영향에 중점을 둡니다. AI의 복잡성 증가 및 인간 가치와의 잠재적인 불일치로 인한 윤리적 도전의 급증을 해결하고 윤리적 거버넌스 프레임워크, 다학제 협력 및 기술 솔루션을 필요로 합니다. [235, 236, 214, 235]. 또한 AI 윤리는 모델 개발 수명 주기 전반에 걸쳐 추적성, 감사성 및 투명성을 보장하고 알고리즘 감사, 윤리 위원회 설립, 문서 표준 및 모델 카드 준수 등의 관행을 포함한다[237, 236]. 그러나 이러한 이니셔티브의 채택은 여전히 고르지 않으며 AI 개발 및 배치에서 포괄적이고 일관된 윤리적 관행에 대한 지속적인 필요성을 강조한다.
* **프라이버시 보존:** 이 도메인은 데이터 기밀성 및 무결성을 유지하는 데 중점을 둡니다. 특히 생성 AI의 증가로 인해 사용자 프로파일링의 위험이 발생할 때 직접 데이터 노출을 최소화하기 위해 익명화 및 연합 학습과 같은 전략을 사용합니다. [238, 239]. 이러한 노력에도 불구하고, 상관 공격에 대한 진정한 익명성을 달성하는 것과 같은 도전은 침입 감시로부터 효과적으로 보호하는 것의 복잡성을 강조한다[240, 241]. 프라이버시 법률 준수를 보장하고 안전한 데이터 처리 관행을 구현하는 것은 이러한 맥락에서 중요하며 강력한 개인 정보 보호 메커니즘에 대한 지속적인 필요성을 보여준다.

### _Advanced Learning_

자율 지도 학습, 메타 학습, 미세 조정을 포함한 고급 학습 기법이 AI 연구의 최전선에 있어 AI 모델의 자율성, 효율성, 범용성을 높이고 있다.

* **자체 지도 학습:** 이 메서드는 레이블이 지정 되지 않은 데이터를 사용 하 여 수동 레이블 지정 노력과 모델 편향을 줄입니다 [242, 165, 243]. 데이터 분산 학습 및 원래 입력 재구성[244, 245, 246]을 위한 오토인코더 및 GAN과 같은 생성 모델을 통합하고 양성 샘플 쌍과 음성 샘플 쌍을 구별하도록 설계된 SimCLR[247] 및 MoCo[248]과 같은 대조 방법도 포함한다. 또한, 이는 NLP로부터 영감을 받아, 입력 재구성을 위한 마스킹과 같은 기술을 사용하여, 최근의 비전 변압기 개발에 의해 상당히 향상된 자기-예측 전략을 채용한다[249, 250, 165]. 다양한 방법의 이러한 통합은 AI의 자율적인 훈련 능력을 발전시키는 데 있어 자기 지도 학습의 역할을 강조한다.
* **메타 학습:** 메타 학습 또는 '학습하기 위한 학습'은 제한된 데이터 샘플을 사용하여 새로운 작업 및 도메인에 빠르게 적응할 수 있는 AI 모델을 갖추는 데 중점을 둡니다. [251, 252]. 이 기술은 최적화 프로세스를 마스터하는 것을 포함하며, 데이터가 제한된 상황에서 중요한데, 이는 모델이 현재 데이터 구동 환경에서 필수적인 다양한 작업에 걸쳐 신속하게 적응하고 수행할 수 있도록 한다[253, 254]. 그것은 적은 샷 일반화에 초점을 맞추어 AI가 최소한의 데이터로 광범위한 작업을 처리할 수 있도록 하여 다재다능하고 적응 가능한 AI 시스템 개발에서의 중요성을 강조한다[255, 256, 254, 257].
* **미세 조정:** 미리 훈련된 모델을 특정 도메인 또는 사용자 환경 설정으로 사용자 지정 하 여 틈새 애플리케이션 [258, 60, 259]의 정확성 및 적절성을 향상시킵니다. 그것의 두 가지 주요 접근법은 엔코더 및 분류기의 모든 가중치를 조정하는 엔드 투 엔드 미세 조정[260, 261] 및 특징-추출 미세 조정이며, 여기서 엔코더 가중치는 다운스트림 분류기에 대한 특징을 추출하도록 동결된다[262, 263, 264]. 이 기술은 생성 모델이 특정 사용자 요구 또는 도메인 요구 사항에 더 효과적으로 적응되어 다양한 컨텍스트에 걸쳐 더 다재다능하고 적용 가능하도록 한다.
* **인간 가치 정렬:** 이 새로운 측면은 윤리적 의사 결정 프로세스의 통합 및 인간의 도덕적 가치에 부합하도록 AI 출력의 적응을 포함하는 사회적 규범 및 윤리적 표준을 준수하도록 AI 모델을 인간 윤리 및 가치와 조화시키는 데 중점을 둡니다. [265, 89, 266]. 이는 AI 시스템이 기술적으로 건전할 뿐만 아니라 윤리적, 사회적으로 책임이 있는 결정을 내릴 수 있도록 의료, 금융 및 개인 보조자와 같이 인간과 밀접하게 상호작용하는 시나리오에서 점점 더 중요해지고 있으며, 이는 사회가 신뢰하고 수용하는 AI 시스템을 개발하는 데 인간의 가치 정렬이 중요해지고 있음을 의미한다[89, 267].

### _Emerging Trends_

생성적 AI 연구의 새로운 트렌드는 기술과 인간의 상호 작용의 미래를 형성하고 있으며, 이는 보다 통합적이고 상호 작용적이며 지능적인 AI 시스템으로의 동적 전환을 나타내며 AI 영역에서 가능한 것의 경계를 향한다. 이 분야의 주요 발전은 다음과 같습니다.

* **멀티모달 학습:** 빠르게 진화하는 하위 도메인인 AI의 멀티모달 학습은 언어 이해도를 컴퓨터 비전 및 오디오 처리와 결합하여 더 풍부하고 다중 감각 컨텍스트 인식을 달성하는 데 중점을 둡니다[114, 268]. 제미니 모델과 같은 최근의 발전은 자연스러운 이미지, 오디오, 비디오 이해 및 수학적 추론을 포함한 다양한 멀티모달 태스크에서 최첨단 성능을 입증함으로써 새로운 벤치마크를 설정했다[112]. 제미니의 본질적으로 멀티모달 설계는 상이한 정보 유형들에 걸친 끊김없는 통합 및 동작을 예시한다[112]. 발전에도 불구하고 멀티모달 학습 분야는 여전히 다양한 데이터 유형을 보다 효과적으로 처리하기 위해 아키텍처를 정제하고[269, 270], 다면 정보를 정확하게 나타내는 포괄적인 데이터 세트를 개발하고[269, 271], 이러한 복잡한 시스템의 성능을 평가하기 위한 벤치마크를 설정하는 등의 지속적인 문제에 직면해 있다[272, 273].
* **대화형 및 협력 AI:** 이 하위 도메인은 복잡한 작업에서 인간과 효과적으로 협력하기 위해 AI 모델의 기능을 향상시키는 것을 목표로 합니다. [274, 35]. 이러한 추세는 인간과 함께 작동할 수 있는 AI 시스템을 개발함으로써 생산성 및 의료를 포함한 다양한 애플리케이션에서 사용자 경험과 효율성을 향상시키는 데 중점을 둔다[275, 276, 277]. 이 하위 영역의 핵심 측면은 설명 가능성[278], 인간의 의도 및 행동(마음의 이론) 이해[279, 280], AI 시스템과 인간 간의 확장 가능한 조정과 같은 영역에서 AI를 발전시키는 것으로, 다양한 맥락에서 인간의 능력을 보조하고 증가시킬 수 있는 보다 직관적이고 상호 작용하는 AI 시스템을 만드는 데 중요한 협력 접근법이다[281, 35].
* **AGI 개발:** 인간 인지의 포괄적이고 다각적인 측면을 모방 하는 AI 시스템을 만드는 비전 목표를 나타내는 AGI는 인간 인지 능력의 깊이와 폭과 밀접하게 일치 하는 전체론적 이해 및 복잡 한 추론을 위한 능력을 가진 AI 개발에 중점을 둔 하위 도메인입니다 [282, 283, 32]. AGI는 인간의 지능을 복제하는 것뿐만 아니라 다양한 작업을 자율적으로 수행할 수 있는 시스템을 만드는 것을 포함하여 인간과 유사한 적응력과 학습 능력을 보여준다[282, 283]. AGI의 추구는 AI 연구 개발의 경계를 지속적으로 밀어붙이는 장기적인 포부이다.
* **AGI 격리:** AGI 안전 및 격리는 고도의 고급 AI 시스템과 관련된 잠재적 위험을 인정하며, 이러한 고급 시스템이 기술적으로 능숙할 뿐만 아니라 인간 가치 및 사회적 규범과 윤리적으로 일치하는지 확인하는 데 중점을 둡니다. 초지능 시스템을 개발하는 방향으로 진행됨에 따라 엄격한 안전 프로토콜과 제어 메커니즘을 확립하는 것이 중요해졌다[11]. 주요 관심 분야는 표현 편향 완화, 분포 이동 해결, AI 모델 내 가짜 상관 관계 수정 등이다[11, 284]. AI 개발을 책임감 있고 윤리적인 기준과 일치시켜 의도하지 않은 사회적 결과를 방지하는 것이 목표입니다.

## IV Innovative Horizon of MoE

MoE 모델 아키텍처는 변압기 기반 언어 모델의 선구적인 발전을 나타내며, 비교할 수 없는 확장성과 효율성을 제공한다(도 4). 1조 6천억 개의 파라미터 스위치 트랜스포머[285] 및 8x7B 파라미터 믹스트라[286]와 같은 최근 모델에 의해 입증된 바와 같이, MoE 기반 설계는 다양한 언어 작업에 걸쳐 모델 규모와 성능의 프론티어를 빠르게 재정의하고 있다.

### _Core Concept and Structure_

MoE 모델은 훈련 및 추론에서 향상된 확장성과 효율성을 제공하는 신경망 설계의 상당한 혁신을 나타낸다[287, 288, 110]. 그들의 코어에서, MoE 모델들은 조밀한 계층들을 다수의 전문가 네트워크들을 포함하는 희소 MoE 계층들로 대체함으로써 희소성-구동 아키텍처를 활용하는데, 여기서 각각의 전문가는 트레이닝 데이터 또는 태스크의 특정 서브세트에 전용되고, 트레이닝 가능한 게이팅 메커니즘은 이러한 전문가들에게 입력 토큰들을 동적으로 할당함으로써, 계산 자원들을 최적화하고 태스크의 복잡성에 효과적으로 적응한다[94, 21, 110]. MoE 모델은 사전 트레이닝 속도 면에서 상당한 이점을 보여, 조밀한 모델[94, 287]을 능가한다. 그러나, 이들은 미세 조정의 난제에 직면하며, 모든 전문가를 비디오 랜덤 액세스 메모리(VRAM)에 로딩해야 하기 때문에 추론을 위해 상당한 메모리를 필요로 한다[289, 290, 110]. MoE의 구조는 전문가 라우팅을 위한 게이팅 네트워크를 포함하는 라우터 층과 변압기 층을 교대로 연결하는 것을 포함하며, 이는 문제 해결에 있어서 상당한 파라미터 스케일링 및 고급 전문화를 허용하는 아키텍처로 이어진다[291, 21].

MoE 모델의 두드러진 특징은 계산 효율의 약간의 감소만을 경험하면서 모델 용량을 천 배 이상 증폭할 수 있는 대규모 데이터 세트를 관리하는 유연성이다[289, 292]. 이들 모델의 핵심 구성요소인 희소-게이트 혼합-전문가 계층은 수많은 단순 피드-포워드 전문가 네트워크와 전문가 선택을 담당하는 훈련 가능한 게이팅 네트워크로 구성되며, 이는 각 입력 인스턴스에 대한 전문가의 동적 및 희소 활성화를 용이하게 하여 높은 계산 효율을 유지할 수 있다[293, 294, 110].

스위치 트랜스포머와 같은 MoE 모델의 최근 발전은 라우터의 지능적 능력이 지능형 라우팅의 중요한 이점을 강조했다.

그림 4: MoE의 혁신 개념도

적절한 전문가에 대 한 경로 토큰은 MoE 모델에 상당한 이점을 부여 하 여 계산 시간 상수를 유지 하 고 모델 크기를 확장할 수 있습니다 [295, 296, 297]. 실험적 증거들은 라우터들이 데이터 클러스터들에 따라 입력들을 라우팅하는 것을 학습하여, 실제 애플리케이션들에서의 가능성을 증명한다는 것을 시사한다[295, 289]. MoE 모델의 핵심 개념과 구조는 동적 라우팅 및 전문화 기능에 있으며, 신경망을 확장하고 다양한 작업에서 효율성과 적응성을 향상시키는 유망한 방법을 제공하지만 라우터의 견고성은 적대적 공격으로부터 보호되어야 한다[289, 298].

### _Training and Inference Efficiency_

MoE 모델, 특히 믹스트랄 8x7B는 고밀도 모델에 비해 우수한 사전 훈련 속도로 유명하지만 모든 전문가를 로딩해야 하기 때문에 미세 조정의 장애물에 직면하고 추론을 위해 상당한 VRAM을 요구한다[289, 290, 110]. MoE 아키텍처의 최근 발전은 특히 인코더-디코더 모델에서 주목할만한 트레이닝 비용 효율을 가져왔으며, 고밀도 모델과 비교할 때 특정 컨텍스트에서 최대 5배의 비용 절감을 보여주는 증거를 보여준다[287, 289, 298, 287]. DeepSpeed-MoE[287]와 같은 혁신은 새로운 아키텍처 설계와 모델 압축을 제공하여 MoE 모델 크기를 약 3.7배 감소시키고 추론을 최적화하여 최대 7.3배 더 나은 지연 시간과 비용 효율성을 달성했다. 특히 Lina [299]와 같은 혁신과 함께 분산된 MoE 훈련 및 추론의 진행은 텐서 분할을 강화하여 전체 통신 및 훈련 단계 시간을 향상시킬 뿐만 아니라 추론 중 자원 스케줄링을 최적화하여 훈련 단계 시간을 최대 1.73배까지 크게 줄이고 95번째 백분위수 추론 시간을 기존 시스템에 비해 평균 1.63배 낮춤으로써 전체 통신 병목 현상을 효과적으로 해결했다. 이러한 개발은 조밀한 MoE 모델에서 희박한 MoE 모델로 큰 모델 경관의 중요한 변화를 표시하여 더 적은 리소스로 더 높은 품질의 모델을 훈련시켜 AI의 잠재적 적용을 확장했다.

### _Load Balancing and Router Optimization_

효과적인 로드 밸런싱은 전문가들 사이에서 계산 부하의 균일한 분배를 보장하기 위해 MoE 모델들에서 필수적이며, MoE 계층들 내의 라우터 네트워크는 특정 토큰들을 프로세싱하기 위한 적절한 전문가들을 선택하는 것을 담당하며, 이러한 밸런스를 달성하는 데 중추적인 역할을 하며, 이는 MoE 모델들의 안정성 및 전체 성능에 기초한다[293, 289, 288, 300, 110]. 라우터 Z-손실 정규화 기술의 개발은 게이팅 메커니즘을 미세 조정함으로써 MoE 모델의 전문가 불균형을 해결하는 데 중요한 역할을 하며, 전문가에 걸친 보다 공평한 워크로드 분배를 보장하고 안정적인 트레이닝 환경을 조성하여 모델 성능을 향상시키고 트레이닝 시간 및 계산 오버헤드를 감소시킨다[301, 302]. 동시에, 전문가 역량 관리 전략의 통합은 각자가 처리할 수 있는 토큰 수에 임계값을 설정하여 개별 전문가의 처리 능력을 규제하는 MoE 모델에서 중요한 접근법으로 등장하여 병목 현상을 효과적으로 방지하고 보다 효율적이고 능률적인 모델 작동을 보장하여 복잡한 계산 작업 동안 향상된 훈련 프로세스와 향상된 성능을 제공한다[293, 303, 289].

### _Parallelism and Serving Techniques_

MoE 모델의 최근 발전은 병렬 및 서빙 기술에서 효율성을 강조하여 대규모 신경망에 상당한 영향을 미쳤다. 예를 들어, 딥스피드-MoE는 데이터 병렬, 비전문가 파라미터에 대한 텐서-슬라이싱, 전문가 파라미터에 대한 전문가 병렬과 같은 고급 병렬 모드를 도입하여, 이들의 접근법이 MoE 모델 추론에서 레이턴시와 스루풋을 모두 최적화하여, 다수의 GPU(graphics processing unit) 장치를 사용하는 생산 환경에서 확장 가능한 솔루션을 제공함에 따라 모델 효율성을 향상시킨다[287]. 다국어 태스크 및 코딩과 같은 응용 분야에서 다용도로 사용되는 MoE 모델은 단일 프레임워크 내에서 앙상블과 같은 구조로 인해 복잡한 태스크를 처리하는 데 인상적인 기능을 보여주었다[304, 305, 306]. 특히, Mixtral 및 Switch Transformer와 같은 모델은 1조 6천억 개 이상의 매개변수를 가진 100억 개 이상의 매개변수 밀도 모델에 해당하는 계산 효율을 달성했는데, 이는 MoE 계산 대 모델 크기의 비선형 스케일링의 혜택을 받아 고정된 계산 예산 내에서 상당한 정확도 이득을 가져오기 때문이다[289, 287, 110]. 또한 DeepSpeed-MoE는 모델 압축 기술을 포함하여 정확도를 유지하면서 모델 크기를 최대 3.7배까지 줄였으며, 엔드 투 엔드 MoE 학습 및 추론 솔루션은 향상된 속도와 비용 효율성을 가진 대규모 MoE 모델을 제공하는 데 도움이 되었다[287]. 이러한 혁신은 AI에서 새로운 방향을 열어 밀도가 높은 MoE 모델에서 희박한 MoE 모델로 전환하며, 더 적은 자원을 가진 더 높은 품질의 모델을 훈련하고 배치하는 것이 더 광범위하게 달성될 수 있게 된다.

### _Future Directions and Applications_

MoE 아키텍처에 대한 새로운 연구는 희소 미세 조정 기술의 발전, 명령어 튜닝 방법의 탐색, 성능 및 효율성 이득을 충분히 활용하기 위한 라우팅 알고리즘의 개선에 초점을 맞출 수 있다. 모델이 10억 개 이상의 매개변수를 확장함에 따라 MoE는 과학, 의료, 창의 및 실제 응용 프로그램에 걸쳐 능력을 크게 확장하기 위한 패러다임 전환을 나타낸다. 프론티어 작업은 정확도, 보정 및 안전을 최적화하기 위해 미세 조정 동안 하이퍼파라미터의 자동 조정을 개선하는 것을 목표로 할 수도 있다. MoE 연구는 전이 학습에 대한 전문화를 유지하면서 모델 척도 한계를 계속 밀고 있다. 적응적 희박 액세스를 통해 수천 명의 전문가를 조정하여 추론에서 개방형 도메인 대화까지 다양한 작업에 협력할 수 있습니다. 라우팅 메커니즘의 지속적인 분석은 전문가에 걸친 부하 균형을 맞추고 중복 계산을 최소화하고자 한다. AI 커뮤니티가 규모에서 MoE 방법을 추가로 조사함에 따라 이러한 모델은 언어, 코드 생성, 추론 및 멀티모달 응용 프로그램의 새로운 돌파구에 대한 가능성을 가지고 있다. 교육, 의료, 금융 분석 및 기타 분야에 걸쳐 시사점을 평가하는 데 큰 관심이 있다. 결과는 모델 최적화뿐만 아니라 조합 일반화 이면의 원리를 이해하기 위한 통찰력을 제공할 수 있다.

## V Speculated Capabilities of Q*

AI의 급성장 영역에서 예상되는 Q* 프로젝트는 잠재적인 돌파구의 등대로서 AI 능력의 풍경을 재정의할 수 있는 발전을 예고한다(그림 5).

### _Enhanced General Intelligence_

일반 지능 분야에서 Q*의 발전은 전문화된 AI에서 전체론적 AI로의 패러다임 전환을 나타내며, 이는 인간의 지능과 유사한 모델의 인지 능력의 확장을 나타낸다. 이러한 진보된 형태의 일반 지능은 다양한 신경망 아키텍처와 기계 학습 기술을 통합하여 AI가 다면 정보를 원활하게 처리하고 합성할 수 있도록 한다. T0와 같은 모델을 미러링하는 범용 어댑터 접근법은 Q*에 다양한 도메인의 지식을 빠르게 동화시키는 능력을 부여할 수 있다. 이 방법은 Q*가 적응 가능한 모듈 플러그인을 학습할 수 있도록 하여 기존 기술을 유지하면서 새로운 데이터 유형을 다루는 능력을 향상시켜 좁은 전문 분야를 종합적이고 적응적이며 다재다능한 추론 시스템으로 결합하는 AI 모델로 이어진다. 대응하는 준-수학적 공식은 다음과 같이 표현될 수 있다:

\[EGI(Q*)=\bigoplus_{i=1}^{n}(NN_{i}\odot MLT_{i}) \tag{1}\]

Where:

* \(EGI\): "Enhanced General Intelligence"
* \(NN_{i}\): 다양한 신경망 아키텍처 집합입니다.
* \(MLT_{i}\): 다양한 기계 학습 기법.
* \(\bigoplus\): 이러한 구성 요소의 통합입니다.
* \(\odot\): 신경망과 기계 학습 기술 간의 기능적 상호 작용입니다.

AI의 이러한 발전은 학제 간 혁신과 복잡한 문제 해결을 촉진하는 데 광범위한 의미와 함께 인간의 인지 유연성과 병행할 뿐만 아니라 잠재적으로 능가하는 지능의 출현을 시사한다. Q*의 추측된 능력은 복잡한 윤리적 의미와 거버넌스 문제를 야기한다. AI 시스템이 더 높은 수준의 자율성과 의사 결정에 접근함에 따라 책임 있고 투명한 AI 개발을 보장하기 위해 강력한 윤리적 프레임워크와 거버넌스 구조를 구축하는 것이 중요하다. 여기에는 고급 AI 능력과 관련된 잠재적 위험을 완화하는 것이 포함되며, AI 발전과 함께 진화하는 포괄적이고 역동적인 윤리 지침의 필요성을 강조한다.

### _Advanced Self-Learning and Exploration_

첨단 AI 개발 영역에서 Q*는 자기 학습 및 탐구 능력의 상당한 진화를 나타낼 것으로 예상된다. 알파고와 유사한 정교한 정책 신경망(NN)을 활용하지만 언어 및 추론 작업의 복잡성을 처리하기 위해 상당한 개선이 있을 것으로 추측된다. 이러한 네트워크는 정책 업데이트를 안정화하고 자율 학습의 중요한 요소인 샘플 효율성을 향상시키는 PPO(Proximal Policy Optimization)와 같은 고급 강화 학습 기술을 사용할 것으로 예상된다. 이러한 NN을 트리 또는 사상의 그래프의 새로운 반복을 잠재적으로 포함하는 최첨단 검색 알고리즘과 통합하면 Q*가 복잡한 정보를 자율적으로 탐색하고 동화시킬 수 있을 것으로 예측된다. 이 접근법은 메타 학습 용량을 강화하기 위해 그래프 신경망으로 강화되어 Q*가 이전에 획득한 지식을 유지하면서 새로운 작업 및 환경에 빠르게 적응할 수 있다. 대응하는 준-수학적 공식은 다음과 같이 나타낼 수 있다:

\[ASLE(Q*)=RL(PNN,SA)\times GNN \tag{2}\]

Where:

* \(ASLE\): "Advanced Self Learning and Exploration"
* \(RL\): 강화 학습 알고리즘, 특히 PPO(Proximal Policy Optimization)에 대한 것이다.
* \(PNN\): 언어 및 추론 작업에 맞게 조정된 정책 신경망입니다.
* \(SA\): Tree 또는 Graph of Thought와 같은 정교한 검색 알고리즘입니다.
* \(GNN\): 메타 학습을 위한 Graph Neural Networks의 통합입니다.
* \(\times\): RL과 GNN의 교차 기능 향상.

이러한 기능은 기존 데이터를 이해하는 데 국한되지 않고 새로운 지식을 적극적으로 찾고 합성하도록 장착되어 빈번한 재교육이 필요 없이 진화하는 시나리오에 효과적으로 적응하는 모델을 나타낸다. 이는 기존의 AI 모델을 뛰어넘는 도약을 의미하며, 이전에는 관리되지 않았던 자율성과 효율성 수준을 내재하고 있다.

### _Superior Human-Level Understanding_

우수한 인간 수준의 이해를 달성하려는 Q*의 열망은 알파고와 같은 시스템에서 발견되는 평가 구성요소와 병행하는 VNN(Value Neural Network)을 포함한 여러 신경망의 고급 통합에 달려 있다고 추측된다. 이 네트워크는 언어 및 추론 프로세스에서 정확성과 관련성을 평가하는 것을 넘어 인간 커뮤니케이션의 미묘함을 파고들 것이다. 모델의 깊은 이해 능력은 DeBERTa와 같은 트랜스포머 아키텍처에서 발견되는 것과 같은 고급 자연 언어 처리 알고리즘 및 기술에 의해 향상될 수 있다. 이러한 알고리즘은 Q*가 텍스트뿐만 아니라 의도, 감정 및 기본 의미와 같은 미묘한 사회 정서적 측면을 해석할 수 있도록 권한을 부여한다.

그림 5: 감정 분석과 자연어 추론을 통합한 추측 Q* 역량의 개념 다이어그램 Q*는 공감, 빈정거림 및 태도를 포함한 사회 정서적 통찰의 계층을 탐색할 수 있다. 대응하는 준-수학적 공식은 다음과 같이 표현될 수 있다:

\[SHLU(Q*)=\sum_{alg\in NLP}(VNN\oplus alg) \tag{3}\]

Where:

* \(SHLU\): "Superior Human-Level Understanding"
* \(VNN\): AlphaGo와 같은 시스템의 평가 구성 요소와 유사한 값 신경망입니다.
* \(NLP\): 고급 NLP 알고리즘 집합입니다.
* \(\oplus\): VNN 평가와 NLP 알고리즘의 결합.
* \(alg\): NLP 집합 내의 개별 알고리즘입니다.

현재 언어 모델을 능가하는 이러한 이해 수준은 공감, 상황 인식 상호 작용에서 탁월하도록 Q*를 배치하여 AI 응용 프로그램에서 개인화 및 사용자 참여의 새로운 계층을 가능하게 한다.

### _Advanced Common Sense Reasoning_

고급 상식 추론에서 Q*의 예상 발전은 정교한 논리와 의사 결정 알고리즘을 통합하여 잠재적으로 상징적 AI와 확률적 추론의 요소를 결합할 것으로 예측된다. 이 통합은 일상적인 논리에 대한 직관적인 이해와 인간의 상식과 유사한 이해로 Q*를 부여하여 인공 지능과 자연 지능 사이의 상당한 격차를 해소하는 것을 목표로 한다. Q*의 추론 능력 향상에는 CogSKR과 같은 모델과 유사한 물리학 및 소셜 엔진을 통합하는 그래프 구조화된 세계 지식이 포함될 수 있다. 물리적 현실에 기반을 둔 이 접근법은 현대 AI 시스템에서 종종 없는 일상적인 논리를 포착하고 해석할 것으로 예상된다. Q*는 대규모 지식 기반과 의미 네트워크를 활용함으로써 복잡한 사회적 및 실제 시나리오에 효과적으로 탐색하고 대응할 수 있으며, 추론 및 결정을 인간의 경험 및 기대와 더 밀접하게 정렬할 수 있다. 대응하는 준-수학적 공식은 다음과 같이 나타낼 수 있다:

\[ACSR(Q*)=LogicAI\odot ProbAI\odot WorldK \tag{4}\]

Where:

* \(ACSR\): "Advanced Common Sense Reasoning."
* \(LogicAI\) 및 \(ProbAI\): 각각 기호 AI 및 확률 추론 구성 요소입니다.
* \(WorldK\): 그래프 구조화된 세계 지식의 통합입니다.
* \(\odot\): 상식 추론을 위한 이러한 요소의 통합 연산입니다.

### _Extensive Real-World Knowledge Integration_

광범위한 실제 지식을 통합하기 위한 Q*의 접근법은 논리적 및 사실적 추론을 검증하는 강력한 기초를 제공하는 고급 공식 검증 시스템의 사용을 포함하는 것으로 추측된다. 이 방법은 정교한 신경망 아키텍처 및 동적 학습 알고리즘과 결합될 때 Q*가 기존의 AI 한계를 초월하여 현실 세계의 복잡성에 깊이 관여할 수 있게 한다. 또한 Q*는 검증을 위해 수학적 정리 증명 기술을 사용하여 추론과 출력이 정확할 뿐만 아니라 윤리적으로 근거되도록 할 수 있다. 이 프로세스에 윤리 분류기를 통합하면 신뢰할 수 있고 책임 있는 이해 및 실제 시나리오와의 상호 작용을 제공하는 능력이 더욱 강화된다. 대응하는 준-수학적 공식은 다음과 같이 나타낼 수 있다:

\[ERWKI(Q*)=FVS\otimes NN\otimes LTP\otimes EC \tag{5}\]

Where:

* \(ERWKI\): "광범위한 실세계 지식 통합"
* \(FVS\): 형식 검증 시스템입니다.
* \(NN\): 신경망 아키텍처입니다.
* \(LTP\): 논리적 및 사실적 유효성 검사를 위한 수학적 정리 증명입니다.
* \(EC\): 윤리 분류기의 통합.
* \(\otimes\): 지식 합성과 윤리적 정렬을 위한 포괄적인 통합입니다.

또한 Q*의 추측된 능력은 고용 시장과 노동 역학을 크게 재편할 가능성이 있다. Q*는 고급 기능을 통해 복잡한 작업을 자동화하여 작업 요구 사항의 전환과 새로운 기술 요구 사항의 출현으로 이어질 수 있다. 이를 위해서는 인력 전략과 교육 패러다임에 대한 재평가가 필요하며, 이는 진화하는 기술 지형과 일치하고 인력이 이러한 고급 AI 시스템과 상호 작용하고 보완할 수 있는 장비를 갖추고 있는지 확인해야 한다.

## VI Projected Capabilities of AGI

AGI는 소프트웨어 패러다임에서 인간의 인지 능력을 반영하기 위해 노력하는 AI의 변혁적 도약으로 서 있다(그림 6). AGI의 진화는 자율적 적응을 위해 정책 신경망과 정교한 강화 학습 기법을 활용하는 진보된 자가 학습 능력으로 특징지어진다. 이러한 네트워크와 Tree/Graph of Thought와 같은 알고리즘의 통합은 AGI가 다양한 도메인에 걸쳐 독립적으로 지식을 획득하고 적용할 수 있는 미래를 제시한다.

도 6: 프로젝티드 AGI 역량의 개념도

### _Revolution of Autonomous Learning_

AGI는 자기 학습과 탐구에 혁명을 일으킬 것으로 예상된다[282, 307, 283, 32]. PPO와 같은 방법들을 통합함으로써, AGI 모델들은 훈련 데이터에 대한 현재의 AI 모델들의 의존도를 초과하는 자율적인 학습 및 문제 해결 수준을 달성하도록 위치되며, 이는 진화하는 시나리오들에 응답하여 빈번한 재훈련의 필요성을 감소시키고 동적 적응을 용이하게 하는 잠재적인 패러다임 전환을 나타낸다[181, 308].

### _확장 Cognitive Abilities_

다양한 아키텍처를 통합하기 위해 고안된 AGI는 인간 인지의 다면적 특성을 복제하는 수준의 일반 지능을 약속할 수 있다[282, 309]. GPT 및 BERT와 같은 모델을 미러링하는 범용 어댑터 접근법은 다양한 정보의 신속한 동화를 촉진할 수 있으며 AGI를 인간 지성과 유사한 적응성으로 여러 도메인에 걸쳐 작업을 수행할 수 있는 시스템으로 배치할 수 있다[282, 310]. AGI의 완전한 능력은 추측으로 남아 있지만 현재 추세는 첨단 의료 진단에 대한 잠재적 적용을 시사하며, 이는 AI 기반 예측 의학 모델의 최근 돌파구로 입증되며 AGI가 의료 진단 및 치료에 혁명을 일으킬 가능성을 나타낸다.

### _승강 이해 및 상호 작용_

AGI는 변압기 아키텍처와 같은 알고리즘을 활용하여 인간 언어 및 사회 정서적 미묘함에 대한 비할 데 없는 이해를 달성할 것으로 예상되며, 이는 AGI가 복잡하고 공감하며 맥락적으로 인식되는 상호 작용에 참여할 수 있도록 하여 AI 시스템이 통신하고 상호 작용하는 방식에 혁명을 일으키는 잠재적인 응용 프로그램을 제안한다[282, 307, 311].

### _Advanced Common Sense Reasoning_

AGI에 통합된 상징적 AI와 확률적 추론은 이러한 시스템에 타고난 상식을 불어넣어 인공 지능과 자연 지능 사이의 격차를 해소하여 AGI가 인간의 사고 과정과 밀접하게 정렬된 추론을 통해 실제 시나리오에 효과적으로 탐색하고 대응할 수 있도록 할 수 있다[282, 312, 313].

### _Holistic Integration of Knowledge_

공식 검증 시스템에 의해 안내된 광범위한 실제 지식을 통합하는 AGI의 잠재력은 AGI의 산출물이 정확할 뿐만 아니라 윤리적으로 근거되는 미래 능력을 암시하며, 이는 실제 복잡성과 책임 있는 상호 작용을 위한 AGI의 능력을 시사한다[282, 311]. AGI의 예상 능력은 AGI의 고급 데이터 분석 및 예측 모델링이 환경 모니터링, 기후 패턴 예측 및 지속 가능한 솔루션 고안에서 더 우수하고 중요한 역할을 할 수 있는 기후 변화와 같은 중요한 글로벌 문제를 해결하는 데 확장되어 글로벌 생태학적 노력에 크게 기여한다[282, 283, 32].

### _AGI Development_의 도전 및 기회_

AGI의 발전은 도전과 기회를 모두 포함한다. AGI는 창의적인 분야의 생산성 향상과 교차 모드 생성 기술의 혁신을 약속하지만 데이터 편향, 계산 효율성 및 윤리적 의미와 같은 실질적인 과제는 지속된다[32, 15]. 이러한 과제는 데이터 큐레이션, 효율적인 시스템 및 사회적 영향에 초점을 맞춘 AGI 개발에서 균형 잡힌 접근을 필요로 한다[309].

AGI 개발의 맥락에서 다양한 영역의 전문가들은 현재의 AI 능력을 과대평가하지 않도록 주의하고 AGI의 이론적 틀과 오늘날의 AI의 실제 현실 사이의 격차를 강조한다[314, 32]. AGI의 구상된 자율성과 인지 능력은 현재의 AI 모델과 분리하여 AI 시스템이 인간의 개입 없이 다양한 영역에 걸쳐 작업을 수행할 수 있는 미래를 제시한다[282]. 이러한 발전 궤적은 사회에서 변혁적 세력이 되기 위한 AGI의 여정에서 윤리적 고려와 기술적 돌파구의 중요성을 강조한다[15, 32]. 진정한 AGI를 달성하기 위한 타임라인을 투영하는 것은 추측으로 남아 있지만, 잠재적인 장애물을 인식하는 것은 현재 계산 능력의 한계, 인간과 유사한 인지 능력을 복제하는 복잡성과 같이 중요하다. 이들은 책임감 있고 양심적인 발전을 보장하는 AGI 추구에서 지속적인 연구와 윤리적 고려가 필요함을 강조한다.

## VII 영향 분석 생성 AI 연구 분류

MoE, 멀티모달리티, AGI 등 첨단 AI 개발이 등장하면서 생성 AI 연구의 풍경은 상당한 변혁을 겪고 있다. 이 섹션에서는 이러한 개발이 생성 AI에서 연구 분류법을 어떻게 재편하고 있는지 분석한다.

### _영향 분석 기준_

다양한 연구 영역에 걸쳐 변혁적 변화를 선동하는 생성 AI의 지속적으로 진화하는 경관은 이러한 진보의 영향에 대한 체계적인 평가를 필요로 하며, 표 II에 자세히 설명된 일련의 기준을 설정하여 영향을 정량화하고 분류하는 분석 렌즈 역할을 하며 기술 진보와 연구 초점 영역의 진화하는 패러다임 사이의 동적 상호 작용에 깊이 뿌리를 두고 있다. 우리의 분석 프레임워크는 생성 AI 연구의 영역이 재구성되는 정도를 반영하여 창발에서 구식에 이르는 기울기 척도로 구성되었다. 5개의 별개의 클래스로 분류하는 것은 모든 영역이 균일하게 영향을 받는 것은 아니라는 것을 인정하면서 복잡한 평가를 허용한다. 이 다중 계층 접근법은 기술적 혼란의 역사적 패턴과 과학적 탐구의 적응성에 의해 알려진다.

우리의 평가 위계의 정점에서 '신흥 방향'은 진행 중인 AI 돌파구에 의해 추진되는 미지의 연구 비스트의 출현을 요약하며, 이는 추측이 아니라 AI 진화의 역사적 연속체에 기초하며, 기술력의 급증은 각각의 과학적인 수수께끼와 길을 펼친다[315, 316]. 재지정을 필요로 하는 영역'은 확립되었지만 변곡점에 있음을 발견하여 새로운 AI 패러다임을 동화시키기 위한 전략적 피벗과 규칙 기반 전문가 시스템에서 적응형 기계 학습 프레임워크로의 전환과 유사한 전통적인 방법론의 개편이 필요하다는 연구 영역을 나타낸다. 여전히 관련 있는' 분류는 지속적인 과학적 조사를 해결하거나 고유한 유연성을 통해 AI 혁신의 조류에 영향을 받지 않는 선별된 연구 영역의 끈기를 확인한다[317]. 대조적으로, '중복될 가능성이 있다'로 분류된 영역은 잠재적인 진부화에 직면하여 전략적 선견지명과 자원 재배치를 사전 과학적 침체에 초대한다[318]. 마지막으로, '고유적으로 해결할 수 없는' 과제는 인간 윤리와 문화적 다양성의 복잡한 웹에 뿌리를 두고 해결을 거부하는 AI 연구 내의 영구적인 문제를 환기시키는 역할을 하여 인간의 가치와 사회적 명령의 다루기 힘든 태피스트리 내에 AI 추구를 고정시킨다[319, 320].

### _영향 분석 개요_

이 세부 섹션은 MoE, 다중 모드 및 AGI의 최근 진전에 특정한 초점을 두고 생성 AI 영역 내에서 연구 분류법에 대해 수행된 영향 분석에 대한 자세한 개요를 제공하며, 모델 아키텍처에서 정교한 학습 방법론에 이르기까지 생성 AI 연구의 다양한 측면에 대한 이러한 혁신적인 개발의 영향을 평가하는 것을 목표로 하며 LLM 연구의 여러 영역과 하위 영역에 걸친 정량적 및 정성적 평가를 모두 포함하여 각 영역이 이러한 기술 발전에 의해 영향을 받는 정도를 조명한다. 이 평가는 새로운 연구 방향의 출현, 기존 연구 영역의 리디렉션 필요성, 특정 방법론의 지속적인 관련성, 기타의 잠재적 중복성 등의 요인을 고려하여 <표 Ⅲ>에 요약하였다.

#### Iv-B1 Impact On Model Architecture

변환기 모델은 MoE와 AGI에서 모두 4의 리디렉션 요구 사항(\(\hookrightarrow\))과 멀티모달리티에서 3의 관련성(\(\leftrightarrow\))으로 점수를 매겨 전체 점수 11을 얻었다. 이러한 모델은 현재 많은 AI 아키텍처의 백본을 형성하는 복잡한 입력 시퀀스를 처리하는 데 계속 관련이 있다. 그러나 MoE 및 AGI의 출현은 보다 역동적이고 전문화된 아키텍처로의 전환을 나타낸다. 변압기는 여전히 필수적이지만, 향상된 성능 및 적응성을 위해 이러한 고급 시스템과 진화 및 통합될 필요가 있다.

반복 신경망은 MoE와 AGI 문맥에서 중복(\(\searrow\)) 2가 될 가능성이 있고 다중 모드에서는 여전히 관련성(\(\leftrightarrow\)) 3이 되어 총 7점이라는 점수로 인해 관련성의 잠재적인 하락에 직면해 있다. 시퀀스 처리에 효과적이지만, RNN은 변압기와 같은 새로운 모델에 비해 장거리 종속성과 낮은 효율성을 처리하는 데 한계가 있다. 그들은 순차적 데이터를 포함하는 멀티모달 태스크에서 일부 관련성을 유지할 수 있지만 일반적으로 더 진보된 아키텍처에 의해 가려진다.

MoE 모델은 자체 개발에서 일관된 관련성(\(\leftrightarrow\))이 3점, 다중 모드에서 5점(\(\nearrow\))이 AGI 맥락에서 4점(\(\hookrightarrow\))과 결합하여 전체 점수 12점에 달한다. MoE 모델은 다양한 데이터 유형을 다루는 능력으로 인해 다중 모드에서 새로운 연구의 최전선에 있다. AGI의 경우 이러한 모델은 특히 초기 전문화를 넘어서는 영역에서 일반 지능을 나타내는 시스템에 효과적으로 통합하기 위한 조정이 필요하다.

멀티모달 모델은 MoE와 AGI 맥락 모두에서 5점(\(\nearrow\))의 새로운 연구 방향에 대해 높은 점수를 받았고, 멀티모달성의 현재 관련성에 대해 3점(\(\leftrightarrow\))의 점수를 받아 전체 13점으로 정점을 이루었다. MoE의 통합과 AGI 추구는 멀티모달 모델의 연구를 위한 새로운 경로를 열고 있다. 이러한 개발은 전문화된 AI 시스템과 일반화된 AI 시스템 모두의 핵심 측면인 여러 모달리티에서 정보를 처리하고 합성하는 능력을 향상시키는 데 중요하다.

#### Iv-B2 Impact On Training Techniques

지도 학습은 4의 리디렉션 점수(\(\hookrightarrow\))와 다중 모드에서 3의 관련성 점수(\(\leftrightarrow\)) 및 AGI의 맥락에서 2의 잠재적 중복성(\(\searrow\))을 나타내는 점수가 할당되어 전체 점수 9로 정점을 이룬다. 지도 학습은 MoE 프레임워크에 맞게 적응해야 하지만 레이블이 지정된 데이터에 의존하는 다중 모드 AI 모델과 관련이 있다. 그러나 AGI에서 보다 자율적인 학습 방법으로 전환됨에 따라 일반적으로 지도 학습과 관련된 광범위한 레이블 데이터 세트에 대한 의존도가 감소하여 중요성이 감소할 수 있다.

\begin{table}
\begin{tabular}{|c|p{142.3pt}|p{142.3pt}|p{142.3pt}|} \hline
**Symbol** & **Criteria** & **Score** & **Definition** & **Justification** \\ \hline \(\nearrow\) & Emerging Direction & 5 & New research areas expected to arise as a direct consequence of AI advancements. & Emphasizes novel research domains emerging from AI breakthroughs [315, 316]. \\ \hline \(\hookrightarrow\) & Requiring Redriction & 4 & Areas that need to shift focus or methodology to stay relevant with new AI developments. & Technological shifts necessitate reevaluation and redirection in AI research [315, 317]. \\ \hline \(\leftrightarrow\) & Still Relevant & 3 & Areas where the advancements have minimal or no impact, maintaining their current status and methodologies. & Observes the persistence of certain AI research areas despite technological advancements [317]. \\ \hline \(\searrow\) & Likely to Become & 2 & Areas that may lose relevance or become obsolete with the advent of new AI technologies. & Discusses rapid obsolescence in AI methodologies due to new technologies [318]. \\ \hline \(\triangle\) & Inherently Unresolvable & 1 & Challenges that may remain unresolved due to complexities like subjective human perspectives and diverse cultural values. & Inherent difficulties in issues such as aligning AI with diverse human values and ethics [319, 320]. \\ \hline \end{tabular}
\end{table} TABLE II: Criteria for Analyzing Impact on Generative AI ResearchUnsupervised Learning scores a redirection requirement (\(\rightarrow\)) of 4 in both MoE and AGI contexts and maintains its relevance (\(\leftrightarrow\)) with a score of 3 in multimodality, resulting in a total score of 11. In the MoE architecture, unsupervised learning methods may need adjustments, particularly in managing dynamic task allocation. It remains crucial for understanding unlabeled data across various modalities. In AGI, unsupervised learning is expected to evolve beyond traditional techniques, focusing on more advanced self-discovery and intrinsic learning mechanisms.

강화학습은 MoE에서 3점, 멀티모달리티에서 4점, 리디렉션(\(\rightarrow\))이 필요한 것으로 평가되고, AGI에서 5점으로 새로운 연구 영역(\(\nearrow\))으로 식별되어 총 12점을 제공한다. 이 기술은 MoE 모델 구조를 최적화하는 데 계속해서 중요한 역할을 한다. 멀티모달리티 영역에서는 서로 다른 모달리티 간의 복잡한 상호 작용을 효과적으로 관리하기 위한 전략적 전환이 필요하다. AGI는 강화학습이 특히 자신의 환경에서 학습하는 자율시스템 개발에서 중요한 영역으로 부상하고 있다.

전이학습은 MoE에서 일관성 있는 관련성 점수(\(\leftrightarrow\)) 3점, 멀티모달리티에서 새로운 연구 방향(\(\nearrow\)) 5점, AGI에서 리디렉션 요구 사항(\(\rightarrow\)) 4점을 받아 전체 점수 12점으로 누적된다. 멀티모달 상황에서 전이 학습은 서로 다른 양식 간의 학습 전이를 용이하게 하기 때문에 점점 더 중요해지고 있다. AGI의 진화와 함께 이 기술은 더 광범위하고 일반화된 지식 응용 프로그램을 수용하기 위해 상당한 변화를 겪을 것으로 예상된다.

#### Vi-B3 영향 애플리케이션 도메인

자연어 이해는 MoE와 멀티모달리티 모두에서 3점, AGI에서 떠오르는 방향(\(\nearrow\)) 점수는 5점으로 총 11점으로 일관성이 있다. MoE 모델은 크고 다양한 데이터 세트를 처리할 수 있는 능력을 통해 정확성과 깊이를 향상시켜 NLU의 관련성을 지원한다. 멀티모달 AI에서 NLU는 다양한 데이터 형식의 언어를 이해하는 데 중요한 구성 요소로 남아 있다. AGI의 발전으로 NLU는 보다 발전된 인간다운 이해 및 해석 능력으로 나아가면서 상당한 확장을 겪을 것으로 예상된다.

자연 언어 생성은 MoE에서 3점으로 관련성(\(\leftrightarrow\))을 유지하고, 멀티모달리티에서 4점으로 리디렉션(\(\rightarrow\))을 요구하며, AGI에서 5점으로 새로운 연구 영역(\(\nearrow\))으로 식별되어 총 12점으로 구성된다. MoE의 확장성은 NLG를 향상시키는 데 중요하지만 멀티모달 컨텍스트에서는 NLG가 다른 모달리티와 효과적으로 정렬하기 위한 전략적 조정이 필요할 수 있다. AGI가 진화함에 따라 NLG는 특히 인간과 유사한 창의성과 적응력을 반영하는 콘텐츠를 만드는 데 새로운 연구 영역에 진출할 것으로 예상된다.

대화형 AI는 MoE에서 4점으로 리디렉션(\(\rightarrow\))이 표시되고, 멀티모달리티와 AGI 모두에서 5점으로 새로운 연구 방향(\(\nearrow\))이 표시되며, 전체 점수는 14점이다. MoE는 대화형 AI를 향상시키지만 MoE의 분산된 전문 지식을 충분히 활용하기 위해서는 전략적 변화가 필요할 수 있다. 여러 모달리티의 통합은 대화형 AI의 새로운 길을 열어 다양한 감각 데이터를 포함하도록 범위를 확장한다. AGI의 개발은 이 영역에서 혁명적인 발전을 가져와 보다 자율적이고 상황 인식적이며 인간과 유사한 상호 작용을 위한 길을 열도록 설정되었다.

창의적 인공지능은 4의 리디렉션 요구 사항(\(\rightarrow\))을 점수화한다.

\begin{table}
\begin{tabular}{|l|l|c|c|c|c|} \hline
**Domain** & **Subdomain** & **MoE** & **Multimodality** & **AGI** & **Overall Score** \\ \hline \multirow{2}{*}{Model Architecture} & Transformer Models & \(\hookrightarrow\) (4) & \(\leftrightarrow\) (3) & \(\hookrightarrow\) (4) & 11 \\ \cline{2-6}  & Recurrent Neural Networks & \(\searrow\) (2) & \(\leftrightarrow\) (3) & \(\searrow\) (2) & 7 \\ \cline{2-6}  & Mixture of Experts & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & \(\hookrightarrow\) (4) & 12 \\ \cline{2-6}  & Multimodal Models & \(\nearrow\) (5) & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & 13 \\ \hline Training Techniques & Supervised Learning & \(\hookrightarrow\) (4) & \(\leftrightarrow\) (3) & \(\searrow\) (2) & 9 \\ \cline{2-6}  & Unsupervised Learning & \(\hookrightarrow\) (4) & \(\leftrightarrow\) (3) & \(\hookrightarrow\) (4) & 11 \\ \cline{2-6}  & Reinforcement Learning & \(\leftrightarrow\) (3) & \(\hookrightarrow\) (4) & \(\nearrow\) (5) & 12 \\ \cline{2-6}  & Transfer Learning & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & \(\hookrightarrow\) (4) & 12 \\ \hline Application Domains & Natural Language Understanding & \(\leftrightarrow\) (3) & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & 11 \\ \cline{2-6}  & Natural Language Generation & \(\leftrightarrow\) (3) & \(\hookrightarrow\) (4) & \(\nearrow\) (5) & 12 \\ \cline{2-6}  & Conversational AI & \(\hookrightarrow\) (4) & \(\nearrow\) (5) & \(\nearrow\) (5) & 14 \\ \cline{2-6}  & Creative AI & \(\hookrightarrow\) (4) & \(\nearrow\) (5) & \(\nearrow\) (5) & 14 \\ \hline Compliance and Ethical Considerations & Bias Mitigation & \(\hookrightarrow\) (4) & \(\hookrightarrow\) (4) & \(\nearrow\) (5) & 13 \\ \cline{2-6}  & Data Security & \(\leftrightarrow\) (3) & \(\leftrightarrow\) (3) & \(\leftrightarrow\) (3) & 9 \\ \cline{2-6}  & AI Ethics & \(\hookrightarrow\) (4) & \(\hookrightarrow\) (4) & \(\triangle\) (1) & 9 \\ \cline{2-6}  & Privacy Preservation & \(\hookrightarrow\) (4) & \(\hookrightarrow\) (4) & \(\hookrightarrow\) (4) & 12 \\ \hline Advanced Learning & Self-supervised Learning & \(\hookrightarrow\) (4) & \(\nearrow\) (5) & \(\leftrightarrow\) (3) & 12 \\ \cline{2-6}  & Meta-learning & \(\leftrightarrow\) (3) & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & 11 \\ \cline{2-6}  & Fine Tuning & \(\leftrightarrow\) (3) & \(\leftrightarrow\) (3) & \(\searrow\) (2) & 8 \\ \cline{2-6}  & Human Value Alignment & \(\triangle\) (1) & \(\triangle\) (1) & \(\triangle\) (1) & 3 \\ \hline Emerging Trends & Multimodal Learning & \(\nearrow\) (5) & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & 13 \\ \cline{2-6}  & Interactive and Cooperative AI & \(\hookrightarrow\) (4) & \(\leftrightarrow\) (3) & \(\nearrow\) (5) & 12 \\ \cline{2-6}  & AGI Development & \(\hookrightarrow\) (4) & \(\Rightarrow\) (4) & \(\leftrightarrow\) (3) & 11 \\ \cline{2-6}  & AGI Containment & \(\triangle\) (1) & \(\triangle\) (1) & \(\nearrow\) (5) & 7 \\ \hline \end{tabular}
\end{table}
표 III: MoE, 멀티모달리티 및 AGI가 생성 AI ResearchMoE에 미치는 영향, 멀티모달리티 및 AGI 모두에서 5의 신흥 연구 방향(\(\nearrow\))에 대한 높은 점수, 총 14로 이어진다. MoE의 맥락에서, 창조 AI는 신규 콘텐츠를 생성하기 위한 MoE의 능력을 활용하기 위해 재정렬될 필요가 있을 수 있다. 창의적인 AI에서 다양한 양식의 조합은 흥미진진한 새로운 연구 기회를 제공하여 보다 복잡하고 다양한 산출물의 생성을 가능하게 한다. AGI가 진행됨에 따라 창의적인 AI의 역량을 대폭 넓혀 잠재적으로 기존 경계를 뛰어넘고 창의성의 새로운 영역을 개척할 수 있을 것으로 기대된다.

#### V-B4가 준수 및 윤리적 고려 사항에 미치는 영향

MoE, 멀티모달리티 및 AGI의 맥락에서 편향 완화는 MoE와 멀티모달리티 모두에서 4의 리디렉션 요구 사항(\(\rightarrow\))과 AGI에서 5의 새로운 연구 방향(\(\nearrow\))을 점수화하여 전체 점수가 13이다. MoE 아키텍처는 전문가 네트워크의 다양성으로 인해 편향 완화에 대한 새로운 접근법을 요구하며, 그렇지 않으면 편향을 증폭할 수 있다. 멀티모달 시스템에서 편향 완화는 이미지 및 오디오와 같은 비텍스트 형태를 포함하여 다양한 데이터 유형의 편향을 해결하기 위한 새로운 전략을 필요로 한다. AGI의 광범위한 인지 능력으로 다양한 영역에 걸친 편향을 이해하고 해결하기 위한 포괄적인 접근법이 중요한 연구 영역으로 부상하고 있다.

데이터 보안은 MoE, 멀티모달리티, AGI에서 3점으로 일관된 관련성(\(\leftrightarrow\))을 유지하여 총 9점으로 이어진다. 데이터 보안의 기본 원칙은 MoE의 발전에도 불구하고 여전히 중요하며, 이는 분산 특성을 위한 맞춤형 전략이 필요할 수 있다. 멀티모달 AI에서 다양한 데이터 유형의 보안 처리가 계속해서 가장 중요하다. 데이터 보안의 핵심 교리는 AGI의 발전에도 지속되지만 보안 조치의 복잡성과 범위는 증가할 가능성이 높다.

AI 윤리는 MoE와 멀티모달리티 모두에서 4점으로 리디렉션(\(\rightarrow\))에 표시되고, AGI에서 1점으로 본질적으로 해결되지 않는 도전(\(\triangle\))에 직면하여 총 9점을 누적한다. MoE 모델의 의사 결정 과정과 투명성은 윤리적 고려 사항에 대한 재평가가 필요하다. 멀티모달 AI에서 윤리적 문제, 특히 멀티모달 데이터의 해석과 사용에 있어 새로운 접근법이 필요하다. AGI의 윤리적 과제는 복잡할 것으로 예상되며 완전히 해결하기 어려울 수 있는 깊은 철학적, 사회적 의미를 포함한다.

프라이버시 보존은 MoE, 멀티모달리티 및 AGI에 걸쳐 4의 리디렉션 요구(\(\leftrightarrow\))를 점수화하여 전체 12의 점수를 얻는다. MoE 시스템의 분산된 특성은 여러 전문가가 처리한 데이터를 처리하기 위해 프라이버시 보존 기술에 대한 재평가가 필요하다. 멀티모달 AI 시스템, 특히 이미지 및 사운드와 같은 민감한 데이터를 처리하는 시스템은 맞춤형 개인 정보 보호 전략을 필요로 한다. AGI의 광범위한 데이터 처리 기능을 통해 개인 정보 보호에 대한 고급적이고 잠재적으로 새로운 접근법이 필요하다.

#### V-B5 Impact on Advanced Learning

MoE의 맥락에서 자기 지도 학습은 4점의 점수로 리디렉션(\(\rightarrow\))이 필요하며, 이는 진화하는 아키텍처에 적응할 필요성을 나타낸다. 5점의 새로운 연구 방향(\(\nearrow\))은 다중 모드에서 식별되어 텍스트, 이미지 및 오디오와 같은 다양한 자율 데이터 유형의 통합을 제안한다. AGI의 경우 자가 지도 학습은 3점으로 관련성이 있으며(\(\왼쪽 오른쪽\)) 시스템의 자율성과 적응성에 기여하지만 더 복잡한 전략과 통합될 가능성이 있다. 전체 영향 점수는 12입니다.

메타 학습은 MoE와 멀티모달리티에 걸쳐 3점으로 일관된 관련성(\(\leftrightarrow\))을 유지하여 MoE의 동적 특성과 잘 일치하고 멀티모달 컨텍스트에서 다양한 데이터 유형 및 작업에 빠르게 적응하는 것을 돕는다. AGI에서는 5점으로 새로운 연구 방향(\(\nearrow\))으로 표시되어 인간과 유사한 적응성과 학습 효율성을 달성하는 새로운 연구를 제안한다. 메타 학습 총점은 11점입니다.

미세 조정은 MoE와 멀티모달리티 모두에서 3점으로 계속 관련이 있으며, 사전 훈련된 모델을 특정 작업에 적용하고 멀티모달 모델을 조정하는 데 필수적이다. 그러나 AGI는 광범위한 도메인에 걸쳐 자율적으로 이해하고 학습하는 시스템을 개발하여 전통적인 미세 조정 프로세스의 필요성을 줄이는 것을 목표로 하기 때문에 AGI에서는 2점으로 중복(\(\searrow\))될 가능성이 높다. 미세 조정을 위한 전체 충격 점수는 8입니다.

AI를 인간의 가치와 일치시키는 것은 MoE, 멀티모달리티, AGI의 모든 맥락에서 본질적으로 해결할 수 없는 도전(\(\triangle\))을 1점으로 한다. 이는 MoE 모델이 다루는 작업의 복잡성과 다양성, 멀티모달 AI에서 다양한 데이터 유형의 통합, AGI가 포괄하는 광범위한 인지 능력을 반영한다. 이러한 요인은 AI를 인간 가치와 일치시키는 데 있어 중요한 진행 중인 도전에 기여하여 총 점수가 3점이다.

#### V-B6이 새로운 경향에 미치는 영향

멀티모달 학습은 텍스트, 이미지 및 오디오와 같은 다양한 데이터 유형을 통합하는 능력을 반영하여 MoE 및 AGI 컨텍스트 모두에서 5점으로 새로운 연구 방향(\(\nearrow\))으로 표시된다. 이러한 통합은 MoE의 전문 작업과 AGI의 다양한 형태의 데이터 처리에 중요하다. 멀티모달리티의 영역에서는 3점의 핵심 측면(\(\leftrightarrow\))으로 남아 있어 지속적인 멀티모달 AI 개발에 필수적이다. 전체 영향 점수는 13입니다.

대화형 및 협동 AI는 MoE 모델이 광범위한 적용을 위해 더 많은 대화형 요소를 포함하도록 적응하기 때문에 점수가 4인 MoE에서 리디렉션(\(\hookrightarrow\))이 필요하다. 다중 모드에서 상호작용과 협력은 특히 로봇 공학 및 가상 비서와 같은 분야에서 3점으로 계속 중심(\(\leftrightarrow\))이다. AGI의 진화는 대화형 AI의 상당한 발전을 포함하며, 5점의 새로운 연구 영역(\(\nearrow\))으로 표시한다. 이러한 경향의 총점은 12점이다.

AGI의 개발은 MoE와 다중 모드 모두에서 리디렉션(\(\rightarrow\))이 필요하며, 각각은 4점이며, 이는 보다 통합되고 복잡한 시스템이 필요함을 나타낸다. AGI는 3점으로 자신의 필드(\(\leftrightarrow\))의 최전선에 남아 있으며, 각각의 돌파구는 그 진행에 직접적인 영향을 미친다. AGI 개발을 위한 전체 영향 점수는 11이다.

AGI 격리는 MoE 및 다중 모드 모두에서 풀 필요가 없는 도전으로 식별되며, 이러한 영역은 AGI와 관련된 자율성 및 복잡성 수준에 도달하지 않을 것으로 예상되기 때문에 점수가 1이다. 그러나 AGI가 진행됨에 따라 효과적인 봉쇄 전략에 대한 새로운 필요성이 5점으로 표시(\(\nearrow\))되어 안전하고 통제된 AI 배치 보장의 중요성을 강조한다. 총 영향 점수는 7입니다.

## VIII 생성 AI의 최신 연구 우선 순위

Q*의 출현으로 표시된 새로운 시대의 벼랑 끝에 접근하여 사용 가능한 AGI의 실현에 더 가까이 다가갈 가능성이 높기 때문에 생성 AI의 연구 지형은 중요한 변화를 겪고 있다.

### _MoE_의 최신 연구 우선 순위

MoE 도메인은 점점 더 두 가지 중요한 영역에 초점을 맞추고 있다:

* **모델 아키텍처에서 다중 모드 모델:** MoE와 AGI의 통합은 다중 모드 모델에서 연구를 위한 새로운 경로를 열고 있습니다. 이러한 발전은 전문화된 AI 시스템과 일반화된 AI 시스템 모두에 중요한 여러 모달리티에서 정보를 처리하고 합성하는 능력을 향상시키고 있다.
* **신흥 추세에서 멀티모달 학습:** MoE는 전문 작업을 위해 텍스트, 이미지 및 오디오와 같은 다양한 데이터 유형을 통합 하 여 멀티모달 학습의 최전선에 있습니다. 이러한 추세는 현장의 향상에 직접적인 영향을 미치고 있다.

또한, AI 연구의 자금 동향 및 투자 패턴에 대한 분석에서는 MoE의 멀티모달 모델과 같은 영역으로 상당한 전환을 나타낼 수 있다. 복잡한 데이터 처리 및 자율 시스템을 포함하는 분야로 자본 흐름이 증가하는 것이 특징인 이러한 경향은 향후 연구 우선 순위의 방향을 형성하고 있다. 그것은 학문 및 산업 주도 이니셔티브 모두에 영향을 미치는 생성 AI의 잠재력에 대한 증가하는 관심과 투자를 강조한다.

### _멀티모달리티에서 최신 연구 우선 순위_

멀티모달리티의 영역에서 몇 가지 영역이 새로운 연구 우선순위로 식별된다.

* **모델 아키텍처에서 MoE:** MoE 모델은 멀티모달 컨텍스트에서 다양한 데이터 형식을 처리하는 데 점점 더 적합해지고 있습니다.
* **훈련 기술에서 학습 전달:** 전이 학습은 특히 다른 양식 간의 학습에 대한 핵심 연구 방향으로 부상하고 있습니다.
* **애플리케이션 도메인의 대화형 AI 및 크리에이티브 AI:** 대화형 AI 및 크리에이티브 AI는 모두 시각, 청각 및 기타 감각 데이터 통합을 포함하여 멀티모달 컨텍스트에서 확장되고 있습니다.
* **고급 학습에서 자체 지도 학습:** 자율적으로 다양한 데이터 유형의 통합을 중심으로 자체 지도 학습의 새로운 연구 방향이 등장하고 있습니다.

또한, 특히 멀티모달 상황에서 생성 AI의 증가는 교육 커리큘럼과 기술 개발에 상당한 영향을 미칠 수 있다. 멀티모달 AI 기술을 중심으로 포괄적인 AI 리터러시를 포함하도록 학술 프로그램을 업데이트해야 할 필요성이 커지고 있다. 이러한 교육의 진화는 AI의 복잡성과 혁신을 탐색하는 데 필요한 기술을 갖추고 AI의 발전에 효과적으로 참여하고 활용하도록 미래의 전문가를 준비하는 것을 목표로 한다.

### _AGI_ 의 최신 연구 우선 순위

AGI 도메인은 여러 분야에서 연구 우선순위가 급증하는 것을 목격하고 있다.

* **모델 아키텍처의 다중 모드 모델:** MoE와 마찬가지로 다중 모드 모델은 AGI에서 중요하므로 더 깊고 미묘한 이해를 가능하게 합니다.
* **훈련 기술의 강화 학습:** AGI의 핵심 영역으로 등장 하는 강화 학습은 환경에서 자율 시스템 학습을 개발 하는 데 중점을 둡니다.
* **애플리케이션 도메인:** AGI는 인간과 유사한 이해 및 창의성에 중점을 두고 자연어 이해 및 생성, 대화형 AI 및 창의적 AI의 경계를 확장합니다.
* **준수 및 윤리적 고려 사항의 편향 완화:** 편향 완화의 새로운 방향은 AGI의 다양한 도메인에 대한 편향을 해결하기 위한 포괄적인 접근 방식에 중점을 두고 있습니다.
* **Advanced Learning에서 메타 학습:** AGI의 인간 유사 적응성 추구는 메타 학습에서 새로운 연구로 이어집니다.
* **신흥 추세:** AGI가 진행됨에 따라 멀티모달 학습, 대화형 및 협력 AI 및 AGI 봉쇄 전략이 중요한 연구 영역이 되고 있습니다.

이러한 AGI의 발전에 따라 AI 연구 자금 및 투자 패턴에서 눈에 띄는 추세가 분명하다. 특히 자연어 이해 및 생성, 자율 시스템과 같은 분야에서 AGI의 프로젝트 및 연구를 지원하는 경향이 있다. 이러한 자금 흐름은 AGI의 역량에 대한 관심이 고조되는 것을 반영할 뿐만 아니라 향후 연구의 궤적을 지시하여 학술 탐색과 산업 주도 프로젝트를 모두 형성한다.

## IX 실용적 시사점 및 Generative AI 기술 한계

MoE, 다중 모드 및 AGI를 포함하는 생성 AI 기술은 고유한 계산 문제를 제시한다. 이 섹션에서는 이러한 고급 AI 모델에 내재된 처리 능력 요구 사항, 메모리 사용량 및 확장성 문제를 탐구합니다.

### _Computational Complexity and Realworld Applications of Generative AI Technologies_

#### Ix-A1 Computational Complexity

MoE, 다중 모드 및 AGI를 포함하는 생성 AI 기술은 고유한 계산 문제를 제시한다. 이 섹션에서는 이러한 고급 AI 모델에 내재된 처리 능력 요구 사항, 메모리 사용량 및 확장성 문제를 탐구합니다.

* **처리 전력 요구 사항**: MoE 아키텍처 및 AGI 시스템을 포함한 고급 생성 AI 모델에는 상당한 처리 전력이 필요합니다 [321]. GPU 및 TPU에 대한 수요는 특히 멀티모달 AI 애플리케이션에서 전형적인 복잡한 계산 및 대규모 데이터 세트를 처리할 때 강조된다.
* **AI 모델링에서 메모리 사용**: 대규모 AI 모델, 특히 GPU에서 실행되는 멀티모달 및 AGI 시스템에서 교육 및 배포의 중요한 문제는 실질적인 GPU 및 VRAM 요구 사항에 있습니다. VRAM은 컴퓨터 RAM과 달리 많은 플랫폼에서 쉽게 확장할 수 없어 상당한 제약이 따르는 경우가 많다. 따라서 GPU 및 VRAM 최적화 및 효율적인 모델 스케일링을 위한 전략을 개발하는 것은 이러한 AI 기술의 실질적인 배치를 위해 중요하다.
* **AI 배포의 확장성 및 효율성**: 생성 AI, 특히 MoE 및 AGI 컨텍스트에서 확장성 문제를 해결하려면 부하 관리 및 병렬 처리 기술을 최적화해야 합니다. 이것은 의료, 금융 및 교육과 같은 분야에서 실제 적용하는 데 필수적입니다.

#### V-A2 Generative AI Technologies의 실제 적용 예제

실제 시나리오에서 생성 AI 모델의 적용은 다양한 부문에서 그들의 변형 가능성과 도전을 보여준다.

* **건강 관리**: 건강 관리에서 생성 AI는 진단 이미징 및 개인화된 의학의 발전을 촉진하지만 데이터 개인 정보 보호 및 민감한 건강 정보의 오남용 가능성에 대한 상당한 우려를 제기합니다[322].
* **재정**: 금융에서 사기 탐지 및 알고리즘 거래를 위한 AI의 사용은 효율성과 정확성을 강조하지만, 동시에 특히 자동화된 의사 결정 프로세스에서 윤리적 문제를 제기하며, 이는 투명성과 책임성이 부족할 수 있습니다. [323].
* **교육**: 개인화된 학습 환경을 만드는 Generative AI의 역할은 교육 접근성 및 맞춤형 교육 측면에서 엄청난 이점을 제공합니다. 그러나 이는 기술에 대한 공평한 접근, AI 생성 콘텐츠(AIGC)의 잠재적 편향에 문제를 제기하고 인간 교육자에 대한 수요를 줄일 수 있다. 또한 AIGC의 사용에 반대하는 교육자에 대한 우려가 증가하고 있으며, 이는 전통적인 교육 방법론과 교육자의 역할을 훼손할 수 있다.

### _Generative AI Technologies_에서의 상용성 및 산업 솔루션_

#### V-B1 Market Readiness

생성 AI 기술의 시장 준비도를 평가하는 것은 비용, 접근성, 배치 문제 및 사용자 채택 추세를 분석하는 것을 포함한다.

* **비용 분석**: MoE, 다중 모드 및 AGI를 포함 하 여 생성 AI를 배포 하는 공식 측면은 시장 채택에 중요 합니다.
* **접근성 및 배포**: 이러한 기술을 기존 시스템에 통합하고 필요한 기술 전문 지식이 채택에 영향을 미치는 주요 요소입니다.
* **사용자 채택 경향**: 현재 채택 패턴을 이해 하면 시장 수용 및 사용자 신뢰 및 인지된 혜택의 역할에 대 한 통찰력을 제공 합니다.

#### V-B2 기존 산업 솔루션

생성형 AI는 혁신적인 솔루션을 제공하고 시장의 역동성을 변화시켜 다양한 산업을 재편하고 있다.

* **섹터-현명한 배포**: 디지털 콘텐츠 만들기부터 프로세스 간소화에 이르기까지 생성 AI의 다양한 애플리케이션도 독창성과 지적 재산권에 대한 질문을 제기합니다.
* **Market Dynamics에 미치는 영향**: AI 솔루션이 전통적인 산업 구조에 미치는 영향과 새로운 비즈니스 모델의 도입은 중요한 고려 사항입니다.
* **문제 및 제약 사항**: 확장성, 데이터 관리 복잡성, 개인 정보 보호 문제 및 윤리적 의미와 같은 제한 사항을 추가 하는 것은 강력한 거버넌스 프레임워크에 필수적입니다.

### _Generative AI Technologies_의 제한 사항 및 향후 방향_

#### V-C1 기술 제한 사항

생성 AI 모델의 기술적 한계를 식별하고 해결하는 것은 발전 및 신뢰성에 중요하다.

* **상황 이해**: 특히 자연어 처리 및 이미지 인식에서 상황을 이해하고 해석하는 AI의 능력을 향상시키는 것이 개선의 핵심 영역입니다.
* **모호한 데이터 처리**: 모호하거나 불완전한 데이터 세트를 처리하기 위한 더 나은 알고리즘 개발은 의사 결정 정확성과 신뢰성에 필수적입니다.
* **인간 판단 탐색**: 정책 및 절차를 해석하는 데 있어 생성 AI의 정확성에도 불구하고 그 영향은 인간 판단을 대체하는 데 제한적입니다. 이는 의사 결정자가 AIGC를 선택적으로 사용하여 편향된 결과를 초래할 수 있는 법적 및 정치적 맥락에서 특히 그렇다. 따라서 이러한 시나리오에서 생성 AI의 효과를 현실적으로 평가해야 한다.

#### V-C2 발전형 인공지능의 실용성 향상을 위한 미래 연구 방향

생성 AI에 대한 향후 연구는 현재의 한계를 해결하고 실제 적용을 확장하는 데 중점을 두어야 한다.

* **개선된 컨텍스트 이해**: 연구는 특히 복잡한 자연 언어 및 이미지 처리 작업에서 더 나은 컨텍스트 인식을 가진 모델 개발을 목표로 해야 합니다.
* **모호한 데이터의 강력한 처리**: 모호한 데이터의 효과적인 처리를 위한 기술을 조사하는 것은 AI 모델의 의사 결정 기능을 향상시키는 데 필수적입니다.
* **법적 및 정치적 아레나에서 AIGC의 윤리적 통합**: 향후 연구는 AIGC를 지원 역할로 활용 하는 프레임워크를 개발 하 여 인간 판단을 향상 하 고 투명성과 공정성에 기여 하는 AI 생성 콘텐츠의 법적 및 정치적 의사 결정 프로세스에 대 한 윤리적 통합에 중점을 두어야 합니다. [324]. 중요한 것은 연구자들은 AI[324]에 내재된 편향과 한계를 이러한 영역에서 인간의 오류 가능성, 윤리적 복잡성 및 가능한 부패 가능성과 함께 고려해야 한다는 것이다.

## Generative AI가 분야 전반에 걸쳐 사전 인쇄에 미치는 영향

이 섹션에 자세히 설명된 과제는 생성 AI 내의 지식 영역과 직접적인 관련이 없지만 생성 AI의 성공, 특히 ChatGPT의 상용화에 의해 촉진된다. AI 분야에서의 프리프린트 확산(도 7) 특히 아르시브와 같은 플랫폼의 cs.AI 범주에서 신중한 고려와 전략적 대응이 필요한 일련의 학문적 과제를 도입했다. 구글 숄타가 상용화 1년 만에 '챗GPT'를 언급한 5만5700여건의 출품작에서 알 수 있듯이 챗GPT와 같은 툴의 빠른 상용화와 채택은 해당 분야가 가속화되는 속도를 보여준다. 이러한 급속한 발전은 상당히 느린 전통적인 동료 검토 프로세스에 반영되지 않는다. 동료 검토 프로세스는 이제 ChatGPT(또는 다른 LLM)로 생성되거나 그러한 LLM에 의해 작성 프로세스가 크게 가속화되어 학술 커뮤니케이션의 병목 현상에 기여하는 원고로 압도되는 것으로 판단된다[325, 326]. 이러한 상황은 컴퓨터 과학 이외의 분야의 많은 저널이 더 긴 리뷰 시간과 더 높은 책상 거부율을 경험하고 있다는 사실로 인해 더욱 복잡해진다. 또한 ChatGPT와 같은 도구를 사용하여 생성되거나 상당히 신속한 원고 및 사전 인쇄의 번성 추세는 컴퓨터 과학을 넘어 다양한 학문 분야로 확장된다. 이러한 경향은 전통적인 동료 검토 프로세스와 확립된 학문적 표준을 항상 준수하지는 않을 수 있는 작업량으로 번성하는 사전 인쇄 생태계 모두를 잠재적으로 압도하는 다가오는 도전을 제시한다.

순전한 양의 사전 인쇄물은 연구를 선택하고 면밀히 조사하는 작업을 매우 까다롭게 만들었다. 현재 연구 시대에 과학 문학의 탐구는 지식이 기하급수적으로 확장되고 보급되는 동시에 이러한 방대한 문헌을 증류하려는 통합 연구 노력이 더 작은 핵심 기여 세트를 식별하고 이해하려고 시도함에 따라 점점 더 복잡해졌다[327]. 따라서 다양한 분야에 걸쳐 학술 문헌의 급속한 확장은 점점 더 방대한 가용 지식에 대한 증거 합성을 수행하려는 연구자에게 중요한 과제를 제시한다[328]. 또한, 출판량의 이러한 폭발은 문헌 검토 및 조사에 뚜렷한 도전을 제기하며, 여기서 기사를 수동으로 선택, 이해 및 비판적으로 평가할 수 있는 인간의 능력이 점점 더 긴장되어 잠재적으로 포괄적인 지식 경관을 종합하는 데 격차가 발생할 수 있다. 결과의 재생산은 이론적 가능성이지만 기술적 전문성 부족, 계산 자원 또는 독점 데이터 세트에 대한 접근과 같은 실질적인 제약은 엄격한 평가를 방해한다. 사전 인쇄 연구를 철저히 평가할 수 없기 때문에 과학적 신뢰성과 타당성의 기초를 훼손하기 때문에 우려된다. 게다가, 학문적 엄격함의 초석인 동료 검토 시스템은 더 압도당할 위험에 처해 있다 잠재적인 결과는 중요하며, 공개된 사전 인쇄물은 과학 커뮤니티 및 그 너머에서 편향이나 오류를 영속화할 수 있다. 출판된 기사와 유사한 사전 인쇄물에 대한 확립된 철회 메커니즘의 부재는 결함이 있는 연구의 지속적인 보급 위험을 악화시킨다.

학계는 갈림길에 서 있어 이 새로운 "메스"를 탐색하는 데 시급하고 사려 깊은 담론이 필요하다. 이러한 맥락에서 동료 검토의 역할은 품질과 타당성에 대한 중요한 체크포인트 역할을 하여 AI 연구의 신속한 생산이 과학적 정확성과 관련성을 위해 엄격하게 연구되도록 하기 때문에 점점 더 중요해진다. 그러나 전통적인 동료 검토의 현재 _modus operandi_는 주로 AI를 주제로 한 연구 및 생성-AI 가속 연구 제출의 기하급수적인 성장과 신흥 AI 주제의 점점 더 전문화된 특성에 보조를 맞출 수 없기 때문에 지속 가능한 것으로 보이지 않는다. 이 상황은 자격을 갖춘 검토자의 유한한 풀에 의해 복잡해지며 지연, 잠재적인 편향 및 학술 커뮤니티의 부담으로 이어진다. 이러한 현실은 AI의 신속한 발전에 보조를 맞출 수 있는 동료 검토 및 연구 보급을 위한 새로운 패러다임에 대한 탐구를 요구한다. 커뮤니티 기반 조사 프로세스를 위한 혁신적인 모델, 향상된 재현성 검사 및 게시 후 조사 및 수정을 위한 동적 프레임워크가 필요할 수 있다. 인간 검토자의 부담을 완화하기 위해 자동화된 도구와 AI 지원 검토 프로세스를 통합하려는 노력도 탐색할 수 있다.

빠르게 진화하는 이 풍경에서 하이브리드 모델을 만드는 것을 포함할 수 있는 전통적인 피어 리뷰 시스템과 번성하는 프리프린트 생태계 사이의 융합을 상상한다(그림 8). 사전 인쇄물이 사전 커뮤니티 기반 검토를 거치는 경우 제품 리뷰 웹사이트 및 트위터와 유사하게 학계의 집단 전문성과 신속한 피드백을 활용한다[330]. 이 접근법은 검증의 초기 계층을 제공하여 제한된 수의 동료 검토자가 간과할 수 있는 문제에 대한 추가 통찰력을 제공할 수 있다. 편집장(EIC)은 커뮤니티 기반 리뷰에서 기사의 주요 비판과 제안을 고려할 수 있어 더 많은 것을 보장할 수 있다.

그림 7: arXiv.orgthorough 및 다양한 평가에서 다른 범주에 대한 연간 사전 인쇄 제출. 후속적으로, 보다 공식적인 동료 검토 프로세스는 학문적 엄격함과 품질 보증을 위해 이러한 사전 인쇄물을 정제하고 보증할 수 있다. 이 하이브리드 모델은 적절한 검토자의 초기 스크리닝 및 식별을 지원하기 위해 AI 및 기계 학습 도구를 활용하는 강력한 기술 지원이 필요할 수 있다. 목표는 빠른 보급에서 검증된 출판까지 끊김 없는 연속체를 확립하여 사전 인쇄의 속도와 동료 검토 연구의 신뢰성을 보장하는 것이다. 결점을 완화하면서 발견의 신속한 보급과 개방 접근과 같은 사전 인쇄의 이점을 활용하기 위해 균형 잡힌 접근이 이루어져야 한다. 새로운 인프라와 규범의 개발은 인공지능 시대에 과학 연구의 무결성과 신뢰성을 유지하는 지속 가능한 모델로 학계를 이끄는 데 중요한 역할을 할 수 있다.

## XI Conclusions

이 로드맵 조사는 특히 Q*와 AGI를 향한 진보적 진보와 같은 추측된 발전에 초점을 맞춘 생성 AI 연구의 변혁적 경향에 대한 탐색에 착수했다. 우리의 분석은 MoE, 멀티모달 학습 및 AGI 추구와 같은 혁신에 의해 주도되는 중요한 패러다임 전환을 강조한다. 이러한 발전은 AI 시스템이 추론, 맥락 이해 및 창의적 문제 해결에서 능력을 크게 확장할 수 있는 미래를 예고한다. 이 연구는 글로벌 형평성과 정의에 기여하거나 방해할 수 있는 AI의 이중 잠재력을 반영한다. 인공지능 혜택의 공평한 분배와 의사 결정 과정에서의 역할은 공정성과 포괄성에 대한 중요한 질문을 제기한다. 정의를 강화하고 격차를 줄이기 위해 AI를 사회 구조에 신중하게 통합하는 것이 필수적이다. 이러한 발전에도 불구하고 몇 가지 열린 질문과 연구 공백이 남아 있다. 여기에는 첨단 AI 시스템과 인간의 가치 및 사회적 규범의 윤리적 정렬을 보장하는 것이 포함되며, 이는 자율성 증가로 인한 도전이다. 다양한 환경에서 AGI 시스템의 안전성과 견고성 또한 상당한 연구 격차로 남아 있다. 이러한 문제를 해결하려면 윤리적, 사회적, 철학적 관점을 통합하는 다학제적 접근이 필요하다.

우리의 조사는 윤리적, 사회학적 및 기술적 관점의 통합을 강조하는 AI의 향후 학제 간 연구를 위한 핵심 영역을 강조했다. 이 접근법은 기술 발전과 사회적 요구 사이의 격차를 해소하고 AI 개발이 인간의 가치 및 글로벌 복지와 일치하도록 하는 공동 연구를 촉진할 것이다. 생성 AI를 재구성하는 데 있어 MoE, 멀티모달 및 AGI의 역할은 중요한 것으로 확인되었으며, 그 발전은 모델 성능과 다양성을 향상시킬 수 있고 윤리적 AI 정렬 및 AGI와 같은 분야에서 향후 연구의 길을 열 수 있기 때문이다. 우리가 전진할 때, AI 발전과 인간의 창의성 사이의 균형은 단순한 목표가 아니라 필수이며, 복잡한 도전을 혁신하고 해결할 수 있는 능력을 증폭시키는 보완력으로서 AI의 역할을 보장한다. 우리의 책임은 기술 발전을 윤리적 기준 및 사회적 웰빙과 일치시키면서 인간 경험을 풍부하게 하기 위해 이러한 발전을 안내하는 것이다.

## Disclaimer

이에 저자는 이해 상충을 선언하지 않는다.

## Abbreviations

* AGI 및 인공지능
* 인공지능
* AIGC & AI 생성 콘텐츠
* 트랜스포머로부터의 BERT 및 양방향 인코더 표현
* CCPA 및 캘리포니아 소비자 개인정보 보호법
* DQN & Deep Q-Networks
*EU 및 유럽 연합
* GAN & Generative Adversarial Network
GDPR 및 일반 데이터 보호 규정
* GPT & Generative Pre-trained Transformers
* GPU & Graphics Processing Unit
* LIDAR & Light Detection and Ranging
* LLM & Large Language Model
* LSTM & Long Short-Term Memory
* MCTS & Monte Carlo Tree Search
* ML & Machine Learning
* MoE & Experts의 혼합물
* NLG 및 자연어 생성
* NLP 및 자연어 처리
* NLU 및 자연어 이해
*NN 및 신경망
* PPO 및 근접 정책 최적화
* RNNs & Recurrent Neural Networks
* VNN & Value Neural Network
* VRAM & 비디오 랜덤 액세스 메모리

## References

* [1] A. Turing, "Computing machinery and intelligence," _Mind_, vol. 59, no. 236, p. 433, 1950.
* [2] D. McDermott, "Artificial intelligence meets natural stupidity," _Acm Sigar Bulletin_, no. 57, pp. 4-9, 1976.
* [3] M. Mirsky, "Steps toward artificial intelligence," _Proceedings of the IRE_, vol. 49, no. 1, pp. 8-30, 1961.
* [4] Y. LeCun, Y. Bengio, and G. Hinton, "Deep learning," _nature_, vol. 521, no. 7553, pp. 436-444, 2015.
* [5] M. Mirsky and S. Parett, "An introduction to computational geometry," _Cambridge mass., HIT_, vol. 479, no. 480, p. 104, 1969.
* [6] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, "Learning representations by back-propagating errors," _nature_, vol. 323, no. 6088, pp. 533-536, 1986.

그림 8: 전통적인 동료 리뷰와 사전 인쇄 생태계의 융합 가능성

* [7] G.-G. Lee, L. Shi, E. Latif, Y. Gao, A. Bewersdorf, M. Nyyaaba, S. Guo, Z. Wu, Z. Liu, H. Wang _et al._, "Multimodality of ai for education: Towards artificial general intelligence," _arXiv preprint arXiv:2312.06037_, 2023.
* [8] P. Maddigan and T. Susnjak, "Chat2vis: Generating data visualisations via natural language using chatpot, codex and gpt-3 large language models," _IEEE Access_, 203.
* [9] T. R. McIntosh, T. Liu, T. Susnjak, P. Watters, A. Ng, and M. N. Halgamuge, "A culturally sensitive test to evaluate nuanced gpt hallucination," _IEEE Transactions on Artificial Intelligence_, vol. 1, no. 01, pp. 1-13, 2023.
* [10] M. R. Morris, J. Sohl-dickstein, N. Fiedel, T. Warkentin, A. Dafoe, A. Faust, C. Farabet, and S. Leges, "Levels of agi: Operationalizing progress on the path to agi," _arXiv preprint arXiv:2311.02462_, 2023.
* [11] J. Schuett, N. Dreksler, M. Anderljung, D. McCaffary, L. Heim, E. Bluemke, and B. Garfinkel, "Towards best practices in agi safety and governance: A survey of expert opinion," _arXiv preprint arXiv:2305.07153_, 2023.
* [12] X. Shuai, J. Rollins, I. Moulinier, T. Castis, M. Edmunds, and F. Schilder, "A multidimensional investigation of the effects of publication retraction on scholarly impact," _Journal of the Association for Information Science and Technology_, vol. 68, no. 9, pp. 2225-2236, 2017.
* [13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, "Attention is all you need," _Advances in neural information processing systems_, vol. 30, 2017.
* [14] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever _et al._, "Improving language understanding by generative pre-training," 2018.
* [15] C. Huang, Z. Zhang, B. Mao, and X. Yao, "An overview of artificial intelligence ethics: _IEEE Transactions on Artificial Intelligence_, 2022.
* [16] L. Besancon, N. Peiffer-Smadja, C. Segalas, H. Jiang, P. Masuzzo, C. Smout, E. Billy, M. Deforet, and C. Leyrat, "Open science saves lives: lessons from the covid-19 pandemic," _BMC Medical Research Methodology_, vol. 21, no. 1, pp. 1-18, 2021.
* [17] C. R. Triggle, R. MacDonald, D. J. Triggle, and D. Grierson, "Requiem for impact factors and high publication charges," _Accountability in Research_, vol. 29, no. 3, pp. 133-164, 2022.
* [18] T. McIntosh, A. Kayes, Y.-P. P. Chen, A. Ng, and P. Watters, "Ransomware mitigation in the modern era: A comprehensive review, research challenges, and future directions," _ACM Computing Surveys (CSUR)_, vol. 54, no. 9, pp. 1-36, 2021.
* [19] T. McIntosh, T. Liu, T. Susnjak, H. Alavizadeh, A. Ng, R. Nowrozy, and P. Watters, "Harnessing gpt-4 for generation of cybersecurity gpc policies: A focus on msomware attack mitigation," _Computers & Security_, vol. 134, p. 103424, 2023.
* [20] H. Bao, W. Wang, L. Dong, Q. Liu, O. K. Mohammed, K. Aggarwal, S. Som, S. Piao, and F. Wei, "Vlmo: Unified vision-language pre-training with mixture-of-modality-experts," _Advances in Neural Information Processing Systems_, vol. 35, pp. 32897-32912, 2022.
* [21] N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepkiphin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Firat _et al._, "Glam: Efficient scaling of language models with mixture-of-experts," in _International Conference on Machine Learning_. PMLR, 2022, pp. 5547-5569.
* [22] S. Masoudnia and R. Ebrahimpour, "Mixture of experts: a literature survey," _Artificial Intelligence Review_, vol. 42, pp. 275-293, 2014.
* [23] C. Riquelme, J. Puigever, B. Mustafa, M. Neumann, R. Bentton, A. Susano Pinto, D. Keysers, and N. Houlsby, "Scaling vision with sparse mixture of experts," _Advances in Neural Information Processing Systems_, vol. 34, pp. 8583-8595, 2021.
* [24] S. E. Yuksel, J. N. Wilson, and P. D. Gader, "Twenty years of mixture of experts," _IEEE transactions on neural networks and learning systems_, vol. 23, no. 8, pp. 1177-1193, 2012.
* [25] L. Zhang, S. Huang, W. Liu, and D. Tao, "Learning a mixture of granularity-specific experts for fine-grained categorization," in _Proceedings of the IEEE/CVF International Conference on Computer Vision_, 2019, pp. 8331-8340.
* [26] D. Martin, S. Malpica, D. Gutierrez, B. Masia, and A. Serrano, "Multimodality in wr: A survey," _ACM Computing Surveys (CSUR)_, vol. 54, no. 108, pp. 1-36, 2022.
* [27] Q. Sun, Q. Yu, Y. Cui, F. Zhang, X. Zhang, Y. Wang, H. Gao, J. Liu, T. Huang, and X. Wang, "Generative pretraining in multimodality," _arXiv preprint arXiv:2307.05222_, 2023.
* [28] L. Wei, L. Xie, W. Zhou, H. Li, and Q. Tian, "Mvp: Multimodality-guided visual pre-training," in _European Conference on Computer Vision_. Springer, 2022, pp. 337-353.
* [29] J. Wu, W. Zhou, X. Qian, J. Lei, L. Yu, and T. Luo, "Menet: Lightweight multimodality enhancement network for detecting salient objects in rgb-thermal images," _Neurocomputing_, vol. 527, pp. 119-129, 2023.
* [30] Q. Ye, H. Xu, G. Xu, J. Ye, M. Yan, Y. Zhou, J. Wang, A. Hu, P. Shi, Y. Shi _et al._, "mplug-owl: Modularization empowers large language models with multimodality," _arXiv preprint arXiv:2304.14178_, 2023.
* [31] K. LaGrandeur, "How safe is our reliance on ai, and should we regulate it?" _AI and Ethics_, vol. 1, pp. 93-99, 2021.
* [32] S. McLean, G. J. Read, J. Thompson, C. Baber, N. A. Stanton, and P. M. Salmon, "The risks associated with artificial general intelligence: A systematic review," _Journal of Experimental & Theoretical Artificial Intelligence_, vol. 35, no. 5, pp. 649-663, 2023.
* [33] Y. K. Dwivedi, L. Hughes, E. Ismagilova, G. Aarts, C. Coombs, T. Crick, Y. Duan, R. Dwivedi, J. Edwards, A. Ering, V. Galancos, P. V. Ilavarsan, M. Janssen, P. Jones, A. K. Kar, H. Kizgin, B. Kronemann, B. Lal, B. Lucini, R. Medaglia, K. Le Meunier-FitzHugh, L. C. Le Meunier-FitzHugh, S. Misra, E. Moggi, S. K. Sharma, J. B. Singh, V. Raghavan, R. Raman, N. P. Rama, S. Samothrakis, J. Spencer, K. Tamlimani, A. Tambadji, P. Walton, and M. D. Williams, "Artificial intelligence (ai): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy," _International Journal of Information Management_, vol. 57, p. 101994, 2021.
* [34] I. Gabriel, "Artificial intelligence, values, and alignment," _Minds and Machines_, vol. 30, pp. 411-437, 2020.
* [35] A. Shaban-Nejad, M. Michalowski, S. Bianco, J. S. Brownstein, D. L. Buckeridge, and R. L. Davis, "Applied artifical intelligence in healthcare: Listening to the winds of change in a post-covid-19 world," pp. 1969-1971, 2022.
* [36] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang, A. Madotto, and P. Fung, "Survey of hallucination in natural language generation," _ACM Computing Surveys_, vol. 55, no. 12, pp. 1-38, 2023.
* [37] B. Min, H. Ross, E. Sulem, A. P. B. Veyesh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heintz, and D. Roth, "Recent advances in natural language processing via large pre-trained language models: A survey," _ACM Computing Surveys_, vol. 56, no. 2, pp. 1-40, 2023.
* [38] J. Li, X. Cheng, W. X. Zhao, J.-Y. Nie, and J.-R. Wen, "Haleval: A large-scale hallucination evaluation benchmark for large language models," in _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, 2023, pp. 6449-6464.
* [39] L. Uiedinger, J. Mellor, M. Rauh, C. Griffin, J. Uesato, P.-S. Huang, M. Cheng, M. Glaese, B. Aalle, A. Kasirzadeh _et al._, "Ethical and social risks of harm from language models," _arXiv preprint arXiv:2112.04359_, 2021.
* [40] X. Zhiheng, Z. Rui, and G. Tao, "Safety and ethical concerns of large language models," in _Proceedings of the 22nd Chinese National Conference on Computational Linguistics (Volume 4: Tutorial Abstracts)_, 2023, pp. 9-16.
* [41] P. F. Brown, V. J. Della Pietra, P. V. Desouza, J. C. Lai, and R. L. Mercer, "Class-based n-gram models of natural language," _Computational linguistics_, vol. 18, no. 4, pp. 467-480, 1992.
* [42] S. Katz, "Estimation of probabilities from sparse data for the language model component of a speech recognizer," _IEEE transactions on acoustics, speech, and signal processing_, vol. 35, no. 3, pp. 400-401, 1987.
* [43] R. Kneser and H. Ney, "Improved backing-off for m-gram language modeling," in _1995 international conference on acoustics, speech, and signal processing_, vol. 1. IEEE, 1995, pp. 181-184.
* [44] R. Kuhn and R. De Mori, "A cache-based natural language model for speech recognition," _IEEE transactions on pattern analysis and machine intelligence_, vol. 12, no. 6, pp. 570-583, 1990.
* [45] H. Ney, U. Essen, and R. Kneser, "On structuring probabilistic dependences in stochastic language modelling," _Computer Speech & Language_, vol. 8, no. 1, pp. 1-38models to follow instructions with human feedback," _Advances in Neural Information Processing Systems_, vol. 35, pp. 27 730-27 744, 2022.
* [51] T. Susnjak, "Beyond predictive learning analytics modelling and onto explainable artificial intelligence with prescriptive analytics and chat-gpt," _International Journal of Artificial Intelligence in Education_, pp. 1-31, 2023.
* [52] T. Susnjak, E. Griffin, M. McCutcheon, and K. Potter, "Towards clinical prediction with transparency: An explainable ai approach to survival modelling in residential aged care," _arXiv preprint arXiv:2312.00271_, 2023.
* [53] R. Yang, T. F. Tan, W. Lu, A. J. Thirunavukarasu, D. S. W. Ting, and N. Liu, "Large language models in health care: Development, applications, and challenges," _Health Care Science_, vol. 2, no. 4, pp. 255-263, 2023.
* [54] D. Baidoo-Anu and L. O. Anash, "Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chat-gpt in promoting teaching and learning," _Journal of AI_, vol. 7, no. 1, pp. 52-62, 2023.
* [55] T. Susnjak, "Chatgpt: The end of online exam integrity?" _arXiv preprint arXiv:2212.09292_, 2022.
* [56] A. Tlili, B. Shehata, M. A. Adarkwah, A. Bozkurt, D. T. Hickey, R. Huang, and B. Aygramang, "What if the devil is my guardian angel: Cmstap as a case study of using chatbots in education," _Smart Learning Environments_, vol. 10, no. 1, p. 15, 2023.
* [57] M. A. AlAfnan, S. Dishari, M. Joviac, and K. Lomidze, "Chatgpt as an educational tool: Opportunities, challenges, and recommendations for communication, business writing, and composition courses," _Journal of Artificial Intelligence and Technology_, vol. 3, no. 2, pp. 60-68, 2023.
* [58] A. S. George and A. H. George, "A review of chatgpt ai's impact on several business sectors," _Partners Universal International Innovation Journal_, vol. 1, no. 1, pp. 9-23, 2023.
* [59] G. K. Hadfield and J. Clark, "Replay markets: The future of ai governance," _arXiv preprint arXiv:2304.04914_, 2023.
* [60] M. Bakker, M. Chadwick, H. Sheahan, M. Tessler, L. Campbell-Gillingman, J. Balaguer, N. McAlesee, A. Glaese, J. Asianides, M. Botvinick _et al._, "Fine-tuning language models to find agreement among humans with diverse preferences," _Advances in Neural Information Processing Systems_, vol. 35, pp. 38 176-38 189, 2022.
* [61] Z. Hu, Y. Lan, L. Wang, W. Xu, E.-P. Lim, R. K.-W. Lee, L. Bing, and S. Poria, "Llm-adapters: An adapter family for parameter-efficient fine-tuning of large language models," _arXiv preprint arXiv:2304.01933_, 2023.
* [62] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A. Raffel, "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning," _Advances in Neural Information Processing Systems_, vol. 35, pp. 1950-1965, 2022.
* [63] H. Zheng, L. Shen, A. Tang, Y. Luo, H. Hu, B. Du, and D. Tao, "Learn from model beyond fine-tuning: A survey," _arXiv preprint arXiv:2310.08184_, 2023.
* [64] P. Manakul, A. Liusie, and M. J. Gales, "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models," _arXiv preprint arXiv:2303.08896_, 2023.
* [65] A. Martino, M. Iannelli, and C. Truong, "Knowledge injection to counter large language model (llm) hallucination," in _European Semantic Web Conference_. Springer, 2023, pp. 182-185.
* [66] J.-Y. Yao, K.-P. Ning, Z.-H. Liu, M.-N. Ning, and L. Yuan, "Llm lies: Hallucinations are not bugs, but features as adversarial examples," _arXiv preprint arXiv:2310.01496_, 2023.
* [67] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao, Y. Zhang, Y. Chen _et al._, "Sriven's song in the ai ocean: A survey on hallucination in large language models," _arXiv preprint arXiv:2309.01219_, 2023.
* [68] J. Ji, M. Liu, J. Dai, X. Pan, C. Zhang, C. Bian, R. Sun, Y. Wang, and Y. Yang, "Beveratils: Towards improved safety alignment of llm via a human-preference dataset," _arXiv preprint arXiv:2307.04657_, 2023.
* [69] Y. Liu, Y. Yao, J.-F. Ton, X. Zhang, R. G. H. Cheng, Y. Klochkov, M. F. Taufiq, and H. Li, "Trustworthy llmns: a survey and guideline for evaluating large language models" alignment," _arXiv preprint arXiv:2308.05374_, 2023.
* [70] Y. Wang, W. Zhong, L. Li, F. Mi, X. Zeng, W. Huang, L. Shang, X. Jiang, and Q. Liu, "Aligning large language models with human: A survey," _arXiv preprint arXiv:2307.12966_, 2023.
* [71] Z. Sun, Y. Shen, Q. Zhou, H. Zhang, Z. Chen, D. Cox, Y. Yang, and C. Gan, "Principle-driven self-alignment of language models from scratch with minimal human supervision," _arXiv preprint arXiv:2305.03047_, 2023.
* [72] Y. Wolf, N. Wies, Y. Levine, and A. Shashua, "Fundamental limitations of alignment in large language models," _arXiv preprint arXiv:2304.11082_, 2023.
* [73] H. Dang, L. Mecke, F. Lehmann, S. Goller, and D. Buschek, "How to promp? opportunities and challenges of zero-and few-shot learning for human-ai interaction in creative applications of generative models," _arXiv preprint arXiv:2209.01190_, 2022.
* [74] R. Ma, X. Zhou, T. Gui, Y. Tan, L. Li, Q. Zhang, and X. Huang, "Template-free prompt tuning for few-shot ner," _arXiv preprint arXiv:2109.13532_, 2021.
* [75] C. Qin and S. Joty, "Lfp5: A unified framework for lifelong few-shot language learning based on prompt tuning of 5," _arXiv preprint arXiv:2110.07298_, 2021.
* [76] S. Wang, L. Tang, A. Majeety, J. F. Rousseau, G. Shih, Y. Ding, and Y. Peng, "Trustworthy assertion classification through prompting," _Journal of biomedical informatics_, vol. 132, p. 104139, 2022.
* [77] Y. Fan, F. Jiang, P. Li, and H. Li, "Gramramagmt: Exploring open-source llms for native chinese grammatical error correction with supervised fine-tuning," in _CCF International Conference on Natural Language Processing and Chinese Computing_. Springer, 2023, pp. 69-80.
* [78] D. Liga and L. Robaldo, "Fine-tuning gpt-3 for legal rule classification," _Computer Lane & Security Review_, vol. 51, p. 105864, 2023.
* [79] Y. Liu, A. Singh, C. D. Freeman, J. D. Co-Reyes, and P. J. Liu, "Improving large language model fine-tuning for solving math problems," _arXiv preprint arXiv:2310.10047_, 2023.
* [80] Z. Talat, A. Neveol, S. Biderman, M. Clinciu, M. Dey, S. Longpre, S. Lucioni, M. Masoud, M. Mitchell, D. Radev _et al._, "You reap what you you: On the challenges of bias evaluation under multilingual settings," in _Proceedings of BigScience Episode 5-Workshop on Challenges & Perspectives in Creating Large Language Models_, 2022, pp. 26-41.
* [81] Y. Liu, S. Yu, and T. Lin, "Hessian regularization of deep neural networks: A novel approach based on stochastic estimators of hessian trace," _Neurocomputing_, vol. 536, pp. 13-20, 2023.
* [82] Y. Lu, Y. Bo, and W. He, "Conference adaptive regularization for deep learning with noisy labels," _arXiv preprint arXiv:2108.08212_, 2021.
* [83] G. Pereyra, G. Tucker, J. Chorowski, L. Kaiser, and G. Hinton, "Regularizing neural networks by penalizing confident output distributions," _arXiv preprint arXiv:1701.05648_, 2017.
* [84] E. Chen, Z.-W. Hong, J. Pajarinen, and P. Agrawal, "Redeeming intrinsic rewards via constrained optimization," _Advances in Neural Information Processing Systems_, vol. 35, pp. 4996-5008, 2022.
* [85] Y. Jiang, Z. Li, M. Tan, S. Wei, G. Zhang, Z. Guan, and B. Han, "A stable block adjustment method without ground control points using bound constrained optimization," _International Journal of Remote Sensing_, vol. 43, no. 12, pp. 4708-4722, 2022.
* [86] M. Kachuee and S. Lee, "Constrained policy optimization for controlled self-learning in conversational ai systems," _arXiv preprint arXiv:2209.08429_, 2022.
* [87] Z. Song, H. Wang, and Y. Jin, "A surrogate-assisted evolutionary framework with regions of interests-based data selection for expensive constrained optimization," _IEEE Transactions on Systems, Man, and Cybernetics: Systems_, 2023.
* [88] J. Yu, T. Xu, Y. Rong, J. Huang, and R. He, "Structure-aware conditional variational auto-encoder for constrained molecule optimization," _Pattern Recognition_, vol. 126, p. 108581, 2022.
* [89] P. Butlin, "Ai alignment and human reward," in _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, 2021, pp. 437-445.
* [90] F. Faal, K. Schmitt, and J. Y. Yu, "Reward modeling for mitigating toxicity in transformer-based language models," _Applied Intelligence_, vol. 53, no. 7, pp. 8421-8435, 2023.
* [91] J. Leike, D. Krueger, T. Everitt, M. Martic, V. Maini, and S. Legg, "Scalable agent alignment via reward modeling: a research direction," _arXiv preprint arXiv:1811.07781_, 2018.
* [92] L. Li, Y. Chai, S. Wang, Y. Sun, H. Tian, N. Zhang, and H. Wu, "Tool-augmented reward modeling," _arXiv preprint arXiv:2310.0465_, 2023.
* [93] F. Barreto, L. Mohatkar, M. Shirokkar, V. Sarode, S. Gonsalves, and A. Johns, "Generative artificial intelligence: Opportunities and challenges of large language models," in _International Conference on Intelligent Computing and Networking_. Springer, 2023, pp. 545-553.
*[9*[96] H. Naveed, A. U. Khan, S. 추명 사갑수 안와 어스만 Barnes, and A. Mian, "A comprehensive overview of large language models," _arXiv preprint arXiv:2307.06435_, 2023.
* [97] F. Xue, Y. Fu, W. Zhou, Z. Zheng, and Y. You, "To repeat or not to repeat: Insights from scaling llm under token-crisis," _arXiv preprint arXiv:2305.13230_, 2023.
* [98] M. Nowaz Rabbani Chowdhury, S. Zhang, M. Wang, S. Liu, and P.-Y. Chen, "Patch-level routing in mixture-of-experts is provably sample-efficient for convolutional neural networks," _arXiv e-prints_, pp. arXiv:2306, 2023.
* [99] J. Peng, K. Zhou, R. Zhou, T. Hartvigsen, Y. Zhang, Z. Wang, and T. Chen, "Sparse moc as a new treatment: Addressing forgetting, fitting, learning issues in multi-modal multi-task learning," in _Conference on Pismy and Learning (Recent Speciality Track)_, 2023.
* [100] C. N. d. Santos, J. Lee-Thorp, I. Noble, C.-C. Chang, and D. Uthus, "Memory augmented language models through mixture of word experts," _arXiv preprint arXiv:2311.10768_, 2023.
* [101] W. Wang, G. Ma, Y. Li, and B. Du, "Language-routing mixture of experts for multilingual and code-switching speech recognition," _arXiv preprint arXiv:2307.05956_, 2023.
* [102] X. Zhao, X. Chen, Y. Cheng, and T. Chen, "Sparse moc with language guided routing for multilingual machine translation," in _Conference on Pismy and Learning (Recent Spotfish Track)_, 2023.
* [103] W. Huang, H. Zhang, P. Peng, and H. Wang, "Multi-gate mixture-of-expert combined with synthetic minority over-sampling technique for multimode imbalanced fault diagnosis," in _2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD)_. IEEE, 2023, pp. 456-461.
* [104] B. Liu, L. Ding, L. Shen, K. Peng, Y. Cao, D. Cheng, and D. Tao, "Diversifying the mixture-of-experts representation for language models with orthogonal optimizer," _arXiv preprint arXiv:2310.09762_, 2023.
* [105] W. Wang, Z. Lai, S. Li, W. Liu, K. Ge, Y. Liu, A. Shen, and D. Li, "Prophet: Fine-grained load balancing for parallel training of large-scale moc models," in _2023 IEEE International Conference on Cluster Computing (CLUSTER)_. IEEE, 2023, pp. 82-94.
* [106] X. Yao, S. Liang, S. Han, and H. Huang, "Enhancing molecular property prediction via mixture of collaborative experts," _arXiv preprint arXiv:2312.03292_, 2023.
* [107] Z. Xiao, Y. Jiang, G. Tang, L. Liu, S. Xu, Y. Xiao, and W. Yan, "Adversarial mixture of experts with category hierarchy soft constraint," in _2021 IEEE 37th International Conference on Data Engineering (ICDE)_. IEEE, 2021, pp. 2453-2463.
* [108] M. Agbee, R. Mohamani, A. Khan, and P. Abrahamsson, "Implementing ai ethics: Making sense of the ethical requirements," in _Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering_, 2023, pp. 62-71.
* [109] Z. Chen, Y. Deng, Y. Wu, Q. Gu, and Y. Li, "Towards understanding the mixture-of-experts layer in deep learning," _Advances in neural information processing systems_, vol. 35, pp. 23 049-23 062, 2022.
* [110] Y. Zhou, T. Lei, H. Liu, N. Du, Y. Huang, Y. Zhao, A. M. Dai, Q. V. Le, J. Laudon _et al._, "Mixture-of-experts with expert choice routing," _Advances in Neural Information Processing Systems_, vol. 35, pp. 7103-7114, 2022.
* [111] N. Guha, C. Lawrence, L. A. Gailmard, K. Rodolfa, F. Surani, R. Bommasani, I. Raji, M.-F. Cuellar, C. Honigsberg, P. Liang _et al._, "Ai regulation has it own alignment problem: The technical and institutional feasibility of disclosure, registration, licensing, and auditing," _George Washington Law Review, Forthcoming_, 2023.
* [112] Gemini Team, Google, "Gemini: A family of highly capable multimodal models," 2023, accessed: 17 December 2023. [Online]. Available: [https://storage.google.com/content-imedim-reading/emini_1_report.pdf](https://storage.google.com/content-imedim-reading/emini_1_report.pdf)
* [113] J. N. Acosta, G. J. Falcone, P. Rajpurkar, and E. J. Topol, "Multimodal biomedical ai," _Nature Medicine_, vol. 28, no. 9, pp. 1773-1784, 2022.
* [114] S. Qi, Z. Cao, J. Rao, L. Wang, J. Xiao, and X. Wang, "What is the limitation of multimodal llms? a deeper look into multimodal lms through prompt," _Information Processing & Management_, vol. 60, no. 6, p. 103510, 2023.
* [115] B. Xu, D. Kocyrijt, R. Grimm, B. P. Griffin, and F. Cheng, "Applications of artificial intelligence in multimodality cardiovascular imaging: a state-of-the-art review," _Progress in cardiovascular diseases_, vol. 63, no. 3, pp. 367-376, 2020.
* [116] A. Birhane, V. U. Prabhu, and E. Kahembwe, "Multimodal datasets: misogyrp, pornography, and malignant stereotypes," _arXiv preprint arXiv:2110.01963_, 2021.
* [117] Y. Li, W. Li, N. Li, X. Qiu, and K. B. Manckaran, "Multimodal information interaction and fusion for the parallel computing system using ai techniques," _International Journal of High Performance Systems Architecture_, vol. 10, no. 3-4, pp. 185-196, 2021.
* [118] C. Zhang, Z. Yang, X. He, and L. Deng, "Multimodal intelligence: Representation learning, information fusion, and applications," _IEEE Journal of Selected Topics in Signal Processing_, vol. 14, no. 3, pp. 478-493, 2020.
* [119] H. Qiao, V. Liu, and L. Chilton, "Initial images: using image prompts to improve subject representation in multimodal ai generated art," in _Proceedings of the 14th Conference on Creativity and Cognition_, 2022, pp. 15-28.
* [120] A. E. Stewart, Z. Keirn, and S. K. D'Mello, "Multimodal modeling of collaborative problem-solving facets in triads," _User Modeling and User-Adapted Interaction_, pp. 1-39, 2021.
* [121] L. Xue, N. Yu, S. Zhang, J. Li, R. Martin-Martin, J. Wu, C. Xiong, R. Xu, J. C. Niebles, and S. Savarese, "Ulip-2: Towards scalable multimodal pre-training for 3d understanding," _arXiv preprint arXiv:2305.08275_, 2023.
* [122] L. Yan, L. Zhao, D. Gasevic, and R. Martinez-Maldonado, "Scalability, sustainability, and criticality of multimodal learning analytics," in _LAAK22: 12th international learning analytics and knowledge conference_, 2022, pp. 13-23.
* [123] Y. Liu-Thompkins, S. Okazaki, and H. Li, "Artificial empathy in marketing interactions: Bridging the human-ai gap in affective and social customer experience," _Journal of the Academy of Marketing Science_, vol. 50, no. 6, pp. 1198-1218, 2022.
* [124] M. S. Rahman, S. Bag, M. A. Hossain, F. A. M. A. Fattah, M. O. Gani, and N. P. Rana, "The new wave of ai-powered luxury brands online shopping experience: The role of digital multisensor cues and customers," engagement, _Journal of Retailing and Consumer Services_, vol. 72, p. 103273, 2023.
* [125] E. Sachdeva, N. Agarwal, S. Chundi, S. Roelofs, J. Li, B. Dariush, C. Choi, and M. Kochenderfer, "Rank2ell: A multimodal driving dataset for joint importance ranking and reasoning," _arXiv preprint arXiv:2309.06597_, 2023.
* [126] C. Cui, Y. Ma, X. Cao, W. Ye, Y. Zhou, K. Liang, J. Chen, J. Lu, Z. Yang, K.-D. Liao _et al._, "TA survey on multimodal large language models for autonomous driving," _arXiv preprint arXiv:2311.12320_, 2023.
* [127] A. B. Temsamani, A. K. Chavali, W. Vervoort, T. Tytelaars, G. Radevski, H. Van Hamme, K. Mets, M. Hutsebut-Buysse, T. De Schepper, and S. Latre, "A multimodal ai approach for intuitively instructable autonomous systems: a case study of an autonomous off-highway vehicle," in _The Eighteenth International Conference on Autonomic and Autonomous Systems, ICAS 2022, May 22-26, 2022, Venice, Italy_, 2022, pp. 31-39.
* [128] J. Lee and S. Y. Shin, "Something that they never said: Multimodal disinformation and source vividness in understanding the power of ai-enabled deepfake news," _Media Psychology_, vol. 25, no. 4, pp. 531-546, 2022.
* [129] S. Muppalla, S. Jia, and S. Lyu, "Integrating audio-visual features for multimodal deepfake detection," _arXiv preprint arXiv:2310.03827_, 2023.
* [130] S. Kumar, M. K. Chaube, S. N. Nenavath, S. K. Gupta, and S. K. Tetaarve, "Privacy preservation and security challenges: a new frontier multimodal machine learning research," _International Journal of Sensor Networks_, vol. 39, no. 4, pp. 227-245, 2022.
* [131] J. Marchang and A. Di Nuovo, "Assistive multimodal robotic system (amrysx): security and privacy issues, challenges, and possible solutions," _Applied Sciences_, vol. 12, no. 4, p. 2174, 2022.
* [132] A. Pena, I. Serna, A. Morales, J. Fierrez, A. Ortega, A. Herraarte, M. Calcantara, and J. Ortega-Garcia, "Human-centric multimodal machine learning: Recent advances and testbed on ai-based recruitment," _SN Computer Science_, vol. 4, no. 5, p. 434, 2023.
* [133] R. Wolfe and A. Caliskan, "American= white in multimodal language-and-image ai," in _Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society_, 2022, pp. 800-812.
* [134] R. Wolfe, Y. Yang, B. Howe, and A. Caliskan, "Contrastive language-vision ai models pretrained on web-scraped multimodal data exhibit sexual objiection bias," in _Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency_, 2023, pp. 1174-1185.
* [135] M. Afshar, B. Sharma, D. Digach, M. Ogas, R. Brown, N. Chhabra, H. M. Thompson, T. Markossian, C. Joyce, M. M. Churveda _et al._, "Development and multimodal validation of a substance misuse algorithm for referral to treatment * [136] H. Alwahaby, M. Cukurova, Z. Papamitsiou, and M. Giannakos, "The evidence of impact and ethical considerations of multimodal learning analytics: A systematic literature review," _The Multimodal Learning Analytics Handbook_, pp. 289-325, 2022.
* [137] Q. Miao, W. Zheng, Y. Lv, M. Huang, W. Ding, and F.-Y. Wang, "Dao to hanoi via desci: Ai paradigm shifts from alphago to chatgpt," _IEEE/CAA Journal of Automatica Sinica_, vol. 10, no. 4, pp. 877-897, 2023.
* [138] Y. Rong, "Roadmap of alphago to alphastar: Problems and challenges," in _2nd International Conference on Artificial Intelligence, Automation, and High-Performance Computing (IAHIPC 2022)_, vol. 12348. SPIE, 2022, pp. 904-914.
* [139] Y. Gao, M. Zhou, D. Liu, Z. Yan, S. Zhang, and D. N. Metaxas, "A data-scalable transformer for medical image segmentation: architecture, model efficiency, and benchmark," _arXiv preprint arXiv:2203.00131_, 2022.
* [140] W. Peebles and S. Xie, "Scalable diffusion models with transformers," in _Proceedings of the IEEE/CVF International Conference on Computer Vision_, 2023, pp. 4195-4205.
* [141] R. Pope, S. Douglas, A. Chowdhury, J. Devlin, J. Bradbury, J. Heek, K. Xiao, S. Agrawal, and J. Dean, "Efficiently scaling transformer inference," _Proceedings of Machine Learning and Systems_, vol. 5, 2023.
* [142] Y. Ding and M. Jia, "Convolutional transformer: An enhanced attention mechanism architecture for remaining useful life estimation of bearings," _IEEE Transactions on Instrumentation and Measurement_, vol. 71, pp. 1-10, 2022.
* [143] Y. Ding, M. Jia, Q. Miao, and Y. Cao, "A novel time-frequency transformer based on self-attention mechanism and its application in fault diagnosis of rolling bearings," _Mechanical Systems and Signal Processing_, vol. 168, p. 108616, 2022.
* [144] G. Wang, Y. Zhao, C. Tang, C. Luo, and W. Zeng, "When shift operation meets vision transformer: An extremely simple alternative to attention mechanism," in _Proceedings of the AAAI Conference on Artificial Intelligence_, vol. 36, no. 2, 2022, pp. 2423-2430.
* [145] H. Cai, J. Li, M. Hu, C. Gan, and S. Han, "Efficientvit: Lightweight multi-scale attention for high-resolution dense prediction," in _Proceedings of the IEEE/CVF International Conference on Computer Vision_, 2023, pp. 17 302-17 313.
* [146] X. Liu, H. Peng, N. Zheng, Y. Yang, H. Hu, and Y. Yuan, "Efficientvit: Memory efficient vision transformer with cascaded group attention," in _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, 2023, pp. 14 420-14 430.
* [147] Y. Li, Q. Fan, H. Huang, Z. Han, and Q. Gu, "A modified yolov8 detection network for uav aerial image recognition," _Drones_, vol. 7, no. 5, p. 304, 2023.
* [148] F. M. Talat and H. ZainEldin, "An improved fire detection approach based on yolov8-8 for smart cities," _Neural Computing and Applications_, vol. 35, no. 28, pp. 20 939-20 954, 2023.
* [149] S. Tamang, B. Sen, A. Pradhan, K. Sharma, and V. K. Singh, "Enhancing cost-19 safety: Exploring yolov object detection for accurate face mask classification," _International Journal of Intelligent Systems and Applications in Engineering_, vol. 11, no. 2, pp. 892-897, 2023.
* [150] J. Lu, R. Xiong, J. Tian, C. Wang, C.-W. Hsu, N.-T. Tsuo, F. Sun, and J. Li, "Battery degradation prediction against uncertain future conditions with recurrent neural network enabled deep learning," _Energy Storage Materials_, vol. 50, pp. 139-151, 2022.
* [151] A. Oman, "Bidirectional convolutional recurrent neural network architecture with group-wise enhancement mechanism for text sentiment classification," _Journal of King Saud University-Computer and Information Sciences_, vol. 34, no. 5, pp. 2098-2117, 2022.
* [152] F. Shan, X. He, D. J. Armaghani, P. Zhang, and D. Sheng, "Success and challenges in predicting thm penetration rate using recurrent neural networks," _Tuanfling and Underground Space Technology_, vol. 130, p. 104728, 2022.
* [153] C. Sridhar, P. K. Pareek, R. Kalidoss, S. S. Jamal, P. K. Shukla, S. J. Nuagah _et al._, "Optimal medical image size reduction model creation using recurrent neural network and genpsowvq," _Journal of Healthcare Engineering_, vol. 2022, 2022.
* [154] J. Zhu, Q. Jiang, Y. Shen, C. Qian, F. Xu, and Q. Zhu, "Application of recurrent neural network to mechanical fault diagnosis: A review," _Journal of Mechanical Science and Technology_, vol. 36, no. 2, pp. 527-542, 2022.
* [155] S. Lin, W. Lin, W. Wu, F. Zhao, R. Mo, and H. Zhang, "Segrm: Segment recurrent neural network for long-term time series forecasting," _arXiv preprint arXiv:2308.11200_, 2023.
* [156] Z. Wei, X. Zhang, and M. Sun, "Extracting weighted finite automata from recurrent neural networks for natural languages," in _International Conference on Formal Engineering Methods_. Springer, 2022, pp. 370-385.
* [157] F. Bonassi, M. Farina, J. Xie, and R. Scantolini, "On recurrent neural networks for learning-based control: recent results and ideas for future developments," _Journal of Process Control_, vol. 114, pp. 92-104, 2022.
* [158] Z. Guo, Y. Tang, R. Zhang, D. Wang, Z. Wang, B. Zhao, and X. Li, "Viewrefer: Grasp the multi-view knowledge for 3d visual grounding," in _Proceedings of the IEEE/CVF International Conference on Computer Vision_, 2023, pp. 15 372-15 383.
* [159] C. Pan, Y. He, J. Peng, Q. Zhang, W. Sui, and Z. Zhang, "Baefommer: Bi-directional and early interaction transformers for bird's eye view semantic segmentation," in _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, 2023, pp. 9590-9599.
* [160] P. Xu, X. Zhu, and D. A. Clifton, "Multimodal learning with transformers: A survey," _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 2023.
* [161] I. Molenar, S. de Mooij, R. Azevedo, M. Bannert, S. Jarvelis, and D. Gastevic, "Measuring self-regulated learning and the role of ai: Five years of research using multimodal multichannel data," _Computers in Human Behavior_, vol. 139, p. 107540, 2023.
* [162] S. Steyaert, M. Pizurica, D. Nagaraj, P. Khandelwal, T. Hernandez-Boussard, A. J. Gentles, and O. Gevaert, "Multimodal data fusion for cancer biomarker discovery with deep learning," _Nature Machine Intelligence_, vol. 5, no. 4, pp. 351-362, 2023.
* [163] V. Rani, S. T. Nabi, M. Kumar, A. Mittal, and K. Kumar, "Self-supervised learning: A succinct review," _Archives of Computational Methods in Engineering_, vol. 30, no. 4, pp. 2761-2775, 2023.
* [164] M. C. Schiappa, Y. S. Rawat, and M. Shah, "Self-supervised learning for videos: A survey," _ACM Computing Surveys_, vol. 55, no. 13s, pp. 1-37, 2023.
* [165] J. Yu, H. Yin, X. Xia, T. Chen, J. Li, and Z. Huang, "Self-supervised learning for recommender systems: A survey," _IEEE Transactions on Knowledge and Data Engineering_, 2023.
* [166] V. Bharti, A. Kumar, V. Purohit, R. Singh, A. K. Singh, and S. K. Singh, "A label efficient semi self-supervised learning framework for iot devices in industrial process," _IEEE Transactions on Industrial Informatics_, 2023.
* [167] D. Sam and J. Z. Kolter, "Losses over labels: Weakly supervised learning via direct loss construction," in _Proceedings of the AAAI Conference on Artificial Intelligence_, vol. 37, no. 8, 2023, pp. 9695-9703.
* [168] M. Wang, P. Xie, Y. Du, and X. Hu, "T5-based model for abstractive summarization: A semi-supervised learning approach with consistency loss functions," _Applied Sciences_, vol. 13, no. 12, p. 7111, 2023.
* [169] Q. Li, X. Peng, Y. Qiao, and Q. Hao, "Unsupervised person re-identification with multi-label learning guided self-paced clustering," _Pattern Recognition_, vol. 125, p. 108521, 2022.
* [170] P. Nancy, H. Pallathadka, M. Naved, K. Kaliyaperumal, K. Arumugam, and V. Garchar, "Deep learning and machine learning based efficient framework for image based plant disease classification and detection," in _2022 International Conference on Advanced Computing Technologies and Applications (ICACTA)_. IEEE, 2022, pp. 1-6.
* [171] P. An, Z. Wang, and C. Zhang, "Ensemble unsupervised autoencoders and gaussian mixture model for cyberattack detection," _Information Processing & Management_, vol. 59, no. 2, p. 102844, 2022.
* [172] S. Yan, H. Shao, Y. Xiao, B. Liu, and J. Wan, "Hybrid robust convolutional autoencoder for unsupervised anomaly detection of machine tools under noises," _Robotics and Computer-Integrated Manufacturing_, vol. 79, p. 102441, 2023.
* [173] E. Vaonglu, K. Davasiloglu, and Y. E. Sagduyu, "Machine learning in nextg networks via generative adversarial networks," _IEEE Transactions on Cognitive Communications and Networking_, vol. 8, no. 2, pp. 480-501, 2022.
* [174] K. Yan, X. Chen, X. Zhou, Z. Yan, and J. Ma, "Physical model informed fault detection and diagnosis of air handling units based on transformer generative adversarial network," _IEEE Transactions on Industrial Informatics_, vol. 19, no. 2, pp. 2192-2199, 2022.
* [175] N.-R. Zhou, T.-F. Zhang, X.-W. Xie, and J.-Y. Wu, "Hybrid quantum-classical generative adversarial networks for image generation via learning discrete distribution," _Signal Processing: Image Communication_, vol. 110, p. 116891, 2023.
* [176] P. Ladosz, L. Weng, M. Kim, and H. Oh, "Exploration in deep reinforcement learning: A survey," _Information Fusion_, vol. 85, pp. 1-22, 2022.

* [177] Y. Matsuo, Y. LeCun, M. Sahani, D. Precup, D. Silver, M. Sugiyama, E. Uchibe, and J. Morimoto, "Deep learning, reinforcement learning, and world models," _Neural Networks_, vol. 152, pp. 267-275, 2022.
* [178] D. Berotin, A. Zouitine, M. Zouitine, and E. Rachbou, "Look where you look! saliency-guided q-networks for generalization in visual reinforcement learning," _Advances in Neural Information Processing Systems_, vol. 35, pp. 30 693-30 706, 2022.
* [179] A. Hafiz, "A survey of deep q-networks used for reinforcement learning: State of the art," _Intelligent Communication Technologies and Virtual Mobile Networks: Proceedings of ICICV 2022_, pp. 393-402, 2022.
* [180] A. Hafiz, M. Hassaballah, A. Alqahtani, S. Alsubai, and M. A. Hameed, "Reinforcement learning with an ensemble of binary action deep q-networks," _Computer Systems Science & Engineering_, vol. 46, no. 3, 2023.
* [181] A. Alagha, S. Singh, R. Mizouni, J. Bentahar, and H. Otrok, "Target localization using multi-agent deep reinforcement learning with proximal policy optimization," _Future Generation Computer Systems_, vol. 136, pp. 342-357, 2022.
* [182] S. S. Hassan, Y. M. Park, Y. K. Tun, W. Saad, Z. Han, and C. S. Hong, "3to: Thr-enabled throughput and trajectory optimization of uavs in 6g networks by proximal policy optimization deep reinforcement learning," in _ICC 2022-IEEE International Conference on Communications_. IEEE, 2022, pp. 5712-5718.
* [183] A. K. Jayant and S. Bhatnagar, "Model-based safe deep reinforcement learning via a constrained proximal policy optimization algorithm," _Advances in Neural Information Processing Systems_, vol. 35, pp. 24 432-24 445, 2022.
* [184] B. Lin, "Reinforcement learning and bandits for speech and language processing: Tutorial, review and outlook," _Expert Systems with Applications_, p. 122254, 2023.
* [185] B. Luo, Z. Wu, F. Zhou, and B.-C. Wang, "Human-in-the-loop reinforcement learning in continuous-action space," _IEEE Transactions on Neural Networks and Learning Systems_, 2023.
* [186] A. Raza, K. P. Tran, L. Koehl, and S. Li, "Designing ceg monitoring healthcare system with federated transfer learning and explainable ai," _Knowledge-Based Systems_, vol. 236, p. 107763, 2022.
* [187] S. Siahpour, X. Li, and J. Lee, "A novel transfer learning approach in remaining useful life prediction for incomplete dataset," _IEEE Transactions on Instrumentation and Measurement_, vol. 71, pp. 1-11, 2022.
* [188] Z. Guo, K. Lin, X. Chen, and C.-Y. Chit, "Transfer learning for angle of arrivals estimation in massive mimo system," in _2022 IEEE/ICIC International Conference on Communications in China (ICCC)_. IEEE, 2022, pp. 506-511.
* [189] S. Liu, Y. Lu, F. Zheng, H. Shen, and J. Bao, "Adaptive reconstruction of digital twins for machining systems: A transfer learning approach," _Robotics and Computer-Integrated Manufacturing_, vol. 78, p. 102390, 2022.
* [190] H. Liu, J. Liu, L. Cui, Z. Teng, N. Duan, M. Zhou, and Y. Zhang, "Logiqa 2.0--an improved dataset for logical reasoning in natural language understanding," _IEEE/ACM Transactions on Audio, Speech, and Language Processing_, 2023.
* [191] Y. Meng, J. Huang, Y. Zhang, and J. Han, "Generating training data with language models: Towards zero-shot language understanding," _Advances in Neural Information Processing Systems_, vol. 35, pp. 462-477, 2022.
* [192] R. M. Samant, M. R. Bachute, S. Gite, and K. Kotecha, "Framework for deep learning-based language models using multi-task learning in natural language understanding: A systematic literature review and future directions," _IEEE Access_, vol. 10, pp. 17 078-17 097, 2022.
* [193] H. Weld, X. Huang, S. Long, J. Poon, and S. C. Han, "A survey of joint intent detection and slot filling models in natural language understanding," _ACM Computing Surveys_, vol. 55, no. 8, pp. 1-38, 2022.
* [194] S. Ajmal, A. A. I. Ahmed, and C. Jalota, "Natural language processing in improving information retrieval and knowledge discovery in healthcare conversational agents," _Journal of Artificial Intelligence and Machine Learning in Management_, vol. 7, no. 1, pp. 34-47, 2023.
* [195] A. Montejo-Raez and S. M. Jimenez-Zaffa, "Current approaches and applications in natural language processing," _Applied Sciences_, vol. 12, no. 10, p. 4859, 2022.
* [196] K. Vijayan, O. Anand, and A. Sahai, "Language-agnostic text processing for information extraction," in _CS & IT Conference Proceedings_, vol. 12, no. 23, CS & IT Conference Proceedings, 2022.
* [197] C. D. Manning, "Human language understanding & reasoning," _Daedalus_, vol. 151, no. 2, pp. 127-138, 2022.
* [198] W. Peng, D. Xu, T. Xu, J. Zhang, and E. Chen, "Are gpt embeddings useful for ads and recommendation?" in _International Conference on Knowledge Science, Engineering and Management_. Springer, 2023, pp. 151-162.
* [199] E. Erdem, M. Kuyu, S. Yagcioglu, A. Frank, L. Parcalabscu, B. Plank, A. Babii, O. Turuta, A. Erdem, I. Calixto _et al._, "Neural natural language generation: A survey on multisquality, multimodality, controllability and learning," _Journal of Artificial Intelligence Research_, vol. 73, pp. 1131-1207, 2022.
* [190] J. Qian, L. Dong, Y. Shen, F. Wei, and W. Chen, "Controllable natural language generation with contrastive prefixes," _arXiv preprint arXiv:2202.13257_, 2022.
* [191] H. Rashkin, V. Nikolaev, M. Lamm, L. Aroyo, M. Collins, D. Das, S. Petrov, G. S. Tomar, I. Turc, and D. Reitter, "Measuring attribution in natural language generation models," _Computational Linguistics_, pp. 1-64, 2023.
* [192] A. K. Pandey and S. S. Roy, "Natural language generation using sequential models: A survey," _Neural Processing Letters_, pp. 1-34, 2023.
* [193] J. Y. Khan and G. Uddin, "Automatic code documentation generation using gpt-3," in _Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering_, 2022, pp. 1-6.
* [194] Y. K. Dwivedi, N. Ksheri, L. Hughes, E. L. Slade, A. Jeyaraj, A. K. Kar, A. M. Baabdullah, A. Koola, V. Raghavan, M. Ahuja _et al._, "so what if chatgpt wrote it? multidisciplinary perspectives on opportunities, challenges and implications of generative conversational ai for research, practice and policy," _International Journal of Information Management_, vol. 71, p. 102642, 2023.
* [195] T. Fu, S. Gao, X. Zhao, J.-r. Wen, and R. Yan, "Learning towards conversational ai: A survey," _A Open_, vol. 3, pp. 14-28, 2022.
* [196] H. Ji, I. Han, and Y. Ko, "A systematic review of conversational ai in language education: Focusing on the collaboration with human teachers," _Journal of Research on Technology in Education_, vol. 55, no. 1, pp. 48-63, 2023.
* [197] Y. Wan, W. Wang, P. He, J. Gu, H. Bai, and M. R. Lyu, "Biassaker: Measuring the bias in conversational ai system," in _Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering_, 2023, pp. 515-527.
* [198] S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra, and A. Abraham, "Ai-based conversational agents: A scoping review from technologies to future directions," _IEEE Access_, 2022.
* [200] Z. Xiao, "Seeing us through machines: designing and building conversational ai to understand humans," Ph.D. dissertation, University of Illinois at Urbana-Champaign, 2023.
* [201] H.-K. Ko, G. Park, H. Jeon, J. Jo, J. Kim, and J. Seo, "Large-scale text-to-image generation models for visual artists' creative works," in _Proceedings of the 28th International Conference on Intelligent User Interfaces_, 2023, pp. 919-933.
* [202] A. Pearson, "The rise of creatlives: Using ai to enable and speed up the creative process," _Journal of AI, Robotics & Workplace Automation_, vol. 2, no. 2, pp. 101-114, 2023.
* [203] J. Rezwana and M. L. Maher, "Designing creative ai partners with cofi: A framework for modeling interaction in human-ai co-creative systems," _ACM Transactions on Computer-Human Interaction_, vol. 30, no. 5, pp. 1-28, 2023.
* [204] S. Sharma and S. Bwuma, "Generative adversarial networks (gans) for creative applications: Exploring at and music generation," _International Journal of Multidisciplinary Innovation and Research Methodology, ISSN: 2960-2068_, vol. 2, no. 4, pp. 29-33, 2023.
* [205] B. Attard-Frost, A. De los Rios, and D. R. Walters, "The ethics of ai business practices: a review of 4/ ai ethics guidelines," _AI and Ethics_, vol. 3, no. 2, pp. 389-406, 2023.
* [206] A. Gardner, A. L. Smith, A. Steventon, E. Coughlan, and M. Oldfield, "Ethical funding for trustworthy ai: proposals to address the responsibilities of funders to ensure that projects adhere to trustworthy ai practice," _AI and Ethics_, pp. 1-15, 2022.
* [207] J. Schuett, "Three lines of defense against risks from ai," _AI & SOCIETY_, pp. 1-15, 2023.
* [208] M. Sloane and J. Zakrzewski, "German ai start-ups and "ai ethics". Using a social practice lens for assessing and implementing socio-technical innovation," in _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, 2022, pp. 935-947.
* [209] M. Vasconcelos, C. Cardonha, and B. Goncalves, "Modeling epistemological principles for bias mitigation in ai systems: an illustration in hiring decisions," in _Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society_, 2018, pp. 323-329.

* [219] Y. Yang, A. Gupta, J. Feng, P. Singhal, V. Yadav, Y. Wu, P. Natarajan, V. Hedau, and J. Joo, "Enhancing fairness in face detection in computer vision systems by demographic bias mitigation," in _Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society_, 2022, pp. 813-822.
* [220] R. Schwartz, A. Vassilev, K. Greene, L. Perine, A. Burt, P. Hall _et al._, "Towards a standard for identifying and managing bias in artificial intelligence," _NIST special publication_, vol. 1270, no. 10.6028, 2022.
* [221] W. Guo and A. Caliskan, "Detecting emergent intersectional biases: Contextualized word embeddings ontain a distribution of human-like biases," in _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, 2021, pp. 122-133.
* [222] Y. Kong, "Are "intersectionally fair ai algorithms really fair to women of color? a philosophical analysis," in _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, 2022, pp. 485-494.
* [223] Y. C. Tan and L. E. Celis, "Assessing social and intersectional biases in contextualized word representations," _Advances in neural information processing systems_, vol. 32, 2019.
* [224] L. Cheng, A. Mosallanzadeh, P. Sheth, and H. Liu, "Causal learning for socially responsible ai," _arXiv preprint arXiv:2104.12278_, 2021.
* [225] J. D. Correa, J. Tian, and E. Bareinboim, "Identification of causal effects in the presence of selection bias," in _Proceedings of the AAAI Conference on Artificial Intelligence_, vol. 33, no. 01, 2019, pp. 2744-2751.
* [226] B. Ghai and K. Mueller, "D-bias: a causality-based human-in-the-loop system for tackling algorithmic bias," _IEEE Transactions on Visualization and Computer Graphics_, vol. 29, no. 1, pp. 473-482, 2022.
* [227] J. N. Yan, Z. Gu, H. Lin, and J. M. Rezzotralski, "Silva: Interactively assessing machine learning fairness using causality," in _Proceedings of the 2020 chi conference on human factors in computing systems_, 2020, pp. 1-13.
* [228] E. Bertino, M. Kantarcioglu, C. G. Akcora, S. Samtani, S. Mittal, and M. Gupta, "Ai for security and security for ai," in _Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy_, 2021, pp. 333-334.
* [229] H. Susanto, L. F. Vie, D. Rosiyadi, A. I. Basuki, and D. Setiana, "Data security for connected governments and organisations: Managing automation and artificial intelligence," in _Web 2.0 and cloud technologies for implementing connected government_. IGI Global, 2021, pp. 229-251.
* [230] S. Dilmaghani, M. R. Brust, G. Danoy, N. Cassagnes, J. Pecero, and P. Bouvry, "Privacy and security of big data in a systems: A research and standards perspective," in _2019 IEEE International Conference on Big Data (Big Data)_. IEEE, 2019, pp. 5737-5743.
* [231] T. McIntosh, "Intercepting ransomware attacks with staged event-driven access control," Ph.D. dissertation, La Trobe, 2022.
* [232] T. McIntosh, A. Kayes, Y.-P. P. Chen, A. Ng, and P. Watters, "Applying staged event-driven access control to combat ransomware," _Computers & Security_, vol. 128, p. 103160, 2023.
* [233] P. Hummel, M. Braun, M. Trefter, and P. Dabrock, "Data sovereignty: A review," _Big Data & Society_, vol. 8, no. 1, p. 2053951720982012, 2021.
* [234] M. Lukings and A. Habibi Lashkari, "Data sovereignty," in _Understanding Cybersecurity Law in Data Sovereigny and Digital Governance: An Overview from a Legal Perspective_. Springer, 2022, pp. 1-38.
* [235] M. Hickok, "Lessons learned from ai ethics principles for future actions," _AI and Ethics_, vol. 1, no. 1, pp. 41-47, 2021.
* [236] J. Zhou and F. Chen, "Ai ethics: From principles to practice," _AI & SOCIETP_, pp. 1-11, 2022.
* [237] J. A. Kroll, "Outlining traceability: A principle for operationalizing accountability in computing systems," in _Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency_, 2021, pp. 758-771.
* [238] A. Oseni, N. Moustafa, H. Janicke, P. Liu, Z. Tari, and A. Vasilakos, "Security and privacy for artificial intelligence: Opportunities and challenges," _arXiv preprint arXiv:2102.04660_, 2021.
* [239] B. C. Stahl and D. Wright, "Ethics and privacy in ai and big data: Implementing responsible research and innovation," _IEEE Security & Privacy_, vol. 16, no. 3, pp. 26-33, 2018.
* [240] C. Ma, J. Li, K. Wei, B. Liu, M. Ding, L. Yuan, Z. Han, and H. V. Poor, "Trusted ai in multiagent systems: An overview of privacy and security for distributed learning," _Proceedings of the IEEE_, vol. 111, no. 9, pp. 1097-1132, 2023.
* [241] M. Song, Z. Wang, Z. Zhang, Y. Song, Q. Wang, J. Ren, and H. Qi, "Analyzing user-level privacy attack against federated learning," _IEEE Journal on Selected Areas in Communications_, vol. 38, no. 10, pp. 2430-2444, 2020.
* [242] I. Misra and L. v. d. Maaten, "Self-supervised learning of pretext-invariant representations," in _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, 2020, pp. 6707-6717.
* [243] X. Zhai, A. Oliver, A. Kolesnikov, and L. Beyer, "54d: Self-supervised semi-supervised learning," in _Proceedings of the IEEE/CVF international conference on computer vision_, 2019, pp. 1476-1485.
* [244] T. Chen, X. Zhai, M. Ritter, M. Lucic, and N. Houlsby, "Self-supervised gans via auxiliary rotation loss," in _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, 2019, pp. 12 154-12 163.
* [245] S. Jemi and P. Favaro, "Self-supervised feature learning by learning to spot artifacts," in _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_, 2018, pp. 2733-2742.
* [246] P. Patel, N. Kumari, M. Singh, and B. Krishnamurthy, "Lt-gan: Self-supervised gan with latent transformation detection," in _Proceedings of the IEEE/CVF winter conference on applications of computer vision_, 2021, pp. 3189-3198.
* [247] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, "A simple framework for contrastive learning of visual representations," in _International conference on machine learning_. PMLR, 2020, pp. 1597-1607.
* [248] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, "Momentum contrast for unsupervised visual representation learning," in _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, 2020, pp. 9729-9738.
* [249] A. T. Liu, S.-W. Li, and H.-y. Lee, "Tera: Self-supervised learning of transformer encoder representation for speech," _IEEE/ACM Transactions on Audio, Speech, and Language Processing_, vol. 29, pp. 2351-2366, 2021.
* [250] Y. Pang, W. Wang, F. E. Tay, W. Liu, Y. Tian, and L. Yuan, "Masked autoencoders for point cloud self-supervised learning," in _European conference on computer vision_. Springer, 2022, pp. 604-621.
* [251] T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, "Meta-learning in neural networks: A survey," _IEEE transactions on pattern analysis and machine intelligence_, vol. 44, no. 9, pp. 5149-5169, 2021.
* [252] R. Vilalta and Y. Drissi, "A perspective view and survey of meta-learning," _Artificial intelligence review_, vol. 18, pp. 77-95, 2002.
* [253] M. Al-Shedirat, L. Li, E. Xing, and A. Talwalkar, "On data efficiency of meta-learning," in _International Conference on Artificial Intelligence and Statistics_. PMLR, 2021, pp. 1369-1377.
* [254] Y. Hu, R. Liu, X. Li, D. Chen, and Q. Hu, "Task-sequencing meta learning for intelligent few-shot fault diagnosis with limited data," _IEEE Transactions on Industrial Informatics_, vol. 18, no. 6, pp. 3894-3904, 2021.
* [255] S. Baik, J. Choi, H. Kim, D. Cho, J. Min, and K. M. Lee, "Meta-learning with task-adaptive loss function for few-shot learning," in _Proceedings of the IEEE/CVF international conference on computer vision_, 2012, pp. 9465-9474.
* [256] Y. Chen, Z. Liu, H. Xu, T. Darrell, and X. Wang, "Meta-baseline: Exploring simple meta-learning for few-shot learning," in _Proceedings of the IEEE/CVF international conference on computer vision_, 2021, pp. 9062-9071.
* [257] M. A. Jamal and G.-J. Qi, "Task agnostic meta-learning for few-shot learning," in _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, 2019, pp. 11719-11727.
* [258] R. Behnia, M. R. Ebrahimi, J. Pacheco, and B. Padmanabhan, "Ew-tune: A framework for privately fine-tuning large language models with differential privacy," in _2022 IEEE International Conference on Data Mining Workshops (ICDMW)_. IEEE, 2022, pp. 560-566.
* [259] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, "Fine-intended language models are zero-shot learners," _arXiv preprint arXiv:22019.01652_, 2021.
* [260] W. Kuang, B. Qian, Z. Li, D. Chen, D. Gao, X. Pan, Y. Xie, Y. Li, B. Ding, and J. Zhou, "Federatedscope-llm: A comprehensive package for fine-tuning large language models in federated learning," _arXiv preprint arXiv:2309.00363_, 2023.
* [261] M. Nguyen, K. Kishan, T. Nguyen, A. Chadha, and T. Vu, "Efficient fine-tuning large language models for knowledge-aware response planning," in _Ioint European Conference on Machine Learning and Knowledge Discovery in Databases_. Springer, 2023, pp. 593-611.
* [262] M. Engel* [263] T. T. Nguyen, C. Wilson, and J. Dalins, "Fine-tuning llama 2 large language models for detecting online sexual predatory chats and abusive texts," _arXiv preprint arXiv:2308.14683_, 2023.
* [264] Q. Zhou, C. Yu, S. Zhang, S. Wu, Z. Wang, and F. Wang, "Regionbip: A unified multi-modal pre-training framework for holistic and regional comprehension," _arXiv preprint arXiv:2308.02299_, 2023.
* 2017년 _AI, 윤리 및 사회_ 에 대 한 AAAI 워크샵에서 시스템을 책임지게 하는 것은 무엇입니까?
* [266] I. Gabriel and V. Ghazavi, "The challenge of value alignment: From fairer algorithms to ai safety," _arXiv preprint arXiv:2101.06606_, 2021.
* [267] S. Nyholm, "Responsibility gaps, value alignment, and meaningful human control over artificial intelligence," in _Risk and responsibility in context_. Routledge, 2023, pp. 191-213.
* [268] S. Wu, H. Fei, L. Qu, W. Ji, and T.-S. Chua, "Next-gpt: Any-to-any multimodal lm," _arXiv preprint arXiv:2309.05519_, 2023.
* [269] K. Bayoudh, R. Kanani, F. Hamdaoui, and A. Mihba, "A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets," _The Visual Computer_, pp. 1-32, 2021.
* [270] P. Hu, L. Zhen, D. Peng, and P. Liu, "Scalable deep multimodal learning for cross-modal retrieval," in _Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval_, 2019, pp. 635-644.
* [271] A. Rahate, R. Walambe, S. Ramanna, and K. Kotecha, "Multimodal co-learning: Challenges, applications with datasets, recent advances and future directions," _Information Fusion_, vol. 81, pp. 203-239, 2022.
* [272] L. Che, J. Wang, Y. Zhou, and F. Ma, "Multimodal federated learning: A survey," _Sensors_, vol. 23, no. 15, p. 6986, 2023.
* [273] P. P. Liang, Y. Lyu, X. Fan, Z. Wu, Y. Cheng, J. Wu, L. Chen, P. Wu, M. A. Lee, Y. Zhu _et al._, "Multibench: Multiscale benchmarks for multimodal representation learning," _arXiv preprint arXiv:2107.07502_, 2021.
* [274] Z. Ashktorab, Q. V. Liao, C. Dugan, J. Johnson, Q. Pan, W. Zhang, S. Kumaravel, and M. Campbell, "Human-ai collaboration in a cooperative game setting: Measuring social perception and outcomes," _Proceedings of the ACM on Human-Computer Interaction_, vol. 4, no. CSCW2, pp. 1-20, 2020.
* [275] P. Esmaeilzadeh, T. Mirzaei, and S. Dharanikota, "Patients' perceptions toward human-artificial intelligence interaction in health care: experimental study," _Journal of medical Internet research_, vol. 23, no. 11, p. e25856, 2021.
* [276] M. Nazar, M. M. Alam, E. Yafi, and M. M. Su'ud, "A systematic review of human-computer interaction and explainable artificial intelligence in healthcare with artificial intelligence techniques," _IEEE Access_, vol. 9, pp. 153 316-153 348, 2021.
* [277] A. S. Rajawat, R. Rawat, K. Barhampurkar, R. N. Shaw, and A. Ghosh, "Robotic process automation with increasing productivity and improving product quality using artificial intelligence and machine learning," in _Artificial Intelligence for Future Generation Robotics_. Elsevier, 2021, pp. 1-13.
* [278] S. Mohseni, N. Zarei, and E. D. Ragan, "A multidisciplinary survey and framework for design and evaluation of explainable ai systems," _ACM Transactions on Interactive Intelligent Systems (TiiS)_, vol. 11, no. 3-4, pp. 1-45, 2021.
* [279] M. C. Boehler and T. H. Weisswarse, "Theory of mind based communication for human agent cooperation," in _2020 IEEE International Conference on Human-Machine Systems (ICIMHS)_. IEEE, 2020, pp. 1-6.
* [280] M. M. Celikok, T. Peltola, P. Daee, and S. Kaski, "Interactive ai with a theory of mind," _arXiv preprint arXiv:1912.05284_, 2019.
* [281] A. Dafoe, E. Hughes, Y. Bachrach, T. Collins, K. R. McKee, J. Z. Leibo, K. Larson, and T. Graepel, "Open problems in cooperative ai," _arXiv preprint arXiv:2012.068630_, 2020.
* [282] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg _et al._, "Sparks of artificial general intelligence: Early experiments with gpt-4," _arXiv preprint arXiv:2308.12712_, 2023.
* [283] N. Fei, Z. Lu, Y. Gao, G. Yang, Y. Huo, J. Wen, H. Lu, R. Song, X. Gao, T. Xiang _et al._, "Towards artificial general intelligence via a multimodal foundation model," _Nature Communications_, vol. 13, no. 1, p. 3094, 2022.
* [284] R. Williams and R. Yampolskiy, "Understanding and avoiding ai failures: A practical guide," _Philosophies_, vol. 6, no. 3, p. 53, 2021.
* [285] W. Fedus, B. Zoph, and N. Shazeer, "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity," _The Journal of Machine Learning Research_, vol. 23, no. 1, pp. 5232-5270, 2022.
* [286] S. Shen, L. Hou, Y. Zhou, N. Du, S. Longpre, J. Wei, H. W. Chung, B. Zoph, W. Fedus, X. Chen _et al._, "Mixture-of-experts meets instruction tuning: A winning combination for large language models," _arXiv preprint arXiv:2305.14705_, 2023.
* [287] S. Rajbhandari, C. Li, Z. Yao, M. Zhang, R. Y. Aminabadi, A. A. Awan, J. Raskey, and Y. He, "Deepsposed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale," in _International Conference on Machine Learning_. PMLR, 2022, pp. 18 332-18 346.
* [288] L. Shen, Z. Wu, W. Gong, H. Hao, Y. Bai, H. Wu, X. Wu, J. Bian, H. Xiong, D. Yu _et al._, "Se-moe: A scalable and efficient mixture-of-experts distributed training and inference system," _arXiv preprint arXiv:2205.10043_, 2022.
* [289] C. Hwang, W. Cui, X. Xiong, Z. Yang, Z. Liu, H. Hu, Z. Wang, R. Salas, J. Jose, P. Ram _et al._, "Tutel: Adaptive mixture-of-experts at scale," _Proceedings of Machine Learning and Systems_, vol. 5, 2023.
* [290] Y. Wang, S. Mukherjee, X. Liu, J. Gao, A. H. Awadallah, and J. Gao, "Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models," _arXiv preprint arXiv:2205.12410_, vol. 1, no. 2, p. 4, 2022.
* [291] T. Chen, Z. Zhang, A. Jaiswal, S. Liu, and Z. Wang, "Sparse moe as the new dropout: Scaling dense and self-simhmable transformers," _arXiv preprint arXiv:2303.01610_, 2023.
* [292] H. Zhu, B. He, and X. Zhang, "Multi-gate mixture-of-experts stacked autoencoders for quality prediction in blast furnace inboxmaking," _ACS omega_, vol. 7, no. 45, pp. 41 296-41 303, 2022.
* [293] Z. Chi, L. Dong, S. Huang, D. Dai, S. Ma, B. Patra, S. Singhal, P. Bajaj, X. Song, X.-L. Mao _et al._, "On the representation collapse of sparse mixture or experts," _Advances in Neural Information Processing Systems_, vol. 35, pp. 34 600-34 6162, 2021.
* [294] S. Gupta, S. Mukherjee, K. Subudhi, E. Gonzalez, D. Jose, A. H. Awadallah, and J. Gao, "Sparsky activated mixture-of-experts are robust multi-task learners," _arXiv preprint arXiv:2204.07689_, 2022.
* [295] N. Dikkala, N. Ghosh, R. Meka, R. Panigrahy, N. Vyas, and X. Wang, "On the benefits of learning to route in mixture-of-experts models," in _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, 2023, pp. 9376-9396.
* [296] N. Dryden and T. Hoefler, "Spatial mixture-of-experts," _Advances in Neural Information Processing Systems_, vol. 35, pp. 11 697-11 713, 2022.
* [297] Z. You, S. Feng, D. Su, and D. Yu, "Speechmoe2: Mixture-of-experts model with improved routing," in _ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)_. IEEE, 2022, pp. 7217-7221.
* [298] J. Puigcer, R. Jenatton, C. Riquelme, P. Awasthi, and S. Rhojan-palli, "On the adversarial robustness of mixture of experts," _Advances in Neural Information Processing Systems_, vol. 35, pp. 9660-9671, 2022.
* [299] J. Li, Y. Jiang, Y. Zhu, C. Wang, and H. Xu, "Accelerating distributed (MoE) training and inference with lina," in _2023 USENIX Annual Technical Conference (USENIX ATC 23)_, 2023, pp. 945-959.
* [300] L. Wu, M. Liu, Y. Chen, D. Chen, S. Dai, and L. Yuan, "Residual mixture of experts," _arXiv preprint arXiv:2204.09636_, 2022.
* [301] B. Zoph, I. Bello, S. Kumar, N. Du, Y. Huang, J. Dean, N. Shazeer, and W. Fedus, "Designing effective sparse expert models," _arXiv preprint arXiv:2202.08906_, vol. 2, 2022.
* [302] ----, "St-moe: Designing stable and transferable sparse expert models," _arXiv preprint arXiv:2202.08906_, 2022.
* [303] Y. Chow, A. Tulberberbergarovo, O. Nachum, M. Ryu, M. Ghavamzadeh, and C. Boutilier, "A mixture-of-expert approach to rl-based dialogue management," _arXiv preprint arXiv:2206.00059_, 2022.
* [304] Z. Fan, R. Sarkar, Z. Jiang, T. Chen, K. Zou, Y. Cheng, C. Hao, Z. Wang _et al._, "M3"wit: Mixture-of-experts vision transformer for efficient multi-task learning * [308] Z. Jia, X. Li, Z. Ling, S. Liu, Y. Wu, and H. Su, "Improving policy optimization with generalist-specialist learning," in _International Conference on Machine Learning_. PMLR, 2022, pp. 10 104-10 119.
* [309] M. Simeone, "Unknown future, repeated present: a narrative-centered analysis of long-term ai discourse," _Human Studies & the Digital Age_, vol. 7, no. 1, 2022.
* [310] A. Nair and F. Banaei-Kashani, "Bridging the gap between artificial intelligence and artificial general intelligence: A ten command framework for human-like intelligence," _arXiv preprint arXiv:2210.09366_, 2022.
* [311] M. H. Jarrahi, D. Askay, A. Eshraghi, and P. Smith, "Artificial intelligence and knowledge management: A partnership between human and ai," _Business Horizons_, vol. 66, no. 1, pp. 87-99, 2023.
* [312] D. J. Edwards, C. McEinteggert, and Y. Barnes-Holmes, "A functional contextual account of background knowledge in categorization: Implications for artificial general intelligence and cognitive accounts of general knowledge," _Frontiers in Psychology_, vol. 13, p. 745306, 2022.
* [313] J. McCarthy, "Artificial intelligence, logic, and formalising common sense," _Machine Learning and the City: Applications in Architecture and Urban Design_, pp. 69-90, 2022.
* [314] S. Friederich, "Symbiosis, not alignment, as the goal for liberal democracies in the transition to artificial general intelligence," _AI and Ethics_, pp. 1-10, 2023.
* [315] S. Makirdakis, "The forthcoming artificial intelligence (ai) revolution: Its impact on society and firms," _Futures_, vol. 90, pp. 46-60, 2017.
* [316] S. Pal, K. Kumari, S. Kadam, and A. Saha, "The ai revolution," _IARA Publication_, 2023.
* [317] S. Verma, R. Sharma, S. Deb, and D. Maitra, "Artificial intelligence in marketing: Systematic review and future research direction," _International Journal of Information Management Data Insights_, vol. 1, no. 1, p. 100002, 2021.
* [318] P. Budhwar, S. Chowdhury, G. Wood, H. Aguinis, G. J. Bamber, J. R. Beltran, P. Bosele, F. Lee Cooke, S. Decker, A. DeNisi _et al._, "Human resource management in the age of generative artificial intelligence: Perspectives and research directions on chataptapt," _Human Resource Management Journal_, vol. 33, no. 3, pp. 606-659, 2023.
* [319] J. B. Tekamp and M. H. Anderson, "The implications of diverse human moral foundations for assessing the ethics of artificial intelligence," _Journal of Business Ethics_, vol. 178, no. 4, pp. 961-976, 2022.
* [320] X. Zhou, C. Liu, L. Zhai, Z. Jia, C. Guan, and Y. Liu, "Interpretable and robust ai in eeg systems: A survey," _arXiv preprint arXiv:2304.10755_, 2023.
* [321] C. Zhang, C. Zhang, C. Li, Y. Qiao, S. Zheng, S. K. Dam, M. Zhang, J. U. Kim, S. T. Kim, J. Choi _et al._, "One small step for generative ai, one giant leap for agi: A complete survey on chatapt in aige era," _arXiv preprint arXiv:2304.06488_, 2023.
* [322] K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Walczynski, L. Hou, K. Clark, S. Prohl, H. Cole-Lewis, D. Neal _et al._, "Towards expert-level medical question answering with large language models," _arXiv preprint arXiv:2305.09617_, 2023.
* [323] S. Wu, O. Irsoy, S. Lu, V. Dabravolski, M. Dredze, S. Gehrmann, P. Kambardur, D. Rosenberg, and G. Mann, "Bloomberggrp: A large language model for finance," _arXiv preprint arXiv:2303.17564_, 2023.
* [324] P. Henderson, K. Sinha, N. Angelard-Gontier, N. R. Ke, G. Fried, R. Lowe, and J. Pineau, "Ethical challenges in data-driven dialogue systems," in _Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society_, 2018, pp. 123-129.
* [325] S. A. Bin-Nashwan, M. Sadallah, and M. Bouteraa, "Use of chatapt in academia: Academic integrity hanes in the balance," _Technology in Society_, vol. 75, p. 102370, 2023.
* [326] N. Liu, A. Brown _et al._, "Ai increases the pressure to overhaul the scientific peer review process: comment on "artificial intelligence can generate fraudulent but authentic-looking scientific medical articles: Pandora's box has been opened"," _J Med Internet Res_, vol. 25, p. e50591, 2023.
* [327] A. P. Siddaway, A. M. Wood, and L. V. Hedges, "How to do a systematic review: a best practice guide for conducting and reporting narrative reviews, meta-analyses, and meta-synthesises," _Annual review of psychology_, vol. 70, pp. 747-770, 2019.
* [328] E. Landhuis, "Scientific literature: Information overload," _Nature_, vol. 535, no. 7612, pp. 457-458, 2016.
* [329] G. D. Chloros, V. P. Giannotidis, and P. V. Giannoudis, "Peer-reviewing in surgical journals: revolutionize or perish?" _Annals of surgery_, vol. 275, no. 1, pp. e82-e90, 2022.
* [330] K.-A. Allen, J. Reardon, Y. Lu, D. V. Smith, E. Rainsford, and L. Walsh, "Towards improving peer review: Crowd-sourced insights from twitter," _Journal of university teaching & learning practice_, vol. 19, no. 3, p. 02, 2022.
