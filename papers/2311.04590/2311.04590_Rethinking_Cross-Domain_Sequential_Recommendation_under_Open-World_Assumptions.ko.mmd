[MISSING_PAGE_FAIL:1]

모델링의 선택 편향. 개방 세계 환경에서는 입출력 공간이 확장되고, 보이지 않는 요인에 의해 데이터 분포가 이동한다. 따라서 CDSR에서 모델의 성능을 향상시키기 위해서는 개방형 가정 하에서 발생하는 문제를 해결하는 것이 필수적이다.

먼저 _겹치는 사용자가 거의 없는 여러 도메인의 경우 겹치지 않는 사용자를 사용하여 모델을 구성하고 권장 성능을 개선하는 방법_ 이 있습니까? 대부분의 이전의 CDSR 메소드는 부분적으로 중첩되는 CDSR 설정을 처리하도록 직접 확장될 수 없으며, 특히 실제 세계에서 종종 접하는 도메인 전체에 걸쳐 소수의 공유 사용자만이 존재할 때 더욱 그러하다. 이러한 과제를 해결하기 위해, 최근의 연구들(Beng et al., 2017; Chen et al., 2018; Li et al., 2019; Li et al., 2019)은 중첩 및 비중첩 사용자 임베딩을 모두 향상시키고 비중첩 사용자들 사이에서 관심 정보를 전파하기 위한 그래픽 딥 러닝의 사용을 탐색하였다. 보다 최근에, Cao 등(Cao 등, 2019)은 비중첩 사용자 임베딩의 학습을 개선하기 위해 대조적 교차 도메인 인포맥스 목적을 갖는 그래프 신경망을 설계했다. 그럼에도 불구하고 부분적으로 겹치는 CDSR 시나리오에서 이러한 방법은 큰 한계를 가지며 개방 세계 가정 하에서 성능을 떨어뜨릴 것이다. 이러한 CDSR 접근법은 여전히 중복 사용자에 크게 의존하며, 70% 이상의 사용자가 도메인 간에 공통적이며 여러 도메인 간의 브리지 연결을 설정하고 지식 집계 및 전환 프로세스를 수행한다.

두 번째 문제는 개방형 시나리오의 관찰에서 발생 합니다. 권장 시스템은 주로 활성 사용자와 자주 참여 합니다. 트레이닝 단계에서, 플랫폼에 노출되지 않고, 따라서 모델들에 알려지지 않은 일부 노출되지 않은 사용자들은 테스트 단계에서 표면화될 수 있다. 이 이슈는 오프라인에서 온라인 환경으로 적응한 후에 성능 저하를 야기한다(Li et al., 2019; Li et al., 2019; Li et al., 2019). 두 번째 과제는 _데이터 분산 이동과 함께 환경에서 모델의 선택 편향을 완화하는 방법?_입니다. CaseQ(Li et al., 2019)는 다양한 환경에서 시간적 패턴을 포착하기 위해 시퀀스의 문맥별 표현을 학습한다. 유사하게, DCRec(Li 등, 2019)은 단일-도메인 추천 시스템들에서 인기 편향 이슈를 다루기 위한 새로운 디바이어싱 대조적 학습 패러다임을 제안한다. 그러나 이러한 방법은 개방형 시나리오에 존재하는 도메인 간의 선택 편향을 간과하여 편향된 성능 추정으로 이어진다. 이러한 선택 편향을 해결하기 위해, (Li 등, 2019)는 IPS(Inverse-Propensity-Score) 추정기를 제안하지만, 종종 높은 분산을 겪는다.

본 논문에서는 먼저 개방형 가정 하에서 교차 도메인 순차적 추천을 재고하고 주요 과제를 식별한다. 이러한 문제를 해결하기 위해 본 논문에서는 다중 관심 정보 모듈과 이중 로버스트 추정기를 포함하는 CDSR을 위한 적응형 다중 관심 디바이징 프레임워크를 제안한다.

**우리의 기여는 다음과 같습니다.**

**1)** 알고 있는 범위 내에서는, 이 문서는 CSDR의 개방형 문제를 해결하는 첫 번째 노력입니다. 실증 분석을 통해 기존 CDSR 모델을 오픈 월드 환경으로 확장하면 간과되었던 두 가지 주요 과제가 발생한다는 것을 보여준다. i) 중복되는 사용자에 의존하지 않고, 대부분의 사용자가 중복되지 않는 시나리오에서 모델을 구성하는 방법. 및 ii) 데이터 분배 시프트와 함께 모델의 선택 편향을 제거하는 방법.

**2)** 대부분의 기성 SDSR 메서드 (Li et al., 2019; Li et al., 2019; Li et al., 2019)와 통합 될 수 있는 교차 도메인 순차 권장 사항 (**AMID**)에 대 한 **A** 적응형 **M**ulti-**I**ninterest **D**ebiasing framework** 를 설계 합니다. 다중 관심 정보 모듈(**MIM**)과 이중 로버스트 추정기(**DRE**)로 구성된다. MIM은 중첩된 사용자와 중첩되지 않은 사용자 모두에 대해 교차 도메인 정보를 전달하는 반면, DRE는 선택 편향과 인기 편향을 제거하여 편향되지 않은 성능 추정치를 얻는다. 또한, (Li et al., 2019)에서 사용된 IPS 추정기와 비교하여 편향과 꼬리 경계 측면에서 DRE의 우수성을 입증하는 이론적 분석을 제공한다.

**3)** 커뮤니티, 특히 개방형 가정 하에서 커뮤니티의 추가 연구를 촉진하기 위해 **MYbank-CDR** 이라고 하는 알리페이의 실제 공식 CDSR 데이터 세트를 수집했습니다. 우리가 알고 있는 한 **"MYbank-CDR"** 은 공개적으로 사용 가능한 첫 번째 교차 도메인 금융 데이터 세트입니다. 수집된 데이터 세트 "MYbank-CDR"과 소스 코드는 수락 시 공개적으로 사용할 수 있다.

**4)** 제안된 **AMID** 가 여러 단일 도메인 순차 추천 모델과 통합될 때 CDR, CDSR 및 디바이어싱 방법과 비교하여 최신 결과를 달성한다는 것을 보여줍니다. 또한, 수백만 개의 일일 트래픽 로그를 가진 실제 CDSR 금융 플랫폼에서 제안된 프레임워크의 성능을 검증하기 위해 온라인 실험을 수행한다.

## 2. Motivation: towards open-world CDSR

현재 CDSR 방법은 도메인에 걸쳐 완전히 또는 대부분 겹치는 사용자가 존재한다고 가정하는 폐쇄 세계 가정 하에서 실험을 수행한다. 그러나, 실세계 애플리케이션에서, 도메인들에 걸쳐 중첩되는 사용자들의 수는 전형적으로 소수이다. 오픈월드 환경에서 그들의 성능을 검증하기 위해 세 가지 단일 도메인 순차 추천 방법(BERT4Rec(Liu et al., 2019), GRU4Rec(Li et al., 2019) 및 SASRec(Li et al., 2019))과 세 가지 교차 도메인 순차 추천 방법(Pi-Net(Li et al., 2019), DASL(Li et al., 2019) 및 C\({}^{2}\)DSR(Cao et al., 2019))을 사용하여 아마존 데이터 세트에 대한 동기 실험을 수행한다. 이전 연구(Li et al., 2019; Li et al., 2019)에 따라 서로 다른 CDSR 시나리오를 시뮬레이션하기 위해 중첩 비율 1을 변경한다. 그림 2의 두 도메인에서 모델의 성능에 대한 그래프를 제시한다. 영화 도메인에서 SASRec(SDSR)가 최상의 성능을 달성한다. 유사하게, 100% 중첩 비율을 갖는 뮤직 도메인에서, SASRec(SDSR)는 DASL(CDSR)보다 성능이 우수하다. 이는 기존 CDSR 방법이 중복되는 사용자에 의존하여 모델을 구성하거나 도메인 간 정보를 전송하기 때문에 부분적으로 중복되는 시나리오에서 성능 저하로 이어지기 때문이다. 따라서 이 발견은 오픈 월드 환경에서 적용할 수 있는 고성능 CDSR 모델을 설계하는 동기 요인으로 작용한다(_**1차 챌린지**_). 또한, SDSR 방법이 CDSR 방법에 비해 중복 사용자에 대한 의존도가 낮은 반직관적 현상이 관찰되었다. 이상적인 시나리오에서 SDSR 방법은 중복 사용자 비율이 높을 때 CDSR 방법에 비해 열등한 성능을 보여야 한다. 그러나, 실험 결과는 그 비율이 감소함에 따라 성능 격차가 실제로 감소한다는 것을 보여주었다. 놀랍게도, 비율이 작을 때, 소수의 SDSR 방법의 성능은 CDSR 방법보다 우수하고, 경우에 따라서는 비율이 높을 때에도 우수하다.

이 현상의 근본적인 원인을 분석하기 위해 우리는 열차 집합과 시험 집합 사이의 분포 이동을 시각화하려고 한다. 도 6은 열차 세트(청색 도트) 및 시험 세트(녹색 도트)에 대한 사용자 임베딩 2의 t-SNE 시각화를 디스플레이한다. 25% 비율의 훈련은 실제 시나리오의 훈련 데이터가 보이지 않는 요인으로 고통받을 수 있는 상황을 시뮬레이션한다. 25% 비율에서의 분포 차이가 100% 비율에서의 분포 차이보다 더 크다는 것을 관찰했다. 이러한 시각화 결과는 훈련에서 테스트로의 분포 이동이 CDSR 시나리오에서 실제로 존재함을 확인한다. 분배 이동은 종종 개방 세계 가정 하에서 현실 세계 플랫폼에서 발생한다. 실제 추천 시스템에서는 추정된 전환율 및 비즈니스 규칙과 같은 요소를 기반으로 추천 알고리즘에 의해 노출될 사용자를 선택하는 경우가 있다. 트레이닝 동안, 이들 노출된 사용자들의 데이터만이 그들의 상호작용 라벨들이 의미 있는 것으로 간주되기 때문에 사용되는 반면, 노출되지 않은 사용자들은 간과된다. 그러나 추론 단계에서는 추천 시스템에서 노출될 사용자의 선택을 결정하기 위해 노출되지 않은 사용자를 포함한 모든 사용자에 대해 추정된 변환 점수가 필요하다. 이러한 노출되지 않은 사용자들의 등급 데이터는 랜덤이 아닌 누락되어(Beng et al., 2017), CDSR 시나리오에서 선택 편향을 초래한다. 따라서, 이것은 또 다른 의문을 제기한다 : "오픈-월드 환경에서 여러 도메인에 걸친 데이터 선택 편향을 어떻게 완화할 수 있는가?" (_2nd challenge_)

각주 2: 훈련된 DASL. (Luo et al., 2018) 모델이 사용자 임베딩을 생성하는 데 사용된다.

## 3. Preliminaries

### Problem Definition

본 논문에서는 다중 도메인 \(\mathcal{Z}=\{Z_{1},...,Z_{|\mathcal{Z}|}\}\)으로 구성된 부분 중복 CDSR 시나리오를 고려한다. \(\mathcal{U}=\{u_{1},...,u_{|\mathcal{U}|}\}\), \(\mathcal{V}=\{v_{1}^{Z_{1}},...,v_{|\mathcal{V}|}^{Z_{|\mathcal{Z}|}}\}\)을 사용자 집합, 항목 집합, 등급 집합으로 설정합니다. 하나의 도메인에서 이력 행위만을 갖는 사용자를 비중첩 사용자(non-overlapping user)로 지칭하는 한편, 다수의 도메인에서 이력 행위를 갖는 사용자를 중첩 사용자(overlapping user)로 지칭한다. 특정 사용자로서 사용자의 순차적 행동을 \(\mathcal{S}=\{S^{Z_{1}},...,S^{Z_{|\mathcal{Z}|}}\}\)이라 한다. 예를 들어, \(S^{Z_{i}}=\{o_{1},...,o_{T}\}\)은 단일 도메인 서열을 나타내며, 여기서 \(T\)은 가변 길이이다. CDSR은 데이터 \(\mathcal{D}=\mathcal{U}\times\mathcal{V}\)이 주어졌을 때, 사용자의 여러 도메인에서 과거 아이템 시퀀스를 활용하여 사용자가 선택할 가능성이 가장 높은 각 도메인에서 다음 아이템(즉, \(o_{T+1}\))을 예측하는 개인화된 랭킹 함수를 개발하는 것을 목표로 한다.

기존의 교차 도메인 추천 방법과 달리, CDSR 방법은 순차적 행동 종속성을 모델링하는 데 더 많은 주의를 기울인다. 수학적으로, CDR 방법의 목적은 다음과 같이 공식화된다:

\[\text{argmax}\ \ p^{X}\left(r_{u,v}^{X}=v|U^{X},U^{Y},V^{X}\right),\text{if} \ \ v\in\mathcal{V}^{X}. \tag{1}\]

여기서 \(r_{u,v}\)은 도메인 \(X\)에서 사용자 \(u\)에서 항목 \(v\)으로의 예측을 나타낸다. 그러나, CDSR 접근법의 목적은 주어진 사용자 \(u\)에 대한 다음 항목을 그들의 상호작용 시퀀스에 기초하여 예측하는 것이다:

\[\text{argmax}\ \ p^{X}\left(r_{|S^{X}|+1}^{X}=v|S^{X},S^{Y},U^{X},U^{Y},V^{X} \right),\text{if}\ \ \ v\in\mathcal{V}^{X}. \tag{2}\]

그림 3. 선택 편향은 겹치는 사용자가 거의 없는 교차 도메인 순차 시나리오에서 분포 이동을 유발할 수 있다(통제 비율은 25%).

그림 2. 실선은 SDSR 방법을 나타내고 파선은 CDSR 방법을 나타낸다. SASRec(SDSR)는 중복되는 사용자가 풍부하지 않기 때문에 무비 도메인에서 모든 CDSR 방법에 비해 성능이 우수하다.

### Causal Graph

불완전하고 불충분한 관측 정보의 문제를 해결하기 위해 인과적 관점을 구성하고 적응형 다중 관심 디바이어싱 프레임워크를 제안한다. \ (\mathcal{S}_{U}^{Z},\mathcal{R}_{U}^{Z}\), \(SC^{Z}\), \(GC\)은 역사적 사건 시퀀스, 관찰된 등급, 도메인별 교란자 및 일반 교란자의 확률 변수를 나타낸다. \ (O\)는 관측치(\(O=1\), 관측치(\(O=0\), 관측치(unobserved)의 관측변수를 나타내는 것으로 일반적으로 \(O^{Z_{1}}\)와 \(O^{Z_{2}}\)에 의해 결정된다. 두 도메인에서 사용자가 관찰되지 않으면 \(O\)은 0이고, 그렇지 않으면 1이다. SDSR 방법은 주어진 사용자에 대해 지정된 교란자 \(SC^{Z}\)를 학습하는 데 중점을 두고, 이전 CDSR 방법은 중첩 사용자를 기반으로 모델을 구성하여 일반 교란자 \(GC\)를 얻는다. \((SC^{Z}\), \(GC)\rightarrow\mathcal{R}_{U}^{Z}\) 사이의 연결은 상호 작용 레이블에 대한 도메인 특정 및 일반 교란 요인의 인과 효과를 나타낸다. 관찰연구(Han et al., 2017; Wang et al., 2018; Wang et al., 2019)에서는 수집된 평점 데이터가 불균등하게 제시되는 경우가 많으며, 변수 \(\mathcal{S}_{U}^{Z}\)과 \(\mathcal{R}_{U}^{Z}\)는 주어진 사례의 관찰 \(O\)에 영향을 미칠 수 있다. 이 메커니즘은 선택 편향을 일으켜 이상적인 테스트 분포와 비교하여 관찰된 등급 데이터의 일관되지 않은 분포를 초래한다.

다른 관점에서 인과 그래프는 원인과 결과 사이의 연관성의 두 가지 원인을 묘사한다. (1) 바람직한 인과 효과 \(S\rightarrow(SC,GC)\to R\); (2) 충돌 경로 \(S\to O\gets R\)은 \(S\)과 \(R\)을 공통 효과(조건화) \(O=1\)을 통해 연결한다. \(O=1\)에서 조건화된 분석은 \(S\)과 \(R\) 사이의 스퓨리어스 연관성을 생성할 수 있다. 영역 \(Z_{1}\)과 \(Z_{2}\)은 일반적으로 관찰된 변수에 영향을 미친다는 점에 유의하는 것이 중요하다. 관측된 자료로부터 학습된 모형들은 선택 편향의 문제에 영향을 받을 수 있다. 개방형 환경에서 이는 온라인 성능 저하를 방지하기 위해 해결해야 할 중요한 문제이다.

### Single-domain 순차적 추천 방법

본 연구에서는 단일 도메인 순차 추천 모델을 CDSR 모델에 원활하게 통합함으로써 단일 도메인 순차 추천 모델의 성능을 향상시킬 수 있는 범용 교차 도메인 구조를 개발하는 것을 주요 목표로 한다. 이를 위해 먼저 단일 도메인 순차 추천 네트워크의 기본 메커니즘을 탐구한다.

**임베딩 계층.** 고정 길이 시퀀스 \(S=\{v_{1},...,v_{T}\}\)를 \(d\) 차원 임베딩 공간에 매핑합니다. 이는 절단 또는 패딩을 통해 달성됩니다. 또한, 학습 가능한 매개 변수 위치 임베딩 행렬을 사용하여 시퀀스의 시간 순서 정보를 향상시킨다. 특히,\(\mathbf{S}_{u}=\{\mathbf{h}_{v_{1}}^{{}^{\prime}},...,\mathbf{h}_{v_{T}}^{{}^{ \prime}}\}\in\mathbb{R}^{T\times d}\)의 시퀀스 임베딩을 얻는다.

**순차 정보 인코더.** 이전 단일 도메인 순차 추천 방법에서는 시퀀스 간의 단기/장기 항목 관계를 추출 하기 위해 다양한 순차 정보 인코더를 설계 했습니다. 예를 들어, GRU4Rec(Han et al., 2017)는 순차적 추천을 위해 다수의 GRU 계층을 설계한다. SASRec(Han et al., 2017)는 잔여 연결들을 갖는 셀프-어텐션 블록들을 적층하는 것을 제안하는 반면, BERT4Rec(Wang et al., 2018)는 사용자 행동 시퀀스들을 모델링하기 위해 심층 양방향 셀프-어텐션을 개발한다. 편의상, 설계된 순차 정보 인코더를 나타내는 함수 \(\mathcal{F}\)을 통해 향상된 순차 임베딩을 얻는다. 이 프로세스는 \(\mathbf{h}_{v_{1}},..,\mathbf{h}_{v_{T}}=\mathcal{F}(\mathbf{h}_{v_{1}}^{{}^{ \prime}},...,\mathbf{h}_{v_{T}}^{{}^{\prime}})\)로 공식화됩니다.

## 4. Methodology

### 다중 관심 정보 모듈

본 절에서는 일반 SDSR 모델을 CDSR 모델로 변환할 수 있는 다중 관심 정보 모듈을 소개한다. 모듈은 관심 그룹 구축과 정보 전파의 두 단계로 구성된다. 단순화를 위해 두 개의 도메인만을 예시로 포함하고 그들에 대한 동작을 보여주지만, 우리의 방법은 여러 도메인에 적용될 수 있다. 우리의 디자인은 유사한 선호도를 가진 사용자를 식별하고 가능한 한 광범위하게 정보를 공유하여 관심 그룹을 만드는 목표에 동기를 부여합니다.

**그룹 구성.** 처음에는 시퀀스 간의 유사성을 점별로 평가 하 여 그룹 플래그를 계산 합니다. 예를 들어, 서로 다른 도메인에서 사용자 \(u_{i}\)와 \(u_{j}\)의 두 시퀀스 \(\mathcal{S}_{u_{i}}^{Z_{1}\in\mathbb{R}^{T\times d}\)과 \(\mathcal{S}_{u_{j}}^{Z_{2}\in\mathbb{R}^{T\times d}\)을 고려한다. 그런 다음 사용자 간에 그룹 플래그를 다음과 같이 결정 합니다.

\[\mathbf{a}^{\prime}{}_{ij}=\max\{(\mathcal{S}_{u_{i}}^{Z_{1}}\mathbf{W}_{1})(\mathcal{S}_{u_{j}^{Z_{2}}\mathbf{W}_{2}^{\top}\} \tag{3}\)

여기서 변환행렬은 \(\mathbf{W}_{1}\), \(\mathbf{W}_{2}\in\mathbb{R}^{d\times d}\)이다. 최대 함수는 \(T\times T\)의 유사도 관계로부터 \(u_{i}\)와 \(u_{j}\) 사이의 가장 가까운 유사도를 찾는 데 사용된다. 마지막으로, \(\mathbf{a}_{ij}=1\)은 사용자 \(u_{i}\)과 \(u_{j}\)이 같은 그룹에 있는 것을 의미한다.

\[\mathbf{a}_{ij}=\left\{\begin{array}{ll}0\,,&\mathbf{a}^{\prime}{}_{ij}<k\\ 1\,,&\mathbf{a}^{\prime}{}_{ij}\geq k\end{array}\right. \tag{4}\]

**정보 전파.** 관심 그룹을 구성한 후에는 동일한 그룹 간에 도메인 간 정보가 전파됩니다. 교차 도메인 메시지 \(\mathbf{m}_{u_{i}^{Z_{1}}\leftarrow u_{j}^{Z_{2}}}\in\mathbb{R}^{T\times d}\)를 얻을 수 있습니다.

\[\mathbf{m}_{u_{i}^{Z_{1}}\leftarrow u_{j}^{Z_{2}}}=\mathbf{a}_{ij}\cdot( \mathcal{S}_{u_{j}^{Z_{2}}\mathbf{W}_{ip}} \tag{5}\]

여기서 \(\mathbf{W}_{ip}\in\mathbb{R}^{d\times d}\)는 교차 도메인 지식을 전달하는 훈련 가능한 매개 변수이다. 사용자가 여러 도메인에서 행동을 할 때, 동일한 사용자가 다른 도메인(예: \(\mathbf{m}_{u_{i}^{Z_{1}}\leftarrow u_{i}^{Z_{2}}\))에서 메시지를 전파한다. 대상 사용자(예: \(u_{i}^{Z_{1}}\))의 경우 마지막 차원을 따라 다른 도메인의 모든 정보를 연결하여 집계된 메시지 \(\mathbf{m}^{\prime}{}_{u_{i}^{Z_{1}}}\in\mathbb{R}^{T\times d\times N}\)를 얻는다. 여기서 \(N\)은 샘플링된 사용자의 수이다. 그리고 변환 행렬 \(\mathbf{W}_{C}\in\mathbb{R}^{N\times 1}\)과 \(\mathbf{W}_{F}\in\mathbb{R}^{d\times d}\)을 이용하여 정보를 융합하고 초기 시퀀스 정보와 연결된 향상된 시퀀스 표현 \(\mathcal{S}_{u_{i}}^{Z_{2}\in\mathbb{R}^{ZT\times d}\)을 얻는다. 여기서 스퀴즈 함수는 행렬의 차원을 감소시킨다. **다른 도메인의 사용자의 경우 유사한 방식으로 정보 전파가 발생합니다.* *

\[\mathcal{S}_{u_{i}}^{*Z}=\mathrm{Concat}(\mathcal{S}_{u_{i}}^{Z},\mathrm{Squeeze }(\mathbf{m}^{\prime}{}_{u_{i}^{Z}}\mathbf{W}_{C}))\mathbf{W}_{F} \tag{6}\}

### Prediction Layer

대상 항목 \(v_{k}\)에 대한 사용자의 \(u_{i}\) 선호도를 추정하기 위한 예측 계층을 다음과 같이 구성합니다.

\[\hat{\nu}_{u_{i},v_{k}}^{Z}=\sigma(\mathrm{MLPs}(\mathrm{Mean}(\mathcal{S}_{u_{ i}}^{*Z})||\mathbf{v}_{k}^{Z})) \tag{7}\] 여기서 MLP는 향상된 시퀀스 임베딩과 항목 임베딩을 입력으로 하는 적층된 MLP 계층으로 구성된다. Sigmoid 함수는 \(\sigma\)으로 표시되고 Mean 함수는 시간적 차원을 따라 임베딩을 평균화한다.

### CDSR에 대한 이중 강인성 추정기

이 부분에서는 전통적인 DR 추정기(Wang et al., 2017)를 교차 도메인 순차 시나리오로 일반화하는 새로운 이중 로버스트 추정기를 제안한다. \(\hat{\mathbf{R}}^{Z}\in\mathbb{R}^{\mathcal{U}^{Z}\times\mathcal{V}^{Z}}\)는 예측 행렬, \(\mathbf{R}^{Z}\in\mathbb{R}^{\mathcal{U}^{Z}\times\mathcal{V}^{Z}}\)는 true rating 행렬, 예측 부정확성 \(\mathcal{P}\) 및 이중 로버스트 추정기 \(\mathcal{E}^{*}_{\text{DR}}\)은 다음과 같이 정의됩니다.

\[\mathcal{P}=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\frac{1}{|\mathcal{D }^{Z}|}\sum_{u,u\in\mathcal{D}^{Z}}e^{Z}_{u,v}. \tag{8}\]

\[\mathcal{E}^{*}_{\text{DR}}=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}} \frac{1}{|\mathcal{D}^{Z}|}\sum_{u,u\in\mathcal{D}^{Z}}\left(e^{Z}_{u,v}+ \frac{o^{Z}_{u,v}\hat{o}^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}}\right) \tag{9}\]

여기서 MAE 또는 MSE에 대한 선택적 측정 메트릭을 통해 \(e^{Z}_{u,v}=|\hat{r}^{Z}_{u,v}-r^{Z}_{u,v}|\) 또는 \(e^{Z}_{u,v}=(\hat{r}^{Z}_{u,v}-r^{Z}_{u,v})^{2}\)이다. 전치오차 \(\hat{e}^{Z}_{u,v}=g_{\phi Z}(\text{Mean}(\hat{S}^{Z}_{u})||\psi^{Z}))\)는 관측자료에 대한 예측오차 \(e_{u,v}\)를 추정하기 위한 전치모델에 의해 계산된다. 또한 성향 \(\hat{p}_{u,v}=g_{\psi Z}(\text{Mean}(S^{Z}_{u})||\psi^{Z})\)을 학습한다. 임퓨테이션 모델 \(g_{\phi Z}\)과 성향 모델 \(g_{\psi Z}\)은 다중 작업 방식으로 구현된다. 추정량의 편의는 다음과 같이 도출된다.

**Lemma 4.1 (DR 추정기의 편향)**. 모든 사용자-아이템 쌍에 대한 치환 오류 \(\hat{\mathbf{E}}^{Z}\)과 학습된 성향 \(\hat{\mathbf{P}}^{Z}\)이 주어지면 CDSR 태스크에서 DR 추정기의 편향은 다음과 같다.

\[\text{Bias}(\mathcal{E}^{*}_{DR})=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z} }\left[\frac{1}{|\mathcal{D}^{Z}|}\left|\sum_{u,v\in\mathcal{D}^{Z}}\Delta^{Z}_{u,v}\hat{o}^{Z}_{u,v}\right|\right] \tag{10}\]

여기서 대치 오류 \(\delta^{Z}_{u,v}\) 및 학습된 성향 \(\Delta^{Z}_{u,v}\)은 다음과 같이 정의됩니다.

\[\Delta^{Z}_{u,v}=\frac{\hat{p}^{Z}_{u,v}-\hat{p}^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}},\ \delta^{Z}_{u,v}=e^{Z}_{u,v}-\hat{e}^{Z}_{u,v} \tag{11}\]

**결과 4.1 (이중 견고성)**. CDSR에 대한 DR 추정기는 모든 사용자-항목 쌍에 대해 귀속된 오류 \(\hat{\mathbf{E}}^{Z}\) 또는 학습된 성향 \(\hat{\mathbf{P}}^{Z}\)이 정확할 때 편향되지 않습니다.

**Lemma 4.2 (DR 추정기의 꼬리 경계)**. 임의의 예측 행렬 \(\hat{\mathbf{R}}^{Z}\), 확률 \(1\)-\(\eta\)에 대해, 치환 오차 \(\hat{\mathbf{E}}^{Z}\)과 학습된 성향 \(\hat{\mathbf{P}}^{Z}\)이 주어졌을 때, DR 추정기의 기대값과의 편차는 CDSR 태스크에서 다음과 같은 꼬리 경계를 갖는다.

\mathcal{E}^{*}_{DR}-\mathbb{E}_{0}[\mathcal{E}^{*}_{DR}]\right|\leq \sqrt{\frac{\log(\frac{2}{\eta})}{2|\mathcal{I}|(\sum\limits_{Z\in\mathcal{Z} }|\mathcal{D}^{Z}|)^{2}}\sum_{Z\in\mathcal{Z}\left[\frac{1}{|\mathcal{D}^{Z}| }\sum_{u,v\in\mathcal{D}^{Z}}\left(\frac{\delta^{Z}_{u,v}}{\hat{p}^{Z}_{u,v} }\right)^{2}\right]}. \tag{12}\]

**결과 4.2(꼬리 경계 비교)** 귀환된 오차 \(\hat{\mathbf{E}}^{Z}\)가 각 \(u,v\in\mathcal{D}^{Z}\)에 대해 \(0\leq\hat{e}^{Z}_{u,v}\leq 2\epsilon^{Z}_{u,v}\)이라고 가정하면, 학습된 성향 \(\hat{\mathbf{P}}\)에 대해 제안된 추정기의 꼬리 경계는 IPSCDR(Tail and Kumar, 2017)에 사용되는 IPS 추정기보다 낮을 것이다. 알레마와 결과에 대한 증명은 부록 A에 나와 있다.

### Joint learning

공동 학습을 위해 교번 훈련을 적용합니다. 첫 번째 단계에서는 제안된 하이브리드 손실을 최소화하여 관측 데이터에 대한 대체 및 예측 모델을 학습한다.

\[\mathcal{L}_{e}(\theta,\phi,\psi)= \frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}\left(\frac{1}{| \mathcal{O}^{Z}|}\sum_{u,v\in\mathcal{O}^{Z}}e_{u,v}+\lambda_{1}\sum_{u,u\in\mathcal{O}^{Z}}\frac{(\hat{e}_{u,v}-e_{u,v})^{2}}{\hat{p}_{u,v}}\right) \tag{14}\] \[+\lambda_{2}||\theta||^{2}_{F}+\lambda_{3}||\psi||^{2}_{F}+\lambda_ {4}||^{2}_{F} \tag{13}\]

Frobenius norm \(||.||^{2}_{F}\) 행렬의 정규 분포를 측정하는 데 사용됩니다. 하이퍼파라미터 \(\lambda_{1,2,3,4}\)는 정규화와 다중 손실 사이의 트레이드오프를 제어하는 데 사용된다. 관찰된 데이터에 대한 모델을 훈련시킨 후, 우리는 편향을 완화하기 위해 \(\mathcal{D}^{Z}\)에 대한 예측 모델 \(\theta\)을 계속 훈련시킨다.

\[\mathcal{L}_{r}(\theta,\phi,\psi)= \frac{1}{|\mathcal{Z}|}\sum_{x\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{2}|}\sum_{u,v\in\mathcal{D}^{x}}\left(\hat{e}_{u,v}+\frac{o_{u,v}( e_{u,v}-\hat{e}_{u,v})}{\hat{p}_{u,v}}\right)\right] \tag{16}\] \[+\lambda_{5}||\theta||_{F}^{2} \tag{15}\]

라벨 \(y_{u,v}\)은 집합 \(\mathcal{D}^{Z}-\mathcal{O}^{Z}\)의 데이터 포인트에 사용할 수 없다. \ (\lambda_{5}\)는 정규화 항과 균형을 이룬다. 우리 프레임워크의 학습 과정은 부록 B에 나와 있다.

## 5. Experiments

### Experimental Setup

실험을 수행하기 위해 이전 연구(Chen et al., 2017; Li et al., 2018)의 방법론을 따랐으며, 24개의 아이템 도메인으로 구성된 아마존 데이터 세트 3을 사용했다. 우리는 "Cloth-Sport"와 "Phone-Elec"라는 두 개의 도메인 쌍을 선택하고 두 가지 다른 작업을 공식화했다. 또한 각 작업에 대한 통계를 요약한 표 3을 수집한다. 온라인 플랫폼에서 선택 편향을 복제하기 위해 각 데이터 세트에 대해 중복되지 않는 비율 \(\mathcal{K}_{u}\)을 조정하여 \(\{25\%,75\%\}\)에서 선택했다. 비율을 변경하면 도메인 간에 중복되지 않는 사용자의 수가 달라지며, \(\mathcal{K}_{u}\)이 높을수록 편향된 환경이 덜하다는 것을 나타낸다. 이전 CDSR 문헌(Chen et al., 2017; Li et al., 2018; Li et al., 2018)에 따라 개발된 모델의 성능을 평가하기 위해 leave-one-out 기법을 사용했다. 편향되지 않은 평가를 보장하기 위해 이전 연구(Li et al., 2018; Li et al., 2018)에서 사용된 방법론을 채택했으며, 여기서 999개의 부정적인 항목(즉, 사용자가 상호작용하지 않은 항목)을 무작위로 선택하고 1개의 긍정적인 항목(즉, 지상-진실 상호작용)과 결합하여 순위 테스트를 위한 추천 후보를 형성한다. 우리는 CDSR 문헌에서 흔히 볼 수 있는 정규화된 할인 누적 이득(NDCG@10) 및 적중률(HR@10) 메트릭을 사용하여 모델을 평가했다. 모든 비교 모델에 대해 각 실험을 5회 실행하고 평균 및 분산으로 결과를 보고했다. 실험 설정에 대한 자세한 내용은 부록 C.1에 나와 있다.

각주 3: [http://jmcualley.ucsd.edu/data/amamamam/index](http://jmcualley.ucsd.edu/data/amamamam/index) 2014.html

### Performance Comparisons

**비교 방법.** 우리는 (1) 단일 도메인 순차 추천 방법, 즉 BERT4Rec (Wang et al., 2017), GRU4Rec (He et al., 2017) 및 SASRec (He et al., 2017)의 세 가지 클래스와 방법을 비교 합니다. (2) 종래의 Cross-domain 추천 방법, 즉 STAR(Wang et al., 2017), MAMDR(Li et al., 2018), SSCDR(He et al., 2017). (3) Cross-domain 순차 추천 방법, 즉 Pi-Net (Li et al., 2018), DASL (Li et al., 2018) 및 C\({}^{2}\)DSR (Chen et al., 2017). (4) Debiased 추천 방법, 즉 DCRec(Li et al., 2018), CaseQ(Li et al., 2018) 및 IPSCDR(Li et al., 2018). 이러한 기준선에 대한 자세한 소개는 부록 C.2에서 찾을 수 있다. 표 4에서 볼 수 있듯이 우리의 AMID는 겹치는 사용자와 겹치지 않는 사용자 모두에 대한 교차 도메인 지식을 전파하는 것을 고려하고 대부분의 최신 SDSR 백본 모델과 결합할 수 있는 가장 다재다능하고 보편적인 접근법이다. 디바이어싱 프레임워크(Li et al., 2018; Li et al., 2018)와 관련하여, 우리의 AMID 접근법은 다수의 도메인으로부터의 다수의 유형의 바이어스, 특히 선택 바이어스를 동시에 완화할 수 있다. 또한, CDSR에 대한 제안된 이중 로버스트 추정기는 낮은 분산을 가지며, 이는 높은 분산을 갖는 IPSCDR(Li et al., 2018)의 IPS 추정기와 다르다.

**정량적 결과.** 표 1-2는 선택 편향 크기가 다른 두 CDSR 작업에 대한 정량적 비교 결과를 보여줍니다. \(\mathcal{K}_{u}\)이 클수록 편향된 시나리오가 적음을 나타낸다. 각 열의 최상의 결과는 볼드체로 강조 표시되고 두 번째로 좋은 결과는 밑줄이 그어져 있다. 예상대로 모든 모델의 성능은 \(\mathcal{K}_{u}\)이 증가함에 따라 증가하는데, 이는 편향된 시나리오가 더 많아지면 모델이 수렴하기 어려울 수 있기 때문입니다. 분석 결과 다음과 같은 통찰력 있는 결과를 얻었다. (1) 대부분의 경우 도메인에서 생성된 편향을 제거하는 디바이어싱 기준선이 더 편향된 시나리오(즉, \(\mathcal{K}_{u}=25\%\))에서 CDSR 기준선보다 더 나은 성능을 보인다. (2) 더 작은 \(\mathcal{K}_{u}\)의 편향된 시나리오에서, 우리의 프레임워크는 차선 모델에 비해 더 큰 성능을 달성하며, 이는 우리의 AMID가 편향을 효과적으로 완화함을 나타낸다. (3) 추정량의 낮은 분산으로 인해 AMID는 IPSCDR보다 편향되지 않고 더 나은 성능을 보인다.

**모델 효율성.** 모든 비교 모델은 80GB 메모리가 있는 단일 NVIDIA GeForce A100과 646 RAM이 있는 Intel Core i7-8700K CPU가 있는 동일한 머신에서 훈련되고 테스트됩니다. 특히, 일반적인 C\({}^{2}\)DSR, SASRec + CaseQ, SASRec + IPSCDR 및 SASRec + AMID의 매개변수 수는 0.276M, 0.210M, 0.192M 및 0.193M으로 표시된 동일한 크기였다. 하나의 샘플 배치를 처리할 때 C\({}^{2}\)DSR, SASRec + CaseQ, SASRec + IPSCDR, SASRec + AMID의 학습/테스트 효율은 각각 0.130s/0.049s, 0.083s/0.027s, 0.143s/0.045s, 0.111s/0.032s이다. 따라서, 제안된 AMID는 오픈 월드 CDSR 시나리오에서 우수한 성능 향상을 달성하면서도 유망한 시간 효율성을 유지한다.

**절제 연구.** 접근법에서 각 주요 구성 요소의 효과를 더 잘 평가하기 위해 MIM만 사용한 변종과 비교하여 절제 연구를 수행했습니다. 특히, MIM이 없을 때 접근법이 SDSR 방법으로 분해되기 때문에 DRE만 사용하는 변형을 포함하지 않았다. 그러나 다중 관심 정보 모듈(MIM)만 장착된 당사의 변형은 대부분의 경우 여전히 최첨단 결과를 달성합니다. 이는 제안된 모듈이 중첩된 사용자와 중첩되지 않은 사용자 모두에게 잠재적인 관심 정보를 효과적으로 전파할 수 있기 때문이다.

### 온라인 A/B 테스트

일부 사용자가 중복되는 오픈월드 금융 CDSR 시나리오에 대해 대규모 온라인 A/B 테스트를 진행합니다. 온라인 서빙 플랫폼에서는 자금 구매, 주택 담보 대출, 어음 할인 등 하나 또는 복수의 금융 도메인에 다수의 사용자가 참여한다. 구체적으로, 우리는 온라인 테스트의 대상으로 일부 중복 사용자를 가진 서빙 플랫폼에서 "대출", "펀드", "계정"의 세 가지 인기 도메인을 선택했다. 하루 동안의 온라인 트래픽 로그의 평균 통계량을 계산하여 표 5에 제시한다. 통제 집단은 잡음이 많은 보조 행동을 직접 활용하는 교차 도메인 순차적 추천 방법인 현재 온라인 솔루션을 사용자에게 테마 추천에 채택한다. 실험 그룹의 경우, 우리는 이 방법에서 놀라운 성공을 거둔 성숙한 SDSR 접근법을 갖추고 있다. 우리는 세 가지 메트릭을 기반으로 결과를 평가한다: 노출된 사용자 수

[MISSING_PAGE_FAIL:7]

세 도메인에서 노출은 9.65%, 클릭률은 5.69%, CVR은 1.32%이다.

### Hyperparameter Analysis

다중 관심 정보 모듈에서 관심 그룹 구성에 대한 임계값 \(k\)의 영향을 조사하기 위해 임계값 \(k\in\{0.5,0.6,0.7,0.8,0.9\}\)을 변화시켜 제거 실험을 수행한다. 그 결과, 더 큰 임계값 \(k\)(\(0.5\에서 0.7\))이 더 많은 관련 관심 정보를 전송할 수 있기 때문에 더 나은 성능을 얻을 수 있음을 보여준다. 그러나 임계값 \(k\)이 0.7 이상으로 증가하면 노이즈 간섭과 중복 정보로 인해 모델의 성능이 떨어진다. 따라서 우수한 성능을 얻기 위해 임계값 \(k\)을 0.7로 설정하였다.

**샘플링된 사용자 수**.** 샘플링된 사용자 수가 다중 관심 정보 모듈에 미치는 영향을 조사하기 위해 샘플링된 사용자 수를 128명에서 1024명으로 변경한 절제 실험을 수행합니다. 본 연구 결과는 샘플링된 사용자 수의 증가가 처음에는 권장 성능을 향상시켰지만 일치하는 이웃이 1024명에 도달하면 결국 감소한다는 것을 나타냅니다. 이러한 관찰은 샘플링된 사용자가 너무 적으면 전달 정보가 충분하지 않고 샘플링된 사용자가 너무 많으면 간섭 잡음이 유입되어 모델의 성능을 손상시킬 수 있음을 나타냅니다. 실제로 표본 사용자 수를 512명으로 선택하여 모델에 가장 적합한 성능을 제공합니다. 더 많은 분석과 결과는 부록 C.3에서 찾을 수 있다.

## 6. 관련 작업

**기존 교차 도메인 권장 사항** 은 단일 도메인 권장 시스템에서 발생 하는 데이터 희소성 및 콜드 스타트 문제를 완화 하는 유망한 솔루션으로 등장 했습니다. 초기 CDR 연구(Han et al., 2016; Wang et al., 2017)는 주로 중첩된 사용자에 의존하여 교차 도메인 지식을 전달하는 접근법을 개발하는 데 초점을 맞추었다. 그러나 실제 CDR 시나리오는 종종 엄격한 중복 요구 사항을 충족하지 않으며 도메인 전반에 걸쳐 공통 사용자의 작은 부분만을 나타낸다. 이러한 과제를 해결하기 위해, 최근의 방법들(Wang et al., 2017; Wang et al., 2017))은 모든 도메인들에 걸친 고유 특성들 및 공통성들을 동시에 효과적으로 포착하기 위해 공유 및 도메인-특정 네트워크들을 포함하는 네트워크 구조를 제안하였다. 이러한 CDR 접근 방식은 대상 도메인에서 성능을 향상시키기 위해 관련 도메인의 귀중한 정보를 통합하지만, CDSR 작업에서 포괄적인 모델링에 필수적인 사용자의 상호 작용 이력 내의 맥락적 순차 의존성을 해결하는 데 여전히 어려움을 겪는다.

**교차 도메인 순차 권장 사항** 은 여러 도메인의 항목을 포함 하는 SR 작업에 대 한 권장 사항을 개선 하도록 설계 되었습니다. Pi-Net(Pasquin et al., 2017)과 PSJNet(Yang et al., 2017)은 중복되는 사용자들 사이에서 정보를 전달하기 위한 게이팅 메커니즘을 고안한다. 유사하게, DASL(Pasquin et al., 2017)은 중첩하는 사용자들 내에서 사용자 선호도들을 양방향으로 전달하기 위해 이중-주의 메커니즘을 설계한다. 상호작용 이분 그래프(Pasquin et al., 2017; Wang et al., 2017)는 사용자들 사이에서 정보를 전파하도록 구성된다. C\({}^{2}\)DSR(Chen et al., 2016)은 사용자 선호도의 표현을 향상시키기 위해 GNN과 결합된 대조적 목적을 도입한다. 그러나 이러한 작업들은 폐쇄 세계의 가정 하에서 중첩된 사용자에 의존하여 교차 도메인 단위를 구성하므로 개방 세계의 경우 성능이 더 나빠진다.

**추천기 시스템에 대한 편향** 은 선택 편향(Chen et al., 2016; Wang et al., 2017), 위치 편향(Han et al., 2016; Wang et al., 2017), 노출 편향(Chen et al., 2016; Wang et al., 2017) 및 인기 편향(Chen et al., 2016; Wang et al., 2017)을 포함하는 사용자 행동 관찰 데이터의 광범위한 편향을 완화하기 위해 제안된다. RS에서 선택 편향을 해결하기 위해 EIB(error-imputation-based) 접근법과 IPS(inverse-propensity-scoring) 접근법의 두 가지 표준 접근법이 제안되었다. EIB 접근법(Yang et al., 2017)은 누락된 평점에 대한 예측 오차를 추정하는 반면, IPS 접근법(Yang et al., 2017; Wang et al., 2017)은 역 성향 점수로 위험 함수를 최적화함으로써 선택 편향을 감소시킨다. 최근에, (Wang et al., 2017)은 다중 제한들을 갖는 교차-도메인 시나리오들에 대한 IPS 추정기를 제안한다. 그러나, EIB 방법들은 대체 부정확성으로 인해 큰 편향을 가질 수 있고(Chen et al., 2016), 성향 기반 방법들은 높은 분산(Wang et al., 2017)을 겪을 수 있으며, 비-최적 결과를 초래한다. (Wang et al., 2017)는 IPS 추정기의 분산을 감소시키기 위해 자기 정규화된 역 성향 스코어링 추정기를 제안한다. 덜 편향된 추정량을 설계하기 위해 이중 로버스트 모델(Wang et al., 2017)은 단일 도메인 추천에 대한 성향 점수와 대체 모델을 통합한다.

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & \multicolumn{2}{c}{**\# exposure**} & \multicolumn{1}{c}{**\# click**} & \multicolumn{1}{c}{**CVR**} \\ \hline Loan Domain & +9.80\% & +5.27\% & +1.42\% \\ Fund Domain & +7.32\% & +4.94\% & +0.98\% \\ Account Domain & +11.73\% & +6.85\% & +1.57\% \\ \hline \hline \end{tabular}
\end{table}
표 6. 온라인 A/B 테스트 결과 9.15 ~ 9.28, 2023

그림 6. 임계값 \(k\)과 샘플링된 사용자 수의 영향.

## 7. 결론 및 논의

본 논문에서는 개방형 가정하에서 기존의 CDSR 방법에 대한 철저한 연구를 수행한다. 이러한 문제를 해결하기 위해 본 논문에서는 다중 관심 정보 모듈(multi-interest information module, MIM)과 CDSR을 위한 이중 강건 추정기(doubly robust estimator, DRE)를 포함하는 적응형 다중 관심 디바이징 프레임워크를 제안한다. MIM은 사용자 행동을 활용하여 관심 그룹을 구축하고 중첩된 사용자와 중첩되지 않은 사용자 간에 정보를 전파하는 반면, DRE는 오픈 월드 환경에서 추정 편향을 줄이기 위해 교차 도메인 디바이어싱 추정기를 도입한다. 또한 10억 명이 넘는 사용자를 포함하는 알리페이에서 금융 산업 데이터 세트를 수집합니다. 광범위한 오프라인 및 온라인 실험은 다양한 평가 메트릭에서 CDSR 방법 및 디바이어싱 방법을 포함한 기존 방법보다 우수하기 때문에 본 접근법의 놀라운 효과를 보여준다.

**제한 사항.** MIM은 도메인 간 지식을 가능한 한 광범위하게 공유하는 도메인 쌍 간에 관심 그룹을 구성합니다. 실세계 플랫폼에서 상업 활동은 일반적으로 여러 영역으로 구성된다. 그러나, \(|\mathcal{Z}|\) 도메인에 대한 모든 그룹을 구성하는 것은 \(O(|\mathcal{Z}|^{2})\)의 시간 복잡도를 가지며, 이는 도메인 수가 증가함에 따라 상당히 많은 시간이 소요될 수 있다. 따라서 향후 작업에서 여러 도메인 간의 그룹 구성을 위한 보다 효율적인 방법을 개발하는 것이 중요하다.

## References

* H. Abdollapouri, R. Burke, and B. Mobasher (2017)Controlling popularity bias in learning-to-rank recommendation. Proceedings of the 11번째 ACM conference on recommender systems, pp. 42-46. Cited by: SS1.
* J. Cao, X. 콩정승 Liu, and B. Wang(2022)Cons-native cross-domain sequential recommendation. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, pp. 138-147. Cited by: SS1.
* J. Cao, J. Sheng, X. 콩태 Liu, and B. Wang (2022) Cross-domain recommendation to cold-start users via variational information bottleneck. In 2022 IEEE 38th International Conference on Data Engineering (ICDE), pp. 2209-2223. Cited by: SS1.
* J. Chen, H. Dong, X. 왕봉민 Wang, X. 그(2023)는 추천 시스템의 편향과 디비아: 설문조사와 향후 방향. ACM Transactions on Information Systems41(3), pp. 1-39. Cited by: SS1.
* J. Chen, C. Wang, M. 에스터큐 시영 Feng, and C. Chen (2018) Social Recommendation with missing at random data. 2018 IEEE International Conference on Data Mining (ICDM), pp. 29-38. Cited by: SS1.
*Q. 최태 위영 Zhang, Q. Zhang(2020)HeroGRAPH: multi-target cross-domain recommendation을 위한 이종 그래프 프레임워크. MSUHQ'RS에서, 인용: SS1.
*M. Dudik, J. Langford, and L. Li(2011)Doubly robust policy evaluation and learning. arXiv preprint arXiv:1103.4601. Cited by: SS1.
* A. Gilotte, C. Chanaires, T. Nedelec, A. Abraham, S. Dolle (2018)Offline-a\(b\) testing for recommender systems. Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, pp. 198-206. Cited by: SS1.
* L. 곽래 탕태 진락 주철 Viet Hung Nguyen, and H. Yin (2021)DA-gcn: a domain-aware attentionive graph convolution network for shared-accent cross-domain sequential recommendation. arXiv preprint arXiv:2105.03300. Cited by: SS1.
* J. M. Hernandez-Lobato, N. Houlsby, Z. Ghahramani (2014) Probabilistic matrix factorization with non-random missing data. In International conference on machine learning, pp. 1512-1520. Cited by: SS1.
* J. Mignard, L. Houlsby, Z. Ghahramani (2014) Probabilistic matrix factorization with non-random missing data. In International conference on machine learning, pp. 138-152. Cited by: SS1.
* B. Hidiasi, A. Karatzoglou, L. Baltrunas, and D. Tikk (2015)Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06899. Cited by: SS1.
*K. 호프만 Whiteson, M. De Rijke (2013)Reusing historical interaction data for faster online learning to rank for 1. In Proceedings of the sixth ACM international conference on Web search and data mining, pp. 183-192. Cited by: SS1.
* G. Hu, Y. Zhang, Q. Yang (2018)Conet: Cross-domain recommendation을 위한 협력적 크로스 네트워크. In Proceedings of the 27th ACM international conference on information and knowledge management, pp. 667-676. Cited by: SS1.
* T. 조아킴스, A. 스와미나단, T. 슈나벨(2017) 편향된 피드백으로 순위를 매기는 편향되지 않은 학습 Proceedings of the 10th ACM international conference on web search and data mining, pp. 781-789. Cited by: SS1.
*S. et al. (2019)Semi-supervised learning for cross-domain recommendation to cold-start users. CIKM에서, Cited by: SS1.
* W. Krichene과 S. 항목 추천을 위해 샘플링된 메트릭에 대해 렌더링(2020)합니다. In Proceedings of the 26th ACM SIGKDD international conference on Knowledge discovery & data mining, pp. 1748-1757. Cited by: SS1.
* P. Li, Z. 장민 주영 Hu, 및 A. Tuzhilin (2021)Dual Attentionive sequential learning for cross-domain click-through rate prediction. In Proceedings of the 27th ACM SIGKDD conference on Knowledge discovery & data mining, pp. 3172-3180. Cited by: SS1.
* P. Li and A. Tuzhilin (2020)DDLDT: deep dual transfer cross domain recommendation. In Proceedings of the 13th International Conference on Web Search and Data Mining, pp.331-339. Cited by: SS1.
*S. 이락 야오성 무원 조영호 이태용 Guo, B. Ding, and J. Wen (2021)DBLoising learning based cross-domain recommendation. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pp. 3190-3199. Cited by: SS1.
* D. Liu, P. Cheng, Z. 동X 허원 Pan, Z. Ming (2020) 균일한 데이터를 통한 반사실적 추천을 위한 일반적인 지식 증류 프레임워크이다. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 831-840. Cited by: SS1.
*M. Liu, J. Li, G. Li, and P. Pan (2020) Cross domain recommendation via bi-directional transfer graph collaborative filtering networks. In Proceedings of the 29th ACM international conference on information & knowledge management, pp. 885-894. Cited by: SS1.
* W. 류석 정종수 허영 Tan, 및 C. Chen(2022)Exploiting variational domain-invariant user embedding for partially overplayed cross domain recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 312-321. Cited by: SS1.
* L. 류영 이병가오 탕수 왕종리 류진 Li, S. Pin(2023)NAMD: 다중 도메인 추천을 위한 모델 불가지론 학습 프레임워크. In 2023 IEEE 39th International Conference on Data Engineering (ICDE), pp. 2102-2103. Cited by: SS1.
*M. 마필렌 진진 렌림 Zhao, F. Liu, J. Ma, M. de Rijke (2022) Mixed information flow for cross-domain sequential recommendations. ACM Transactions on Knowledge Discovery from Data (TKDD)16 (4), pp. 32-32. Cited by: SS1.
*M. 마필렌 린진 진진마 de Rijke (2019)\(\pi\)-net: 공유 계정 교차 도메인 순차적 추천을 위한 병렬 정보 공유 네트워크. In Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval, pp. 685-694. Cited by: SS1.
* B. Marlin, R. S. Zemel, S. Roweis, M. Slaney (2012) Collaborative filtering and missing at random assumption. UAI. 에 의해 인용된다: SS1.
* W. 오양 장락 조재욱 장호주 Liu, Y. Du(2020)Minet: Cross-domain click-through rate prediction을 위한 혼합 관심 네트워크. In Proceedings of the 29th ACM international conference on information & knowledge management, pp. 2669-2676. Cited by: SS1.
* L. Pexa and P. Volras (2020) Off-line vs. 소규모 전자상거래에서 추천시스템의 온라인 평가 In Proceedings of the 31st ACM Conference on Hypertext and Social Media, pp. 391-300. Cited by: SS1.
* M. E. Roberts, B. M. Stewart, and R. A. Nielsen (2020)Adjusting for confounding with test matching. American Journal of Political Science64(4), pp. 887-903. Cited by: SS1.
*Y. Saito (2020)는 누락되지 않은 무작위 명시적 피드백을 디바이어싱하기 위한 대칭 트라이-트레이닝이다. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 309-318. Cited by: SS1.
*Y. Saito (2020)Unbiased pairwise learning from bias implicit feedback. 2020 ACM SIGIR 국제정보검색학회 회보에서 SS1을 인용하였다.
* T. 슈나벨, A 스와미나단, A 싱, N Chandak, T. Joachims (2016)Recommendations as treatment: debiasing learning and evaluation. In international conference on machine learning, pp. 1670-1679. Cited by: SS1.
*X. et al. (2021)One model for serve all: star topology adaptive recommender for multi-domain tf prediction. CIKM에서, Cited by: SS1.
* H. Steck (2010) 누락된 데이터에 대한 추천 시스템의 훈련 및 테스트 랜덤이 아니다. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 713-722. Cited by: SS1.
* H. Steck(2013)Evaluation of recommendations: rating-prediction and ranking. Proceedings of the 7th ACM conference on Recommender systems, Cited by: SS1.

* Sun 등(2019) Fei Sun, Jun Liu, Jian Wu, Changua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representation from transformer. 「제28회 ACM 정보 및 지식 관리에 관한 국제 회의의 진행례」에 기재되어 있다. 1441-1450.
* Sun 등(2021) Wenchao Sun, Muyang Ma, Pengfei Ren, Yujie Lin, Zhumin Chen, Zhaochun Ren, Jun Ma, and Maarten De Rijke. 2021. 공유 계정 교차 도메인 순차 권장 사항을 위한 병렬 분할 조인 네트워크입니다. _ IEEE Transactions on Knowledge and Data Engineering_(2021).
* Swaminathan and Joachims (2015) Adith Swaminathan and Thostern Joachims. 2015. The self-normalized estimator for counterfactual learning. _ advances in neural information processing systems_ 28 (2015).
* 베르시닌 (2018) Roman Vershynin. 2018. _고차원 확률: 데이터 과학에 응용 프로그램이 있는 소개_ 입니다. 47권 케임브리지 대학 언론사
* Wang 등(2019) Xiaotio Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2019. Doubly robust joint learning for recommendation on data missing not random. _Machine Learning에 대 한 국제 회의_ 에서입니다. PMLR, 6638-6647.
* Wang 등(2021) Xiaotio Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2021. 몇 개의 편향되지 않은 등급과 추천 시스템의 선택 편향을 결합한다. <제14회 ACM 국제회의 웹 검색 및 데이터 마이닝의 진행>에서. 427-435.
* Wu 등(2021) Qitun Wu, Henri Zhang, Xiaofeng Cao, Junichi Wang, Hongyuan Zha. 2021. Towards open-world recommendation: Inductive model-based collaborative filtering approach. _Machine Learning에 대 한 국제 회의_ 에서입니다. PMLR, 11329-11339.
* Xu 등(2023) Wuiyang Xu, Shaohuai Li, Mingming Ha, Xiaobo Guo, Qiongun Ma, Xiaolei Liu, Linxun Chen, and Zhenfeng Zhu. 2023. Multi-Target Cross Domain Recommendation을 위한 Neural Node Matching. _ arXiv preprint arXiv:2302.05919_ (2023).
* Yang 등(2022) Chenxiao Yang, Qitun Wu, Qingsong Wen, Zhiqiang Zhu, Liang Sun, and Junchi Yan. 2022. out-of-distribution sequential event prediction: A causal treatment. _ arXiv preprint arXiv:2210.1305_ (2022).
* Yang 등(2023) Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang, Da Luo, and Kangyi Lin. 2023. Debiased Contrastive Learning for Sequential Recommendation. _The Web Conference 2023: International World Wide Web Conference_.
*Yue et al.(2020) Kun Yue, Jiahui Wang, Xinhai Li, and Kuang Hu. 2020. Representation-based completion of knowledge graph with open-world data. _2020 제5회 컴퓨터 통신 시스템 국제 회의(ICCCS)_에서. IEEE, 1-8.
* Zhang et al.(2018) Qian Zhang, Dianshuang Wu, Je Lu, and Guangwang Zhang. 2018. Cross-domain recommendation with probabilistic knowledge transfer. _신경 정보 처리에 관한 국제 회의_ 에서. 스프링거 208-219
* Zhao et al.(2017) Lii Zhao, Sinno Jialin Pan, and Qiang Yang. 2017. A Unified framework of active transfer learning for cross-system recommendation. _ Artificial Intelligence_245(2017), 38-55).
* Zhao 등(2020) Wayne Xin Zhao, Junhua Chen, Pengfei Wang, Qi Gu, and Ji-Rong Wen. 2020. Revisiting alternative experimental settings for evaluating top-n item recommendation algorithm. 「제28회 ACM 국제 정보 지식 관리 회의 회보」에 기재되어 있다. 2329-2332.
* Zhu 등(2020) Feng Zhu, Yan Wang, Chao Chao Chen, Guanfeng Liu, Mehmet Orgun, and Jia Wu. 2020. 교차 도메인 및 교차 시스템 권장 사항을 위한 심층 프레임워크입니다. _ arXiv preprint arXiv:2009.06245_ (2020).

## Appendix A Appendix A: Lemmas 및 정리 증명

**Lemma 4.1** (DR 추정기의 편향).: 모든 사용자-항목 쌍에 대 한 대체 오류 \(\hat{\mathbf{E}}^{Z}\) 및 학습 성향 \(\hat{\mathbf{p}}^{Z}\)이 지정 된 CDSR 작업에서 DR 추정기의 편향은 다음과 같습니다.

\[\text{Bias}(\mathcal{E}^{*}_{DR})=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z }}\left[\frac{1}{|\mathcal{D}^{Z}|}\left|\sum_{\mu,\nu\in\mathcal{D}^{Z}} \Delta^{Z}_{u,\nu}\delta^{Z}_{u,\nu}\right|\right] \tag{17}\]

증거: 편향의 정의에 따라 CDSR에 대한 DR 추정기의 편향을 다음과 같이 도출할 수 있다.

\mathcal{P}-\mathbb{E}_{\mathbf{Q}[\mathcal{E}^{*}_{DR}]|,\] (20) \[=|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}\left[\frac{1}{|\mathcal{D}^{Z}|}\nu\mathcal{D}\sum_{Z}|}\nu\hat{\epsilon}^{Z}_{u,\nu}\delta^{Z}_{u,\nu}\right)\right]\!,\] (22) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z}_{u,\nu}-\frac{p^{Z}_{u,\nu}\delta^{Z}_{u,\nu}}{\hat{p}^{Z}_{u,\nu}}{\hat{Z}_{u,\nu}\right]\!,\] (23) \[=\frac{1}{|\math

증거가 완성되는 거죠 이전 연구(Zhao et al., 2019; Zhang et al., 2020)에 이어, 치환 오차 \(\delta^{Z}_{u,\nu}\)와 학습된 성향 \(\Lambda^{Z}_{u,\nu}\)을 다음과 같이 정의한다.

\[\delta^{Z}_{u,\nu}=\epsilon^{Z}_{u,\nu}-\hat{\epsilon}^{Z}_{u,\nu}\quad \Lambda^{Z}_{u,\nu}=\frac{\hat{p}^{Z}_{u,\nu}-p^{Z}_{u,\nu}}{\hat{p}^{Z}_{u, \nu}} \tag{24}\]

**결과 4.1** (Double Robustness): CDSR에 대한 DR 추정기는 모든 사용자-항목 쌍에 대해 오차 \(\hat{\mathbf{E}}^{Z}\) 또는 학습된 성향 \(\hat{\mathbf{P}}^{Z}\)이 정확할 때 편향되지 않는다.

증명: 한 측면에서, 치환 오차가 정확할 때, 우리는 \(u,\nu\in\mathcal{D}^{Z}\)에 대한 \(\delta^{Z}_{u,\nu}=0\)을 갖는다. 이 경우, CDSR에 대한 DR 추정기의 바이어스는,

(25) \[\text{Bias}(\mathcal{E}^{*}_{DR})\] (26) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}|}\left|\sum_{\mu,\nu\in\mathcal{D}^{Z}}\Delta^{Z}_{u,\nu}\delta^{Z}_{u,\nu}\right|\right],\] (27) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}\left[\frac{1}{|\mathcal{D}^{Z}|}\left|\sum_{\mu,\nu\in\mathcal{D}^{Z}}\Delta^{Z}_{u,\nu}\cdot 0 \right|\right],\] (28) \[=0.\] (29)

다른 측면에서, 학습된 성향이 정확할 때, \(u,\nu\in\mathcal{D}^{Z}\)에 대한 \(\Delta^{Z}_{u,\nu}=0\)을 갖는다. 이러한 경우에 우리는 CDSR에 대한 DR 추정기의 바이어스를 계산할 수 있다.

(30) \[\text{Bias}(\mathcal{E}^{*}_{DR})\] (31) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\left|\sum_{\mu,\nu\in\mathcal{D}^{Z}}\Delta^{Z}_{u,\nu} \delta^{Z}_{u,\nu}\right|\right],\] (32) \[=0.\] (33)

치환된 오차 또는 학습된 성향이 정확할 때 제안된 추정기의 편향은 정확하다. 증명이 완료되었습니다.

**Lemma 4.2** (Tail Bound of DR Estimator): 주어진 치환 오차 \(\hat{\mathbf{E}}^{Z}\), 학습된 성향 \(\hat{\mathbf{P}}^{Z}\), 임의의 예측 행렬 \(\hat{\mathbf{R}}^{Z}\)에 대해 확률 1-\(\eta\), DR 추정기의 기대값과의 편차는 CDSR 태스크에서 다음과 같은 꼬리 경계를 갖는다.

(34) \[\sqrt{\frac{\log(\frac{\eta}{\eta})}{2|\mathcal{Z}|(\sum\limits_{Z \in\mathcal{Z}}|\mathcal{D}^{Z}|)^{2}}\sum\limits_{Z\in\mathcal{Z}}\left[ \frac{1}{|\mathcal{D}^{Z}|}\sum\limits_{u,u\in\mathcal{D}^{Z}}\left(\frac{ \delta_{u,v}^{Z}}{\hat{p}_{u,v}^{Z}}\right)^{2}\right]}\] (35)

증명: 표기가 어수선해지는 것을 피하기 위해, 본 발명에서는 표기된 랜덤 변수 \(X_{u,v}^{Z}\)를 도입한다.

\[\chi_{u,v}^{Z}=\hat{\epsilon}_{u,v}^{Z}+\frac{\alpha_{u,v}^{Z}\delta_{u,v}^{Z} }{\hat{p}_{u,v}^{Z}} \tag{36}\]

관찰 지표 \(\alpha_{u,v}^{Z}\)이 확률 \(p_{u,v}^{Z}\)을 갖는 베르누이 분포를 따르는 것을 고려하면 다음과 같이 확률 변수 \(X_{u,v}^{Z}\)의 분포 패턴을 얻을 수 있다.

(37) \[P(\chi_{u,v}^{Z})=\left\{\begin{array}{cc}p_{u,v}^{Z}\\ 1-p_{u,v}^{Z}\end{array},&\chi_{u,v}^{Z}=\hat{\epsilon}_{u,v}^{Z}+\kappa_{u,v} ^{Z}\\ \chi_{u,v}^{Z}=\hat{\epsilon}_{u,v}^{Z}\end{array}\right.\] (38)

where \(\kappa_{u,v}^{Z}\) is given by

\[\kappa_{u,v}^{Z}=\frac{\epsilon_{u,v}^{Z}-\hat{\epsilon}_{u,v}^{Z}}{\hat{p}_{u,v}^{Z}}=\frac{\delta_{u,v}^{Z}}{\hat{p}_{u,v}^{Z}} \tag{39}\]

확률 1의 확률변수 \(\kappa_{u,v}^{Z}\)에 대한 간격 \([\hat{\epsilon}_{u,v}^{Z},\hat{\epsilon}_{u,v}^{Z}+\kappa_{u,v}^{Z}]\)을 결정하는 것은 간단한 과정이다. 이는 관측 지표 \(\alpha_{u,v}^{Z}\)가 독립적인 확률 변수라는 가정에 의해 촉진되며, 이는 확률 변수 \(\kappa_{u,v}^{Z}\)도 독립적이라는 것을 보장한다. Hoffding(1994)에 대한 Hoeffding의 부등식의 일반적인 형태는 39로 나타낼 수 있다. \(X_{1},...,X_{N}\)을 독립적인 확률변수로 하자. 각 \(i\)에 대해 \(X_{i}\in[a_{i},b_{i}]\)을 가정한다. 임의의 \(\epsilon>0\)에 대하여 우리는 부등식을 갖는다.

\[P\left(\left|\frac{1}{|\mathcal{Z}|}\sum\limits_{Z\in\mathcal{Z}}\frac{1}{| \mathcal{D}^{Z}|}\left[\sum\limits_{u,u\in\mathcal{D}^{Z}}\kappa_{u,v}^{Z} \right]-\frac{1}{|\mathcal{Z}|}\sum\limits_{Z\in\mathcal{Z}}\frac{1}{| \mathcal{D}^{Z}|}\left[\sum\limits_{u,u\in\mathcal{D}^{Z}}\mathbb{B}_{0}( \chi_{u,v}^{Z})\right]\right|\geq\epsilon\right) \tag{40}\]

\[\leq 2\exp\left(\frac{-2\epsilon^{2}\left(\sum\limits_{Z\in \mathcal{Z}}|\mathcal{D}^{Z}|\right)^{2}}{\frac{1}{|\mathcal{Z}|}\sum\limits_ {Z\in\mathcal{Z}}\frac{1}{|\mathcal{D}^{Z}|}\sum\limits_{u,v\in\mathcal{D}^{Z}}(\kappa_{u,v}^{Z})^{2}}\right) \tag{41}\]

\(\epsilon\)을 풀기 위해 부등식의 오른쪽을 \(\eta\)으로 설정하고 다음 단계를 진행할 수 있다.

\mathcal{Z}|\sum\limits_{Z\in\mathcal{Z}}\frac{1}{|\mathcal{D}^{Z}|}\sum\limits_{u,v\in\mathcal{D}^{Z}}(\kappa_{u,v}^{Z})^{2}\right) \tag{43}\] \[\mathcal{Z}|\mathcal{Z}\left[\frac{1}{|\mathcal{Z}|\sum\limits_{u,v\mathcal{D}\in\mathcal{Z}}\left[\frac{1}{|\mathcal{Z}|\sum\limits_{u,v\mathcal{D}}}(\kappa_{u,v}^{Z})^{2}\right]}\] (45) \[\iff\epsilon=\sqrt{\frac{\log(\frac{\eta}{\eta})}{2|\mathcal{Z}\epsilon=\sqrt{\

증명이 완료되었습니다.

(\hat{\mathbf{E}}^{Z}\)이 각 \(u,v\in\mathcal{D}^{Z}\)에 대해 \(0\leq\hat{\epsilon}_{u,v}^{Z}\leq 2\epsilon_{u,v}^{Z}\)이라고 가정하면, 학습된 성향 \(\hat{\mathbf{P}}\)에 대해 제안된 추정기의 꼬리 경계는 IPSCDR(Tail Bound, 2009)에 사용되는 IPS 추정기보다 낮을 것이다.

증명: 다음과 같은 부등식을 도출할 수 있음

\mathcal{Z}|\mathcal{Z}\left[\frac{1}{|\mathcal{Z}|\sum\limits_{Z\in\mathcal{Z}\tag{47}\] \[\implies\hat{\epsilon}_{u,v}^{Z}-\epsilon_{u,v}^{Z}\leq\epsilon_{u,v}^{Z}\] (48) \[\implies(\delta_{u,v}^{Z})^{2}\leq(\epsilon_{u,v}^{Z})^{2}\left[\frac{1}{|\mathcal{Z}|(\sum\limits_{Z\in\mathcal{Z}|\mathcal{Z}\limits_{Z\in\mathcal{Z}|(\frac{\epsilon_{u,v}^{Z}}{\hat{p}_{u,v}^{Z})^{2}\right]}\] (50) \[\leq\sq

마지막 부등식에서 첫 번째 행은 CDSR에 대한 DR 추정기의 꼬리 경계를 나타내고, 두 번째 행은 CDSR에 대한 IPS 추정기의 꼬리 경계를 나타낸다(Tail Bound, 2009; D'Auria, 2010). 이로써 증명이 완료된다.

## Appendix B. Appendix B. 방법론

이전 작업(호핑, 2009)에 이어, 우리는 또한 모델을 훈련하기 위해 공동 학습 메커니즘을 채택한다. 최적화 절차는 Alg. 1에 나와 있습니다.

```
0: 실제 평가 \(\mathbf{R}\), 학습 성향 \(\hat{\mathbf{P}}\)은 관측 자료 \(\mathcal{O}\)에서 얻었다.
1:forstep \(q\in\{1,...,Q\}\)do
2: 여러 도메인에서 사용자-항목 쌍의 일괄 처리 \(\mathcal{Z}\)을 \(\mathcal{O}\)에서 샘플링합니다.
3: 손실 함수 \(\mathcal{L}_{e}\)를 계산한다.
4: 모델 매개 변수 \(\theta^{q+1}\leftarrow\theta^{q}-\eta\nabla_{\theta}\mathcal{L}_{e}(\theta, \phi,\psi)\) 업데이트
5: Propensities 모델 매개 변수 \(\phi^{q+1}\leftarrow\phi^{q}-\eta\nabla_{\phi}\mathcal{L}_{e}(\theta,\phi,\psi)\) 업데이트
6: imputation model parameter \(\psi^{q+1}\leftarrow\psi^{q}-\eta\nabla_{\phi}\mathcal{L}_{e}(\theta,\phi,\psi)\) 업데이트
7:endfor
8:forstep \(q\in\{1,...,Q^{\prime}\}\)do
9: \(\mathcal{D}\)에서 여러 도메인 \(\mathcal{Z}\)에서 사용자-항목 쌍의 배치를 샘플링합니다.
10: 손실 함수 \(\mathcal{L}_{r}\)를 계산한다.
11: 모델 매개 변수 \(\theta^{q+1}\leftarrow\theta^{q}-\eta^{\prime}\nabla_{\theta}\mathcal{L}_{r}( \theta,\phi,\psi)\) 업데이트
12:endfor
```

**알고리즘 1** AMID의 최적화 체계입니다.

## 부록 C. 실험

### Experiment Setup

**평가 메트릭** 각 도메인에서 사용자를 훈련용 80%, 유효성 검사용 10%, 테스트용 10%의 세 가지 세트로 나누었습니다. 데이터를 전처리하기 위해, 선행 연구(Beng et al., 2017; Liu et al., 2018)의 접근법에 따라, 각각의 도메인에서 10개 미만의 상호작용을 갖는 아이템 및 5개 미만의 상호작용을 갖는 사용자가 필터링되었다. 이는 사용자/항목에 의해 학습된 임베딩이 소스 영역을 대표하도록 보장했다. 비중첩 비율 \(\mathcal{K}_{u}\)을 도입하여 비중첩 사용자의 수를 제어하고 서로 다른 디바이어스 시나리오를 시뮬레이션하였다. 예를 들어, \(\mathcal{K}_{u}=25\%\)인 Amazon "Cloth-Sport" 데이터셋에서, 트레이닝 세트의 중첩된 사용자 수는 (27,519 + 107,984 - 16,377 * 2) * 0.25 * 0.8 = 20,549로 계산되었다. 동일한 샘플링 전략이 검증 세트에 적용되었지만, 테스트 세트는 다운샘플링되지 않았다. 이 샘플링 전략은 훈련 세트가 주로 선택되거나 노출될 가능성이 더 높은 사용자로 구성된 오픈 월드 환경에서 선택 편향의 발생을 시뮬레이션할 수 있는 반면 테스트 세트는 신중한 선택 없이 더 넓은 범위의 사용자를 커버한다. 이 연구에서 사용된 모든 평가 메트릭은 더 높은 값으로 더 나은 성능을 나타낸다. \(\mathcal{D}\)에서 보이지 않는 사용자와 관련하여, 관측 데이터에 대해 선택되지 않은 겹치지 않는 사용자를 보이지 않는 사용자의 대체물로 사용한다. 시퀀스를 유지하면서 보이지 않는 사용자의 실제 등급을 제거합니다.

**매개 변수 설정** 다른 접근 방식 간의 공정한 비교를 보장 하기 위해 모든 방법에 대해 동일한 하이퍼 매개 변수를 설정 합니다. 구체적으로 임베딩 차원을 128로, 배치 크기를 512로, 학습률을 0.001로, 음의 샘플링 수를 훈련용 1로, 검증 및 테스트를 위해 199로 고정했다. 우리는 모든 매개변수를 업데이트하기 위해 Adam 최적화기를 사용했다. 비교 기준선의 경우 공식 문헌에 보고된 하이퍼 매개변수 값을 채택했다. 우리 모델과 결합된 SDSR 모델의 경우 SDSR 모델의 하이퍼 매개 변수를 수정하지 않았다. 추가적으로, 그룹 플래그 \(k\)를 제어하기 위한 임계값은 0.7로 설정되고, 샘플링된 사용자들의 크기는 배치 크기로 설정된다. \(\lambda_{1}=0.01\)과 \(\lambda_{23,4,5}=1e^{-4}\)으로 설정하였다. 손실 \(\mathcal{L}_{e}\)이 있는 첫 번째 단계의 학습률은 \(1e^{-3}\)이고 손실 \(\mathcal{L}_{r}\)이 있는 두 번째 단계의 학습률은 \(1e^{-5}\)이다.

### Compared methods

**단일 도메인 순차 권장 방법:**

**BERT4Rec**(Wang et al., 2017)는 양방향 자체 주의 네트워크를 설계하여 사용자 행동 시퀀스를 모델링합니다. 정보 유출을 방지하고 양방향 모델의 학습을 최적화하기 위해 Cloze 목표를 사용하여 왼쪽 및 오른쪽 컨텍스트를 모두 고려하여 시퀀스에서 무작위로 마스킹된 항목을 예측한다. PyTorch에서의 BERT4Rec의 구현은 URL에서 찾을 수 있다. 4

각주 4: [https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch](https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch)

**GRU4Rec**(Wang et al., 2017)는 RNN 모델을 추천 시스템에 적용하는 동안 희소 순차 데이터를 모델링하는 문제를 해결합니다. 이를 위해 저자들은 이러한 모델을 훈련하기 위해 특별히 설계된 새로운 순위 손실 함수를 제안한다. PyTorch에서의 GRU4Rec의 구현은 URL 5에서 찾을 수 있다.

각주 5: [https://github.com/hungpathah/GRU4REC-pytorch](https://github.com/hungpathah/GRU4REC-pytorch)

**SARec**(Wang et al., 2017)은 권장 시스템에서 모델 간결성과 복잡성을 균형 잡는 문제를 해결 하는 자체 주의 기반 순차 모델입니다. SASRec는 주의 메커니즘을 사용하여 사용자의 행동 이력에서 관련 항목을 식별하고 상대적으로 적은 행동을 기반으로 다음 항목을 예측하는 동시에 RNN과 같은 장기 의미론을 포착한다. 이를 통해 SASRec는 매우 희박하고 밀도가 높은 데이터 세트 모두에서 잘 수행할 수 있습니다. PyTorch에서 SASRec의 구현은 URL 6에서 찾을 수 있다.

각주 6: [https://github.com/primer/SARec/pytorch](https://github.com/primer/SARec/pytorch)

**기존 도메인 간 권장 방법:**

**STAR** (Wang et al., 2017)는 모든 도메인의 데이터를 동시에 활용 하 여 여러 도메인에 서비스를 제공 하는 단일 모델을 훈련 하는 것을 목표로 합니다. 이 모델은 각 도메인의 고유한 특성을 포착하는 동시에 서로 다른 도메인 간의 공통점을 모델링한다. 모든 도메인에 공통인 하나의 공유 네트워크와 각 도메인에 맞춤화된 하나의 도메인별 네트워크로 구성된 네트워크 구조를 사용하여 이를 달성한다. 이 두 네트워크의 가중치를 결합하여 통합된 네트워크를 생성한다. Tensorflow에서 Pi-Net의 구현은 URL 7에서 확인할 수 있다.

각주 7: [https://github.com/RManLoa/MAMDR/tree/master](https://github.com/RManLoa/MAMDR/tree/master)

**MAMDR**(Wang et al., 2017)은 MDR(multi-domain recommendation)을 위한 MAMDR이라는 새로운 모델 불가지론 학습 프레임워크를 제시한다. MDR의 다양한 데이터 배포 및 도메인 간의 충돌 문제를 해결한다. MAMDR은 충돌을 완화하기 위한 도메인 협상 전략과 매개변수 일반화 가능성을 개선하기 위한 도메인 정규화 접근법을 통합한다. 이는 다중 도메인 추천을 위한 모든 모델 구조에 적용될 수 있다. 이 작업에는 전문가 없이 수천 개의 도메인에 서비스를 제공하기 위해 타오바오에서 사용되는 확장 가능한 MDR 플랫폼도 포함된다. 비교에서, 우리는 URL에서 찾을 수 있는 텐서플로우에서 그들의 공식 구현을 활용한다. 8

각주 8: [https://github.com/#ManLoa/MAMDR/tree/master](https://github.com/#ManLoa/MAMDR/tree/master)

**SSCDR**(Wang et al., 2017)는 다른 도메인에서 관찰된 선호도를 기반으로 콜드 스타트 사용자에 대한 선호도를 추론하는 문제를 해결합니다. SSCDR은 레이블이 제한된 데이터에서도 도메인 간 관계를 효과적으로 학습하는 준지도 매핑 접근법을 제안한다. 각 도메인의 사용자와 아이템에 대한 잠재 벡터를 학습하고 이들의 상호작용을 거리로 인코딩한다. 그런 다음 프레임워크는 중첩하는 사용자의 라벨링된 데이터와 모든 항목의 라벨링되지 않은 데이터를 모두 사용하여 교차 도메인 매핑 함수를 학습한다. SSCDR은 또한 콜드 스타트 사용자의 이웃 정보를 집계하여 잠재 벡터를 예측하는 효과적인 추론 기술을 통합한다.

**도메인 간 순차 권장 방법:**

**Pi-Net**[(27)]은 두 도메인에 대 한 권장 사항을 동시에 생성 하 고 각 타임스탬프에서 사용자 행동을 공유 하 여 동일한 계정에서 다른 사용자 행동을 식별 하 고 다른 도메인에서 권장 사항을 개선할 수 있는 한 도메인에서 행동을 식별 하는 문제를 해결 합니다. Pi-Net은 병렬 정보 공유를 활용함으로써 공유 계정 교차 도메인 순차 추천 태스크에서 교차 도메인 시나리오에 대한 추천 정확도와 효율성을 향상시킨다. Tensorflow에서 Pi-Net의 구현은 URL 9에서 확인할 수 있다.

각주 9: [https://github.com/manurysang/PINet](https://github.com/manurysang/PINet)

**DASL**[(19)]은 원본-대상 도메인 쌍에 대한 사용자 선호도의 양방향 잠재 관계를 고려하여 두 도메인에 대해 동시에 향상된 교차 도메인 CTR 예측을 제공함으로써 이전 교차 도메인 순차 추천 모델의 한계를 해결합니다. 제안된 방법은 이중 학습 메커니즘을 특징으로 하며, 두 도메인에서 사용자 선호도를 추출하고 이중 주의 학습 메커니즘을 통해 도메인 간 추천을 제공하기 위해 이중 임베딩 및 이중 주의 구성 요소를 포함한다. 텐서플로우에서의 DASL의 구현은 URL 10에서 찾을 수 있다.

각주 10: [https://github.com/dpv6x/DASL](https://github.com/dpv6x/DASL)

**C\({}^{2}\)DSR**[(2)]는 전송 모듈의 병목 현상을 해결하고 시퀀스 내 및 시퀀스 간 항목 관계를 활용하여 단일 도메인 및 교차 도메인 사용자 선호도를 공동으로 학습함으로써 추천 정확도를 향상시킨다. 이 접근법은 이전 방법의 한계를 극복하고 정확한 사용자 선호도를 캡처한다. PyTorch에서 C\({}^{2}\)DSR의 구현은 URL 11에서 찾을 수 있다.

각주 11: [https://github.com/ltx/DASL](https://github.com/ltx/DASL)

**권장 방법 편향 해제:**

**DCRee**[(47)]는 순차 패턴 인코딩을 전역 협력 관계 모델링과 통합 한다고 주장하는 새로운 권장 패러다임입니다. 그것은 인기 편향과 사용자 적합성 및 실제 관심을 해결하기 위한 현재 대조 학습 방법의 실패와 라벨 부족 문제를 해결하려고 시도한다. PyTorch에서의 DCRee의 구현은 URL 12에서 찾을 수 있다.

각주 12: [https://github.com/ltx/DASL](https://github.com/ltx/DASL)

훈련에서 테스트로의 단일 도메인 순차적 추천에서 인기 편향과 시간적 분포 이동의 영향을 완화하기 위해 **CaseQ**[(46)]가 제안된다. 이를 위해 CaseQ는 백도어 조정에 기반한 학습 목표와 결합된 계층적 분기 구조를 채택하여 상황별 표상의 학습을 가능하게 한다. PyTorch에서의 CaseQ의 구현은 URL 13에서 찾을 수 있다.

각주 13: [https://github.com/cltx/DCRee](https://github.com/cltx/DCRee)

**IPSCDR**[(21)]은 도메인 간 시나리오에 맞게 조정된 새로운 IPS(역방향 성향 점수) 추정기를 개발했습니다. 이 접근법은 또한 성향 점수 학습을 위한 세 가지 유형의 제한을 통합한다. 이러한 방법들을 활용함으로써, IPSCDR은 도메인 간에 사용자 정보를 전달할 때 선택 편향 및 인기 편향을 포함하는 도메인 편향을 효과적으로 완화한다. 사용 가능한 공식적인 코드 출시가 없기 때문에 관련 IPS 기반 프레임워크를 적용하여 IPSCDR에 대한 코드를 재구성했다. PyTorch에서의 IPS 기반 프레임워크의 구현은 URL 14에서 찾을 수 있다.

각주 14: [https://github.com/kmk/ipsc/caseq](https://github.com/kmk/ipsc/caseq)

### Hyperparameter Analysis

손실함수에서 트레이드오프 매개변수 \(\lambda_{1}\)의 영향을 평가하기 위해 AMID 모델에 대한 최적의 값을 찾기 위해 \(\lambda_{1}=0.001,0.01,0.1\)의 다른 값으로 일련의 실험을 수행했다. 실험은 5회 실행되고 결과는 평균과 분산으로 보고된다. 표 7-8의 결과를 통해 \(\lambda=0.01\)의 SDSR 모델이 \(\mathcal{K}_{u}\)이 다른 Cloth-Sport 및 Phone-Elec 시나리오 모두에서 최상의 성능을 달성했음을 알 수 있다. 또한 Cloth-Sport 시나리오에서는 \(\lambda=0.001\)의 모델이 \(\lambda=0.1\)의 모델보다 더 나은 성능을 보이는 반면 Phone-Elec 시나리오에서는 \(\lambda=0.1\)의 모델이 \(\lambda=0.001\)의 모델보다 더 나은 성능을 보인다.

다중 관심 정보 모듈에서 관심 그룹 구성에 대한 임계값 \(k\)의 영향을 조사하기 위해 임계값 \(k\in\{0.5,0.6,0.7,0.8,0.9\}\)을 변화시켜 제거 실험을 수행한다. 우리는 Cloth-Sport 및 Phone-Elec 시나리오에서 NDCG@10 및 HR@10을 사용하여 평균 평가 점수를 측정한다. 그 결과, 더 큰 임계값 \(k\)(\(0.5\에서 0.7\))이 더 많은 관련 관심 정보를 전송할 수 있기 때문에 더 나은 성능을 얻을 수 있음을 보여준다. 그러나 임계값 \(k\)이 0.7 이상으로 증가하면 노이즈 간섭과 중복 정보로 인해 모델의 성능이 떨어진다. 따라서 우수한 성능을 얻기 위해 임계값 \(k\)을 0.7로 설정하였다.

**샘플링된 사용자 수**.** 샘플링된 사용자 수가 다중 관심 정보 모듈에 미치는 영향을 조사하기 위해 샘플링된 사용자 수를 128에서 1024까지 다양 한 절제 실험을 수행 합니다. Cloth-Sport 및 Phone-Elec 시나리오 모두에 대 한 평균 평가 점수 (NDCG@10 및 HR@10)를 측정 하 고 결과를 그림 8에 표시 합니다. 본 연구 결과는 샘플링된 사용자 수의 증가가 처음에는 권장 성능을 향상시켰지만 일치 하는 이웃이 1024에 도달 하면 결국 감소 합니다. 이러한 관찰은 샘플링된 사용자가 너무 적으면 전달 된 정보가 부족 하 고 샘플링된 사용자가 너무 많으면 간섭 잡음이 발생 하 여 모델의 성능을 손상 시킬 수 있음을 나타냅니다. 실제로 표본 사용자 수를 512명으로 선택하여 모델에 가장 적합한 성능을 제공합니다.

## 부록 D 잠재적 사회 영향

우리는 대부분의 기성 SDSR 방법의 성능을 향상시키기 위해 적응형 다중 관심 디바이어싱 프레임워크를 제안한다. 우리의 접근법을 활용하여 전자 상거래 회사는 사용자에게 더 적절한 제품을 추천하고 수익을 높일 수 있습니다. 또한, 우리의 모델 AMID는 소수 사용자를 대상으로 잠재적인 관심사를 탐색하는 디바이징 프레임워크를 고안한다. 결과적으로, 우리의 연구는 추천 시스템의 공정성을 촉진하고 알고리즘 편향으로 인해 발생할 수 있는 사회적 불평등을 완화하는 데 도움이 될 수 있다.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline \multirow{2}{*}{**Methods**} & \multicolumn{4}{c}{**Cloth-domain recommendation**} & \multicolumn{4}{c}{**Sport-domain recommendation**} \\ \cline{2-9}  & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=25\%} & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=75\%} & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=25\%} & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=75\%} \\ \cline{2-9}  & NDCG@10 & HR@10 & NDCG@10 & HR@10 & NDCG@10 & HR@10 & NDCG@10 & HR@10 \\ \hline \hline \(\lambda_{4}\) = **0.001** : & & & & & & & & \\ BERT4Rec [38] + AMID & 2.89\(\pm\)0.10 & 5.63\(\pm\)0.12 & 3.74\(\pm\)0.21 & 6.98\(\pm\)0.25 & 4.65\(\pm\)0.27 & 9.17\(\pm\)0.30 & 5.63\(\pm\)0.21 & 10.55\(\pm\)0.43 \\ GRU4Rec [12] + AMID & 3.01\(\pm\)0.15 & 5.82\(\pm\)0.19 & 3.79\(\pm\)0.13 & 7.20\(\pm\)0.32 & 4.77\(\pm\)0.11 & 9.32\(\pm\)0.31 & 5.81\(\pm\)0.22 & 10.91\(\pm\)0.25 \\ SA8Rec [17] + AMID & 3.08\(\pm\)0.29 & 6.05\(\pm\)0.35 & 4.11\(\pm\)0.09 & 7.50\(\pm\)0.27 & 4.88\(\pm\)0.19 & 9.36\(\pm\)0.25 & 5.87\(\pm\)0.22 & 10.94\(\pm\)0.20 \\ \hline \hline \(\lambda_{4}\) = **0.01** : & & & & & & & \\ BERT4Rec [38] + AMID & 2.99\(\pm\)0.07 & 5.70\(\pm\)0.13 & 3.79\(\pm\)0.15 & 7.09\(\pm\)0.32 & 4.73\(\pm\)0.29 & 9.30\(\pm\)0.41 & 5.70\(\pm\)0.12 & 10.63\(\pm\)0.36 \\ GRU4Rec [12] + AMID & 3.10\(\pm\)0.17 & 5.95\(\pm\)0.16 & 3.94\(\pm\)0.15 & 7.30\(\pm\)0.30 & 4.89\(\pm\)0.10 & 9.42\(\pm\)0.28 & 5.90\(\pm\)0.17 & 11.01\(\pm\)0.17 \\ SA8Rec [17] + AMID & **3.20\(\pm\)0.22** & **6.14\(\pm\)0.33** & **4.19\(\pm\)0.10** & **7.62\(\pm\)0.20** & **4.97\(\pm\)0.15** & **9.48\(\pm\)0.22** & **5.96\(\pm\)0.14** & **11.04\(\pm\)0.26** \\ \hline \hline \(\lambda_{4}\) = **0.01** : & & & & & & & \\ BERT4Rec [38] + AMID & 2.75\(\pm\)0.12 & 5.51\(\pm\)0.15 & 3.56\(\pm\)0.10 & 6.88\(\pm\)0.39 & 4.50\(\pm\)0.27 & 9.13\(\pm\)0.51 & 5.50\(\pm\)0.17 & 10.44\(\pm\)0.34 \\ GRU4Rec [12] + AMID & 2.91\(\pm\)0.19 & 5.76\(\pm\)0.13 & 3.79\(\pm\)0.14 & 7.11\(\pm\)0.29 & 4.68\(\pm\)0.09 & 9.24\(\pm\)0.34 & 5.73\(\pm\)0.15 & 10.79\(\pm\)0.31 \\ SA8Rec [17] + AMID & 3.02\(\pm\)0.21 & 5.97\(\pm\)0.28 & 3.99\(\pm\)0.15 & 7.40\(\pm\)0.17 & 4.75\(\pm\)0.11 & 9.25\(\pm\)0.30 & 5.77\(\pm\)0.19 & 10.83\(\pm\)0.24 \\ \hline \hline \end{tabular}
\end{table}
표 7: \(\mathcal{K}_{u}\)이 다른 양방향 Cloth-Sport CDR 시나리오에서 \(\lambda_{4}\)의 하이퍼파라미터 분석(%)입니다.**

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline \multirow{2}{*}{**Methods**} & \multicolumn{4}{c}{**Phone-domain recommendation**} & \multicolumn{4}{c}{**Elec-domain recommendation**} \\ \cline{2-9}  & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=25\%} & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=75\%} & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=25\%} & \multicolumn{2}{c}{\(\mathcal{K}_{u}\)=75\%} \\ \cline{2-9}  & NDCG@10 & HR@10 & NDCG@10 & HR@10 & NDCG@10 & HR@10 & NDCG@10 & HR@10 \\ \hline \hline \(\lambda_{4}\) = **0.001** : & & & & & & & \\ BERT4Rec [38] + AMID & 7.67\(\pm\)0.25 & 14.18\(\pm\)0.41 & 7.88\(\pm\)0.39 & 14.54\(\pm\)0.21 & 10.87\(\pm\)0.14 & 18.29\(\pm\)0.30 & 11.83\(\pm\)0.15 & 19.77\(\pm\)0.37 \\ GRU4Rec [12] + AMID & 8.05\(\pm\)0.13 & 15.20\(\pm\)0.45 & 8.08\(\pm\)0.10 & 15.02\(\pm\)0.23 & 11.44\(\pm\)0.10 & 19.21\(\pm\)0.14 & 12.25\(\pm\)0.15 & 20.58\(\pm\)0.25 \\ SA8Rec [17] + AMID & 7.94\(\pm\)0.11 & 14.69\(\pm\)0.09 & 8.05\(\pm\)0.32 & 14.68\(\pm\)0.23 & 11.40\(\pm\)0.29 & 19.03\(\pm\)0.24 & 12.21\(\pm\)0.15 & 20.48\(\pm\)0.19 \\ \hline \hline \(\lambda_{4}\) = **0.01** : & & & & & & & \\ BERT4Rec [38] + AMID & 7.95\(\pm\)0.23 & 14.49\(\pm\)0.36 & 8.15\(\pm\)0.33 & 14.85\(\pm\)0.28 & 11.26\(\pm\)0.07 & 18.58\(\pm\)0.27 & 11.16\(\pm\)0.09 & 20.08\(\pm\)0.31 \\ GRU4Rec [12] + AMID & **8.33\(\pm\)0.09** & **15.49\(\pm\)0.50** & **8.34\(\pm\)0.21** & **15.29\(\pm\)0.29** & **17.14\(\pm\)0.07** & **19.50\(\pm\)0.08** & **12.53\(\pm\)0.11** & **20.85\(\pm\)0.20** \\ SA8Rec [17] + AMID & 8.20\(\pm\)0.10 & 14.99\(\pm\)0.16 & 8.32\(\pm\)0.20 & 14.96\(\pm\)0.15 & 11.71\(\pm\)0.23 & 19.28\(\pm\)0.23 & 12.52\(\pm\)0.13Figure 8. The results of SASRec\(\star\)AMID with different number of the sampled users on the Cloth-Sport & Phone-Elec scenarios. 25% and 75% denotes different \(\mathcal{K}_{u}\).

그림 7. Cloth-Sport & Phone-Elec 시나리오에서 서로 다른 임계값 \(k\)을 갖는 SASRec\(\star\)AMID의 결과. 25%와 75%는 서로 다른 \(\mathcal{K}_{u}\)을 나타낸다.
