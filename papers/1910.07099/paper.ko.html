<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '전환율 예측을 위한 포스트클릭 행위 분해를 통한 전체 공간 멀티태스크 모델링\n' +
      '\n' +
      'Hong Wen\n' +
      '\n' +
      '교신 저자: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      'Alibaba Group\n' +
      '\n' +
      '항저우, 저장, 중국 311121qinggan.wh@alibaba-inc.com\n' +
      '\n' +
      'Jing Zhang\n' +
      '\n' +
      '시드니대학교\n' +
      '\n' +
      'Darlington NSW 2008, Australiajing.zhang1@sydney.edu.au\n' +
      '\n' +
      'Yuan Wang\n' +
      '\n' +
      'Alibaba Group\n' +
      '\n' +
      '항저우, 저장, 중국 311121wy175696@alibaba-inc.com\n' +
      '\n' +
      'Fuyu Lv\n' +
      '\n' +
      'Alibaba Group\n' +
      '\n' +
      '항저우, 저장, 중국 311121fuyu.lfy@alibaba-inc.com\n' +
      '\n' +
      'Wentian Bao\n' +
      '\n' +
      'Alibaba Group\n' +
      '\n' +
      '항저우, 저장, 중국 311121wentian.bwt@alibaba-inc.com\n' +
      '\n' +
      '권림광양\n' +
      '\n' +
      'Alibaba Group\n' +
      '\n' +
      '항저우, 저장, 중국 311121{tieyi.lq,shaoyao}@taobao.com\n' +
      '\n' +
      '###### Abstract.\n' +
      '\n' +
      '추천 시스템은 현대 전자 상거래의 필수적인 부분으로서 클릭-관류율(CTR)과 전환율(CVR) 예측의 두 가지 기본 모듈로 구성된다. CVR은 구매량에 직접적인 영향을 미치지만, 샘플 선택 편향(SSB) 및 데이터 희소성(DS) 문제로 인해 예측은 잘 알려져 있다. 기존의 방법들은 일반적으로 사용자 순차적 행동 경로 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)구매"를 기반으로 구축되어 SSB 문제를 처리하는데 효과적이나, 여전히 희귀한 구매 훈련 샘플로 인해 DS 문제를 해결하는데 어려움을 겪고 있다. 사용자가 클릭 후 항상 여러 구매 관련 행동을 취하는 것을 관찰하여 클릭 후 행동 분해의 새로운 아이디어를 제안한다. 구체적으로, 클릭과 구매 사이에 디조인트 구매 관련 결정적 액션(DAction) 및 기타 액션(OAction)이 병렬로 삽입되어, 새로운 사용자 순차적 행동 그래프 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)구매"를 형성한다. 이 그래프에 대한 모델을 정의하면 전체 공간에 대한 모든 인상 샘플과 D(O)Action의 여분의 풍부한 감독 신호를 활용할 수 있으며, 이는 SSB와 DS 문제를 함께 효과적으로 해결할 수 있다. 이를 위해, 본 논문에서는 Elaborated Entire Space Supervised Multi-task Model(_ESM\\({}^{2}\\)_)이라는 새로운 심층 추천 모델을 제안한다. 그래프 상에 정의된 조건부 확률 규칙에 따라, 분해된 일부 하위 타겟을 병렬로 예측하고 이를 순차적으로 구성하여 최종 CVR을 공식화한다. 오프라인 및 온라인 환경에 대한 광범위한 실험은 최신 모델보다 _ESM\\({}^{2}\\)_의 우수성을 보여준다. 소스 코드와 데이터 세트가 릴리스됩니다.\n' +
      '\n' +
      '추천 시스템, 전체 공간 멀티 태스크 학습, 포스트 클릭 행위 분해, 전환율 예측 +\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 † †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 † †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '+\n' +
      '각주 †: 두 저자 모두 이 논문에 동등하게 기여했다.\n' +
      '\n' +
      '샘플은 노출에 비해 순차적 행동 경로 "click\\(\\rightarrow\\)purchase"의 훈련 샘플 수가 CVR 작업의 큰 매개변수 공간에 적합하지 않아 DS 문제가 발생한다. 그림 2와 같이 SSB와 DS 문제를 어떻게 다룰 것인가는 효율적인 산업 수준의 추천 시스템을 개발하는 데 중요하다.\n' +
      '\n' +
      '이러한 과제를 해결하기 위해 여러 연구가 수행되었다(Ma et al., 2018; Wang et al., 2018; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). 예를 들어 Ma _et al_입니다. 본 논문에서는 사용자 순차 행동 경로 상에서 CVR 태스크를 정의하는 ESM(Entire Space Multi-Task Model) 모델을 제안한다. 이 모델은 다중 태스크 학습 프레임워크를 통해 사용자 순차 행동 경로 상에서 "impression\\(\\rightarrow\\)click\\(\\rightarrow\\)purchase"를 정의한다. 후시점 CTR 및 후시점 클릭-스루 변환율(CTCVR)이라는 두 가지 보조 작업에 대해 전체 공간에 걸쳐 모든 인상 샘플로 트레이닝된다. 따라서 CTR과 CTCVR에서 도출된 CVR은 온라인 추론 시 동일한 전체 공간에서도 적용 가능하므로 SSB 문제를 효과적으로 해결할 수 있다. 또한 레이블이 풍부한 샘플이 있는 보조 CTR 네트워크는 CVR 네트워크와 동일한 기능 표현을 공유하여 DS 문제를 완화하는 데 도움이 된다. ESMM은 SSB와 DS 문제를 동시에 처리함으로써 기존의 방법보다 더 나은 성능을 달성하지만, 여전히 희귀한 구매 훈련 샘플인 \\(i\\)로 인해 DS 문제를 완화하기 위해 고군분투한다._ e_, 0.1% 미만의 인상 행동은 우리의 전자 상거래 플랫폼의 대규모 실제 거래 로그에 따라 구매로 전환한다.\n' +
      '\n' +
      '로그에 대한 자세한 분석 후 사용자가 클릭 후 항상 구매 관련 조치를 취하는 것을 관찰합니다. 예를 들어, 사용자들은 몇몇 이유들(_i_.\\ (e\\). 할인 대기 중. 게다가, 이러한 행동은 실제로 구매 행동보다 더 풍부합니다. 이에 동기 부여하여 클릭 후 행동 분해의 새로운 아이디어를 제안한다. 구체적으로, 클릭과 구매 사이에 디조인트 구매 관련 결정적 액션(DAction) 및 기타 액션(OAction)이 병렬로 삽입되어, 새로운 사용자 순차적 행동 그래프 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)구매"를 형성하며, 여기서 태스크 관계는 조건부 확률에 의해 명시적으로 정의된다. 또한, 이 그래프에서 모델을 정의하면 전체 공간에 대한 모든 인상 샘플과 클릭 후 행동에서 발생하는 여분의 풍부한 감독 신호를 활용하여 SSB 및 DS 문제를 효율적으로 해결할 수 있다.\n' +
      '\n' +
      '본 논문에서는 위의 아이디어를 구현하기 위해 심층 신경망에 의존한다. 구체적으로, 우리는 1) 공유 임베딩 모듈(SEM), 2) 분해된 예측 모듈(DPM), 3) 순차적 구성 모듈(SCM)의 세 가지 모듈로 구성된 Elaborated Entire Space Supervised Multi-task Model(\\(ESM^{2}\\))이라는 새로운 심층 신경망 추천 모델을 제안한다. 먼저, SEM은 ID 피처들의 원-핫 피처 벡터를 선형 완전 연결 레이어를 통해 조밀한 표현에 임베딩한다. 그런 다음, 이러한 임베딩은 후속 DPM에 공급되며, 여기서 개별 예측 네트워크는 전체 공간에 걸쳐 모든 인상 샘플에 대해 다중 작업 학습을 사용하여 분해된 하위 표적의 확률을 병렬로 추정한다. 마지막으로 SCM은 그래프에 정의된 조건부 확률 규칙에 따라 최종 CVR과 일부 보조 확률을 순차적으로 구성한다. 그래프의 일부 하위 경로에서 정의된 다중 손실은 \\(ESM^{2}\\)의 훈련을 감독하는 데 사용된다.\n' +
      '\n' +
      '본 논문의 주요 기여도는 다음과 같이 요약된다.\n' +
      '\n' +
      '\\(\\bullet\\) 우리가 아는 한, 우리는 전체 공간에 대해 CVR을 모델링하기 위해 클릭 후 행동 분해 개념을 처음으로 도입했다. 명시적 분해는 새로운 사용자 순차 행동 그래프 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)구매"를 생성한다.\n' +
      '\n' +
      '\\(\\bullet\\) 사용자 행동 그래프에 정의된 조건부 확률 규칙에 따라 다중 태스크 학습 프레임워크에서 CVR 예측과 보조 태스크를 동시에 모델링하는 새로운 심층 신경망 추천 기법인 \\(ESM^{2}\\)을 제안한다. \\ (ESM^{2}\\)는 레이블이 있는 풍부한 클릭 후 액션 데이터를 수집함으로써 SSB 및 DS 문제를 효율적으로 해결할 수 있다.\n' +
      '\n' +
      '이 모델은 실제 오프라인 데이터셋에서 대표적인 최신 기법보다 더 나은 성능을 보인다. 또한 이를 온라인 추천 시스템에 구현하여 산업 응용 분야에서 그 가치를 확인하였다.\n' +
      '\n' +
      '본 논문의 나머지 부분은 다음과 같이 구성되어 있다. 제2절에서는 관련 작업에 대한 간략한 조사를 제시하고, 제3절에서는 제안된 모델의 세부 사항을 제시한다. 제4절에서는 실험 결과 및 분석을 제시하고, 제5절에서는 결론을 맺는다.\n' +
      '\n' +
      '## 2. 관련 작업\n' +
      '\n' +
      '본 논문에서 제안하는 방법은 전체 공간에 대한 다중 태스크 학습 프레임워크를 사용하여 변환률 예측 문제를 구체적으로 다룬다. 따라서, 가장 관련된 내용을 간략히 살펴본다\n' +
      '\n' +
      '도 1. e-커머스 플랫폼에서의 온라인 추천의 다이어그램으로서, \\(i\\)._ e_., 시스템 추천 및 사용자 피드백.\n' +
      '\n' +
      '도 2. 트레이닝 공간이 클릭된 샘플들만을 구성하는 반면, 추론 공간은 모든 인상 샘플들에 대한 전체 공간인 종래의 CVR 예측에서의 샘플 선택 바이어스 문제의 예시. 그리고 데이터 볼륨은 인상부터 구매까지 점차 감소했습니다.\n' +
      '\n' +
      '1) 전환율 예측과 2) 다중 작업 학습의 두 가지 측면에서 작업한다.\n' +
      '\n' +
      '**변환 속도 예측:** 변환 속도 예측은 검색 엔진 (한 등, 2015; Wang 등, 2017), 추천 시스템 (한 등, 2015; Wang 등, 2017) 및 온라인 광고 (한 등, 2015; Wang 등, 2017)와 같은 많은 온라인 애플리케이션의 핵심 구성 요소입니다. 그러나, CVR 작업에 대해 직접적으로 제안된 문헌은 거의 없다(Han et al., 2015; Wang et al., 2017; Wang et al., 2017). 최근 CTR 방법의 번영하는 발전에 관계없이(Han et al., 2015; Wang et al., 2017; Wang et al., 2017). 실제로, CVR 모델링은 변환이 인상 항목의 매우 작은 부분만이 결국 클릭되고 구매되는 극히 드문 이벤트이기 때문에 매우 어렵다. 최근, 심층 신경망은 특징 표현 및 종단간 모델링에서의 현저한 능력으로 인해 추천 시스템을 포함한 많은 영역에서 상당한 진전을 이루었다(Han et al., 2015; Wang et al., 2017; Wang et al., 2017; Wang et al., 2017; Wang et al., 2017). 본 논문에서는 또한 변환률 예측 작업을 모델링하기 위해 심층 신경망을 채택한다. 이와는 달리, 본 논문에서는 클릭 후 행동 분해 개념을 기반으로 새로운 사용자 순차 행동 그래프 "impression\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)purchase"를 도출한다. 그래프 상에서 정의된 조건부 확률 규칙에 따라, 본 논문에서 제안하는 네트워크 구조는 분해된 여러 개의 서브 타겟을 병렬로 예측하여 순차적으로 구성함으로써 최종 CVR을 공식화한다.\n' +
      '\n' +
      '**다중 작업 학습:** 사용자의 구매 행동의 시간적 다단계 특성으로 인해 이전 작업은 다중 작업 학습 프레임워크에 의해 전환율 예측 작업을 공식화하려고 시도합니다. 예를 들어 Hadash _et al_. 순위 및 등급 예측 작업을 동시에 모델링하여 다중 작업 학습 기반 추천 시스템을 제안합니다 (Hadash et al., 2015). Ma _et al_. 데이터에서 작업 관계를 명시적으로 학습하는 다중 게이트 혼합 전문가라는 다중 작업 학습 방법을 제안 합니다 (Hadash et al., 2015). Gao _et al_. 여러 유형의 행위 간의 캐스케이딩 관계를 학습하는 신경 다중 작업 추천 모델을 제안 합니다 (Gao et al., 2016). 이와 달리 CTR 및 CVR 작업을 사용자의 순차적 행위 그래프와 연관시켜 동시에 모델링합니다. 여기서 작업 관계는 조건부 확률로 명시적으로 정의 됩니다 (섹션 3 참조). Ni _et al_. 보다 효과적인 개인화를 위해 다수의 태스크에 걸쳐 보편적인 사용자 표현을 학습하도록 제안한다(He et al., 2017). 또한 다양한 작업에 포함된 기능을 공유하여 이러한 아이디어를 탐구합니다. 최근 Ma _et al_. CVR 예측을 위한 전체 공간 다중 작업 모델(ESMM)을 제안한다(Ma 등, 2015). CTR 태스크와 CTCVR 태스크를 보조적으로 주 CVR 태스크에 추가한다. 이 방법은 ESMM에서 부분적으로 영감을 얻었지만 다음과 같은 큰 차이점이 있다. 본 논문에서는 새로운 사용자 순차 행동 그래프 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)구매"를 재구성하기 위해 클릭 후 행동 분해의 새로운 아이디어를 제안한다. 이 그래프에 대한 모델을 정의하면 최종 CVR과 일부 보조 작업을 함께 공식화할 수 있다. 이는 전체 공간에 대한 모든 인상 샘플과 구매 행동과 관련성이 높은 사용자의 클릭 후 행동에서 발생하는 풍부한 감독 신호를 활용하여 결과적으로 SSB와 DS 문제를 동시에 해결할 수 있다.\n' +
      '\n' +
      '## 3. 제안된 방법\n' +
      '\n' +
      '### Motivation\n' +
      '\n' +
      '실제로, 디스플레이되는 아이템부터 성공적으로 구매되는 아이템까지, 우리는 사용자가 선택할 수 있는 여러 종류의 순차적인 액션들이 존재할 수 있음을 식별한다. 예를 들어, 하나의 관심 아이템을 클릭한 후, 사용자가 거침없이 직접 구매하거나, 장바구니에 추가한 후 결국 구매를 할 수 있다. 이러한 행동 경로는 그림 3(a)와 같다. 그림 3(b)와 같이 미리 정의된 특정 구매 관련 클릭 후 동작 _i.e._, 쇼핑 카트(SCart)에 추가 및 위시 목록(Wish list)에 추가에 따라 이러한 경로를 단순화하고 그룹화할 수 있다. 온라인 실제 로그에 대한 데이터 분석을 기반으로 클릭된 행동의 1%만이 결국 구매로 전환되어 희귀 구매 훈련 샘플을 나타낸다. 그러나 SCart 및 Wish와 같은 여러 클릭 후 작업의 데이터 볼륨은 구매보다 훨씬 큽니다. 예를 들어, 클릭된 동작이 제공된 장바구니에 10%가 추가됩니다. 게다가, 이러한 클릭 후 액션은 최종 구매 액션과 매우 관련이 있으며, _예를 들어_ 12%(또는 31%)는 장바구니(또는 위시 리스트)에 추가된 후에 결국 구매될 것이다. 구매와의 높은 관련성과 관련하여 클릭 후 행동의 더 큰 양을 어떻게 활용하여 CVR 예측에 어떤 방식으로 도움이 될 수 있는가?\n' +
      '\n' +
      '직관적으로, 하나의 해결책은 구매와 함께 이러한 구매 관련 포스트 클릭 동작을 멀티 태스크 예측 프레임워크로 모델링하는 것이다. 중요한 것은 명시적인 순차 상관 관계(예:_)를 가지므로 올바르게 공식화하는 방법입니다. 이를 위해 그림 3(c)와 같이 SCart 및 Wish와 같이 미리 정의된 특정 구매 관련 클릭 후 액션을 병합하기 위해 Deterministic Action(DAction)이라는 단일 노드를 정의한다. DAction은 두 가지 속성을 갖는다 : 1) 그것은 구매 액션과 관련성이 높고, 2) 사용자의 피드백으로부터 풍부한 결정론적 감독 신호들, 예를 들어, 일부 특정 액션들(_i.e._, 클릭 후 쇼핑 카트 또는 위시 리스트에 추가)에 대한 1 및 없음에 대한 0. 또한 클릭과 구매 사이에 다른 행위(OAction)라는 노드를 추가하여 DAction을 제외한 다른 클릭 후 행위를 처리한다. 이와 같이, 종래의 행동 경로 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)구매"는 도 3(c)에 도시된 바와 같이, 새로운 정교화된 사용자 순차 행동 그래프 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)구매"로 된다. 이 그래프에 대한 모델을 정의하면 전체 공간에 걸쳐 모든 인상 샘플을 활용할 수 있으며 SSB와 DS 문제를 효율적으로 피할 수 있는 D(O)Action의 추가 풍부한 감독 신호를 활용할 수 있다. 우리는 이 새로운 아이디어를 클릭 후 행동 분해라고 부른다.\n' +
      '\n' +
      '### 조건부 확률 분해\n' +
      '\n' +
      '본 절에서는 그림 3(c)에 정의된 디그래프에 따른 CVR의 조건부 확률 분해와 관련 보조 작업을 제시한다. 첫째, \\(p_{i}^{\\mathit{ctr}}\\)로 표기된 항목 \\(x_{i}\\)의 사후 조회 클릭율 확률은 이그래프에서 "인상\\(\\rightarrow\\) 클릭" 경로를 묘사한 것으로 볼 때 클릭될 조건부 확률로 정의된다. 수학적으로 다음과 같이 표기할 수 있다.\n' +
      '\n' +
      '\\[p_{i}^{\\mathit{ctr}}=p\\left(c_{i}=1\\left|v_{i}=1\\right.\\right)\\overset{\\Delta}{=} y_{1i}, \\tag{1}\\]\n' +
      '\n' +
      '여기서, \\(c_{i}\\in C\\)는 \\(i^{\\mathit{t}}h\\) 아이템 \\(x_{i}\\)이 클릭되고 있는지, \\(c_{i}\\in\\{0,1\\}\\), \\(C\\)은 클릭되고 있는 모든 아이템의 레이블 스페이스, \\(i\\in[1,N]\\) 및 \\(N\\)은 아이템의 개수이다. 마찬가지로, \\(v_{i}\\in V\\)는 \\(i^{\\mathit{t}}h\\) 항목 \\(x_{i}\\)을 보고 있는지 여부(_i.e._, impression), \\(v_{i}\\in\\{0,1\\}\\), \\(V\\)는 보고 있는 모든 항목의 레이블 공간이다. \\ (y_{1i}\\)는 단순화를 위한 대용 기호이다.\n' +
      '\n' +
      '그리고 이그래프에서 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)DAction" 경로를 나타내는 항목 \\(p_{i}^{etavr}\\)으로 표기된 항목 \\(x_{i}\\)의 클릭-스루 닥션 전환율(click-through DAction conversion rate)을 조건부 닥션을 취할 확률로 정의한다. 수학적으로 다음과 같이 표기할 수 있다.\n' +
      '\n' +
      '\\[\\begin{split} p_{i}^{etavr}&=p\\left(a_{i}=1\\left|v_{ i}=1\\right.\\right)\\\\ &=\\sum_{c_{i}\\in\\{0,1\\}}p\\left(a_{i}=1\\left|v_{i}=1\\right.,c_{i} \\right)p\\left(c_{i} \\left|v_{i}=1\\right.\\right)\\\\ &=p\\left(a_{i}=1\\left|v_{i}=1\\right.,c_{i}=0\\right)p\\left(c_{i}=1\\left|v_{i}=1\\right.\\right)\\\\ &\\quad+p\\left(a_{i}=1\\left|v_{i}=1\\right.,c_{i}=1\\right)p\\left(c_ {i}=1\\left|v_{i}=1\\right.\\right)\\\\ &=y_{zi}y_{1i}\\end\n' +
      '\n' +
      '여기서, \\(a_{i}\\in A\\)는 \\(i^{th}\\) 항목 \\(x_{i}\\)이 섹션 3.1에서 정의된 일부 특정 동작을 취하고 있는지 여부를 나타내며, \\(a_{i}\\in\\{0,1\\}\\), \\(A\\)은 일부 특정 동작을 취하고 있는 모든 항목의 레이블 공간이다. \\ (y_{zi}=p\\left(a_{i}=1\\left|v_{i}=1\\right.,c_{i}=1\\right)\\), "click\\(\\rightarrow\\)DAction" 경로를 묘사하는 것은 \\(y_{1i}\\)으로 단순화하기 위한 대용 기호이다. \\(y_{zi}=p\\left(a_{i}=1\\left|c_{i}=1\\right).\\ right)\\) 모든 샘플이 인상 샘플이기 때문이다(_i.e._, \\(v_{i}=1\\)). 주목할 만한 것은 식이다. (2)는 클릭되지 않고 어떠한 동작도 일어나지 않는다는 사실로 인해, _i.e._, \\(p\\left(a_{i}=1\\left|v_{i}=1\\right.,c_{i}=0\\right)\\)=0이다.\n' +
      '\n' +
      '다음으로, \\(p_{i}^{cvr}\\)로 표기된 아이템 \\(x_{i}\\)의 전환율 확률은 클릭이 되었을 때 구매될 조건부 확률로 정의되며, 이는 디그래프의 "click\\(\\rightarrow\\)D(Action\\(\\rightarrow\\)purchase" 경로를 묘사한다. 수학적으로 다음과 같이 표기할 수 있다.\n' +
      '\n' +
      '\\[\\begin{split} p_{i}^{ecvr}&=p\\left(b_{i}=1\\left|c_ {i}=1\\right.\\right)\\\\ &=\\sum_{a_{i}\\in\\{0,1\\}p\\left(b_{i}=1\\left|c_{i}=1\\right.,a_{i} \\right)p\\left(a_{i} \\left|c_{i}=1\\right.\\right)\\\\ &=p\\left(b_{i}=1\\left|c_{i}=1\\right.,a_{i}=0\\right)p\\left(a_{i}=0\\left|c_{i}=1\\right.\\right)\\\\ &\\quad+p\\left(b_{i}=1\\left|c_{i}=1\\right.,a_{i}=1\\right)p\\left(a_{i}=1\\left|c_{i}=1\\right.\\right)\\\\ &\\quad\\overset{\\Delta}{=}\n' +
      '\n' +
      '여기서, \\(b_{i}\\in B\\)는 \\(i^{th}\\) 아이템 \\(x_{i}\\)을 구매 중인지, \\(b_{i}\\in\\{0,1\\}\\), \\(B\\)는 구매 중인 모든 아이템의 라벨 공간이다. \\ (y_{zi}=p\\left(b_{i}=1\\left|c_{i}=1\\right.,a_{i}=1\\right)\\), \\(y_{4i}=p\\left(b_{i}=1\\left|c_{i}=1\\right.,a_{i}=0\\right)\\)는 \\(y_{1i}\\)으로 단순화하기 위한 일부 대리 기호이다. \\ (y_{3i}\\) 또는 \\(y_{4i}\\)은 각각 디그래프에서 "DAction\\(\\rightarrow\\)purchase" 또는 "OAction\\(\\rightarrow\\)purchase" 경로를 나타낸다.\n' +
      '\n' +
      '(p_{i}^{ctcvr}\\)로 표기된 아이템 \\(x_{i}\\)의 클릭 전환율 확률(click-through conversion rate)은 구매가 이루어진 조건부 확률로 정의되며, 이는 디그래프의 완전한 그래프 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\) 구매"를 나타낸다. 수학적으로 다음과 같이 표기할 수 있다.\n' +
      '\n' +
      '\\[\\begin{split} p_{i}^{etcvr}&=p\\left(b_{i}=1\\left|v_ {i}=1\\right.\\right)\\\\ &=\\sum_{c_{i}}p\\left(b_{i}=1\\left|v_{i}=1\\right.,c_{i}\\right)p \\left(c_{i}\\left|v_{i}=1\\right.\\right)\\\\ &=\\sum_{c_{i}}\\sum_{a_{i}}p\\left(b_{i}=1\\left|v_{i}\\right.,c_{i},a_ {i}\\right)p\\left(a_{i}\\left|v_{i}\\right.,c_{i}\\left)p\\left(c_{i}\\left|v_{i} \\right.\\right)\\\\ &=y_{4i}\\left(1-y_{2i}\\right)y_{1i}+y_{3i}y_{2i}y_{1i}\\\\ &=\n' +
      '\n' +
      '여기서는 모호성을 야기하지 않고 단순화를 위해 세 번째 등식에서 \\(v_{i}=1\\)을 대체하기 위해 \\(v_{i}\\)을 사용한다. (p\\left(b_{i}=1\\left|v_{i}=1\\right.,c_{i}=0,a_{i}\\right)\\)는 0, \\(\\forall a_{i}\\in\\{0,1\\}\\)과 같다. 실제로, Eq. (4) 그래프 "impression\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)purchase"를 "impression\\(\\rightarrow\\)click"과 "click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)purchase"로 분해하여 Eq를 적분함으로써 도출할 수 있다. (1) 및 식. (3) chain rule에 따라, _i.e._, \\(p_{i}^{etcvr}=p_{i}^{etr}\\ast p_{i}^{cvr}\\).\n' +
      '\n' +
      '### 정교화된 전체 공간 감독 다중 작업 모델\n' +
      '\n' +
      'Eq. (1)\\(\\sim\\)식. (4)는 4개의 은닉확률변수 \\(y_{1i}\\), \\(y_{2i}\\), \\(y_{3i}\\), \\(y_{4i}\\)으로부터 \\(p_{i}^{ctr}\\), \\(p_{i}^{etavr}\\), \\(p_{i}^{ecvr}\\)을 유도할 수 있으며, 이는 그래프의 일부 하위 경로에 대한 조건부 확률을 나타내는 _i.e_, "impression\\(\\rightarrow\\)click", "click\\(\\rightarrow\\)DAction", "DAction\\(\\rightarrow\\)purchase" 및 "OAction\\(\\rightarrow\\)purchase"이다. 한편, 이러한 네 개의 서브 타겟은 전체 공간에 걸쳐 정의되며, 모든 인상 샘플을 사용하여 예측될 수 있다. \\(y_{2i}\\)을 예로 들면, 클릭된 샘플만을 가지고 직접 \\(y_{2i}\\)을 훈련하는 것은 SSB 문제를 겪는다. 실제로 \\(y_{2i}\\)은 다음과 같은 중간 변수이다.\n' +
      '\n' +
      '도 3. 클릭 후 행동 분해에 기초한 제안된 사용자 순차 행동 그래프의 예시. (a) "인상\\(\\rightarrow\\)click\\(\\rightarrow\\)Scart\\(\\rightarrow\\)purchase"와 같은 클릭 후 행동을 구별한 후 인상부터 구매까지의 여러 경로. (b) 간략화된 구매 프로세스를 설명하기 위해 디그래프가 사용되며, 여기서 에지 위의 숫자는 상이한 경로의 희소성을 나타낸다. (c) 여러 특정 구매 관련 클릭 후 액션은 단일 노드, _i.e._, DAction에 병합되며, 이는 또한 그들의 감독 신호를 상속한다. Oction은 DAction을 제외한 다른 경우를 나타낸다.\n' +
      '\n' +
      '\\(p_{i}^{ctr}\\)과\\(p_{i}^{etavr}\\)은 Eq. (2). \\(p_{i}^{ctr}\\)과 \\(p_{i}^{etavr}\\)은 모든 인상 샘플을 사용하여 전체 공간에 대해 모델링되었기 때문에 파생된 \\(y_{2i}\\)도 전체 공간에 적용 가능하므로 모델에서는 SSB가 없다. 한편, 사용자의 로그에 따라 \\(p_{i}^{ctr}\\), \\(p_{i}^{etavr}\\), \\(p_{i}^{etcvr}\\)의 Ground truth 레이블을 사용할 수 있으며, 이는 이러한 하위 표적을 감독하는 데 사용될 수 있다. 따라서 직관적인 방법은 멀티 태스크 학습 프레임워크를 사용하여 동시에 모델링하는 것이다. 이를 위해 본 논문에서는 CVR 예측을 위한 새로운 심층 신경망 추천 모델인 Elaborated Entire Space Supervised Multi-task Model (\\(ESM^{2}\\))을 제안한다. \\ (ESM^{2}\\)는 1) \\(p_{i}^{ctr}\\), \\(p_{i}^{etavr}\\), \\(p_{i}^{etcvr}\\)이 전체 공간에 대해 모델링되고 모든 인상 샘플을 사용하여 예측되며, 2) Eq로부터 유도된 \\(p_{i}^{cvr}\\)이기 때문에 그 이름을 얻게 된다. (3) 또한 전체 공간 다중 작업 모델링의 이점을 얻을 수 있으며 이는 실험 부분에서 검증될 것이다. \\ (ESM^{2}\\)는 1) 공유 임베딩 모듈, 2) 분해된 예측 모듈, 3) 순차적 구성 모듈의 세 가지 핵심 모듈로 구성된다. 이를 각각 구체적으로 제시하면 다음과 같다.\n' +
      '\n' +
      '**공유 임베딩 모듈(SEM):** 먼저 사용자 필드, 항목 필드 및 사용자-항목 교차 필드에서 나오는 모든 희소 ID 기능과 조밀한 숫자 기능을 임베딩하는 공유 임베딩 모듈을 고안합니다. 사용자 기능에는 사용자 ID, 연령, 성별 및 구매 권한이 포함됩니다. 항목 기능에는 항목 ID, 가격, 과거 로그에서 누적된 CTR 및 CVR, _etc_가 포함됩니다. 사용자 항목 기능에는 항목에 대한 사용자의 과거 선호도 점수 _etc_가 포함됩니다. 조밀한 수치특징은 먼저 경계값을 기준으로 이산화한 후 원-핫 벡터로 표현한다. 여기서 우리는 \\(f_{i}=\\left\\{f_{ij},\\forall j\\in\\Lambda_{f}\\right\\}\\)을 사용하여 \\(i^{th}\\) 훈련 샘플의 원-핫 특징을 나타내며, 여기서 \\(\\Lambda_{f}\\)은 모든 종류의 특징의 인덱스 집합을 나타낸다. 원-핫 인코딩의 희소성 특성으로 인해 선형 완전 연결 레이어를 사용하여 조밀한 표현으로 임베딩하고 다음과 같이 공식화할 수 있다.\n' +
      '\n' +
      '\\[g_{ij}=P_{\\theta_{j}}^{T}f_{ij}, \\tag{5}\\]\n' +
      '\n' +
      '여기서, \\(P_{\\theta_{j}}\\)은 \\(j^{th}\\) 종류의 특징들에 대한 임베딩 행렬을 나타내고, \\(\\theta_{j}\\)은 네트워크 파라미터들을 나타낸다.\n' +
      '\n' +
      '**분해 된 예측 모듈 (DPM):** 그러면 모든 기능 임베딩이 얻어지면 함께 연결 되 고 여러 분해 된 예측 모듈에 공급 되 고 각각에 의해 공유 됩니다. DPM의 각 예측 네트워크는 경로에서 분해된 표적의 확률을 각각 "인상\\(\\rightarrow\\)click", "click\\(\\rightarrow\\)DAction", "DAction\\(\\rightarrow\\)purchase", "OAction\\(\\rightarrow\\)purchase"로 추정한다. 본 논문에서는 Multi-Layer Perception (_MLP_)를 예측 네트워크로 사용한다. 출력 계층을 제외한 모든 비선형 활성화 함수는 _ReLU_입니다. 여기서 _Sigmoid_ 함수를 사용하여 출력을 0에서 1까지의 실수 값을 취하는 확률로 매핑합니다. 수학적으로 다음과 같이 공식화할 수 있습니다.\n' +
      '\n' +
      '\\[y_{ki}=\\sigma\\left(\\varphi_{\\beta_{k}}^{k}\\left(g_{i}\\right)\\right), \\tag{6}\\]\n' +
      '\n' +
      '여기서 \\(\\sigma\\)은 _Sigmoid_ 함수를, \\(\\varphi_{\\beta_{k}}^{k}\\)은 _k번째 MLP에 의해 학습된 매핑 함수를, \\(\\beta_{k}\\)은 네트워크 매개 변수를 나타낸다. 예를 들어, 도 4의 첫 번째 _MLP_에 도시된 바와 같이, 이를 출력한다\n' +
      '\n' +
      '그림 4: 전체 공간에 대한 \\(ESM^{2}\\) 모델의 다이어그램은 SEM, DPM 및 SCM의 세 가지 핵심 모듈로 구성된다. SEM은 희박한 피쳐를 조밀한 표현에 삽입합니다. DPM은 분해된 표적의 확률을 예측한다. SCM은 이들을 순차적으로 통합하여 최종 CVR 및 기타 관련 보조 작업인 CTR, CTAVR 및 CTCVR을 계산한다.\n' +
      '\n' +
      '추정된 확률 \\(y_{1}\\)은 실제로 뷰 후 클릭율이다.\n' +
      '\n' +
      '**순차 구성 모듈 (SCM):** 마지막으로 위의 예측 된 확률을 Eq에 따라 순차적으로 구성 하는 순차 구성 모듈을 고안 합니다. (1) \\(\\sim\\) Eq. (4) 전환율 \\(p^{ctr}\\)을 산출하기 위해 후시점 클릭율 \\(p^{ctr}\\), 클릭-스루 DAction 대화율 \\(p^{ctrvar}\\), 클릭-스루 전환율 \\(p^{ctrcvr}\\)을 포함하는 보조 타겟을 각각 산출한다. 그림 4의 상단 부분에서 볼 수 있듯이 SCM은 그림 3의 구매 결정 디그래프에 의해 정의된 기본 조건부 확률을 나타내는 매개 변수가 없는 피드 포워드 신경망이다.\n' +
      '\n' +
      '**비고:** 1) 모든 작업이 동일한 임베딩을 공유하여 모든 인상 샘플로 학습되므로 _즉_ 전체 공간에 대해 모델링되어 추론 단계 동안 SSB 문제가 발생하지 않습니다. 2) 경량 DPM은 공유 임베딩 모듈에 의해 엄격하게 정규화되며, 이는 학습 가능한 매개 변수의 대부분을 구성합니다. 3) 모델은 SEM이 병렬로 실행되어 온라인 배포 시 대기 시간이 짧을 수 있는 효율적인 네트워크 설계를 제안합니다.\n' +
      '\n' +
      '### Training objective\n' +
      '\n' +
      '우리는 훈련 집합을 나타내기 위해 \\(S=\\{(c_{i},a_{i},b_{i};f_{i})\\}_{i=1}^{N}\\)을 사용하는데, 여기서 \\(c_{i}\\), \\(a_{i}\\), \\(b_{i}\\)는 \\(i번째}\\) 인상 샘플이 클릭되고 결정론적 행동을 취하여 구매되었는지 여부를 그라운드 트루스 레이블을 나타낸다. 그런 다음, 우리는 모든 트레이닝 샘플들의 공동 포스트뷰 클릭-스루 확률을 다음과 같이 정의할 수 있다:\n' +
      '\n' +
      '\\[p^{ctr}=\\prod_{i\\in C_{+}}p_{i}^{ctr}\\prod_{j\\in C_{-}}\\left(1-p_{j}^{ctr} \\right), \\tag{7}\\]\n' +
      '\n' +
      '여기서 \\(C_{+}\\) 및 \\(C_{-}\\)은 각각 레이블 공간 \\(C\\)의 양성 및 음성 샘플을 나타낸다. 식에서 음수 로그를 취한 후. (7)은 추천 시스템에서 널리 사용되는 \\(p^{ctr}\\)의 _logloss_를 구하고, _i.e._,\n' +
      '\n' +
      '\\[L_{ctr}=-\\sum_{i\\in C_{+}}logp_{i}^{ctr}-\\sum_{j\\in C_{-}}log\\left(1-p_{j}^{ ctr}\\right). \\tag{8}\\]\n' +
      '\n' +
      '마찬가지로 다음과 같이 \\(p^{ctrv}\\)와 \\(p^{ctrv}\\)의 손실함수를 구할 수 있다.\n' +
      '\n' +
      '\\[L_{ctavr}=-\\sum_{i\\in A_{+}}logp_{i}^{ctavr}-\\sum_{j\\in A_{-}}log\\left(1-p_{j}^ {ctavr}\\right), \\tag{9}\\]\n' +
      '\n' +
      'and\n' +
      '\n' +
      '\\[L_{ctevr}=-\\sum_{i\\in B_{+}}logp_{i}^{ctevr}-\\sum_{j\\in B_{-}}log\\left(1-p_{j}^ {ctevr}\\right). \\tag{10}\\]\n' +
      '\n' +
      '최소화될 최종 훈련 목표는 다음과 같이 정의된다:\n' +
      '\n' +
      '\\[L\\left(\\Theta\\right)=w_{ctr}\\times L_{ctr}+w_{ctavr}\\times L_{ctavr}+w_{ctevr} \\times L_{ctevr}, \\tag{11}\\]\n' +
      '\n' +
      '여기서, \\(\\Theta=\\left\\{\\theta_{j},\\forall j\\in\\Lambda_{f}\\right\\}\\cup\\left\\{\\theta_{i},i=1,2,3,4\\right\\}\\)은 \\(ESM\\)2의 모든 네트워크 파라미터를 나타낸다. \\(w_{ctr}\\), \\(w_{ctavr}\\), \\(w_{ctevr}\\)은 본 논문에서 각각 1로 설정한 \\(L_{ctr}\\), \\(L_{ctavr}\\), \\(L_{ctevr}\\)의 손실가중치이다.\n' +
      '\n' +
      '각주 2: 우리가 아는 한, 이 전체 공간 모델링 작업에 적합한 공개 데이터 세트가 없기 때문에 재현성 및 향후 연구를 위해 데이터 세트를 공개할 것이다.\n' +
      '\n' +
      '**설명:** 1) 분해 된 하위 작업을 감독 하기 위해 중간 손실을 추가 하면 클릭 후 행동에서 레이블이 지정 된 풍부한 데이터를 효율적으로 활용 하 여 모델이 DS 문제에 영향을 적게 받을 수 있습니다. 2) 전체 공간 모델링의 관점에서 모든 손실을 계산 하 여 SSB 문제를 효과적으로 해결 합니다.\n' +
      '\n' +
      '## 4. Experiments\n' +
      '\n' +
      '제안된 \\(ESM\\)2 모델의 효율성을 평가하기 위해 실제 전자상거래 시나리오와 온라인 배포에서 수집된 오프라인 데이터 세트에 대해 광범위한 실험을 수행했다. \\ (ESM\\)2는 GBDT(Chen et al., 2017), DNN(He et al., 2019), 과샘플링 아이디어를 사용하는 DNN(Krizhevsky et al., 2014) 및 ESMM(Krizhevsky et al., 2014)을 포함하는 몇몇 대표적인 최첨단(SOTA) 방법들과 비교된다. 먼저 데이터 세트 작성, 평가 메트릭, 이러한 SOTA 방법에 대한 간략한 설명 및 구현 세부 정보를 포함한 평가 설정을 제시한다. 그런 다음 비교 결과와 분석을 제시한다. 다음으로 절제 연구가 제시되고 다른 클릭 후 행동에 대한 성능 분석이 뒤따른다.\n' +
      '\n' +
      '각주 2: 우리가 아는 한, 이 전체 공간 모델링 작업에 적합한 공개 데이터 세트가 없기 때문에 재현성 및 향후 연구를 위해 데이터 세트를 공개할 것이다.\n' +
      '\n' +
      '### Evaluation settings\n' +
      '\n' +
      '#### 4.1.1. 데이터 세트 준비\n' +
      '\n' +
      '우리는 세계에서 가장 큰 제3자 소매 플랫폼 중 하나인 온라인 전자 상거래 플랫폼에서 사용자의 순차적 행동과 피드백 로그 1을 수집하여 오프라인 데이터 세트를 만든다. 사용자/아이템/사용자-아이템 특징 및 순차적 피드백 라벨(_e.g., 클릭 여부, 또는 DAction 여부, 또는 구매 여부)을 갖는 3억 개 이상의 인스턴스가 필터링된다. 이 오프라인 데이터 세트의 통계는 표 1에 나열되어 있다. 이들은 다시 합동 훈련 세트, 검증 세트 및 테스트 세트로 나뉜다.\n' +
      '\n' +
      '각주 1: 이 전체 공간 모델링 작업에 적합한 공개 데이터 세트가 없기 때문에 재현성 및 향후 연구를 위해 데이터 세트를 공개할 것이다.\n' +
      '\n' +
      '#### 4.1.2. 평가 메트릭\n' +
      '\n' +
      '제안된 모델의 유효성을 종합적으로 평가하고 SOTA 방법과 비교하기 위해 추천 및 광고 시스템에서 널리 사용되는 3가지 메트릭인 _i.e., Area Under Curve (AUC), GAUC (Sutton et al., 2017; Wang et al., 2018) 및 \\(F_{1}\\) 점수를 채택하며, 여기서 AUC는 랭킹 능력을 반영한다.\n' +
      '\n' +
      '\\[AUC=\\frac{1}{|S_{+}|}\\sum_{|S_{-}|}\\sum_{x^{\\prime}\\in S_{+}}\\sum_{x^{\\prime} \\in S_{-}}}I\\left(\\phi\\left(x^{+}\\right)>\\phi\\left(x^{-}\\right)\\right), \\tag{12}\\]\n' +
      '\n' +
      '여기서, \\(S_{+}\\) 및 \\(S_{-}\\)은 각각 양성/음성 샘플의 집합을 나타내고, \\(|S_{+}|\\) 및 \\(|S_{-}|\\)은 \\(S_{+}\\) 및 \\(S_{-}\\)의 샘플 수를 나타내며, \\(\\phi\\left(\\cdot\\right)\\)는 예측 함수, \\(I\\left(\\cdot\\right)\\)는 지표 함수이다.\n' +
      '\n' +
      'GAUC(Wang et al., 2018)는 다음과 같이 계산된다. 먼저, 모든 테스트 데이터는 개별 사용자 ID에 따라 서로 다른 그룹으로 분할된다. 그런 다음 AUC는 모든 단일 그룹에서 계산된다. 마지막으로 가중 AUC를 평균화한다. 수학적으로, GAUC는 다음과 같이 정의된다:\n' +
      '\n' +
      '\\[GAUC=\\frac{\\sum_{u}w_{u}\\times AUC_{u}}{\\sum_{u}w_{u}}, \\tag{13}\\]\n' +
      '\n' +
      '여기서 \\(w_{u}\\)는 사용자 \\(u\\)에 대한 가중치입니다 (오프라인 평가의 경우 1로 설정). \\ (AUC_{u}\\)는 사용자 \\(u\\)에 대한 AUC를 나타낸다.\n' +
      '\n' +
      '더욱이, \\(F_{1}\\) 점수는 다음과 같이 정의된다:\n' +
      '\n' +
      '\\[F_{1}=\\frac{2\\times P\\times R}{P+R}, \\tag{14}\\]\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l} \\hline \\hline Category & \\#User & \\#Item & \\#Impression \\\\ \\hline Number & 13,383,415 & 10,399,095 & 326,325,042 \\\\ \\hline \\hline Category & \\#Click & \\#Purchase & \\#DAction \\\\ \\hline Number & 20,637,192 & 226,918 & 2,501,776 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1. 오프라인 데이터세트의 통계.\n' +
      '\n' +
      '여기서, \\(P\\) 및 \\(R\\)은 정밀도 및 재현율을 나타내며, _i.,_:\n' +
      '\n' +
      '\\[P=\\frac{TP}{TP+FP}, \\tag{15}\\]\n' +
      '\n' +
      '\\[R=\\frac{TP}{TP+FN}, \\tag{16}\\]\n' +
      '\n' +
      '여기서 \\(TP\\), \\(FP\\) 및 \\(FN\\)은 각각 참 양성, 거짓 양성 및 거짓 음성 예측의 수를 나타낸다.\n' +
      '\n' +
      '#### 4.1.3. 비교 방법에 대한 간단한 설명\n' +
      '\n' +
      '대표적인 최첨단의 방법을 설명하면 다음과 같다.\n' +
      '\n' +
      '\\(\\bullet\\)**GBDT**(Chen et al., 2017): 그래디언트 부스팅 결정 트리(GBDT) 모델은 그래디언트 부스팅 머신(GBM)의 개념을 따르고, 경쟁적이고, 매우 견고하며, 회귀 및 분류 작업에 대한 해석 가능한 절차를 생성할 수 있다(Krizhevsky et al., 2015). 본 논문에서는 이를 비딥러닝 기반의 대표적인 방법으로 사용한다.\n' +
      '\n' +
      '\\(\\bullet\\)**DNN**(Krizhevsky et al., 2015): 또한 \\(ESM^{2}\\)에서 단일 분기와 동일한 구조와 하이퍼 파라미터를 갖는 심층 신경망 베이스라인 모델을 구현한다. \\(ESM^{2}\\)과 달리, "click\\(\\rightarrow\\)purchase" 또는 "impression\\(\\rightarrow\\)click" 경로에 있는 샘플로 학습하여 변환율 \\(p^{cvr}\\) 또는 클릭율 \\(p^{ctr}\\)을 각각 예측한다.\n' +
      '\n' +
      'DNN-OS**(Krizhevsky et al., 2015): "impression\\(\\rightarrow\\)purchase"와 "click\\(\\rightarrow\\)purchase" 경로에 대한 데이터 희소성으로 인해 일반화된 심층 신경망을 학습하기 어렵다. 이 문제를 해결 하기 위해 DNN-OS라는 심층 모델을 학습 하는 동안 양성 샘플을 보강 하기 위해 _over-sampling_ 전략을 활용 합니다. 위의 DNN 모델과 동일한 구조와 하이퍼-파라미터를 가진다.\n' +
      '\n' +
      '\\(\\bullet\\)**ESMM**(Krizhevsky et al., 2015): 공정한 비교를 위해 ESMM에 대해 위의 심층 모델과 동일한 백본 구조를 사용합니다. 구매 관련 클릭 후 행동을 고려하지 않고 사용자 순차 경로 "인상\\(\\rightarrow\\)click\\(\\rightarrow\\) 구매"에 대한 전환율을 직접 모델링한다.\n' +
      '\n' +
      '간단히 말해서, 첫 번째 세 가지 방법은 "인상\\(\\rightarrow\\)click" 및 "클릭\\(\\rightarrow\\)구매" 경로에 있는 샘플을 사용하여 \\(p^{ctr}\\) 및 \\(p^{ctr}\\)을 예측하는 방법을 각각 학습한 다음 이를 함께 곱하여 클릭스루 전환율 \\(p^{ctctr}\\)을 도출한다. ESM과 우리의 \\(ESM^{2}\\)은 공간 전체를 모델링하여 \\(p^{ctctr}\\)과 \\(p^{ctr}\\)을 직접 예측한다.\n' +
      '\n' +
      '#### 4.1.4. Hyper-parameters 설정\n' +
      '\n' +
      'GBDT 모델의 경우 트리 수, 깊이, 노드를 분할하기 위한 최소 인스턴스 수, 각 반복에 대한 훈련 세트의 샘플링 비율, 각 반복에 대한 특징의 샘플링 비율 및 손실 함수의 유형을 각각 150, 8, 20, 0.6, 0.6 및 _로지스틱 손실_로 설정하며, 이는 검증 세트의 AUC 점수에 따라 선택된다. 딥 뉴럴 네트워크 기반 모델의 경우, Adam optimizer를 사용하여 TensorFlow에서 구현된다. 학습률은 0.0005로 설정되고 미니 배치 크기는 1000으로 설정된다. 로지스틱 손실은 모든 모델에서 각 예측 작업에 대한 손실 함수로 사용된다. _MLP_에는 5개의 레이어가 있으며, 여기서 각 레이어의 차원은 표 2에 요약된 대로 각각 512, 256, 128, 32 및 2로 설정된다.\n' +
      '\n' +
      '### Main results\n' +
      '\n' +
      '#### 4.2.1. 오프라인 데이터 세트 비교\n' +
      '\n' +
      '이 하위 섹션에서는 오프라인 테스트 세트에 있는 모든 경쟁자의 AUC, GAUC 및 \\(F_{1}\\) 점수를 보고한다. 표 3은 AUC 및 GAUC 결과를 요약한 것이다. DNN 방법은 기준선 GBDT 모델에 비해 CVR AUC, CTCVR AUC 및 CTCVR GAUC에 대해 각각 0.0242, 0.0102, 0.0117의 이득을 달성함을 알 수 있다. 심층 신경망의 강력한 표현 능력을 보여줍니다. 바닐라 DNN과 달리 DNN-OS는 DS 문제를 해결하기 위해 오버 샘플링 전략을 사용하여 DNN보다 더 나은 성능을 달성한다. ESMM은 SSB와 DS 문제를 동시에 해결하기 위해 "impression\\(\\rightarrow\\)click\\(\\rightarrow\\)purchase" 경로를 모델로 한다. 전체 공간과 풍부한 훈련 샘플에 대한 모델링의 이점을 통해 DNN-OS보다 성능이 우수하다. 그럼에도 불구하고, ESMM은 제안된 \\(ESM^{2}\\)에 의해 추가로 이용되면서 클릭 후 행동의 영향을 무시하면서 희귀한 구매 훈련 샘플로 인해 DS 문제를 해결하기 위해 여전히 어려움을 겪고 있다. 다중 태스크 학습 프레임워크 하에서 병렬로 분해된 일부 서브 타겟을 예측한 후, \\(ESM^{2}\\)은 이들을 순차적으로 구성하여 최종 CVR을 공식화한다. 모든 방법 중에서 가장 좋은 점수를 얻고 있음을 알 수 있다. 예를 들어, ESMM에 대한 이득은 CVR AUC, CTCVR AUC 및 CTCVR GAUC에 대해 각각 0.0088, 0.0101, 0.0145이다. 오프라인 AUC에서 0.01의 이득은 항상 온라인 RS에 대한 수익의 상당한 증가를 의미한다는 것을 언급할 가치가 있다(Krizhevsky et al., 2015; Krizhevsky et al., 2015).\n' +
      '\n' +
      '\\(F_{1}\\) 점수는 CVR과 CTCVR에 대해 각각 다른 임계값을 설정하여 여러 값을 보고한다. 먼저, 예측된 CVR 또는 CTCVR 점수에 따라 모든 인스턴스를 내림차순으로 정렬한다. 그런 다음 CVR 태스크의 희소성(예측 샘플의 약 1%가 양수)으로 인해 top@0.1%, top@0.6% 및 top@1%의 세 가지 임계값을 선택하여 예측을 그에 따라 양성 그룹과 음성 그룹으로 나눈다. 마지막으로, 이러한 다른 임계값에서 이러한 예측의 정밀도, 재현율 및 \\(F_{1}\\) 점수를 계산한다. 결과는 표 4 및 표 5에 요약되어 있다. 표 3과 유사한 경향을 관찰할 수 있다. 다시 한번, 제안된 방법 \\(ESM^{2}\\)은 다른 설정에서 최상의 성능을 달성한다.\n' +
      '\n' +
      '#### 4.2.2. 온라인 배포 비교\n' +
      '\n' +
      '매일 수억 명의 사용자 (예: 트래픽 피크에서 초당 1억 명 이상의 사용자)를 서버 하기 때문에 심층 네트워크 모델을 추천 시스템에 배포 하는 것은 쉬운 작업이 아닙니다. 따라서,\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c} \\hline \\hline Hyper-parameter & Choice \\\\ \\hline Loss function & Logistic Loss \\\\ Optimizer & Adam \\\\ Number of layers in MLP & 5 \\\\ Dimensions of layers in MLP & [512,256,128,32,2] \\\\ Batch size & 1000 \\\\ Learning rate & 0.0005 \\\\ Dropout ratio & 0.5 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2. DNN, DNN-OS, ESMM 및 \\(ESM^{2}\\)을 포함하는 심층 신경망 기반 모델의 하이퍼-파라미터.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c} \\hline \\hline Method & CVR AUC & CTCVR AUC & CTCVR GAUC \\\\ \\hline GBDT & 0.7823 & 0.8059 & 0.7747 \\\\ \\hline DNN & 0.8065 & 0.8161 & 0.7864 \\\\ \\hline DNN-OS & 0.8124 & 0.8192 & 0.7893 \\\\ \\hline ESMM & 0.8398 & 0.8270 & 0.7906 \\\\ \\hline \\(ESM^{2}\\) & **0.8486** & **0.8371** & **0.8051** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3. 모든 방법의 AUC 및 GAUC 점수.\n' +
      '\n' +
      '높은 처리량과 낮은 대기 시간으로 실시간 CVR 예측을 하기 위해서는 실용적인 모델이 필요하다. 예를 들어, 각 방문자에 대한 수백 개의 추천 아이템이 우리 시스템에서 100 밀리초 미만으로 예측되어야 한다. 병렬 네트워크 구조 덕분에, 우리의 모델은 계산적으로 효율적이며 20 밀리초 이내에 각 온라인 요청에 응답할 수 있다. 온라인 평가를 공정하고 자신감 있고 비교할 수 있도록 A/B 테스트를 위해 배포된 각 방법에는 동일한 수의 사용자, 즉 수백만 명의 사용자가 포함되었다. 결과는 GBDT 모델을 기준선으로 사용하는 그림 5에 나열되어 있다. 알 수 있는 바와 같이, DNN, DNN-OS 및 ESMM은 비교 가능한 성능을 달성하고 베이스라인 모델을 상당히 능가하는 반면, ESMM은 약간 더 나은 성능을 수행한다. 제안된 방법은 \\(ESM^{2}\\)과 위의 방법들 사이의 상당한 마진이 우월함을 보여준다. 또한 ESMM에 비해 3%의 CVR 프로모션에 기여하여 e-commercial 플랫폼에 상당한 비즈니스 가치를 나타낸다.\n' +
      '\n' +
      '**비고:** 1) 심층 신경망은 의사 결정 트리 기반 GBDT보다 더 강한 표현 능력을 가지고 있다. 2) 전체 샘플 공간에 대한 다중 작업 학습 프레임워크는 SSB 및 DS 문제를 해결하는 효율적인 도구 역할을 한다. 3) 클릭 후 행동 분해 개념을 기반으로 \\(ESM^{2}\\) 전체 공간에 대한 CVR 모델링 및 결정론적 행동의 풍부한 감독 신호를 활용하여 SSB 및 DS 문제를 효율적으로 해결하고 최상의 성능을 달성한다.\n' +
      '\n' +
      '### Ablation studies\n' +
      '\n' +
      '이 부분에서는 심층 신경망의 하이퍼 매개변수 설정, 조밀한 수치 피쳐 임베딩의 효과 및 클릭 후 행동을 분해하는 선택을 포함한 자세한 절제 연구를 각각 제시한다.\n' +
      '\n' +
      '#### 4.3.1. Hyper-parameters of deep neural network\n' +
      '\n' +
      '여기서 우리는 \\(ESM^{2}\\) 모델에서 매개변수 선택 과정을 설명하기 위해 _dropout ratio, hidden layer의 수_ 및 _항목 특징 임베딩의 차원_이라는 세 가지 중요한 매개변수를 예로 든다.\n' +
      '\n' +
      '드롭아웃(Krizhevsky 등, 2012)은 트레이닝 동안 일부 신경 노드들을 랜덤하게 비활성화시킴으로써 정규화하는 기법을 지칭한다. 랜덤성을 도입하여 심층 신경망의 일반화를 높일 수 있다. 우리는 우리 모델에서 탈락 비율의 0.2에서 0.7까지 다양한 선택을 시도한다. 그림 6(a)와 같이 탈락률 0.5가 가장 좋은 성능으로 이어진다. 따라서 지정되지 않은 경우 모든 실험에서 0.5로 설정했다.\n' +
      '\n' +
      '네트워크 도면층의 깊이를 증가시키면 모형 용량을 향상시킬 수 있지만 잠재적으로 과적합으로 이어질 수도 있습니다. 따라서 검증 세트의 AUC 점수에 따라 이 하이퍼 매개 변수를 신중하게 설정했다. 그림 6(b)에서 알 수 있듯이, 시작 단계인 _i.e._에서는 2개 레이어에서 5개 레이어로 은닉 레이어 수를 늘리면 모델의 성능이 일관되게 향상된다. 그러나 5개의 계층에서 포화되어 더 많은 계층을 증가시키면 AUC 점수가 약간 감소하므로 모델이 훈련 세트를 과도하게 맞출 수 있다. 따라서 우리는 지정되지 않은 경우 모든 실험에서 5개의 은닉층을 사용한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c|c c c|c c c} \\hline  & \\multicolumn{3}{c|}{CVR@top0.1\\%} & \\multicolumn{3}{c|}{CVR@top0.6\\%} & \\multicolumn{3}{c}{CVR@top1\\%} \\\\ \\hline Method & Recall & Precision & F1-Score & Recall & Precision & F1-Score & Recall & Precision & F1-Score \\\\ \\hline GBDT & 4.382\\% & 14.348\\% & 6.714\\% & 16.328\\% & 9.894\\% & 12.322\\% & 27.384\\% & 7.384\\% & 11.631\\% \\\\ \\hline DNN & 4.938\\% & 15.117\\% & 7.445\\% & 17.150\\% & 10.495\\% & 13.021\\% & 28.481\\% & 8.196\\% & 12.729\\% \\\\ \\hline DNN-OS & 5.383\\% & 15.837\\% & 8.034\\% & 17.381\\% & 10.839\\% & 13.353\\% & 29.032\\% & 8.423\\% & 13.058\\% \\\\ \\hline ESMM & 5.813\\% & 16.295\\% & 8.570\\% & 18.585\\% & 11.577\\% & 14.267\\% & 29.789\\% & 8.961\\% & 13.777\\% \\\\ \\hline \\(ESM^{2}\\) & **6.117\\%** & **17.145\\%** & **9.017\\%** & **23.492\\%** & **10.574\\%** & **14.584\\%** & **30.032\\%** & **9.034\\%** & **13.890\\%** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4. CVR에 대한 모든 방법의 Precision, Recall 및 \\(F_{1}\\) 점수.\n' +
      '\n' +
      '그림 5. 추천 시스템에 다른 모델을 배치하여 CVR에 대한 A/B 테스트 결과.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c c c|c c c|c c c} \\hline  & \\multicolumn{3}{c|}{CTCVR@top0.1\\%} & \\multicolumn{3}{c|}{CTCVR@top0.6\\%} & \\multicolumn{3}{c}{CTCVR@top1\\%} \\\\ \\hline Method & Recall & Precision & F1-Score & Recall & Precision & F1-Score & Recall & Precision & F1-Score \\\\ \\hline GBDT & 2.937\\% & 0.701\\% & 1.132\\% & 4.870\\% & 0.649\\% & 1.145\\% & 8.894\\% & 0.531\\% & 1.002\\% \\\\ \\hline DNN & 3.168\\% & 0.851\\% & 1.341\\% & 5.269\\% & 0.768\\% & 1.340\\% & 9.461\\% & 0.643\\% & 1.204\\% \\\\ \\hline DNN-OS & 3.382\\% & 0.871\\% & 1.385\\% & 5.369\\% & 0.801\\% & 1.395\\% & 9.863\\% & 0.673\\% & 1.260\\% \\\\ \\hline ESMM & 3.858\\% & 0.915\\% & 1.479\\% & 5.504\\% & 0.828\\% & 1.439\\% & 10.088\\% & 0.691\\% & 1.294\\% \\\\ \\hline \\(ESM^{2}\\) & **4.219\\%** & **1.001\\%** & **1.618\\%** & **5.987\\%** & **0.900\\%** & **1.566\\%** & **10.991\\%** & **0.753\\%** & **1.410\\%** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5. CTCVR에 대한 모든 방법의 Precision, Recall 및 \\(F_{1}\\) 점수.\n' +
      '\n' +
      '항목 특징 임베딩의 차원은 고차원 특징들이 더 많은 정보를 보유하지만 잡음을 포함하고 더 높은 모델 복잡성으로 이어지는 중요한 매개변수이다. 우리는 매개변수의 다른 설정을 시도하고 결과를 그림 6(c)에 표시한다. 알 수 있는 바와 같이, 차원을 증가시키는 것은 일반적으로 성능을 향상시킨다. 그것은 마침내 128로 포화되지만, 그것을 두 배로 늘리면 더 이상 이득이 없다. 따라서 모델 용량과 복잡도 사이의 trade-off를 만들기 위해 특정되지 않은 경우 모든 실험에서 항목 특징 임베딩의 차원을 128로 설정했다.\n' +
      '\n' +
      '#### 4.3.2. 밀집 수치 특징 임베딩의 효과\n' +
      '\n' +
      '우리의 작업에는 몇 가지 숫자 기능이 있습니다. 일반적인 관례는 먼저 원-핫 벡터로 이산화한 다음 ID 특징과 함께 연결하여 섹션 3.3에 설명된 대로 선형 투영 레이어를 통해 조밀한 특징으로 임베딩하는 것이다. 그러나 수치 특징의 원-핫 벡터 표현이 이산화 동안 정밀도를 저하시킬 수 있다고 가정한다. 대조적으로, 우리는 수치 특징들을 정규화하고 Tanh 활성화 함수, _i.e._를 사용하여 그것들을 임베딩함으로써 다른 해를 시도한다,\n' +
      '\n' +
      '\\[g_{ij}=\\tanh\\left(\\frac{f_{ij}-\\mu_{fj}}{\\sigma_{f_{j}}}\\right), \\tag{17}\\]\n' +
      '\n' +
      '여기서 \\(\\mu_{fj}\\)와 \\(\\sigma_{fj}\\)은 \\(j^{th}\\) 종류의 특징의 평균과 표준편차를 나타낸다. 그리고, 임베딩된 특징들을 ID 특징들과 함께 ESM^{2}\\ 모델의 입력으로 연결한다. 이산화 기반 방법에 비해 0.004 AUC의 이득을 달성한다. 따라서 특정되지 않은 경우 모든 실험에서 조밀한 수치 특징을 정규화 기반 임베딩 방법을 사용한다.\n' +
      '\n' +
      '#### 4.3.3. 클릭 후 행위 분해 효과\n' +
      '\n' +
      '클릭 후 동작을 분해할 때 다른 동작을 DAction 노드 _예:_, Scart만, Only Wish 또는 Scart와 Wish(SCart와 Wish) 모두에 통합할 수 있습니다. 여기서는 다양한 선택의 효과를 평가한다. 결과는 표 6에 요약되어 있다. 알 수 있는 바와 같이, Scart와 Wish의 조합은 최상의 AUC 점수를 달성한다. DS 문제를 해결하기 위해 다른 두 사례보다 구매 관련 라벨 데이터가 더 많기 때문에 합리적이다.\n' +
      '\n' +
      '### 사용자 행위 성능 분석\n' +
      '\n' +
      '본 연구에서는 ESMM과 \\(ESM^{2}\\)의 성능 및 그 차이를 이해하기 위해, 사용자의 구매 행동 수 _i.e._, [0,10], [11,20], [21,50], [50,+]에 따라 4개의 그룹으로 나누어 각 그룹에서 CVR과 CTCVR의 AUC 점수를 보고하고, 그 결과를 그림 7에 나타내었다. 두 방법의 CVR AUC(CTCVR AUC)는 구매 행동 수가 증가함에 따라 감소한다. 그러나 각 그룹에서 ESMM에 비해 \\(ESM^{2}\\)의 상대적 이득은 _i.e._, 0.72%, 0.81%, 1.13%, 1.30% 증가하는 것을 관찰할 수 있다. 일반적으로 구매 행동이 많은 사용자는 항상 Scart와 Wish와 같은 적극적인 클릭 후 행동을 가지고 있다. \\(ESM^{2}\\) 모델은 사용자의 피드백에 의해 감독되는 DAction 노드를 추가하여 이러한 클릭 후 행동을 다룬다. 따라서 ESMM보다 더 나은 표현 능력을 가지며, 구매 빈도가 높은 사용자들에게 더 나은 성능을 달성한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c} \\hline  & CVR AUC & CTCVR AUC & CTCVR GAUC \\\\ \\hline SCart & 0.8457 & 0.8359 & 0.7996 \\\\ \\hline Wish & 0.8403 & 0.8319 & 0.7962 \\\\ \\hline SCart and Wish & **0.8486** & **0.8371** & **0.8051** \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6. 클릭 후 행동에 대한 선택 결과.\n' +
      '\n' +
      '그림 6. \\(ESM^{2}\\)에서 서로 다른 하이퍼 파라미터 설정의 결과.\n' +
      '\n' +
      '그림 7. ESMM과 \\(ESM^{2}\\)에 대한 CVR과 CTCVR의 AUC 점수는 구매 행동 수에 따라 다른 그룹에서 나타났다. 섹션 4.4를 참조하십시오.\n' +
      '\n' +
      '## 5. Conclusion\n' +
      '\n' +
      '본 논문에서는 전자상거래 추천 시스템의 맥락에서 CVR 태스크를 모델링하기 위한 클릭 후 행동 분해의 새로운 아이디어를 소개한다. 사용자 순차 행동 그래프 "impression\\(\\rightarrow\\)click\\(\\rightarrow\\)D(O)Action\\(\\rightarrow\\)purchase"를 구성하여 전체 공간에 대한 CVR을 모델링한다. 조건부 확률 규칙을 기반으로 그래프의 명시적 하위 경로에 정의된 사후 뷰 클릭율, 클릭 스루 대화율, 클릭 스루 변환율을 포함한 CVR과 관련된 보조 작업을 네 개의 숨겨진 확률 변수로 분리한다. 결과적으로, 본 논문에서는 CVR과 관련된 보조 태스크를 동시에 예측하기 위해 다중 태스크 학습 프레임워크를 사용하여 \\(ESM^{2}\\)이라는 새로운 심층 신경망 추천 모델을 제안한다. 모든 인상 샘플로 훈련하고 결정론적 클릭 후 행동의 풍부한 레이블을 활용함으로써, 우리의 \\(ESM^{2}\\) 모델은 SSB 및 DS 문제를 효율적으로 해결한다. 오프라인 및 온라인 환경에 대한 광범위한 실험은 최신 모델보다 \\(ESM^{2}\\)의 우수성을 보여준다.\n' +
      '\n' +
      '## Acknowledgment\n' +
      '\n' +
      '이 작업은 보조금 61806062에 따라 중국 국립 자연 과학 재단(NSFC)에 의해 부분적으로 지원되었다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* (1)\n' +
      '* Chen 등(2019) Qiwei Chen, Huan Zhao, Wei Li, Pipei Huang, and Wenwu Ou. 2019. Behavior Sequence Transformer for E-commerce Recommendation in Alibaba. _ arXiv preprint arXiv:1905.06874_ (2019).\n' +
      '* Dupret and Piwowarski (2008) Georges E Dupret and Benjamin Piwowarski. 2008. user browsing model to predict search engine click data from past observations.. 《제31회 연례 국제 ACM SIGIR 회의의 정보 검색 연구 및 개발에 관한 회보》에서. ACM, 331-338.\n' +
      '* Effendi and Ali (2017) Muhammad Junaid Effendi and Syed Abbas Ali. 2017. Click Through rate prediction for contextual advertisement using linear regression. _ arXiv preprint arXiv:1701.08744_ (2017).\n' +
      '* Feng 등(2019) Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, and Keping Yang. 2019. Deep Session Interest Network for Click-Through Rate Prediction. _ arXiv preprint arXiv:1905.06482_ (2019).\n' +
      '* 프리드먼(2001) Jeromeo F F Friedman. 2001. Greedy function approximation: gradient boosting machine. _ Annals of statistics_ (2001), 1189-1232.\n' +
      '* 가오 등(2019) Chen Gao, Xiangnan He, Lushan Gan, Xiangming Chen, Fuli Feng, Yong Li, Tat-Seng Chua, and Dempeng Jin. 2019. Multi-Behavior Data로부터 Neural Multi-Task Recommendation. _2019 IEEE 35th International Conference on Data Engineering (ICDE)_에서. IEEE, 1554-1557.\n' +
      '* Golbeck et al. (2006) Jennifer Golbeck, James Hendler, et al. 2006. Flumtrest: Movie recommendations using trust in web-based social networks. _Proceedings of the IEEE Consumer communications and networking conference_, Vol. 96. Citeseer, 282-286.\n' +
      '* Graepel 등(2010) Thorne Graepel, Joquinquino Candela, Thomas Borchert, and Ralf Herbrich. 2010. Web-scale bayesian click-through rate prediction for sponsor search advertising in microsoft\'s bing search engine. 옴니프레스\n' +
      '* Graves et al. (2013) Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent neural networks. <2013 IEEE International conference on acoustics, speech and signal processing>에서. IEEE, 6645-6649.\n' +
      '* Guo 등(2017) Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization machine based neural network for CTR prediction. _ arXiv preprint arXiv:1703.04247_ (2017).\n' +
      '* Hadah et al. (2018) Guy Hadah, Oren Ser Shalom, and Rita Osadley. 2018. Rank and Rate: multi-task learning for recommender systems. <제12회 ACM 컨퍼런스 on Recommender Systems>의 Proceedings_. ACM, 451-454.\n' +
      '* Hanfeijn Pan et al. (2014) Xinran He, Junfeng Pan, Qu Jin, Tianbing Xu, Bo Li, Tao Xu, Yanxin Shi, Antoine Allahah, Ralf Herbrich, Stuart Bowers, et al. 2014. Practical lessons from predict click on advertising at facebook. <온라인 광고를 위한 데이터 마이닝에 관한 제8 국제 워크숍의 진행>에서. ACM, 1-9\n' +
      '* Hinton 등(2006) Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. 2006. A fast learning algorithm for deep belief nets. _ Neural computation_18, 7(2006), 1527-1554.\n' +
      '* Krizhevsky 등(2012) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. [신경 정보 처리 시스템의 발전]에 있습니다. 1097-1105.\n' +
      '* Lee et al. (2012) Kuang-chih Lee, Burkay Orten, Ali Dasdan, and Wentong Li. 2012. Estimating conversion rate in display advertising from past performance data. _Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining_. ACM, 768-776.\n' +
      '* Lin 등(2017) Quan Lin, Shengpan Pan, Liang Wang, Junwei Pan, Fengdan Wan, and Hongxia Yang. 2017. A practical framework of conversion rate prediction for online display advertising. _Proceedings of the ADKDD\'17_. 119\n' +
      '* Lv 등(2019) Fuyu Lv, Taiwei Jin, Changlong Yu, Fei Sun, Quan Lin, Keping Yang, and Wilfred Ng. 2019. SDM: Sequential deep matching model for online large-scale recommender system. 「제28회 ACM 국제 정보 및 지식 관리에 관한 회의의 진행례」에 기재되어 있다. 2635-2643.\n' +
      '* Ma 등(2018) Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jili Chen, Lichan Hong, and Ed H Chi. 2018. Multi-gate mixture-of-experts를 이용한 Multi-task learning에서의 태스크 관계 모델링. _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. ACM, 1930-1939년\n' +
      '* Ma 등(2018) Xiao Ma, Lijin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Ultra space multi-task model: Post-click conversion rate를 추정하는 효과적인 접근 방법. _The 43th International ACM SIGIR Conference on Research & Development in Information Retrieval_에서. ACM, 1137-1140.\n' +
      '* Navinduramers 등(2011) Jeff Narinduramers, Mehmet Hadi Gunes, and subsibul J Louis. 2011. Friend recommendations in social network using genetic algorithm and network topology. _2011 IEEE Congress of Evolutionary Computation (CEC)_에서. 2207-2214.\n' +
      '* Wan 등(2018) Yabe Ni, Dan Ou, Shichei Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Precise your users in depth: Learning universal user representation from multiple e-commerce tasks. _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. ACM, 506-605.\n' +
      '*Pan 등(2008) Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Lin, Rajan Lakose, Martin Scholz, and Qiang Yang. 2008. One-class collaborative filtering. _2008 Eighth IEEE International Conference on Data Mining_에서. IEEE, 502-511.\n' +
      '* Qu 등(2016) Yanruru Qu, Han Cai, Kan Ren, Weihang Zhang, Tong, Ying Wen, and Jun Wang. 2016. Product-based neural network for user response prediction. 2016 IEEE 16th International Conference on Data Mining(ICDD)_에서. IEEE, 1149-1154.\n' +
      '* Shen 등(2014) Yejong Shen, Xiaodong Li, Jianfeng Gao, Li Deng, and Greg Greggirensell. 2014. A latent semantic model with convolutional-pooling structure for information retrieval. 「정보 및 지식 관리에 관한 회의에 관한 제25차 ACM 국제 회의의 진행」에 기재되어 있다. ACM, 101-110.\n' +
      '* Srivastava 등(2014) Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: 신경망이 과적합되는 것을 방지하는 간단한 방법. _ The Journal of Machine Learning research_15, 1(2014), 1929-1958.\n' +
      '* Sun 등(2019) Fei Sun, Jun Liu, Jian Wu, Changua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4ke: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. _ arXiv preprint arXiv:1904.06690_ (2019).\n' +
      '* Weiss(2004) Gary M Weiss. 2004. Mining with rarity: a unifying framework. _ ACM Sigkdd Explorations Newsletter 6_, 1(2004), 7-19.\n' +
      '* Wen 등(2019) Hong Wen, Jing Zhang, Quan Lin, Keping Yang, and Pipei Huang. 2019. Multi-Level Deep Cascade Trees for Conversion Rate Prediction in Recommendation System. "인공지능에 관한 AAAI 회의의 진행"에서요.\n' +
      '* Xiao 등(2017) Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. 2017. Attentional factorization machines: attention network를 통한 feature interaction의 가중치를 학습. _ arXiv preprint arXiv:1708.04641_ (2017).\n' +
      '* Yang et al.(2016) Hongxia Yang, Quan Lu, Angus Xianen Qiu, and Chun Han. 2016. Large scale cvr prediction through dynamic transfer learning of global and local features. 빅데이터, 스트림 및 이기종 소스 마이닝: 알고리즘, 시스템, 프로그래밍 모델 및 응용 프로그램_에서의 워크샵. 103-119.\n' +
      '* Zadroznyny (2004) Bianca Zadroznyny. 2004. Learning and evaluation classifier under sample selection bias. _Machine Learning에 대한 국제 회의 진행률_ 에서입니다.\n' +
      '* Zhang et al.(2016) Weinan Zhang, Tianxiong Zhou, Jun Wang, Jan Xu. 2016. Bid-aware gradient descent for unbiased learning with censored data in display advertising. _Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining_. ACM, 665-674.\n' +
      '* Zhang 등(2014) Yuyu Zhang, Hanjun Dai, Chang Xu, Jun Feng, Taiifeng Wang, Jiang Bian, Wang, and Tie-Yan Liu. 2014. Sequential click prediction for sponsor search with recurrent neural networks. 인공지능에 관한 AAAI 회의에서요.\n' +
      '* Zhou 등(2019) Guorui Zhou, Na Mon, Ying Fan Qi, Weiqing Bian, Chang Zhao, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. "인공지능에 관한 AAAI 회의의 진행"에서요.\n' +
      '* Zhou 등(2018) Guorui Zhou, Xiaoqiang Zhu, Chenux Song, Ting Fan, Han Zhu, Xiao Ma, Yanjun Yan, Junqi Jin, and Kun Gai. 2018. Deep interest network for click-through rate prediction. _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. ACM, 1059-1068.\n' +
      '* Zhu 등(2017) Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Min Zeng, Han Li, and Kun Gai. 2017. Hook Display 광고에서 클릭당 최적화된 비용. 「제23차 ACM SIGKDD 국제 지식 검색 및 데이터 마이닝 회의의 진행례」에 기재되어 있다.\n' +
      '* Zhu 등(2018) Han Zhu, Xiang Li, Pengeye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning Tree-based Deep Model for Recommender Systems. _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. ACM, 1079-1088.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>