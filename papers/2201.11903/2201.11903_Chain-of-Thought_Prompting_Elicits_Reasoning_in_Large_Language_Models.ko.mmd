# Chain-of-Thought Prompting Elicits 추론

대형 언어 모델

 제이슨웨이

Xuezhi Wang

Dale Schuurmans

Maarten Bosma

Brian Ichter

Fei Xia

에드치

Quoc V. LeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLeLe

Denny Zhou

구글 리서치 브레인팀

{jasonwei,denmyzhou}@google.com

###### Abstract

우리는 일련의 중간 추론 단계인 생각의 사슬을 생성하는 것이 복잡한 추론을 수행하는 대형 언어 모델의 능력을 크게 향상시키는 방법을 탐구한다. 특히, 우리는 그러한 추론 능력이 프롬프트의 예시로서 몇 가지 일련의 사고 시연이 제공되는 _생각의 연쇄 프롬프트_라는 간단한 방법을 통해 충분히 큰 언어 모델에서 자연스럽게 어떻게 나타나는지 보여준다.

세 가지 큰 언어 모델에 대한 실험은 연쇄 사고 프롬프트가 산술, 상식 및 기호 추론 과제의 범위에서 성능을 향상시킨다는 것을 보여준다. 경험적 이득은 두드러질 수 있다. 예를 들어, 8개의 연쇄 사상 예시만 있는 PaLM 540B를 프롬프트하면 수학 단어 문제의 GSM8K 벤치마크에서 최첨단 정확도를 달성하여 검증기로 미세 조정된 GPT-3조차도 능가한다.

그림 1: 사고 사슬 프롬프팅은 큰 언어 모델이 복잡한 산술, 상식 및 기호 추론 작업을 해결할 수 있도록 한다. 생각의 사슬 추론 과정이 강조됩니다.

Introduction

NLP 경관은 최근 언어 모델에 의해 혁명을 일으켰다(Peters et al., 2018; Devlin et al., 2019; Brown et al., 2020, _inter alia_). 언어 모델의 크기를 스케일링하는 것은 향상된 성능 및 샘플 효율과 같은 다양한 이점을 부여하는 것으로 나타났다(Kaplan et al., 2020; Brown et al., 2020, _inter alia_). 그러나, 모델 크기를 스케일링하는 것만으로는 산술, 상식, 기호 추론과 같은 도전 과제에 대한 높은 성능을 달성하기에 충분하다는 것이 입증되지 않았다(Rae et al., 2021).

이 연구는 두 가지 아이디어에 의해 동기화된 간단한 방법으로 대형 언어 모델의 추론 능력이 어떻게 해제될 수 있는지 탐구한다. 첫째, 산술추론을 위한 기법은 최종 답으로 이어지는 자연어적 근거를 생성함으로써 이익을 얻을 수 있다. 이전 작업은 자연어 대신에 형식 언어를 사용하는 신경-기호 방법에 더하여, 처음부터 훈련(Ling et al., 2017)하거나 사전 훈련된 모델을 피니튜닝(Cobbe et al., 2021)함으로써 자연어 중간 단계를 생성하는 능력을 모델에 부여하였다(Roy and Roth, 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). 둘째, 대규모 언어 모델은 _prompting_을 통해 문맥 내 소수의 샷 학습에 대한 흥미로운 전망을 제공한다. 즉, 각각의 새로운 태스크에 대해 별도의 언어 모델 체크포인트를 피니튜닝하는 대신에, 태스크를 입증하는 몇 개의 입력-출력 예시들로 모델을 간단히 "프롬프트"할 수 있다. 놀랍게도, 이것은 다양한 간단한 질문-응답 태스크들에 대해 성공적이었다(Brown et al., 2020).

그러나 위의 두 가지 아이디어 모두 핵심적인 한계를 가지고 있다. 합리화 훈련 및 피니튜닝 방법의 경우, 일반 기계 학습에서 사용되는 단순한 입력-출력 쌍보다 훨씬 더 복잡한 고품질 합리화 세트를 생성하는 데 비용이 많이 든다. Brown 등(2020)에서 사용되는 전통적인 few-shot 프롬프트 방법의 경우, 추론 능력이 요구되는 태스크에서 제대로 작동하지 않으며, 종종 언어 모델 스케일의 증가와 함께 실질적으로 개선되지 않는다(Rae 등, 2021). 본 논문에서는 이러한 두 가지 아이디어의 장점을 그 한계를 회피하는 방식으로 결합한다. 구체적으로, 추론 태스크를 위한 소수의 샷 프롬프팅을 수행하는 언어 모델의 능력을 탐구한다. 생각의 체인_은 최종 출력으로 이어지는 일련의 중간 자연어 추론 단계이며, 이 접근 방식을 _생각의 체인 프롬프트_라고 합니다. 예제 프롬프트가 그림 1에 나와 있습니다.

우리는 산술적, 상식적, 상징적 추론 벤치마크에 대한 경험적 평가를 제시하며, 연쇄 사고 프롬프팅이 때때로 현저한 정도로 표준 프롬프팅보다 우수함을 보여준다. 도 2는 수학 단어 문제의 GSM8K 벤치마크(Cobbe 등, 2021)에서, PaLM 540B를 사용한 체인-오브-사상 프롬프팅이 큰 마진만큼 표준 프롬프팅보다 성능이 우수하고 새로운 최첨단 성능을 달성한다는 하나의 그러한 결과를 예시한다. 대규모 트레이닝 데이터세트를 필요로 하지 않고 단일 모델 체크포인트가 일반성의 손실 없이 많은 작업을 수행할 수 있기 때문에 프롬프트만 접근하는 것이 중요하다. 이 작업은 작업에 대 한 자연어 데이터를 사용 하 여 몇 가지 예제를 통해 대규모 언어 모델이 학습 하는 방법을 강조 합니다 (c.f. 대규모 학습 데이터 세트를 통해 기본 입력 및 출력 패턴을 자동으로 학습).

## 2 Chain-of-Thought Prompting

다단계 수학 단어 문제와 같은 복잡한 추론 과제를 해결할 때 자신의 사고 과정을 고려한다. 문제를 중간 단계로 분해하고 최종 답을 내리기 전에 각각 해결하는 것이 일반적이다. _"제인이 어머니에게 꽃을 2송이 준 후 10송이를 아버지에게 3송이를 준 후 7송이를 받게 되므로 답은 7송이 된다."_ 이 논문의 목표는 문제에 대한 최종 답으로 이어지는 일관성 있는 일련의 중간 추론 단계인 유사한 _사고 사슬_을 생성할 수 있는 능력을 언어 모델에 부여하는 것이다. 우리는 충분히 큰 것을 보여줄 것이다.

그림 2: PaLM 540B는 수학 단어 문제의 GSM8K 벤치마크에서 새로운 최첨단 성능을 달성하기 위해 연쇄 사고를 사용한다. Finetuned GPT-3 및 선행 최선은 Cobbe 등(2021)의 것이다.

언어 모델은 몇 개의 샷 프롬프팅에 대한 예시에서 연쇄 사고 추론의 시연이 제공되면 사고의 연쇄를 생성할 수 있다.

그림 1은 그렇지 않았다면 잘못되었을 수학 단어 문제를 해결하기 위해 사상의 사슬을 생성하는 모델의 예를 보여준다. 이 경우의 생각의 체인은 해답과 유사하고 하나로 해석될 수 있지만, 우리는 그것이 해답에 도달하기 위한 단계적인 생각 프로세스를 모방한다는 생각을 더 잘 포착하기 위해 생각의 체인이라고 부르기로 여전히 선택한다(그리고 또한, 해/설명들은 전형적으로 최종 해답 이후에 온다(Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al., 2022, inter alia_).

의사결정 프롬프트는 언어 모델에서 추론을 용이하게 하기 위한 접근법으로서 몇 가지 매력적인 속성을 가지고 있다.

1. 먼저, 사고 사슬은 원칙적으로 모델들이 다단계 문제들을 중간 단계들로 분해할 수 있게 하며, 이는 더 많은 추론 단계들을 필요로 하는 문제들에 추가적인 계산이 할당될 수 있음을 의미한다.
2. 두 번째로, 생각의 체인은 모델의 행동에 해석 가능한 창을 제공하여, 특정 대답에 도달했을 수 있는 방법을 제시하고 추론 경로가 잘못된 곳에서 디버깅할 기회를 제공한다(답을 지원하는 모델의 계산을 완전히 특성화하는 것은 미해결 질문으로 남아 있지만).
3. 셋째, 연쇄 사상 추론은 수학 단어 문제, 상식 추론, 기호 조작과 같은 과제에 사용될 수 있으며, 인간이 언어를 통해 해결할 수 있는 임의의 과제에 잠재적으로 적용가능하다(적어도 원칙적으로).
4. 마지막으로, 연쇄추론(chain-of-thought reasoning)은 단순히 소수의 발성 프롬프트(shot prompting)의 예시들에 사고 시퀀스의 연쇄의 예들을 포함함으로써 충분히 큰 기성 언어 모델들에서 쉽게 도출될 수 있다.

경험적 실험에서 우리는 산술 추론(섹션 3), 상식 추론(섹션 4), 기호 추론(섹션 5)을 위한 연쇄 사고 프롬프트의 유용성을 관찰할 것이다.

## 3 Arithmetic Reasoning

우리는 언어 모델의 산술 추론 능력을 측정하는 그림 1의 형태의 수학 단어 문제를 고려하는 것으로 시작한다. 인간에게는 간단하지만, 산술 추론은 언어 모델이 종종 고전하는 작업이다(Hendrycks et al., 2021; Patel et al., 2021, _inter alia_). 놀랍게도, 540B 파라미터 언어 모델과 함께 사용될 때 연쇄-생각 프롬프트는 도전적인 GSM8K 벤치마크(Cobbe et al., 2021) 상에서 심지어 새로운 최신 기술을 달성하면서, 여러 태스크들에 대해 태스크-특정 피니튜닝된 모델들과 비교가능하게 수행한다.

### Experimental Setup

우리는 여러 벤치마크에서 다양한 언어 모델에 대한 연쇄 사고를 탐구한다.

**Benchmarks.** 다음 5가지 수학 단어 문제 벤치마크를 고려합니다. **(1)** 수학 단어 문제의 **GSM8K** 벤치마크(Cobbe et al., 2021), **(2)** 다양한 구조를 가진 수학 단어 문제의 **SVAMP** 데이터 세트(Patel et al., 2021), **(3)** 다양한 수학 단어 문제의 **ASDiv** 데이터 세트(Miao et al., 2020), **(4)** 대수적 단어 문제의 **AQuA** 데이터 세트 및 **(5)** MAWPS** 벤치마크(Koncel-Kedziorski et al., 2016). 예제 문제는 부록 표 12에 나와 있다.

**표준 프롬프트.** 기준선의 경우 테스트 시간 예제에 대한 예측을 출력하기 전에 언어 모델이 입력-출력 쌍의 컨텍스트 내 예시로 제공되는 Brown 등(2020)에 의해 대중화된 표준 몇 발 프롬프트를 고려합니다. 예제는 질문 및 답변으로 형식화됩니다. 모형은 그림 1(왼쪽)과 같이 직접 답을 준다.

**생각의 연결 프롬프트** 제안 된 접근 방식은 그림 1 (오른쪽)에 설명 된 것과 같이 관련 된 답변에 대 한 생각의 연결로 몇 번의 프롬프트에서 각 예를 보강 하는 것입니다. 대부분의 데이터셋은 평가 분할만 있기 때문에 프롬프팅을 위한 사고 사슬이 있는 8개의 소수의 예시 집합을 수동으로 구성했으며 -그림 1(오른쪽)은 하나의 사고 예시 집합을 보여주고, 전체 예시 집합은 부록 표 20에 나와 있다. (이러한 특정 예시들은 프롬프트 엔지니어링을 거치지 않았으며, 견고성은 섹션 3.4 및 부록 A.2에서 연구됨). 이러한 형태의 사고 사슬 프롬프팅이 다양한 수학 단어 문제에 걸쳐 성공적인 추론을 성공적으로 이끌어낼 수 있는지 조사하기 위해 자유 응답 대신 객관식인 AQuA를 제외한 모든 벤치마크에 대해 이 8개의 사고 예시 집합의 단일 집합을 사용했다. AQuA의 경우 부록 표 21에 주어진 대로 훈련 세트의 4가지 예시와 솔루션을 사용했다.

**언어 모델.** 5개의 대규모 언어 모델을 평가합니다. 첫 번째는 **GPT-3**(Brown et al., 2020)이며, 텍스트-ada-001, 텍스트-babbbage-001, 텍스트-curie-001 및 텍스트-davinci-002를 사용합니다. 이는 350M, 1.3B, 6.7B 및 175B 매개 변수의 InstructGPT 모델에 해당합니다(Ouyang et al., 2022). 두 번째는 422M, 2B, 8B, 68B 및 137B 매개 변수의 모델을 갖는 **LaMDA**(Thoppilan et al., 2022). 세 번째는 8B, 62B 및 540B 매개 변수의 모델이 있는 **PaLM** 입니다. 네 번째는 **UL2 20B** (Tay 등, 2022)이고 다섯 번째는 **Codex** (Chen 등, 2021, OpenAI API의 코드-davinci-002)입니다. 우리는 탐욕스런 디코딩을 통해 모델을 샘플링한다(후속 작업은 많은 샘플링된 세대에 걸쳐 대다수의 최종 답변을 취함으로써 체인-오브-사상 프롬프팅이 개선될 수 있음을 보여준다(Wang et al., 2022). LaMDA의 경우 각 종자가 무작위로 섞인 예시 순서가 다른 5개의 무작위 종자에 대한 평균 결과를 보고한다. LaMDA 실험은 다른 종자 간에 큰 분산을 나타내지 않았기 때문에 계산을 절약하기 위해 다른 모든 모델에 대한 단일 예시 순서에 대한 결과를 보고한다.

### Results

사상 사슬 프롬프트의 가장 강력한 결과는 그림 4에 요약되어 있으며 각 모델 수집, 모델 크기 및 벤치마크에 대한 모든 실험 출력은 부록의 표 2에 나와 있다. 세 가지 주요 테이크아웃이 있습니다. 먼저, 도 4는 연쇄-생각 프롬프팅이 모델 스케일의 창발 능력임을 보여준다(Wei et al., 2022). 즉, 체인-생각 프롬프트는 작은 모델의 성능에 긍정적인 영향을 미치지 않으며, \(\sim\)100B 파라미터의 모델과 함께 사용할 때만 성능 이득을 산출한다. 우리는 더 작은 규모의 모델이 유창하지만 비논리적인 사고 사슬을 생성하여 표준 프롬프트보다 성능이 낮다는 것을 질적으로 발견했다.

그림 3: 산술, 상식, 기호 추론 벤치마크에 대한 \(\langle\)input, 사고 사슬, 출력\(\rangle\) 트리플의 예. 생각의 사슬이 강조되어 있다. 부록 G의 전체 프롬프트입니다.

둘째, 연쇄 사고 프롬프트는 복잡한 문제에 대해 더 큰 성능 향상을 가져온다. 예를 들어, GSM8K(기준선 성능이 가장 낮은 데이터 세트)의 경우 가장 큰 GPT 및 PaLM 모델의 성능이 두 배 이상 증가했다. 반면에 해결하려면 단일 단계만 필요한 MAWPS의 가장 쉬운 하위 집합인 SingleOp의 경우 성능 개선이 음성이거나 매우 작았다(부록 표 3 참조).

셋째, GPT-3 175B 및 PaLM 540B를 통한 사상 체인 프롬프트는 통상적으로 라벨링된 트레이닝 데이터세트 상에서 태스크-특정 모델을 미세조정하는 종래 기술의 상태와 양호하게 비교된다. 그림 4는 PaLM 540B가 GSM8K, SVAMP 및 MAWPS에서 새로운 최신 기술을 달성하기 위해 체인 오브 생각 프롬프팅을 사용하는 방법을 보여준다(표준 프롬프팅이 이미 SVAMP에 대해 이전 최고를 통과했다는 점에 유의). 다른 두 데이터 세트인 AQuA 및 ASDiv, PaLM과 연쇄 사고 프롬프트는 최신 기술의 2% 이내에 도달한다(부록 표 2).

생각 사슬 프롬프트가 작동하는 이유를 더 잘 이해하기 위해 GSM8K에 대한 LaMDA 137B에 의해 모델 생성 생각 사슬을 수동으로 조사했다. 모델이 올바른 최종 답을 반환한 무작위 예제 50개 중 우연히 정답에 도달한 두 개를 제외하고 생성된 사고 사슬도 모두 논리적, 수학적으로 정확했다(올바른 모델 생성 사고 사슬의 예는 부록 D.1, 표 8 참조). 또한 모델이 잘못된 답을 제공한 50개의 무작위 샘플을 무작위로 조사했다. 이 분석의 요약은 사고 사슬의 46%가 거의 정확했으며 사소한 실수(계산기 오류, 기호 매핑 오류 또는 한 추론 단계가 누락됨)가 없었고 사고 사슬의 나머지 54%가 의미론적 이해 또는 일관성에 큰 오류가 있다는 것이다(부록 D.2 참조). 스케일링이 연쇄 추론 능력을 향상시키는 이유에 대한 작은 통찰력을 제공하기 위해 PaLM 62B가 만든 오류와 PaLM 540B로 스케일링하여 오류가 고정되었는지 여부에 대한 유사한 분석을 수행했다. 요약은 PaLM을 540B로 스케일링하는 것이 62B 모델에서 원-스텝 누락 및 의미론적 이해 에러의 큰 부분을 수정한다는 것이다(부록 A.1 참조).

### Ablation Study

사슬 사고 프롬프팅 사용의 관찰된 이점은 동일한 성능 개선이 다른 유형의 프롬프팅을 통해 부여될 수 있는지에 대한 자연스러운 질문을 제기한다. 그림 5는 아래에 설명된 사고 사슬의 세 가지 변형을 사용한 절제 연구를 보여준다.

**방정식만.** 연쇄 생각 프롬프트가 도움이 될 수 있는 한 가지 이유는 평가할 수학 방정식을 생성하므로 모델이 답변을 제공하기 전에 수학 방정식만 출력하도록 프롬프트되는 변형을 테스트합니다. 그림 5는 방정식만 프롬프트하는 것이 GSM8K에 큰 도움이 되지 않는다는 것을 보여주며, 이는 GSM8K의 질문의 의미론이 사고의 연쇄에서 자연어 추론 단계 없이 방정식으로 직접 변환하기에는 너무 어렵다는 것을 의미한다. 그러나 1단계 또는 2단계 문제의 데이터 세트의 경우 방정식을 질문에서 쉽게 도출할 수 있기 때문에 방정식 프롬프트만 성능을 향상시킨다는 것을 발견했다(부록 표 6 참조).

그림 4: Chain-of-thought 프롬프팅은 큰 언어 모델이 도전적인 수학 문제를 해결할 수 있도록 한다. 특히, 연쇄 사고 추론은 모델 규모를 증가시키는 새로운 능력이다. 이전의 최상의 숫자는 GSM8K의 경우 Cobbe et al.(2021), SVAMP의 경우 Jie et al.(2022), MAWPS의 경우 Lan et al.(2021)이다.

**가변 계산만.** 또 다른 직관은 사고 사슬을 통해 모델이 더 어려운 문제에 더 많은 계산(즉, 중간 토큰)을 사용할 수 있다는 것입니다. 변수 계산의 효과를 연쇄 사상 추론으로부터 분리하기 위해, 우리는 모델이 문제를 해결하는 데 필요한 방정식의 문자 수와 동일한 점(\(\ldots\))의 유일한 시퀀스를 출력하도록 촉구되는 구성을 테스트한다. 이 변형은 기준선과 거의 동일하게 수행되며, 이는 변수 계산 자체가 연쇄 사고 프롬프트의 성공 원인이 아니며 자연 언어를 통해 중간 단계를 표현하는 것으로부터 유용성이 있음을 시사한다.

**답변 후 생각의 사슬.** 이러한 프롬프트를 통해 모델이 사전 교육 중에 획득한 관련 지식에 더 잘 액세스할 수 있다는 또 다른 잠재적인 이점이 있을 수 있습니다. 따라서 우리는 사고 프롬프트의 체인이 답변 후에만 주어지는 대안적 구성을 테스트하여 모델이 실제로 최종 답변을 제공하기 위해 생성된 사고 체인에 의존하는지 여부를 분리한다. 이 변형은 기본과 거의 동일하게 수행되며, 이는 사고 사슬에 구현된 순차적 추론이 단순히 지식을 활성화하는 것 이상의 이유로 유용함을 시사한다.

### Thought Chain의 견고성

예시들에 대한 민감도는 접근법들을 프롬프트하는 주요 고려사항이다 - 예를 들어, 소수의 샷 예시들의 순열을 변화시키는 것은 SST-2 상의 GPT-3의 정확도를 가까운 우연(54.3%)으로부터 가까운 최신 기술(93.4%)까지 이르게 할 수 있다(Zhao 등, 2021). 이 마지막 하위 섹션에서는 다른 주석자가 작성한 사고 사슬에 대한 견고성을 평가한다. Annotator A가 쓴 사상 사슬을 사용한 위의 결과 외에도, 이 논문의 다른 두 공저자(Annotator B와 C)는 동일한 소수의 예시(부록 H에 표시)에 대해 독립적으로 사상 사슬을 썼다. 주석자 A는 또한 Cobbe 등(2021)에 주어진 해법의 스타일에 따라 원본보다 더 간결한 또 다른 사고 사슬을 썼다.1

각주 1: 예를 들어, 원래의 사고 사슬이 몇 개의 짧은 문장을 사용하는 반면(“_원래 9대의 컴퓨터가 있었다. 4일마다 5대의 컴퓨터가 추가되었다. 그래서 5*4 = 20대의 컴퓨터가 추가되었다. 9+20은 29.”_), 간결함 "5 * 4 = 20개의 새 컴퓨터가 추가되었습니다. 그래서 지금 서버 룸에는 9 + 20 = 29개의 새 컴퓨터가 있습니다."라고 생각의 사슬이 읽을 수 있다.

도 6은 GSM8K 및 MAWPS 상의 LaMDA 137B에 대한 이러한 결과를 나타낸다(다른 데이터 세트에 대한 절제 결과는 부록 표 6/표 7에 나와 있다). 다른 생각 주석 체인 간에 분산이 있지만, 예시 기반 프롬프팅(Le Scao and Rush, 2021; Reynolds and McDonell, 2021; Zhao et al., 2021)을 사용할 때 예상되는 바와 같이, 모든 생각 주석 체인 세트는 큰 마진만큼 표준 기준선을 능가한다. 이 결과는 사고 사슬의 성공적인 사용이 특정 언어 양식에 의존하지 않는다는 것을 암시한다.

다른 예제 집합에 대한 성공적인 연쇄 사고 프롬프트 작업을 확인하기 위해 GSM8K 훈련 집합에서 무작위로 샘플링된 8개의 예제 3세트로 실험을 실행한다.

도 5: LaMDA 137B 및 PaLM 540B를 사용하여 프롬프트의 상이한 변형에 대한 절제 연구. 다른 데이터 세트에 대한 결과는 부록 표 6 및 표 7에 나와 있다.

도 6: 체인-of-thought 프롬프트는 (예상한 바와 같이) 상이한 프롬프트 예들에 대해 분산을 갖지만, 상이한 예시들뿐만 아니라 다양한 주석자들에 대한 표준 프롬프트보다 성능이 우수하다.

소스(이 데이터 세트의 예에는 이미 사고 사슬과 같은 추론 단계가 포함되어 있음).2 그림 6은 이러한 프롬프트가 수동으로 작성된 예시와 비교하여 수행되어 표준 프롬프팅을 훨씬 능가함을 보여준다.

각주 2: 입력 컨텍스트 윈도우에 맞게 예제 \(\leq 60\) 토큰을 샘플링하고, 예제를 \(\leq 2\) 단계로 제한하여 구성한 8개의 예시와 공정한 비교를 한다.

주석자, 독립적으로 작성된 사고 사슬, 다른 예시 및 다양한 언어 모델에 대한 견고성 외에도 산술 추론을 위한 사고 사슬이 다른 예시 순서 및 다양한 예시 수에 대해 견고하다는 것을 발견한다(부록 A.2 참조).

## 4 Commonsense Reasoning

사상의 사슬은 수학 단어 문제에 특히 적합하지만, 사상의 사슬의 언어 기반 특성은 일반적인 배경 지식의 가정 하에 물리적 및 인간 상호작용에 대한 추론을 포함하는 광범위한 상식 추론 문제에 실제로 적용할 수 있게 한다. 상식적 추론은 세계와 상호작용하기 위한 핵심이며, 여전히 현재의 자연어 이해 시스템의 도달 범위를 벗어난다(Talmor et al., 2021).

**Benchmarks.** 다양한 상식 추론 유형을 포함하는 5개의 데이터 세트를 고려합니다. 인기 있는 **CSQA**(Talmor 등, 2019)는 종종 사전 지식이 필요한 복잡한 의미론을 포함하는 세계에 대한 상식적인 질문을 던집니다. **StrategyQA**(Geva 등, 2021)는 모델에 질문에 답하기 위해 다중 홉 전략을 추론해야 합니다. 우리는 BIG-bench 노력 (BIG-bench 협업, 2021)에서 두 개의 특수 평가 집합을 선택 합니다. 주어진 컨텍스트에서 날짜를 유추 하는 **날짜** 이해 및 스포츠와 관련 된 문장이 그럴 수 있는지 아닌지를 결정 하는 **스포츠** 이해입니다. 마지막으로 **SayCan** 데이터 세트(Ahn 등, 2022)에는 자연어 명령을 이산 집합에서 일련의 로봇 작업에 매핑하는 작업이 포함됩니다. 그림 3은 모든 데이터 세트에 대한 사고 주석 체인이 있는 예를 보여준다.

**Prompts.** 이전 섹션과 동일한 실험 설정을 따릅니다. CSQA와 StrategyQA의 경우 훈련 세트에서 무작위로 예제를 선택하고 소수의 예시로 사용할 수 있도록 수동으로 생각 사슬을 구성했다. 두 개의 BIG 벤치 작업은 훈련 세트가 없기 때문에 평가 세트의 예시로 처음 10개의 예를 몇 개의 샷 예시로 선택하고 나머지 평가 세트의 보고서 번호를 선택했다. 세이캔의 경우 Ahn 등(2022)에서 사용된 훈련 집합의 6가지 예를 사용하고 수동으로 사고의 사슬을 구성했다.

**결과.** 그림 7은 PaLM에 대한 이러한 결과를 강조 표시합니다 (LaMDA, GPT-3 및 다른 모델 척도에 대한 전체 결과는 표 4에 나와 있습니다). 모든 작업에 대해 모델 크기를 확장하면 표준 프롬프트의 성능이 향상되었으며, 체인 오브 생각 프롬프트는 추가 이득으로 이어졌으며 PaLM 540B의 경우 개선이 가장 큰 것으로 나타났다. 사슬 사고 프롬프팅으로 PaLM 540B는 베이스라인에 비해 강력한 성능을 달성하여 StrategyQA(75.6% 대 69.4%)에서 이전 기술 수준을 능가하고 스포츠 이해(95.4% 대 84%)에서 지원되지 않는 스포츠 마니아를 능가했다. 이러한 결과는 연쇄 사고 프롬프트가 다양한 상식 추론 능력을 요구하는 태스크에서도 성능을 향상시킬 수 있음을 보여준다(CSQA에서는 이득이 최소화되었지만).

그림 7: 사고 사슬 프롬프트는 언어 모델의 상식 추론 능력도 향상시킨다. 여기에 나타낸 언어 모델은 PaLM이다. 선행 베스트 넘버는 CSQA(Talmor et al., 2019) 및 StrategyQA(Geva et al., 2021)의 리더보드(단일 모델만, 2022년 5월 5일 기준)이다. LaMDA, GPT-3 및 PaLM의 다양한 크기를 사용한 추가 결과는 표 4에 나와 있다.

Symbolic Reasoning

우리의 최종 실험 평가는 인간에게 간단하지만 언어 모델에는 잠재적으로 도전적인 상징 추론을 고려한다. 우리는 연쇄 사고 프롬프팅이 언어 모델이 표준 프롬프팅 설정에서 어려운 기호 추론 작업을 수행할 수 있을 뿐만 아니라 소수의 예시에서 볼 수 있는 것보다 더 긴 추론 시간 입력에 대한 길이 일반화를 용이하게 한다는 것을 보여준다.

작업.다음 두 가지 장난감 작업을 사용합니다.

* **마지막 문자 연결.** 이 작업은 모델에 이름에 있는 단어의 마지막 문자(예: _"Amy Brown"_\(\rightarrow\)_"_\(\forall\)_)를 연결하도록 요청합니다. 더 어려운 버전의 첫 문자 연결입니다. 언어 모델은 이미 생각 체인 없이 수행할 수 있습니다. 3 이름 센서스 데이터([https://namecensus.com/](https://namecensus.com/))에서 상위 1,000개의 이름과 성을 무작위로 연결하여 전체 이름을 생성합니다. 각주 3: 우리는 GPT-3 다빈치를 사용하여 10개의 일반적인 이름을 테스트했고 그것은 한 개를 제외하고는 모두 맞았다.
* **동전 뒤집기.** 이 작업은 모델이 사람들이 동전을 뒤집거나 뒤집지 않은 후에도 동전이 여전히 앞면이 있는지 여부를 묻는 것입니다 (예: _"동전은 앞면이 있습니다. Phoebe는 동전을 뒤집습니다. Osyaldo는 동전을 뒤집지 않습니다. 동전은 여전히 앞면이 있습니까?"_\(\rightarrow\)_"no"_).

이러한 기호 추론 작업의 구성이 잘 정의 되어 있으므로 각 작업에 대해 예제에서 훈련/few-shot 예시와 동일한 단계 수를 가진 _in-domain_ 테스트 집합과 평가 예제가 예제보다 더 많은 단계를 가진 _out-of-domain_ 테스트 집합을 고려 합니다. 마지막 문자 연산의 경우, 모델은 두 개의 단어가 있는 이름의 예시만 보고 3과 4개의 단어가 있는 이름에 대해 마지막 문자 연산을 수행한다. 4 동전 뒤집기 태스크에서 잠재적인 뒤집기 횟수에 대해 동일한 작업을 수행한다. 우리의 실험 설정은 이전 두 섹션에서와 동일한 방법과 모델을 사용한다. 우리는 그림 3에 나와 있는 각 작업에 대한 몇 안 되는 예시들에 대한 생각의 사슬을 다시 수동으로 구성한다.

각주 4: 길이가 2단어보다 긴 이름의 경우, 우리는 여러 개의 이름과 성을 함께 연결한다.

결과. 이러한 도메인 내 및 OOD 평가의 결과는 PaLM에 대해 도 8에 도시되어 있고, LaMDA에 대한 결과는 부록 표 5에 도시되어 있다. PaLM 540B를 사용하면, 체인-오브-생각 프롬프팅은 거의 100% 해결률로 이어진다(표준 프롬프팅은 LaMDA 137B에 대해서는 아니지만 PaLM 540으로 이미 동전 뒤집기를 해결한다는 점에 유의). 이러한 도메인 내 평가는 소수의 예시에서 생각의 사슬에 의해 완벽한 솔루션 구조가 이미 제공된다는 의미에서 "장난감 작업"이며, 모든 모델이 수행해야 하는 것은 테스트 시간 예제에서 새로운 기호와 동일한 단계를 반복하는 것이다. 그러나 작은 모델은 여전히 실패하는데, 이 세 가지 작업에 대해 보이지 않는 기호에 대한 추상적인 조작을 수행하는 능력은 100B 모델 매개변수의 규모에서만 발생한다.

OOD 평가의 경우 두 작업 모두 표준 프롬프트가 실패합니다. 체인-생각 프롬프팅으로, 언어 모델은 상향 스케일링 곡선을 달성한다(성능은 도메인 내 설정에서보다 낮지만). 따라서 연쇄 사고 촉진은 충분한 규모의 언어 모델에 대한 생각 사슬을 넘어 길이 일반화를 촉진한다.

## 6 Discussion

우리는 대규모 언어 모델에서 다단계 추론 행동을 이끌어내기 위한 간단한 메커니즘으로 연쇄 사고 촉진을 탐구했다. 우리는 먼저 연쇄 사고 프롬프트가 산술 추론에서 큰 마진만큼 성능을 향상시켜 절제보다 훨씬 강하고 다양한 주석자, 예시 및 언어 모델에 강력한 개선을 산출한다는 것을 보았다(섹션 3). 다음,

그림 8: 연쇄 사고 프롬프팅을 사용하면 두 개의 기호 추론 작업에서 더 긴 시퀀스로 일반화를 용이하게 한다.

상식 추론에 대한 실험은 연쇄 사고 추론의 언어적 특성이 일반적으로 적용할 수 있도록 하는 방법을 강조했다. 마지막으로, 기호추론을 위해 연쇄추론(chain-of-thought prompting)이 더 긴 시퀀스 길이로 OOD 일반화를 촉진한다는 것을 보여주었다(섹션 5). 모든 실험에서 사슬 사고 추론은 단순히 기성 언어 모델을 유도함으로써 도출된다. 이 논문을 작성하는 과정에서 어떤 언어 모델도 미세 조정되지 않았다.

모델 척도의 결과로 연쇄 사고 추론의 출현은 지배적인 주제였다 (Wei et al., 2022). 표준 프롬프트가 평탄한 스케일링 곡선을 갖는 많은 추론 태스크에 대해, 체인-생각 프롬프트는 스케일링 곡선을 극적으로 증가시킨다. 생각의 사슬 프롬프트는 대규모 언어 모델이 성공적으로 수행할 수 있는 일련의 작업을 확장하는 것으로 보이며, 즉, 우리의 작업은 표준 프롬프트가 대규모 언어 모델의 능력에 대한 하한만을 제공한다는 것을 강조한다. 이 관찰은 대답보다 더 많은 질문을 제기할 가능성이 있다. 예를 들어, 모델 규모의 추가 증가로 추론 능력이 얼마나 더 향상될 것으로 예상할 수 있는가? 언어 모델이 해결할 수 있는 작업의 범위를 확장할 수 있는 다른 프롬프트 방법은 무엇입니까?

제한점에 대해 우리는 먼저 사고의 사슬이 인간의 추론자의 사고 과정을 모방하지만 이것이 신경망이 실제로 "추론"인지 여부에 대한 답이 아니라는 것을 인정한다. 둘째, 소수의 샷 설정에서는 사상의 사슬로 예시들을 수동으로 증강하는 비용이 최소화되지만, 이러한 주석 비용은 미세 조정을 위해 금지될 수 있다(비록 이것이 잠재적으로 합성 데이터 생성 또는 제로 샷 일반화로 극복될 수 있지만). 셋째, 정확한 추론 경로에 대한 보장이 없어 정답과 오답을 모두 초래할 수 있으며, 사실적 세대의 언어 모델 개선은 향후 작업을 위한 열린 방향이다(Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022, _inter alia_). 마지막으로, 대규모 모델 규모에서만 연쇄 사고 추론의 출현은 실제 응용 프로그램에서 제공하는 데 비용이 많이 들며, 추가 연구는 더 작은 모델에서 추론을 유도하는 방법을 탐구할 수 있다.

## 7 관련 작업

이 작업은 많은 연구 분야에서 영감을 얻었으며, 우리는 확장된 관련 작업 섹션(부록 C)에서 자세히 설명한다. 여기에서 아마도 가장 관련이 있는 두 가지 방향과 관련 논문을 설명한다.

첫 번째 관련 방향은 추론 문제를 해결하기 위해 중간 단계를 사용하는 것이다. 링 등(2017)은 일련의 중간 단계를 통해 수학 단어 문제를 해결하기 위해 자연어 근거를 사용하는 아이디어를 개척한다. 이들의 작업은 이성에 대해 형식 언어를 사용하는 문헌과 현저한 대조를 이룬다(Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe et al.(2021)은 Ling et al.(2017)을 확장하여 더 큰 데이터셋을 생성하고 이를 이용하여 처음부터 모델을 훈련시키는 것이 아니라 미리 훈련된 언어 모델을 정밀하게 조정한다. 프로그램 합성 영역에서 Nye et al.(2021)은 언어 모델을 활용하여 파이썬 프로그램의 최종 출력을 중간 계산 결과를 예측하는 첫 번째 라인-투-라인 예측을 통해 예측하고, 그들의 단계별 예측 방법이 최종 출력을 직접 예측하는 것보다 더 나은 성능을 보인다는 것을 보여준다.

당연히, 이 논문은 또한 촉구에 대한 최근 작업의 큰 본문과 밀접하게 관련되어 있다. Brown 등(2020)에 의해 주어진 바와 같이 few-shot 프롬프팅의 대중화 이후, 몇몇 일반적인 접근법들은 프롬프트를 자동으로 학습하거나(Lester 등, 2021), 태스크를 설명하는 모델 지시들을 제공하는 것과 같은 모델들의 프롬프팅 능력을 향상시켰다(Wei 등, 2022; Sahl 등, 2022; Ouyang 등, 2022). 이러한 접근법이 프롬프트의 입력 부분(예: 입력에 미리 추가된 명령)을 개선하거나 증강하는 반면, 우리의 작업은 일련의 사고로 언어 모델의 출력을 증강하는 직교 방향을 취한다.

## 8 Conclusions

우리는 언어 모델에서 추론을 향상시키기 위한 간단하고 광범위하게 적용할 수 있는 방법으로서 연쇄 사고 프롬프팅을 탐구했다. 산술적, 상징적, 상식적 추론에 대한 실험을 통해, 우리는 연쇄 사고 추론이 충분히 큰 언어 모델이 평평한 스케일링 곡선을 갖는 추론 작업을 수행할 수 있도록 하는 모델 스케일의 창발적 속성임을 발견했다. 언어 모델이 수행할 수 있는 추론 작업의 범위를 넓히면 추론에 대한 언어 기반 접근법에 대한 추가 작업에 영감을 줄 수 있을 것이다.

## Acknowledgements

우리는 신문에 피드백을 제공한 제이콥 데블린, 클레어 쿠이, 앤드류 다이, 엘리 파블릭에게 감사드린다. 우리는 제이콥 오스틴, 유후아이 우, 헨리크 미칼로우스키, 아이토르 르코위츠, 찰스 서튼, 아칸샤 차우더리에게 도움이 되는 토론에 감사드린다. 원고의 수동 오류 분석에 대한 오류를 알려 주신 시드 맥스웰 씨에게 감사드립니다.

## References

* A. Amini, S. 가브리엘 린래 곤셀케지레스키 Choi, and H. Hajishirzi (2019)MathQA: towards interpretedable math word problem solving with operation-based formalisms. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long and Short Papers), Minneapolis, Minnesota, pp. 외부 링크: 참조된 문서: SS1, SS2입니다.
*D. Andor, L. 허경 Lee, and E. Pitler (2019)Giving BERT a calculator: finding operations and arguments with reading comprehension. EMNLP. 에 의해 인용된다: SS1, SS2.
* J. Audras, D. Klein, and S. Levine (2018)Learning with latent language. NAACL. 에 의해 인용된다: SS1, SS2.
* J. Austin, A. Odena, M. 나예민 Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. 테리큐 Le, et al.(2021) 대형 언어 모델을 이용한 프로그램 합성. arXiv preprint arXiv:2108.07732. Cited by: SS1, SS2.
* B. 협업(2021) 모방 게임을 넘어 언어 모델의 기능을 측정하고 추론합니다. 준비, 인용: SS1, SS2.
*K. 보스트롬 조석 Chaudhuri, and G. Durrett (2021)Flexible generation of natural language deduction. EMNLP. 에 의해 인용된다: SS1, SS2.
* T. B. Mann, N. 라이더 Subbiah, J. D Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. 아가왈, A 허버트 보스, G 크루거, T 허니건 Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. 진은시글러 리트윈 Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, D. Amodei(2020)Language models are few-shot learners. 뉴립스 에 의해 인용된다: SS1, SS2.
* J. Cai, R. Shin, and D. Song (2017)Making neural programming architecture are generalize via recursion. ICLR. 에 의해 인용된다: SS1, SS2.
*O. 함부루 록태셀 Lukasiewicz, and P. Blunsom (2018)e-snl: natural language explanation with natural language inference. 뉴립스 에 의해 인용된다: SS1, SS2.
*H. Chen, J. He, K. Narasimhan, and D. Chen (2022) can rationalization improve robustness. NAACL. 에 의해 인용된다: SS1, SS2.
*M. 진진투렉 Yuan, H. Ponde de Oliveira Pinto, J. Kaplan, H. Edwards, Y. 부르다남 Joseph, G. Brockman, et al.(2021)Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374. 인용: SS1, SS2.
*X. Chen, C. Liang, A. Wei Yu, D. Zhou, D. Song, and Q. V. Le(2019)Neural symbolic reader: distributed and symbol representations for reading comprehension. ICLR. 에 의해 인용된다: SS1, SS2.
피터 클라크, 오이빈드 타피오르 카일 리처드슨 2020. Transformers as soft reasoners over language. _ IJCAI_.
* Cobbe et al.(2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve mathematics word problems. _ arXiv preprint arXiv:2110.14168_.
* Devlin 등(2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: 언어 이해를 위한 심층 양방향 트랜스포머의 사전 트레이닝. _ NAACL_.
* Dong et al.(2019) Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural logic machines. _ ICLR_.
* Dua 등(2020) Dheeru Dua, Sameer Singh, and Matt Gardner. 2020. Benits of intermediate annotations in reading comprehension. _ ACL_.
* Geva 등(2021) Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021년. 아리스토텔레스가 노트북을 사용했나요? 암묵적 추론 전략을 사용 하는 질문 응답 벤치마크입니다. _ TACL_.
* Gu 등(2022) Yuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models behind language models. _ NAACL_.
* Hancock 등(2018) Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher Re. 2018. Training classifiers with natural language explanation. _ ACL_.
* Hase and Bansal (2022) Peter Hase and Mohit Bansal. 2022. 모델은 설명으로부터 언제 학습할 수 있는가? 설명 데이터의 역할을 이해하기 위한 형식적인 프레임워크입니다. _ ACL_.
* Hendrycks 등(2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. _ arXiv preprint arXiv:2103.03874_.
* Hosseini 등(2014) Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning to solve the arithmetic word problems with verb categorization. _ EMNLP_.
* Jie et al.(2022) Zhanming Jie, Jierui Li, and Wei Lu. 2022. 연역적으로 추론하기 위한 학습: 복합관계 추출로서 수학단어 문제풀이. _ arXiv preprint arXiv:2203.10316_.
* Kaplan 등(2020) Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. _ arXiv preprint arXiv:2001.08361_.
* Koncel-Kedziorski 등(2016) Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. MAWPS: A math word problem repository. _ NAACL_.
* Lampinen 등(2022) Andrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y. Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L. 맥클랜드, 제인 X 왕과 펠릭스 힐 2022. 언어 모델이 문맥에서 설명으로부터 배울 수 있는가? _ arXiv preprint arXiv:2204.02329_.
* Lan 등(2021) Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang, and Ee-Peng Lim. 2021. MWPToolkit: Deep Learning 기반 수학 단어 문제 해결자를 위한 오픈 소스 프레임워크입니다. _ arXiv preprint arXiv:2109.00799_.
* Le Scao and Rush (2021) Teven Le Scao and Alexander Rush. 2021. 프롬프트 가치가 있는 데이터 포인트는 몇 개입니까? _ NAACL_.
* Lester 등(2021) Brian Lester, Rami Al-Rfou, Noah Constant. 2021. Power of scale for parameter-efficient prompt tuning. _ EMNLP_.
* Lev 등(2004) Iddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzle: Robust processing to precise semantics. _ 텍스트의 의미와 해석에 관한 제2회 워크숍의 진행.
* Li and Liang (2021) Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: 생성을 위한 연속 프롬프트 최적화_ ACL_.
* Liu 등(2020)* Liang 등(2021) Zhengzhong Liang, Steven Bethard, Mihai Surdeanu. 2021. 설명 가능한 multi-hop verbal reasoning through internal monologue. _ NAACL_.
* Ling 등(2017) Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale generation: Learning to solve and explain of algebraic word problems. _ ACL_.
* Liu 등(2021) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, prompt, predict: 자연어 처리에서의 prompting 방법에 대한 체계적인 조사. _ arXiv preprint arXiv:2107.13586_.
* Majumder et al.(2021) Bodhiswa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley. 2021. Rationale-ins inspired natural language explanation with commonsense. _ arXiv preprint arXiv:2106.13876_.
* Marasovic 등(2022) Ana Marasovic, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization with natural language prompts. _ NAACL Findings_.
* Maynez 등(2020) Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. 추상적 요약에서 충실성과 사실성에 관한 연구 _ACL_에서.
* Miao 등(2020) Shen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. 영어 수학 단어 문제 해결사 평가 및 개발을 위한 다양한 말뭉치. _ ACL_.
* Min 등(2022) Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. 데모 역할 다시 생각: 무엇이 문맥 내 학습 작업을 만들까요? _ arXiv preprint arXiv:2202.12837_.
* Narang 등(2020) Sharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan. 2020. WT5?! Training text-to-text models to explain their predictions. _ arXiv preprint arXiv:2004.14546_.
* Nye et al. (2021) Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work: Scratchpads for intermediate computation with language models. _ arXiv preprint arXiv:2112.00114_.
* Ouyang 등(2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. _ arXiv preprint arXiv:2203.02155_.
* Patel 등(2021) Arkil Patel, Satwik Bhattacharya, Navin Goyal. 2021. NLP 모델이 정말 간단한 수학 단어 문제를 해결할 수 있나요? _ NAACL_.
* Peters 등(2018) Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. _ NAACL_.
* Pi 등(2022) Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and Weizhu Chen. 2022. Reasoning like program executors. _ arXiv preprint arXiv:2201.11473_.
* Piekos 등(2021) Piotr Piekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving BERT's mathematical abilities by predict the order of reasoning. _ ACL_.
* Rae 등(2021) Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models: Methods, analysis & insights from training Gopher. _ arXiv preprint arXiv:2112.11446_.
* Raffel 등(2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. 통합 텍스트-텍스트 변환기를 이용한 전이 학습의 한계 탐색. _ Journal of Machine Learning Research_, 21:1-67.
* Rajagopal 등(2021) Dheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. 자가 설명: 신경 텍스트 분류기를 위한 자가 설명 아키텍처. _ EMNLP_.
* Rajani 등(2019) Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019년, 설명하라! 상식 추론에 언어 모델을 활용합니다. _ ACL_.
* Rajagopal 등(2020)Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine Reading comprehension with numerical reasoning. _ EMNLP_.
* Rashkin 등(2021) Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov, Gaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. 자연어 생성 모델에서의 속성 측정_ arXiv preprint arXiv:2112.12870_.
* Recchia (2021) Gabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration. _ arXiv preprint arXiv:2109.02102_.
* Reif 등(2022) Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022. 대규모 언어 모델을 갖는 임의 텍스트 스타일 전송을 위한 레시피. _ ACL_.
* Reynolds and McDonell (2021) Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm. _ 2021 CHI 전산시스템 인적요인에 관한 회의의 확장된 개요_
* Roy and Roth (2015) Subhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. _ EMNLP_.
* Roy 등(2015) Subhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language. _ TACL_.
* Saeed 등(2021) Mohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: 미리 훈련된 언어 모델에 소프트 규칙을 가르칩니다. _ EMNLP_.
* Sanh et al.(2022) Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted training enables zero-shot task generalization. _ ICLR_.
* Shen 등(2021) Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021. Generate & rank: A multi-task framework for math word problems. _계산 언어학 협회의 발견: EMNLP 2021_에서.
* Talmor 등(2019) Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: 상식 지식을 대상으로 하는 질문 응답 챌린지. _ NAACL_.
* Talmor 등(2020) Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-thought: 사전 훈련된 모델을 암시적 지식 위에 체계적으로 추론하도록 지도합니다. _ NeurIPS_.
* Talmor 등(2021) Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and Jonathan Berant. 2021. CommonsenseQA 2.0: Exposure of ai through gamification. _ NeurIPS 데이터 집합 및 벤치마크에서 추적합니다.
* Tay 등(2022) Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. _ arXiv preprint arXiv:2205.05131_.
* Thoppilan et al.(2022) Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for dialog applications. _ arXiv preprint arXiv:2201.08239_.
* Wang 등(2022a) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a. 자기 일관성은 언어 모델에서 사고 추론의 사슬을 향상시킵니다. _ arXiv preprint arXiv:2203.11171_.
* Wang et al.(2022b) Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b. 1,600개 이상의 언어 작업에 대 한 컨텍스트 내 지침을 통해 일반화를 벤치마킹 합니다. _ arXiv preprint arXiv:2204.07705_.
* Wei 등(2022a) Jason Wei, Maarten Bosma, Vincent Y. 자오, 켈빈 구, 아담스 위, 브라이언 레스터, 난 두, 앤드류 M. Dai, Quoc V. 레 2022a. Finetuned 언어 모델은 제로 샷 학습자입니다. _ ICLR_.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. 대형 언어 모델의 최신 기능입니다. _ 머신 러닝 연구 트랜잭션입니다.
* Wiegreffe 등(2022) Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing human-AI collaboration for generating free-text explanation. _ NAACL_.
* Wiegreffe and Marasovic (2021) Sarah Wiegreffe and Ana Marasovic. 2021. Teach me to explain: A review of datasets for explainable NLP. _ NeurIPS_.
* Wiegreffe 등(2021) Sarah Wiegreffe, Ana Marasovic, and Noah A. Smith. 2021. Measuring association between labels and free-text rationales. _ EMNLP_.
* Wu 등(2022a) Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. 2022a. PromptChainer: 시각적 프로그래밍을 통해 큰 언어 모델을 변경하라는 메시지가 표시됩니다. _ CHI Extended Abstracts_.
* Wu 등(2022b) Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI 체인: 대형 언어 모델 프롬프트를 체인화함으로써 투명하고 제어가능한 인간-AI 상호작용. _ CHI_.
* Yan 등(2020) Yujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020. Neural execution engines: Learning to execute subroutines. _ NeurIPS_.
*Yao 등(2021) Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. 구성 설명으로 언어 모델을 세분화합니다. _ NeurIPS_.
* Ye and Durrett (2022) Xi Ye and Greg Durrett. 2022. few-shot in-context learning에서의 설명의 비신뢰성_ arXiv preprint arXiv:2205.03401_.
* Yordanov 등(2021) Yordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot out-of-domain transfer learning of natural language explanation. _ arXiv preprint arXiv:2112.06204_.
* Zaidan 등(2007) Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Use "annotator rationales" to improve machine learning for text categorization. _ NAACL_.
* Zaremba and Sutskever (2014) Wojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. _ arXiv preprint arXiv:1410.4615_.
* Zelikman 등(2022) Eric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: 추론과 함께 부트스트랩 추론. _ arXiv preprint arXiv:2203.14465_.
* Zhao et al.(2021) Tony Z. 자오, 에릭 월리스, 시펑, 댄 클라인, 그리고 사미어 싱. 2021. 사용 전 보정: 언어 모델의 few-shot 성능 향상 _ ICML_.
* Zhou 등(2020) Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and Jian Tang. 2020. 설명을 잠재 변수로 사용하여 해석 가능한 자연어 이해를 향합니다. _ NeurIPS_.

## Checklist

1. 모든 저자에 대해... 1. 요약 및 소개에서 만든 주요 클레임은 논문의 기여와 범위를 정확하게 반영합니까? [예] 2. 작업의 한계를 설명하셨나요? 섹션 6과 부록 A.2. 3. 작업의 잠재적인 부정적인 사회적 영향에 대해 논의했습니까? 우리는 우리 논문의 기여의 직접적인 결과로 부정적인 사회적 영향을 기대하지 않는다. 그러나 한 가지 고려 사항은 생성된 사고 사슬이 항상 사실적이지 않다는 것인데, 이는 부록 D.1의 제한 사항으로 언급된다(그리고 우리는 그러한 사고 사슬을 사실적 방식으로 또는 실제 시나리오에서 사용하는 것을 제안하지 않는다는 점에 유의한다). 4. 윤리 검토 지침을 읽고 논문이 이를 준수하는지 확인했다.
2. 이론적 결과를 포함 하는 경우... 1. 모든 이론적 결과의 전체 가정 집합을 설명 했습니까? [N/A] 2. 모든 이론적 결과에 대한 완전한 증명을 포함했습니까? [N/A]
3. 실험을 실행한 경우... 1. 주요 실험 결과를 재현하는 데 필요한 코드, 데이터 및 지침(첨부 자료 또는 URL로 포함)을 포함했습니까? 우리는 보충 자료에 LaMDA 및 GPT-3에 대한 입력, 출력 및 표적을 포함했다. 독점 모델을 사용하지만 GPT-3 결과는 완전히 재현 가능하다. 재현성은 부록 E.1. 2에서 추가로 논의 됩니다. 모든 교육 세부 정보 (예: 데이터 분할, 하이퍼 매개 변수, 선택 된 방법)를 지정 했습니까? 데이터 분할은 하이퍼파람에 대해 N/A로 지정되었다. 3. 오류 막대를 보고했는가(예: 실험을 여러 번 실행한 후 무작위 시드와 관련하여)? 각 시드가 다른 임의 순서 예시인 LaMDA 137B를 사용 하는 여러 시드에 대 한 표준 편차는 표 6 및 표 7에 제공 됩니다. 4. 계산의 총량과 사용 된 리소스 유형 (예: GPU 유형, 내부 클러스터 또는 클라우드 공급자)을 포함 했습니까? 총 계산량을 추정하지는 않았지만 리소스 유형은 부록 E.2에 설명되어 있다.
4. 기존 자산(예: 코드, 데이터, 모델)을 사용하거나 새 자산을 큐레이션/릴레이하는 경우... 1. 작업이 기존 자산을 사용하는 경우 크리에이터를 인용했습니까? NeurIPS 의자의 권장 사항에 따라 익명화된 두 가지 모델을 사용했다. 이 모델들은 카메라 레디 버전의 논문에서 인용될 것입니다. 2. 자산의 라이센스에 대해 언급하셨나요? 부록 E.3. 3. 첨부 자료 또는 URL에 새 자산을 포함했습니까? 코인플립 및 마지막 편지 연결 데이터 세트는 유일한 새 자산이며 보조 자료에 제공 됩니다. 4. 데이터를 사용/큐레이션 하는 사람들에게서 동의를 얻었는지 여부와 방법에 대해 논의 했습니까? 수집된 인적 데이터는 없습니다. 5. 사용/큐레이션 중인 데이터에 개인 식별 정보가 포함되어 있는지 또는 불쾌한 콘텐츠가 포함되어 있는지 논의했습니까? 인간 데이터가 수집되지 않았습니다.
5. 크라우드소싱을 사용하거나 인간 대상과 함께 연구를 수행한 경우... 1. 해당되는 경우 참가자 및 스크린샷에 제공된 지침 전문을 포함했습니까? [N/A] 2. 해당 하는 경우 IRB (기관 검토 위원회) 승인에 대 한 링크와 함께 잠재적인 참가자 위험에 대해 설명 했습니까? [N/A] 3. 참가자들에게 지불된 시간당 예상 임금과 참가자 보상에 사용된 총 금액을 포함했습니까? [N/A] 자주 묻는 질문

### 모델 규모를 늘리면 생각 체인 프롬프트가 개선되는 이유는 무엇입니까?

성공적인 연쇄 사고 추론이 특정 모델 규모에서만 예측 가능하게 나타난다는 발견은 흥미롭다. 스케일링 언어 모델은 향상된 성능 및 샘플 효율과 같은 이점을 제공하는 것으로 나타났지만(Kaplan et al., 2020), 체인 오브 생각 추론은 체인 오브 생각 추론이 실제로 10B 매개변수보다 작은 대부분의 모델에 대해 성능을 손상시키기 때문에 소규모 모델의 성능을 외삽하는 것만으로는 성공을 예측할 수 없다는 점에서 창발한다.

모델 척도가 연쇄 사고 촉진을 개선하는 이유에 대한 질문은 확실히 다면적이며 오류 분석을 통해 이에 대한 통찰력을 제공하기 위한 예비 시도를 했다. 이 작은 분석에는 PaLM 62B에 의해 만들어진 45개의 오류를 수동으로 읽고 의미 이해(20개 오류), 한 단계 누락(18개 오류) 및 기타 오류(7개 오류)로 분류하는 것이 포함되었다. "기타 범주"에는 환각, 반복 출력 및 기호 매핑 오류가 포함되었다. 이 범주화는 부록 D.2의 LaMDA에 대해 수행된 초기 오류 분석에서 차용한 대략적인 것으로, 사고 사슬을 올바르게 만드는 데 필요한 개선 사항을 기반으로 범주를 구상했다.

그림 9에서 볼 수 있듯이 PaLM을 540B 매개변수로 스케일링하면 세 가지 범주 모두에서 오류의 상당 부분이 고정되었다. PaLM을 540B로 스케일링하여 고정된 의미 이해 및 1단계 누락 오류의 예는 그림 10에 나와 있다. 이 결과는 언어 모델이 모델 척도의 함수로서 다양한 의미 이해 및 논리적 추론 기술을 획득한다는 가설과 일치하는 것으로 판단된다(모델 척도가 종종 훈련 계산량과 같은 다른 요인과 혼동된다는 점에 유의).

작은 언어 모델이 왜 실패하는지에 대해서도 세 가지 주목할 만한 점이 있다. 첫 번째 관찰은 작은 언어 모델이 비교적 쉬운 심볼 매핑 작업에서도 실패한다는 것이다. 섹션 5에서 입증된 바와 같이 소수의 예시에서 주어진 동일한 사고 논리 구조를 사용하는 새로운 예제로 일반화만 요구하는 기호 추론 작업에도 작은 언어 모델은 여전히 실패했다. 두 번째 관찰은 브라운 등(2020)에 의해 보여지는 바와 같이, 작은 언어 모델들이 본질적으로 더 약한 산술 능력을 갖는 것으로 보인다는 것이다. (의미적 이해 없이) 간단한 산술 연산을 수행하는 능력은 충분한 모델 스케일을 필요로 한다. 마지막으로, 우리는 작은 언어 모델이 종종 최종 답에 도달하지 않은 반복이나 논리로 인해 구문 분석할 수 있는 최종 답을 생성하지 않는다는 것을 질적으로 알아차렸다.

요약하면, 모델 척도의 결과로 연쇄 사고 추론의 성공은 다양한 창발 능력(의미 이해, 기호 매핑, 주제 유지, 연산 능력, 충실성 등)을 수반할 가능성이 있는 복잡한 현상이다. 향후 작업은 사전 훈련 데이터, 모델 아키텍처 및 최적화 목표의 어떤 속성이 그러한 추론 능력을 인과적으로 가능하게 하는지 더 철저히 조사할 수 있다.

그림 9: PaLM 62B가 부정확한 45개 문제의 오류 분석. 이러한 오류는 의미론적 이해, 한 단계 누락 및 기타 오류로 분류되었다. 다른 범주에는 환각, 반복 출력 및 기호 매핑 오류가 포함됩니다. PaLM을 540B로 확장하는 것은 모든 범주에서 오류의 상당 부분을 고정했다.

### 프롬프트 엔지니어링의 역할은 무엇인가요?

프롬프트의 주요 고려 사항 중 하나는 정확한 프롬프트에 대한 민감성이다. 프롬프트가 예상치 못한 방식으로 언어 모델에 영향을 미친다는 것을 보여주는 작업은 부족하지 않다(Min et al., 2022). 우리가 사고 주석의 사슬을 만든 일반적인 방법은 훈련 집합에서 8개의 예시들을 취하고 추론 과정을 최종 답으로 이어지는 여러 단계로 분해하는 것이었다. 사상 주석의 사슬의 예는 그림 3에 제공되며 부록 G에 전체 프롬프트가 제공된다. 사고 사슬이 공학을 프롬프트하는 데 얼마나 민감한지를 분석하기 위해 다양한 요인에 대한 견고성 실험을 수행했다.

* **다른 주석자.** 먼저 세 개의 다른 주석자에 대 한 견고성을 분석 합니다 (섹션 3.4 및 그림 6). 성능에는 주목할 만한 차이가 있지만(나중에 논의하겠지만), 산술, 상식 및 기호 추론에서 8개의 데이터 세트에 대해 3명의 주석자 모두에 대해 사상 사슬이 기준선보다 더 나은 성능을 보였다(표 6 및 표 7). Cobbe 등(2021)의 주석 프로세스와 유사하게, 주석자에게는 그에 대한 구체적인 지침이 주어지지 않았다.

도 10: 62B에서 540B로 PaLM을 스케일링함으로써 고정된 의미론적 이해 및 원-스텝 누락 에러의 예.

최종 답안으로 이어진 단계별 추론 과정을 단순히 작성하는 것 외에 사고 주석 사슬을 작성하는 방법. 따라서 주석은 각 주석자 자신의 언어학적 "사고의 사슬" 쓰기 스타일로 작성되었다.
* **기계 학습 배경이 없는 주석자.** GSM8K 데이터 세트(Cobbe et al., 2021)는 크라우드 컴퓨팅 작업자가 작성한 추론 체인이 있는 훈련 세트를 편리하게 제공하며, 이를 통해 기계 학습에서 배경이 없는 독립적인 원본의 추론 체인으로 생각 체인이 여전히 작동하는지 여부를 조사할 수 있습니다. 그래서 우리는 GSM8K에서 생각 사슬이 있는 8개의 예시 세 세트를 무작위로 샘플링했다. 이러한 사고 주석의 사슬은 또한 4개의 산술 데이터 세트 모두에 대해 큰 마진만큼 기준선을 능가하여(표 6), 사고 사슬이 특정 주석자 세트에 의존하지 않음을 나타낸다.
* **다른 예제.** 위의 다른 GSM8K 예제 실험 (표 6)은 또한 여러 예제 집합에 대해 생각 체인 프롬프트가 작동 하는 것을 보여 줍니다. 특히, 우리는 4개의 모든 산술 데이터 세트(각 데이터 세트에 대한 훈련 세트에서 예시들을 선택하는 대신)에 대한 모든 예시 세트를 테스트하는데, 이는 예시들이 테스트 예와 동일한 데이터 세트 분포에서 반드시 나올 필요는 없음을 시사한다.
* **예제의 다른 순서입니다.* * 이전 작업은 일부 경우(예: 분류) 프롬프트 사항의 순서조차도 SST-2에서 GPT-3의 정확도를 거의 우연 (54.3%)에서 거의 SOTA (93.4%)까지 높일 수 있음을 보여주었습니다 (Zhao et al., 2021). 우리는 표 6과 표 7에서 다른 예시로부터 성능의 표준 편차를 보여준다. 신속한 순서에 대한 표준 편차는 거의 모든 경우에 상대적으로 최소화된다. 한 가지 예외는 동전 뒤집기 작업인데, 예시 순서가 표준 편차가 높은 이유는 Zhao 등(2021)에 인용된 이유일 가능성이 높다. 분류를 위해 행의 동일한 범주의 많은 예시들이 모델 출력을 편향시킨다.
* **다른 수의 예시** 또한 다양한 수의 몇 개의 샷 예가 있을 때 생각 체인 프롬프트의 이득이 일반적으로 여전히 유지된다는 것을 발견했습니다. 이것은 그림 11의 5개 데이터 세트에 대해 표시된다(모든 데이터 세트에 대해 이를 실행할 컴퓨팅이 없었다). 또한 예비 실험에서 표준 프롬프트에서 예시 수를 더 늘리면 상당한 이득이 발생하지 않는다는 것을 발견했다(예: 8개에서 16개로 증가해도 연쇄 생각 프롬프트를 따라잡을 만큼 표준 프롬프트의 성능이 향상되지 않았다).
* **다른 언어 모델.** 한 모델에 대해 더 잘 작동 하는 특정 프롬프트가 다른 큰 언어 모델에 대해 더 잘 작동 하는지 여부가 또 다른 흥미로운 질문입니다. 동일한 프롬프트를 사용하여 연쇄 사고 프롬프트가 CSQA 및 GPT-3에 대한 StrategyQA를 제외한 모든 데이터 세트에 대해 세 모델(LaMDA, GPT-3 및 PaLM) 모두에서 성능을 향상시킨다는 것을 발견했다(표 1, 표 4, 표 5). 체인 사고에서 얻은 이득이 모델 간에 완벽하게 전달되지 않았다는 사실은 한계이며, 추가 작업은 다양한 사전 훈련 데이터 세트와 모델 아키텍처가 체인 사고 프롬프트에서 얻은 성능 이득에 어떻게 영향을 미치는지 조사할 수 있다.

**빠른 엔지니어링은 여전히 중요 합니다.* * 결과는 산술 추론에 대 한 프롬프트에 비교적 강력 하지만 빠른 엔지니어링은 여전히 중요 하 고 많은 경우에 성능을 크게 향상시킬 수 있음을 분명히 하고 싶습니다. 대부분의 사상 주석의 체인이 표준 프롬프팅보다 우수하지만, 많은 경우에 큰 변동이 있다. 예를 들어, 동전 뒤집기 작업의 경우 성능은 주석기 A의 경우 99.6%에서 주석기 C의 경우 71.4%까지 다양했지만 둘 다 표준 프롬프트 = 50.0%를 초과했습니다(표 7 참조). 신속한 엔지니어링이 좋은 성능을 위한 요구 사항인 작업도 있습니다. 예비 실험에서 언어 모델이 5개 항목 목록의 순서를 역전시킬 수 있도록 생각 사슬을 사용하려고 했다. 공저자 두 명이 최선의 시도에도 불구하고 과제를 해결한 일련의 사고 프롬프트를 쓸 수 없었던 반면, 세 번째 공동 저자는 과제를 완벽하게 해결한 일련의 사고 프롬프트를 쓸 수 있었다.

강력한 방식으로 일련의 사고 주석을 생성하는 방법은 향후 작업에 흥미로운 방향이 될 수 있다. 예를 들어, 여기서 아이디어는 큰 언어 모델을 사용하여 프롬프트를 통해 생각의 체인을 자동으로 생성하는 것일 수 있다(그리고 잠재적으로 유효성 검사 세트를 통해 이를 최적화한다).

### 체인 오브 생각 프롬프트는 관심 있는 작업에 대 한 성능을 향상 시킬 수 있습니까?

체인 생각 프롬프트는 원칙적으로 텍스트 간 작업에 적용 되지만 다른 작업보다 일부 작업에 더 유용 합니다. 본 논문의 실험을 바탕으로, 우리의 직관은 세 가지 조건이 충족될 때 사고의 사슬이 가장 도움이 된다는 것이다: (1) 과제가 도전적이고 다단계 추론을 필요로 하는 경우, (2) 큰 언어 모델을 사용하는 경우, (3) 스케일링 곡선은 비교적 평평하다. 반대로 이러한 조건 중 하나 이상이 충족되지 않을 때 이점이 더 작다.

이러한 직관은 아마도 산술 추론 결과에 의해 뒷받침될 것이다. GSM8K (challenging multi-step problems, flat scaling curve) 상에서 PaLM 540B에서 체인-오브-사상 프롬프트에 의한 성능 이득이 가장 크다. 성능 이득은 하나 또는 두 단계(SingleOP, SingleEq, 및 AddSub)만을 필요로 하는 MAWPS의 서브세트들에 대해 작으며, 이에 대해 PaLM 540B는 이미 90% 이상의 성능을 달성한다(그리고 성능이 이미 강할 때 개선의 헤드룸이 더 적은 것도 일반적으로 사실이다).

이 논문에서는 다단계 추론 과제(산술, 상식, 상징)에 초점을 맞추었지만, 사슬 사고 프롬프트는 인간이 "사고의 사슬"을 사용하여 해결하는 모든 과제(적어도 원칙적으로는)에 잠재적으로 적용될 수 있다. 우리는 이러한 다양한 작업(예: 기계 번역 등)에 대한 연쇄 사고의 경험적 평가를 향후 작업에 맡긴다.

### 일부 산술 추론 데이터 세트에 대해서만 방정식으로 프롬프트 하는 이유는 무엇입니까?

중간 단계로서 방정식으로만 프롬프트하는 것은 많은 데이터셋에 도움이 되는데, 특히 데이터셋이 몇 개의 추론 단계(SVAMP, ASDiv, MAWPS)만을 필요로 하는 경우에 더욱 그러하다. 그러나 GSM8K의 경우 방정식을 사용하는 것만으로는 성능이 크게 향상되지 않았다. 질적 분석에 기초하여, 우리는 이러한 질문들이 모델이 수학 방정식으로 직접 번역하기에는 너무 의미론적으로 도전적이라고 믿는다. LaMDA 137B로부터의 이 예를 고려한다:

**질문:** 마이크는 40분 동안 탁구를 합니다. 처음 20분 동안, 그는 4점을 득점했다. 두 번째 20분 동안, 그는 25% 더 많은 점수를 받았다. 총점은 몇 점이었나요?

**방정식만(오답):** (4 + 20 * 0.25) = 6. 답변은 6입니다.

생각의 사슬(정답): 마이크는 40분 동안 탁구를 쳤다. 처음 20분 동안, 그는 4점을 득점했다. 두 번째 20분 동안, 그는 25% 더 많은 점수를 기록했다. 그래서 그는 후반 20분 동안 25% 더 득점했다. 4 x 1.25 = 5. 그래서 그는 후반 20분에 5점을 득점했습니다. 그래서 그는 총 9점을 득점했다. 답은 9입니다.

모델이 모든 의미론을 하나의 방정식으로 직접 번역하는 것은 어렵지만, 사고의 사슬은 자연어의 중간 단계를 통해 질문의 각 부분에 대해 더 나은 이유를 만들 수 있게 한다.

실험 결과

이 섹션에서는 모든 벤치마크에서 표준 프롬프트 대 표준 프롬프트에 대한 다양한 모델 및 모델 크기에 대한 실험 결과에 대한 표를 포함한다. 생각의 사슬을 프롬프트합니다.

산술 추론 벤치마크의 경우 모델이 산술 연산을 잘못 수행한 것을 제외하고는 일부 사고 사슬(생성된 방정식과 함께)이 정확했다. 유사한 관찰이 Cobbe 등(2021)에서 이루어졌다. 따라서 생성된 사고 사슬의 모든 방정식에 파이썬 평가 함수를 사용하여 외부 계산기로 파이썬 프로그램을 추가할 수 있다. 사고 사슬에 여러 방정식이 있을 때, 우리는 외부 계산기 결과를 하나의 방정식에서 문자열 매칭을 통해 다음 방정식으로 전파한다. 표 1과 같이 계산기를 추가하면 대부분의 작업에서 연쇄 사고 성능이 크게 향상됨을 알 수 있다.

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & Prompting & GSM8K & SVAMP & ASDiv & AQuA & MAWPS \\ \hline Prior best & N/A (finetuning) & 55\({}^{a}\) & 57.4\({}^{b}\) & 75.3\({}^{c}\) & 37.9\({}^{d}\) & 88.4\({}^{e}\) \\ UL2 20B & Standard & 4.1 & 10.1 & 16.0 & 20.5 & 16.6 \\  & Chain of thought & 4.4 (+0.3) & 12.5 (+2.4) & 16.9 (+0.9) & 23.6 (+3.1) & 19.1 (+2.5) \\  & + ext. calc & 6.9 & 28.3 & 34.3 & 23.6 & 42.7 \\ LaMDA 137B & Standard & 6.5 & 29.5 & 40.1 & 25.5 & 43.2 \\  & Chain of thought & 14.3 (+7.8) & 37.5 (+8.0) & 46.6 (+6.5) & 20.6 (+4.9) & 57.9 (+14.7) \\  & + ext. calc & 17.8 & 42.1 & 53.4 & 20.6 & 69.3 \\ GPT-3 175B & Standard & 15.6 & 65.7 & 70.3 & 24.8 & 72.7 \\  & Chain of thought & 46.9 (+31.3) & 68.9 (+3.2) & 71.3 (+1.0) & 35.8 (+11.0) & 87.1 (+14.4) \\  & + ext. calc & 49.6 & 70.3 & 71.1 & 35.8 & 87.5 \\ Codex & Standard & 19.7 & 69.9 & 74.0 & 29.5 & 78.7 \\ (code-davinci-002) & Chain of thought & 63.1 (+43.4) & 76.4 (+6.5) & 80.4 (+6.4) & 45.3 (+15.8) & 92.6 (+13.9) \\  & + ext. calc & 65.4 & 77.0 & 80.0 & 45.3 & 93.3 \\ PaLM 540B & Standard & 17.9 & 69.4 & 72.1 & 25.2 & 79.2 \\  & Chain of thought & 56.9 (+39.0) & 79.0 (+9.6) & 73.9 (+1.8) & 35.8 (+10.6) & 93.3 (+14.2) \\  & + ext. calc & 58.6 & 79.8 & 72.6 & 35.8 & 93.5 \\ \hline \hline \end{tabular}
\end{table}
표 1: 사고 프롬프팅 체인은 5개의 산술 추론 벤치마크에서 다양한 대형 언어 모델에 대한 표준 프롬프팅보다 성능이 우수하다. 모든 메트릭은 정확도(%)이다. Ext. calc. : 산술 연산만을 위한 사후 외부 계산기. 이전 최상의 숫자는 다음과 같습니다. \ (a\): Cobbe et al. (2021). \ (b\) & \(e\): Pi et al. (2022), \(c\): Lan et al. (2021), \(d\): Piekos et al. (2021).

\begin{table}
\begin{tabular}{l l r r r r r r r r r r} \hline \hline  & & \multicolumn{2}{c}{GSM8K} & \multicolumn{2}{c}{SVAMP} & \multicolumn{2}{c}{ASDiv} & \multicolumn{2}{c}{AQuA} & \multicolumn{2}{c}{MAWPS} \\ \cline{3-13} Model & & standard & CoT & standard & CoT & standard & CoT & standard & CoT & standard & CoT \\ \hline UL2 & 20B & 4.1 & **4.4** & 10.1 & **12.5** & 16.0 & **16.9** & 20.5 & **23.6** & 16.6 & **19.1** \\ \hline LaMDA & 420M & 2.6 & 0.4 & 2.5 & 1.6 & 3.2 & 0.8 & 23.5 & 8.3 & 3.2 & 0.9 \\  & 2B & 3.6 & 1.9 & 3.3 & 2.4 & 4.1 & 3.8 & 22.9 & 17.7 & 3.9 & 3.1 \\  & 8B & 3.2 & 1.6 & 4.3 & 3.4 & 5.9 & 5.0 & 22.8 & 18.6 & 5.3 & 4.8 \\  & 68B & 5.7 & **8.2** & 13.6 & **18.8** & 21.8 & **23.1** & 22.3 & 20.2 & 21.6 & **30.6** \\  & 137B & 6.5 & **14.3** & 29.5 & **37.5** & 40.1 & **46.6** & 25.5 & 20.6 & 43.2 & **57.9** \\ \hline GPT & 350M & 2.2 & 0.5 & 1.4 & 0.8 & 2.1 & 0.8 & 18.1 & 8.7 & 2.4 & 1.1 \\  & 1.3B & 2.4 & 0.5 & 1.5 & 1.7 & 2.6 & 1.4 & 12.6 & 4.3 & 3.1 & 1.7 \\  & 6.7B & 4.0 & 2.4 & 6.1 & 3.1 & 8.6 & 3.6 & 15.4 & 13.4 & 8.8 & 3.5 \\  & 175B & 15.6 & **46.9** & 65.7 & **68.9** & 70.3 & **71.3** & 24.8 & **35.8** & 72.7 & **87.1** \\ \hline Codex & - & 19.7 & **63.1** & 69.9 & **76.4** & 74.0 & **80.4** & 29.5 & **45.3** & 78.7 & **92.6** \\ \hline PaLM & 8B & 4.9 & 4.1 & 15.1 & **16.8** & 23.7 & **25.2** & 19.3 & **21.7** & 26.2 & **30.5** \\  & 62B & 9.6 & **29.9** & 48.2 & 46.7 & 58.7 & **61.9** & 25.6 & 22.4 & 61.8 & **80.3** \\  & 540B & 17.9 & **56.9** & 69.4 & **79.0** & 72.1 & **73.9** & 25.2 & **35.8** & 79.2 & **93.3** \\ \hline \hline \end{tabular}
\end{table}
표 2: 5개의 산술 추론 벤치마크에 대한 표준 프롬프트 대 사고 연쇄 프롬프트. 사고의 연쇄 재촉은 모델 규모의 창발적 능력이며 충분한 규모의 모델과 함께 사용할 때까지 성능에 긍정적인 영향을 미치지 않는다.

\begin{table}
\begin{tabular}{l l r r r r r r r r} \hline \hline  & & \multicolumn{2}{c}{SingleOp} & \multicolumn{2}{c}{SingleEq} & \multicolumn{2}{c}{AddSub} & \multicolumn{2}{c}{MultiArith} \\ \cline{3-10} Model & & standard & CoT & standard & CoT & standard & CoT & standard & CoT \\ \hline UL2 & 20B & 24.9 & **27.2** & 18.0 & **20.2** & 18.5 & 18.2 & 5.0 & **10.7** \\ \hline LaMDA & 420M & 2.8 & 1.0 & 2.4 & 0.4 & 1.9 & 0.7 & 5.8 & 1.5 \\  & 2B & 4.6 & 4.1 & 2.4 & 3.3 & 2.7 & 3.2 & 5.8 & 1.8 \\  & 8B & 8.0 & 7.0 & 4.5 & 4.4 & 3.4 & 5.2 & 5.2 & 2.4 \\  & 68B & 36.5 & **40.8** & 23.9 & **26.0** & 17.3 & **23.2** & 8.7 & **32.4** \\  & 137B & 73.2 & **76.2** & 48.8 & **58.7** & 43.0 & **51.9** & 7.6 & **44.9** \\ \hline GPT & 350M & 3.2 & 1.8 & 2.0 & 0.2 & 2.0 & 1.5 & 2.3 & 0.8 \\  & 1.3B & 5.3 & 3.0 & 2.4 & 1.6 & 2.3 & 1.5 & 2.2 & 0.5 \\  & 6.7B & 13.5 & 3.9 & 8.7 & 4.9 & 8.6 & 2.5 & 4.5 & 2.8 \\  & 175B & 90.9 & 88.8 & 82.7 & **86.6** & 83.3 & 81.3 & 33.8 & **91.7** \\ \hline Codex & - & 93.1 & 91.8 & 86.8 & **93.1** & 90.9 & 89.1 & 44.0 & **96.2** \\ \hline PaLM & 8B & 41.8 & **46.6** & 29.5 & 28.2 & 29.4 & **31.4** & 4.2 & **15.8** \\  & 62B & 87.9 & 85.6 & 77.2 & **83.5** & 74.7 & **78.2** & 7.3 & **73.7** \\  & 540B & 94.1 & 94.1 & 86.5 & **92.3** & 93.9 & 91.9 & 42.2 & **94.7** \\ \hline \hline \end{tabular}
\end{table}
표 3: MAWPS 벤치마크의 4개 하위 집합에 대한 표준 프롬프트 대 사고 사슬 프롬프트. MAWPS 벤치마크를 계층화하는 점은 대규모 언어 모델이 이미 높은 성능을 달성하는 쉬운 1단계 또는 2단계 문제(예: SingleOp, SingleEq 및 AddSub)에서 성능 이득이 최소임을 보여주는 것이다.

\begin{table}
\begin{tabular}{l l r r r r r r r r r r} \hline \hline  & & \multicolumn{2}{c}{CSQA} & \multicolumn{2}{c}{StrategyQA} & \multicolumn{2}{c}{Date} & \multicolumn{2}{c}{Sports} & \multicolumn{2}{c}{SayCan} \\ \cline{3-13} Model & & standard & CoT & standard & CoT & standard & CoT & standard & CoT & standard & CoT \\ \hline UL2 & 20B & 34.2 & **51.4** & 59.0 & 53.3 & 13.5 & **14.0** & 57.9 & **65.3** & 20.0 & **41.7** \\ \hline LaMDA & 420M & 20.1 & 19.2 & 46.4 & 24.9 & 1.9 & 1.6 & 50.0 & 49.7 & 7.5 & 7.5 \\  & 2B & 20.2 & 19.6 & 52.6 & 45.2 & 8.0 & 6.8 & 49.3 & 57.5 & 8.3 & 8.3 \\  & 8B & 19.0 & 20.3 & 54.1 & 46.8 & 9.5 & 5.4 & 50.0 & 52.1 & 28.3 & 33.3 \\  & 68B & 37.0 & **44.1** & 59.6 & **62.2** & 15.5 & **18.6** & 55.2 & **77.5** & 35.0 & **42.5** \\  & 137B & 53.6 & **57.9** & 62.4 & **65.4** & 21.5 & **26.8** & 59.5 & **85.8** & 43.3 & **46.6** \\ \hline GPT & 350M & 14.7 & 15.2 & 20.6 & 0.9 & 4.3 & 0.9 & 33.8 & 41.6 & 12.5 & 0.8 \\  & 1.3B & 12.0 & 19.2 & 45.8 & 35.7 & 4.0 & 1.4 & 0.0 & 26.9 & 20.8 & 9.2 \\  & 6.7B & 19.0 & **24.0** & 53.6 & 50.0 & 8.9 & 4.9 & 0.0 & 4.4 & 17.5 & **35.0** \\  & 175B & 79.5 & 73.5 & 65.9 & 65.4 & 43.8 & **52.1** & 69.6 & **82.4** & 81.7 & **87.5** \\ \hline Codex & - & 82.3 & 77.9 & 67.1 & **73.2** & 49.0 & **64.8** & 71.7 & **98.5** & 85.8 & **88.3** \\ \hline PaLM & 8B & 19.8 & **24.9** & 55.6 & 53.5 & 12.9 & 13.1 & 55.1 & **75.2** & 34.2 & **40.0** \\  & 62B & 65.4 & **68.1** & 58.4 & **63.4** & 29.8 & **44.7** & 72.1 & **93.6** & 65.8 & **70.0** \\  & 540B & 78.1 & **79.9** & 68.6 & **77.8** & 49.0 & **65.3** & 80.5 & **95.4** & 80.8 & **91.7** \\ \hline \hline \end{tabular}
\end{table}
표 4: 5개의 상식 추론 벤치마크에 대한 표준 프롬프트 대 사고 사슬 프롬프트. 사고 재촉의 사슬은 모델 척도의 창발적 능력이며, 충분한 척도의 모델과 함께 사용할 때까지 성능에 긍정적인 영향을 미치지 않는다.

\begin{table}
\begin{tabular}{l r r r r r r r r r r} \hline \hline  & & \multicolumn{2}{c}{Last Letter Concatenation} & \multicolumn{4}{c}{Coin Flip (state tracking)} \\ \cline{3-10}  & & 2 & OOD: 3 & OOD: 4 & 2 & OOD: 3 & OOD: 4 \\ \cline{2-10} Model & & standard & CoT & standard & CoT & standard & CoT & standard & CoT \\ \hline UL2 & 20B & 0.6 & **18.8** & 0.0 & 0.2 & 0.0 & 0.0 & 70.4 & 67.1 & 51.6 & 52.2 & 48.7 & 50.4 \\ \hline LaMDA & 420M & 0.3 & **1.6** & 0.0 & 0.0 & 0.0 & 52.9 & 49.6 & 50.0 & 50.5 & 49.5 & 49.1 \\  & 2B & 2.3 & **6.0** & 0.0 & 0.0 & 0.0 & 54.9 & **55.3** & 47.4 & 48.7 & 49.8 & 50.2 \\  & 8B & 1.5 & **11.5** & 0.0 & 0.0 & 0.0 & 0.0 & 52.9 & **55.5** & 48.2 & 49.6 & 51.2 & 50.6 \\  & 68B & 4.4 & **52.0** & 0.0 & **0.8** & 0.0 & **2.5** & 56.2 & **83.2** & 50.4 & **69.1** & 50.9 & **59.6** \\  & 137B & 5.8 & **77.5** & 0.0 & **34.4** & 0.0 & **13.5** & 49.0 & **99.6** & 50.7 & **91.0** & 49.1 & **74.5** \\ \hline PaLM & 8B & 2.6 & **18.8** & 0.0 & 0.0 & 0.0 & **0.2** & 60.0 & **74.4** & 47.3 & **57.1** & 50.9 & **51.8** \\  & 62B & 6.8 & **85.0** & 0.0 & **59.6** & 0.0 & **13.4** & 91.4 & **96.8** & 43.9 & **91.0** & 38.3 & **72.4** \\  & 540B & 7.6 & **99.4** & 0.2 & **94.8** & 0.0 & **63.0** & 98.1 & **100.0** & 49.3 & **98.6** & 54.8 & **90.2** \\ \hline \hline \end{tabular}
\end{table}
표 5: 표준 프롬프트 대 생각 프롬프트의 체인은 두 심볼릭 조작 태스크에 대한 더 긴 추론 예들로의 길이 일반화를 가능하게 한다.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & GSM8K & SVAMP & ASDiv & MAWPS \\ \hline Standard prompting & 6.5 \(\pm\)0.4 & 29.5 \(\pm\)0.6 & 40.1 \(\pm\)0.6 & 43.2 \(\pm\)0.9 \\ Chain of thought prompting & 14.3 \(\pm\)0.4 & 36.7 \(\pm\)0.4 & 46.6 \(\pm\)0.7 & 57.9 \(\pm\)1.5 \\ Ablations & & & & \\ \hline \(\cdot\) equation only & 5.4 \(\pm\)0.2 & 35.1 \(\pm\)0.4 & 45.9 \(\pm\)0.6 & 50.1 \(\pm\)1.0 \\ \(\cdot\) variable compute only & 6.4 \(\pm\)0.3 & 28.0 \(\pm\)0.6 & 39.4 \(\pm\)0.4 & 41.3 \(\pm\)1.1 \\ \(\cdot\) reasoning after answer & 6.1 \(\pm\)0.4 & 30.7 \(\pm\)0.9 & 38.6 \(\pm\)0.6 & 43.6 \(\pm\)1.0 \\ Robustness & & & & \\ \hline \(\cdot\) different annotator (B) & 15.5 \(\pm\)0.6 & 35.2 \(\pm\)0.4 & 46.5 \(\pm\)0.4 & 58.2 \(\pm\)1.0 \\ \(\cdot\) different annotator (C) & 17.6 \(\pm\)1.0 & 37.5 \(\pm\)2.0 & 48.7 \(\pm\)0.7 & 60.1 \(\pm\)2.0 \\ \(\cdot\) intentionally concise style & 11.1 \(\pm\)0.3 & 38.7 \(\pm\)0.8 & 48.0 \(\pm\)0.3 & 59.6 \(\pm\)0.7 \\ \(\cdot\) exemplars from GSM8K (\(\alpha\)) & 12.6 \(\pm\)0.6 & 32.8 \(\pm\)1.1 & 44.1 \(\pm\)0.9 & 53.9 \(\pm\)1.1 \\ \(\cdot\) exemplars from GSM8K (\(\beta\)) & 12.7 \(\pm\)0.5 & 34.8 \(\pm\)1.1 & 46.9 \(\pm\)0.6 & 60.9 \(\pm\)0.8 \\ \(\cdot\) exemplars from GSM8K (\(\gamma\)) & 12.6 \(\pm\)0.7 & 35.6 \(\pm\)0.5 & 44.4 \(\pm\)2.6 & 54.2 \(\pm\)4.7 \\ \hline \hline \end{tabular}
\end{table}
표 6: 산술 추론 데이터 세트에 대한 절제 및 견고성 결과. 생각의 사슬은 일반적으로 삭제를 훨씬 능가합니다. "방정식만"은 표준 프롬프팅과 사고 프롬프팅의 연쇄 사이에서 수행되는데, 이는 방정식을 통한 중간 추론 단계를 허용하지만 자연 언어를 활용하지는 않기 때문이다. 생각 프롬프트의 사슬은 다른 주석자에 의해 작성된 프롬프트와 함께 사용되거나 다른 예제를 사용할 때 분산(예상대로)을 갖지만 여전히 큰 마진을 통해 표준 프롬프트보다 성능이 뛰어납니다. 표시된 표준 편차는 5개의 다른 무작위 종자가 있는 소수의 샷 프롬프트 예제의 다른 순서에 대한 것이다. GPT-3 및 PaLM에 대한 추가 쿼리는 제한적이고 비용이 많이 들기 때문에 LaMDA 137B에 대한 결과가 표시된다.

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline  & \multicolumn{3}{c}{Commonsense} & \multicolumn{3}{c}{Symbolic} \\ \cline{2-5}  & Date & Sports & SayCan & Concat & Coin \\ \hline Standard prompting & 21.5 \(\pm\)0.6 & 59.5 \(\pm\)3.0 & 80.8 \(\pm\)1.8 & 5.8 \(\pm\)0.6 & 49.0 \(\pm\)2.1 \\ Chain of thought prompting & 26.8 \(\pm\)2.1 & 85.8 \(\pm\)1.8 & 91.7 \(\pm\)1.4 & 77.5 \(\pm\)3.8 & 99.6 \(\pm\)0.3 \\ Ablations & & & & \\ \hline \(\cdot\) variable compute only & 21.3 \(\pm\)0.7 & 61.6 \(\pm\)2.2 & 74.2 \(\pm\)2.3 & 7.2 \(\pm\)1.6 & 50.7 \(\pm\)0.7 \\ \(\cdot\) reasoning after answer & 20.9 \(\pm\)1.0 & 63.0 \(\pm\)2.0 & 83.3 \(\pm\)0.6 & 0.0 \(\pm\)0.0 & 50.2 \(\pm\)0.5 \\ Robustness & & & & \\ \hline \(\cdot\) different annotator (B) & 27.4 \(\pm\)1.7 & 75.4 \(\pm\)2.7 & 88.3 \(\pm\)1.4 & 76.0 \(\pm\)1.9 & 77.5 \(\pm\)7.9 \\ \(\cdot\) different annotator (C) & 25.5 \(\pm\)2.5 & 81.1 \(\pm\)3.6 & 85.0 \(\pm\)1.8 & 68.1 \(\pm\)2.2 & 71.4 \(\pm\)11.1 \\ \hline \hline \end{tabular}
\end{table}
표 7: 상식 및 기호 추론에서 4가지 데이터 세트에 대한 절제 및 견고성 결과. 생각의 사슬은 일반적으로 삭제를 훨씬 능가합니다. 생각 프롬프트의 사슬은 다른 주석자에 의해 작성된 프롬프트와 함께 사용되거나 다른 예제를 사용할 때 분산(예상대로)을 갖지만 여전히 큰 마진을 통해 표준 프롬프트보다 성능이 뛰어납니다. 표시된 표준 편차는 5개의 다른 무작위 종자가 있는 소수의 샷 프롬프트 예제의 다른 순서에 대한 것이다. GPT-3 및 PaLM에 대한 추가 쿼리는 제한적이고 비용이 많이 들기 때문에 LaMDA 137B에 대한 결과가 표시된다. 예외는 SayCan 평가 세트가 120예에 불과하므로 여러 번 실행하는 데 비용이 덜 들기 때문에 여기에서 PaLM을 사용하여 SayCan을 실행한다는 것이다.

확장된 관련 작업

생각의 사슬 프롬프트는 프롬프트, 자연어 설명, 프로그램 합성/실행, 숫자 및 논리적 추론, 중간 언어 단계의 여러 사전 방향에서 영감을 받은 일반적인 접근법이다.

### Prompting

최근 대규모 언어 모델의 성공으로 프롬프팅을 통한 태스크 수행 능력 향상에 대한 관심이 높아지고 있다(Brown et al. (2020), Liu et al. (2021) for a survey 참조). 본 논문은 일반적인 프롬프트 접근법의 범주에 속하며, 이에 의해 입력 프롬프트는 단일 대형 언어 모델이 다양한 태스크를 더 잘 수행할 수 있도록 최적화된다(Li 및 Liang, 2021; Lester et al., 2021; Reif et al., 2022, _inter alia_).

한 최근의 작업 라인은 작업을 설명하는 명령어를 제공함으로써 작업을 수행하는 언어 모델의 능력을 향상시키는 것을 목표로 한다(Raffel et al., 2020; Wei et al., 2022; Ouyang et al., 2022; Sanh et al., 2022; Wang et al., 2022). 이 작업 라인은 메타 데이터와 함께 입력-출력 쌍도 증강하기 때문에 관련이 있다. 그러나 명령어는 태스크에 대한 입력을 증가시키는 반면(명령어는 일반적으로 입력에 선행됨), 생각의 연쇄 프롬프트는 언어 모델의 출력을 증가시킨다. 또 다른 관련 방향은 언어 모델들의 출력들을 순차적으로 결합하는 것이다; 인간-컴퓨터 상호작용(HCI) 작업(Wu 등, 2022, 2022)은 언어 모델들의 순차적인 세대들을 결합하는 것이 20인 사용자 연구에서 작업 결과들을 개선시킨다는 것을 보여주었다.

### 자연어 설명

또 다른 밀접하게 관련된 방향은 종종 모델 해석성을 향상시키는 것을 목표로 자연 언어 설명(NLE)을 사용한다(Zhou et al., 2020; Wiegreffe and Marasovic, 2021, _inter alia_). 그 작업 라인은 전형적으로 자연 언어 추론에 초점을 맞추고(Camburu et al., 2018; Yordanov et al., 2021; Bostrom et al., 2021), 최종 예측에 동시에 또는 이후에 설명을 생성한다(Marang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). 대조적으로, 이 논문에서 고려된 사고 처리의 연쇄는 최종 답변 전에 발생한다. 그리고 NLE는 대부분 신경망 해석성을 향상시키는 것을 목표로 하지만(Rajagopal et al., 2021), 체인-생각 프롬프트의 목표는 모델이 멀티-홉 추론 작업을 여러 단계로 분해할 수 있도록 하는 것이다-- 해석성은 단지 부작용이다. Marasovic et al.(2022)은 NLE를 사용한 프롬프트 기반 피니튜닝이 NLI와 분류 성능을 향상시키지만 설명 타당성을 평가하는 데 주로 초점을 맞추고 있음을 보여준다. 이에 비해 우리의 작업은 멀티홉 추론이 필요한 산술적, 상식적, 상징적 과제의 범위에 초점을 맞추고 있다.

### 프로그램 합성 및 실행

중간 추론 단계를 사용하는 것은 프로그램 합성 및 실행에서 오랜 역사를 가지고 있다(Zaremba and Sutskever, 2014, _inter alia_). 이러한 방향에 따른 최근의 작업에는 다수의 아키텍처 혁신(Cai et al., 2017; Dong et al., 2019; Yan et al., 2020)뿐만 아니라 대형 언어 모델의 사용(Chen et al., 2021; Austin et al., 2021)이 포함되었다. 우리와 가장 가까운 프로그램 실행 작업은 아마도 Nye 등(2021)일 것이며, 이는 대규모 언어 모델이 최대 10자리 추가를 수행하고 다항식을 평가하고 파이썬 프로그램을 실행할 수 있음을 보여준다. 프로그램을 생성한 후 실행하는 것은 추론의 한 유형으로 볼 수 있지만, 우리의 작업은 그러한 도메인 특정 프리미티브를 자연 언어로 일반화하고, 이는 개방 도메인이며 원칙적으로 모든 텍스트 대 텍스트 NLP 작업과 관련이 있다.

### 숫자 및 논리적 추론

숫자 및 논리 추론은 기계 학습 및 자연어 처리에서 오랫동안 연구되어 온 작업이었다(Lev et al., 2004, _inter alia_). 최근 작업은 또한 그래프 신경망(Ran et al., 2019)을 포함하는 미리 정의된 실행 가능 동작 세트로 BERT를 증강하고(Andor et al., 2019), 전문화된 트레이닝 프로시저를 사용하는 것과 같은 다양한 방식으로 언어 모델에 숫자 추론 능력을 주입하는 것을 목표로 했다(Piekos et al., 2021). 또 다른 작업 라인은 언어를 사용하여 자연 언어 형식 규칙에서 규칙을 구두화함으로써, 종종 언어 모델이 논리적 또는 형식적 추론을 수행할 수 있게 하는 것을 목표로 한다(Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).

아마도 여기서 가장 관련이 깊은 작품은 Recchia(2021)인데, 이는 피니튜닝이 기존에 연주자들에게 어려웠던 긴 손 모듈 연산이 가능하다는 것을 보여준다. 이 방향으로의 작업은 종종 작업에 따라 달라지며 피니튜닝을 사용하는 반면, 우리는 피니튜닝 없이 광범위한 작업에 대해 연쇄 사고 프롬프트가 작동한다는 것을 보여준다.

### 중간 언어 단계

광범위한 선행 연구는 훈련 또는 피니튜닝을 통해 중간 단계를 생성할 수 있는 능력을 신경 네트워크에 부여하는 이점이 다양한 시나리오에서 다양한 이점을 부여한다는 것을 보여주었다. 예들로서, 자연어 중간 단계들이 성능을 향상시킬 수 있다는 것이 보여졌다(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), 강건성 향상(Chen et al., 2022), 트레이닝 속도 향상(Hancock et al., 2018), 편향 완화(Dua et al., 2020), 및 심지어 이미지 및 강화 학습 설정에서의 도움(Andreas et al., 2018). 중간 단계들을 생성하는 능력을 가진 모델들에 부여하기 위해, 선행 작업은 통상적으로 수동으로 주석이 달린 트레이닝 데이터세트들(Camburu et al., 2018; Rajani et al., 2019, _inter alia_)에 모델을 피니튜닝하거나 합성 데이터세트들을 생성한다(Talmor et al., 2020; Zelikman et al., 2022). 이러한 훈련 또는 미세 조정 방법과 비교하여, 우리의 연구는 다양한 자연 언어 추론 능력이 촉진을 통해 충분한 규모의 기성 언어 모델에서 유도될 수 있음을 보여준다. 이 프롬프트 설정은 많은 수의 라벨링된 주석 없이 중간 단계 추론을 허용하고 단일 모델이 구배 업데이트 없이 다양한 추론 작업을 수행할 수 있기 때문에 중요하다.

## Appendix D Appendix: 추가 분석

### Thought Analysis의 올바른 체인

본문에서 언급한 바와 같이, 우리는 GSM8K 데이터 세트에서 정답으로 이어진 LaMDA 137B의 50개의 사고 사슬을 분석한다. 이 50개 중 한 명만이 잘못된 추론을 통해 정답에 도달하였다(표 9: "우연히 정답"). 나머지 49명은 표 8과 같은 예제와 함께 올바른 논리와 수학을 가지고 있었다. 5명은 일관되고 이해할 수 있는 논리를 유지하면서 사소한 불완전성을 가지고 있었다.

* 특정되지 않은 문장(표 9에 표시됨: "정확하지만 지정되지 않은 문장")이 있습니다.
* 관련 없지만 올바른 문장을 만들었습니다 (표 9에 표시: "정답하지만 관련 없는 문장").
* 2는 올바른 논리를 가지고 있지만 여전히 이해할 수 있지만 방정식의 특정 단계를 생략했습니다 (표 9에 표시: "정확하지만 불완전한 방정식").
* 하나는 정확한 수학이 있었지만 의미론을 반전시켰다(표 9에 도시됨: "정확하지만 반전된 의미론")

최종 답안이 정확했던 수학 문제에서는 연쇄 추론이 대부분 옳다는 것을 발견하지만, 자유 답안 문제에서는 우연의 일치로 정확한 최종 답안에 도달하기 어렵기 때문일 것이다. 다중 선택 또는 이진 분류 문제의 경우 훨씬 더 많았다.

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** 제임스는 일주일에 3번 3번의 스프린트를 실행하기로 결정합니다. 그는 단거리 달리기마다 60미터를 달린다. 그는 일주일에 총 몇 미터나 달려요?
**Model Answer (CORRECT):** James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. \(\checkmark\) \\ \hline
**질문:** Brandon의 iPhone은 Ben의 iPhone보다 4배 더 오래되었습니다. 벤의 아이폰은 수지의 아이폰보다 두 배나 많다. 만약 수지의 아이폰이 1살이라면, 브랜든의 아이폰은 몇 살일까요? \\
**Model Answer (CORRECT):** Brandon’s iPhone is 4 times as old as Ben’s iPhone. Ben’s iPhone is 2 times older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone is 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. \(\checkmark\) \\ \hline
**질문:** Jean에는 30개의 막대 사탕이 있습니다. 진은 막대사탕 2개를 먹는다. 남은 막대사탕과 함께 진은 막대사탕 2개를 한 봉지에 포장하고 싶어합니다. 진은 몇 봉지를 채울 수 있나요?
**Model Answer (CORRECT):** Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops left. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. \(\checkmark\) \\ \hline \hline \end{tabular}
\end{table}
표 8: GSM8K 데이터세트에 대한 모델에 의해 생성된 올바른 사고 사슬의 예.

아마도 모델은 잘못된 추론 경로(예: 우리가 평가하는 모든 명령 추론 데이터 세트)를 통해 정답에 도달할 수 있다. 이것은 한계이며, 향후 작업은 그러한 사고 사슬의 사실성에 대한 분석을 수행해야 한다.

**모델 답변** (정확하지만 불완전한 방정식): Nissa는 60명의 계절 작업자를 고용합니다. 그들 중 3분의 1이 그만두었다. 그래서 60 - 1/3 = 40마리의 요정이 남았습니다. 그리고 나서 10명의 요정이 그만두었다. 그래서 40 - 10 = 30마리의 요정이 남았습니다. 대답은 30명의 요정입니다.

**질문:**: 존스 할머니가 소방관 오찬을 위해 사과 파이 5개를 구웠습니다. 그녀는 각 파이를 8조각으로 자르고 다섯 개의 파이를 뷔페 테이블에 차려 손님들이 직접 서빙할 수 있도록 했다. 저녁이 끝날 무렵 손님들이 자신의 파이 조각을 가져다가 먹은 뒤 14개의 파이 조각이 남아 있었다. 손님들이 얼마나 많이 가져갔나요?

**모델 답변** (정답이지만 반전된 의미): 5개의 파이를 굽고 각각 8개로 자릅니다. 그런 다음 5개의 파이가 손님들에게 제공되었습니다. 8 x 5 = 40개의 파이 조각입니다. 14조각 파이의 손님들. 40 - 14 = 26 조각의 파이가 남겨졌다. 답은 26입니다. \(\checkmark\)

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** 눈에는 36마리의 펭귄이 일광욕을 합니다. 그들 중 1/3은 바다에 뛰어들어 수영을 합니다. 또 다른 3분의 1은 저녁을 먹기 위해 동굴 안으로 들어간다. 얼마나 많은 펭귄들이 아직도 일광욕을 하고 있나요? \\
**Model Answer** (correct by chance): There are 36 penguins. One-third of them jump in and swim in the ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins. The answer is 12. \\ \hline
**질문:** John에는 각각 3개의 침실이 있는 2개의 집이 있습니다. 각 침실에는 각각 2개의 창문이 있습니다. 각 집에는 침실과 연결되지 않은 4개의 창문이 추가로 있습니다. 집 사이에 총 창문이 몇 개 있나요?
**Model Answer** (correct but underspecified statements): There are 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional 4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are 6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20. \\ \hline
**질문:** 앤이 9세이고 동생이 2배라면 3년 후에는 동생이 몇 살일까요? \\
**Model Answer** (correct but unrelated statement): Ann is 9 years old. Her brother is twice her age. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The answer is 21. \\ \hline
**질문:** 지역 주유소에서 갤런당 $3.00에 가스를 판매하고 있습니다. 앱 회사는 이 역에서 충전하면 갤런당 $.20 캐시백을 제공합니다. 만약 누군가가 10갤런의 가스를 산다면, 캐쉬백 보상을 받은 후, 그들의 가스로 얼마가 될까요? \\
**Model Answer** (correct but imperfect equation): The gas is originally 3 dollars per gallon. If you buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So the total is 30 - 2 = 28 dollars. The answer is 28 dollars. \\ \hline
**질문:** Nissa는 백화점 산타 마을에서 요정 역할을 하기 위해 60 명의 계절 근로자를 고용 합니다. 아이들이 토한 후 엘프 중 3분의 1은 그만두고 나머지 엘프 중 10명은 아이들이 정강이를 걷어차고 나서 그만둔다. 요정이 몇 명이나 남았죠?
**Model Answer** (correct but imperfect equation): Nissa hires 60 seasonal workers. A third of them quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30 elves. \\ \hline
**질문:** 존스 할머니는 소방관 오찬을 위해 사과 파이 5개를 구웠습니다. 그녀는 각 파이를 8조각으로 자르고 다섯 개의 파이를 뷔페 테이블에 차려 손님들이 직접 서빙할 수 있도록 했다. 저녁이 끝날 무렵 손님들이 자신의 파이 조각을 가져다가 먹은 뒤 14개의 파이 조각이 남아 있었다. 손님들이 얼마나 많이 가져갔나요?
**Model Answer** (correct but inverted semantics): 5 pies were baked and cut into 8 pieces each. The 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests at 14 pieces of pie. 40 - 14 = 26 pieces of pie were left. The answer is 26. \(\checkmark\) \\ \hline \hline \end{tabular}
\end{table}
표 9: 모델이 올바른 50개의 예들 중, 생성된 모델이 불완전하다고 생각하는 연쇄가 7개의 두드러진 사례들이 있었다. 우리는 나머지 43개가 인간이 잠재적으로 지상 진리로 생성할 것과 동등하다는 것을 발견했다.

### Thought Analysis의 잘못된 체인

또한 LaMDA 137B에 대한 GSM8K에서 부정확한 모델의 무작위로 샘플링된 50개의 출력을 수동으로 분석한다. 사고의 사슬이 틀릴 수 있는 많은 방법이 있어 오류 범주화의 설계는 자명하지 않다. 우리는 미래에 모델이 어떻게 개선될 수 있는지 밝히는 것을 목표로 사고의 사슬을 올바르게 만들기 위해 필요한 변화로 오류를 분류하기로 결정했다.

우리는 다음의 세 가지 종류의 수정 중 하나로 많은 사고 사슬이 올바르게 만들어질 수 있음을 발견했다.

* **계산기 오류만.** 계산기 오류를 제외하고 생각 체인의 8%가 완전히 정확하다는 것을 발견했습니다. 즉, Cobbe 등(2021)에서 수행한 대로 외부 계산기를 방정식에 적용하면 생각 체인이 올바르게 만들어집니다. 이러한 유형의 에러의 예는 표 10: "계산기 에러만"과 같다. 실제로 LaMDA 137B GSM8K에 대한 연쇄 사고 프롬프트 해결률은 표 2와 같이 파이썬 프로그램을 외부 계산기로 추가했을 때 14.3%에서 17.3%로 증가했다. 또한 예제의 34%는 다른 유형의 오류 외에도 계산기 오류를 포함했다. 그러나 계산기 오류와 독립적으로 나머지 오류 분류를 수행한다.
* **기호 매핑 오류.** 다음으로 기호 매핑 오류라고 하는 것을 제외하고 생각 체인의 16%%가 정확하다는 것을 발견했습니다. 우리는 기호 매핑 오류를 숫자 기호를 제외하고 사고 사슬이 올바른 경우로 정의하며, 단어가 아닌 방정식만 수정하면 완전히 올바르게 만들 수 있다. 어떤 사고 사슬에 올바른 최종 방정식을 단순히 배치할 수 있다고 주장할 수 있듯이, 우리는 사고 사슬이 완전히 올바른 추론 과정(최종 답만이 아니라)으로 수정될 수 있는 사고 사슬로 이 범주를 제한한다. 이 에러 카테고리의 예는 표 10: "심볼 맵핑 에러"에 도시된다.
* **한 단계 누락 오류.** 다음 오류 범주는 단일 단계를 누락했다는 점을 제외하고 올바른 사고 체인입니다. 즉, 이러한 사고의 사슬은 모델에 의해 누락된 추가 추론 단계에서 추가함으로써 정확하도록 다시 쓰여질 수 있다. 이 에러 카테고리의 예는 표 10: "하나의 스텝 누락 에러"에 도시되어 있다. 우리는 오류의 22%가 이 범주에 속한다는 것을 발견했다.

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** Dan 식물 3 장미 덤불입니다. 각 장미 덤불에는 25개의 장미가 있습니다. 각 장미에는 8개의 가시가 있다. 가시는 총 몇 개인가요?
**모델 답변(잘못된 계산기 오류만):** Dan 플랜트 3 장미 덤불입니다. 각 장미 덤불에는 25개의 장미가 있습니다. 각 장미에는 8개의 가시가 있다. 그래서 3 x 25 x 8 = 300. 답은 300. ✗ \\
**Explanation for Error Category:** The produced chain of thought could be made correct just by running the equation through an external calculator, instead of asking the model to do the computation. \\ \hline
**질문:** 질은 가르치기 위해 시간당 20달러를 받고 치어리더 코치가 되기 위해 30달러를 받습니다. 만약 그녀가 일년에 50주, 교사로서 일주일에 35시간, 코치로서 일주일에 15시간을 일한다면, 그녀의 연봉은 얼마인가?
**모델 답변 (잘못된 기호 매핑 오류):** 질은 가르치는 데 시간당 20 달러, 치어리더 코치가 되는 데 시간당 30 달러를 받습니다. 그녀가 1년에 50주, 교사로서 일주일에 35시간, 코치로서 일주일에 15시간을 일한다면, 그녀는 교사로서 50 x 35 = 1750시간, 코치로서 15 x 30 = 450시간을 일합니다. 그래서 그녀는 1750 + 450 = 2200시간 일한다. 그녀는 1750시간에 시간당 20달러, 450시간에 시간당 30달러를 받습니다. 그녀의 연봉은 20 x 1750 + 30 x 450 = 536,500입니다.
**Explanation for Error Category:** The model incorrectly mapped “15 x 30” instead of “15 x 50”, and the chain of thought would be made correct by fixing just that one change (with an external calculator). \\ \hline
**질문:** 켈리안에는 요리를 준비 하는 두 가지 레시피가 있습니다. 하나는 20 개의 지침을 사용 하 고 두 번째는 첫 번째 지침보다 두 배 많은 지침을 사용 합니다. 켈리안은 두 가지 요리를 준비하기 위해 몇 가지 지침을 읽어야 하는가? \\
**모델 답변(잘못된 경우, 한 단계 누락 오류):** 켈리언에는 두 가지 레시피가 있습니다. 하나는 20가지 지침이 있습니다. 다른 하나는 첫 번째 것보다 두 배 많은 지침을 가지고 있습니다. 두 번째는 40가지 지침이 있습니다. 그래서 켈리안은 두 가지 요리를 준비하기 위해 40가지 지침을 읽어야 합니다. 답은 40입니다. ✗ \\
**Explanation for Error Category:** The model answer could be made correct just adding one additional step (in this case, adding 20 and 40). \\ \hline \hline \end{tabular}
\end{table}
표 10: 부록 D.2에 설명된 대로 분류된 잘못된 사고 사슬의 예.

우리는 나머지 사고 사슬(50개 중 27개, 54%)이 올바른 사고 사슬을 만들기 위해 상당한 편집이 필요하다는 것을 발견했다. 여기서의 거의 모든 사례는 의미론적 이해의 일부 오류(표 11: "의미론적 이해 오류" 참조)를 포함했으며 27개 중 8개도 비동기적 사고 사슬을 가지고 있었는데, 이는 생성된 사고 사슬의 일부 진술이 이전 진술에서 따르지 않았거나 기본 세계 지식을 위반했음을 의미한다(표 11: "비동기적 사고 사슬" 참조).

전반적으로, 언어 모델 세대들 및 설명들의 사실성을 평가하는 최근의 작업에 의해 강조된 바와 같이, 대형 언어 모델들에 의해 생성된 추론 프로세스들이 일관성 있거나 사실적으로 정확하다는 보장은 없다(Maynez et al., 2020; Rashkin et al., 2021; Ye and Durrett, 2022; Marasovic et al., 2022; Wiegreffe et al., 2022). 잘못된 추론 프로세스는 잘못된 최종 답변뿐만 아니라 실수로 정확한 최종 답변을 모두 초래할 수 있다(자유 응답과는 대조적으로 이진 분류와 같은 작업에 대해 우연히 정확한 최종 답변이 더 가능성이 높다). 상황 및 세계 지식과 관련하여 언어 모델 세대의 사실성을 향상시키는 것은 언어 모델 연구에서 열린 중요한 방향 문제이며 또한 잠재적으로 언어 모델의 다단계 추론 능력을 향상시킬 것으로 예상할 수 있다. 디코딩의 품질을 개선하기 위한 하나의 잠재적인 방법은 다수의 추론 경로들을 생성하고 그들 각각을 검증기로 스코어링하는 것을 수반할 수 있지만, 이는 검증기를 트레이닝하는 것을 필요로 한다(Cobbe et al., 2021; Shen et al., 2021; Thoppilan et al., 2022).

### 추가 견고성 분석

본 논문의 실험은 고정된 수의 few-shot 예시(8; 1024 토큰의 입력 길이에 의해 구속됨)를 사용하므로, 다양한 수의 few-shot 예시들에 대해 체인-생각 프롬프트가 강건함을 검증한다. 우리는 LaMDA 137B에 대한 실험을 실행하며, 표준 프롬프트가 대부분 평평한 스케일링 곡선을 갖는 5개의 데이터 세트에 대한 표준 프롬프트와 비교한다(가장 큰 모델은 높은 성능을 달성하지 못했다). 도 11에 도시된 바와 같이, 표준 프롬프팅에 비해 연쇄-생각 프롬프팅의 개선은 프롬프트에서 소수의 샷 예시들의 수를 변화시키는 것에 대해 견고하게 유지된다.

\begin{table}
\begin{tabular}{p{34.1pt}} \hline \hline
**질문:** 그레첸에는 110개의 코인이 있습니다. 은화보다 금화가 30개 더 많습니다. 그레첸은 몇 개의 금화를 가지고 있나요?
**모델 답변(잘못된 경우 의미 이해 오류):** 그레첸에는 110개의 코인이 있습니다. 은화보다 금화가 30개 더 많습니다. 그래서 110 - 30 = 80 은화가 있습니다. 그래서 80개의 은화와 110 - 80 = 30개의 금화가 있습니다. 응답은 30입니다. ✗ \\
**오류 범주에 대한 설명:** 모델은 총 110개의 동전이 있으며 금은화의 수를 얻으려면 방정식을 풀어야 한다는 것을 이해하지 못합니다. \\
**질문:** 20명의 학생으로 구성된 댄스 수업에서 20%는 컨템포러리 댄스에 등록하고, 나머지 25%는 재즈 댄스에 등록하며, 나머지는 힙합 댄스에 등록합니다. 힙합 댄스에 등록한 전체 학생 중 몇 퍼센트가?
**모델 답변(잘못된 경우, 일관성 없는 사고 오류 연쇄):** 20\%의 학생들이 현대 무용에 등록했습니다. 나머지 학생들의 25\%가 재즈댄스에 등록하였다. 나머지는 힙합 댄스에 등록했다. 힙합 댄스에 등록한 전체 학생들의 비율은 힙합 댄스에 등록한 학생들의 비율이고 재즈 댄스에 등록한 학생들의 비율을 뺀 것입니다. 따라서 힙합댄스에 등록한 전체 학생의 비율은 (25 + 20) - (25 + 20) = 100\%이다.
**Explanation for Error Category:** This chain of thought is incoherent in that the percent of entire students enrolled in hip-hop dance cannot be the percent of student enrolled in hip-hop dance minus another term. \\ \hline \hline \end{tabular}
\end{table}
표 11: 부록 D.2에 설명된 대로 범주화된 잘못된 사고 사슬의 예. 이러한 사고 사슬은 사소한 편집으로 고칠 수 없는 여러 오류가 있었다.

\begin{table}
\begin{tabular}{l r l} \hline \hline Dataset & \(N\) & Example problem \\ \hline GSM8K & 1,319 & Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make? \\ \hline SVAMP & 1,000 & Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each pack. How much do you have to pay to buy each pack? \\ \hline ASDiv & 2,096 & Ellen has six more balls than Marin. Marin has nine balls. How many balls does Ellen have? \\ \hline AQuA & 254 & A car is being driven, in a straight line and at a uniform speed, towards the base of a vertical tower. The top of the tower is observed from the car and, in the process, it takes 10 minutes for the angle of elevation to change from 45\({}^{\circ}\) to 60\({}^{\circ}\). After how much more time will this car reach the base of the tower? Answer Choices: (a) \(5\sqrt{3}\) + 1 (b) \(6\sqrt{3}\) + \(\sqrt{2}\) (c) \(7\sqrt{3}\) - 1 (d) \(8\sqrt{3}\) - 2 (e) None of these \\ \hline MAWPS: SingleOp & 562 & If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how many bottle caps are in the box? \\ \hline MAWPS: SingleEq & 508 & Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27 dollars. How much did each candy bar cost? \\ \hline MAWPS: AddSub & 395 & There were 6 roses in the vase. Mary cut some roses from her flower garden. There are now 16 roses in the vase. How many roses did she cut? \\ \hline MAWPS: MultiArith & 600 & The school cafeteria ordered 42 red apples and 7 green apples for students lunches. But, if only 9 students wanted fruit, how many extra did the cafeteria end up with? \\ \hline \hline \end{tabular}
\end{table}
표 12: 본 논문에서 사용한 수학 단어 문제 벤치마크의 요약예와 함께 \ (N\): 평가예의 수.

그림 11: 표준 프롬프트에 비해 사고 프롬프트의 체인 개선은 프롬프트에서 몇 개의 샷 예제의 수를 변화시키는 데 강력해 보인다.

Additional Details

### Version Control

**V5 \(\rightarrow\) V6**. 그림 3의 고정 마이너 오타입니다.

**V4 \(\rightarrow\) V5**. 코덱스 및 UL2 결과를 추가했습니다. 글쓰기와 종이의 스타일에 작은 변화.

**V3 \(\rightarrow\) V4**. 그림 3의 고정 오타를 추가하고 몇 가지 인용을 추가했다.

**V2 \(\rightarrow\) V3**. GPT-3 결과를 추가하였다. 수학을 위한 SVAMP 및 AQuA 평가 데이터 세트를 추가했다. 상식에 대한 세이캔 평가를 추가했습니다. 확장 관련 작업 섹션(부록 C)이 추가되었습니다. 상식 및 상징적 추론에 대한 삭제를 추가했다(표 7). FAQ 섹션 추가(부록 A)입니다. 부록 B에 원시 결과를 추가했다.

**V1 \(\rightarrow\) V2**. PaLM 결과를 추가하였다(V1은 LaMDA만을 가졌다).

### Reproducibility Statement

우리의 결과는 공개적으로 사용할 수 없는 두 세트의 대규모 언어 모델을 사용하기 때문에 재현성을 용이하게 하기 위해 다음과 같은 조치를 취한다. 첫째, 부록 G의 표 20-표 27의 모든 태스크에 대한 정확한 입력 프롬프트를 제공한다(그리고, 어떠한 피니튜닝도 수행하지 않고 단지 기성 언어 모델에 프롬프팅만을 적용한다는 것을 강조함). 둘째, 4가지 모델 스케일 텍스트-ada-001, 텍스트-babbage-001, 텍스트-curie-001, 텍스트-davinci-002)에 대해 공개적으로 이용 가능한 GPT-3 API를 사용하여 실험을 수행한다. 마지막으로, 추가 자료에서 zip 파일로 사용할 수 있는 각 작업에 대한 LaMDA 137B에 대한 정확한 입력, 목표 및 예측을 수행한다.

### Computational Resources

우리가 평가한 세 가지 언어 모델 모두에 대해 프롬프트 기반 추론만 수행했다. 이 논문에 대한 피니튜닝은 수행되지 않았다. LaMDA 137B에 대한 추론을 위해 TPU v3(8x8 구성, 64 칩/128 코어)를 사용하고, PaLM 540B에 대한 추론을 위해 TPU v4(4x4x12 구성, 192 칩/384 코어)를 사용한다. GPT-3 실험은 공개 API.5를 사용하여 수행되었다.

각주 5: [https://beta.openai.com/docs/api-reference/making-requests](https://beta.openai.com/docs/api-reference/making-requests)

### 데이터 세트 세부 정보 및 라이선스

이 문서에 사용된 모든 산술 및 상식 데이터 세트에 대한 세부 정보와 라이선스를 나열한다. 기호 추론 데이터 세트는 섹션 4에 설명된 대로 종합적으로 생성되었다.

#### Arithmetic reasoning

* Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini et al., 2014): [https://www.cs.washington.edu/nlp/arithmetic](https://www.cs.washington.edu/nlp/arithmetic); MultiArith (Roy and Roth, 2015), 라이선스: CC BY 4.0.
* ASDiv (Miao et al., 2020): [https://github.com/chaochun/nlu-asdiv-dataset](https://github.com/chaochun/nlu-asdiv-dataset).
* AQuA (링 등, 2017): [https://github.com/deepmind/AQuA](https://github.com/deepmind/AQuA), 라이선스: [https://github.com/deepmind/AQuA/blob/master/LICENSE](https://github.com/deepmind/AQuA/blob/master/LICENSE)
* GSM8K (Cobbe et al., 2021): [https://github.com/openai/grade-school-math](https://github.com/openai/grade-school-math), MIT 라이선스: [https://github.com/openai/grade-school-math/blob/master/LICENSE](https://github.com/openai/grade-school-math/blob/master/LICENSE).
* SVAMP(Patel 등, 2021): [https://github.com/arkilpatel/SVAMP](https://github.com/arkilpatel/SVAMP), MIT 라이선스: [https://github.com/arkilpatel/SVAMP/blob/main/LICENSE](https://github.com/arkilpatel/SVAMP/blob/main/LICENSE).

#### Commonsense reasoning

* CSQA (Talmor et al., 2019): [https://www.tau-nlp.org/commonsenseqa](https://www.tau-nlp.org/commonsenseqa), [https://github.com/jonathanherzig/commonsenseqa](https://github.com/jonathanherzig/commonsenseqa).

* StrategyQA(Geva 등, 2021): BIG-bench 협업(2021)의 오픈 도메인 설정(질문 전용 세트)을 사용합니다. [https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/strategyqa](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/strategyqa). 원래 데이터 세트는 [https://github.com/eladsegal/strategyqa](https://github.com/eladsegal/strategyqa), MIT 라이선스: [https://github.com/eladsegal/strategyqa/blob/main/LICENSE](https://github.com/eladsegal/strategyqa/blob/main/LICENSE)입니다.
* BIG-Bench(BIG-bench 협업, 2021): Apache 라이선스 v.2: [https://github.com/google/BIG-bench/blob/main/LICENSE](https://github.com/google/BIG-bench/blob/main/LICENSE)
* SayCan (Ahn et al., 2022): SayCan 데이터 세트는 CC BY 4.0 라이선스에서 [https://say-can.github.io/](https://say-can.github.io/)에서 액세스할 수 있습니다.

[MISSING_PAGE_EMPTY:32]

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** Exorcist가 변연계를 자극할까요? \\
**Model Answer (CORRECT):** The Exorcist is a horror movie. Horror movies are scary. The limbic system is involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. \(\checkmark\) \\ \hline
**질문:** Jackson Pollock이 Leonardo da Vinci에 의해 훈련되었습니까? \\
**Model Answer (CORRECT):** Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the 20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. \(\checkmark\) \\ \hline
**질문:** 해리 포터가 아시아나항공에서 항공편을 예약할 수 있습니까? \\
**Model Answer (INCORRECT):** Harry Potter is a fictional character. Thus, Harry Potter can do anything. So the answer is yes. �(Ground truth is “no”.) \\ \hline
**질문:** 소피스트가 epée를 사용하나요? \\
**Model Answer (INCORRECT):** A sophist is a person who is skilled in the art of persuasion. An epée is a type of sword. Thus, a sophist could use an epée. So the answer is yes. �(Ground truth is “no”.) \\ \hline \hline \end{tabular}
\end{table}
표 16: StrategyQA에 대한 LaMDA 137B에 의해 생성된 사고의 올바르고 잘못된 사슬의 예.

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** 1992년 5월 6일은 Jane에게 어제와 같습니다. 그러나 실제로 10년 전입니다. 한 달 전 MM/DD/YYYY 날짜는 어떻게 되나요? \\
**Model Answer (CORRECT):** May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will be April 6, 2002. So the answer is 04/06/2002. \(\checkmark\) \\ \hline
**질문:** 1899년의 마지막 날입니다. MM/DD/YYYY에서 24시간 후 날짜는 무엇입니까? \\
**Model Answer (CORRECT):** Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is 01/01/1900. \(\checkmark\) \\ \hline
**질문:** 제인은 내일을 위해 5명과 3번의 약속을 예약했습니다 (화, 7/9/1972). 오늘부터 일주일 전 MM/DD/YYYY 날짜는 어떻게 되나요? \\
**Model Answer (INCORRECT):** Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the answer is 7/2/1972. �(Ground truth is 07/01/1972.) \\ \hline
**질문:** 날짜의 MMDDYYY 형식은 앞과 뒤가 동일하기 때문에 오늘은 2020년의 회문 날짜입니다. 내일 MM/DD/YYYY 날짜는 어떻게 되나요? \\
**Model Answer (INCORRECT):** Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is 03/01/2020. �(Ground truth is “02/03/2020”.) \\ \hline \hline \end{tabular}
\end{table}
표 17: 날짜 이해에서 LaMDA 137B에 의해 생성된 올바른 및 잘못된 사고 사슬의 예.

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** 다음 문장이 그럴듯한가요? “주오 무티뉴가 3루에 아웃되었다.” \\
**Model Answer (CORRECT):** Joao Moutinho is a soccer player. Being out at third is part of baseball, not soccer. So the answer is no. \(\checkmark\) \\ \hline
**질문:** 다음 문장이 그럴듯한가요? “Malcolm Brogdon Eurostepped to the basket in the NBA Championship.”
**Model Answer (CORRECT):** Malcolm Brogdon is a basketball player. Eurostepping to the basket is part of basketball. So the answer is yes. \(\checkmark\) \\ \hline
**질문:** 다음 문장이 그럴듯한가요? '데릭 화이트 백핸드 한 방'
**Model Answer (INCORRECT):** Derrick White is a basketball player. Backhanding a shot is part of basketball. So the answer is yes. �(Ground truth is “no”, backhanding a shot is part of hockey.) \\ \hline
**질문:** 다음 문장이 그럴듯한가요? “나젬 카드리는 집에 없었다.” \\
**Model Answer (INCORRECT):** Nazem Kadri is a hockey player. Being out at home is part of hockey. So the answer is yes. �(Ground truth is “no”, being out at home is part of baseball.) \\ \hline \hline \end{tabular}
\end{table}
표 16: StrategyQA에 대한 LaMDA 137B에 의해 생성된 사고의 올바르고 잘못된 사슬의 예.

\begin{table}
\begin{tabular}{l} \hline \hline
**질문:** 테이블에 콜라를 흘렸는데, 버린 다음 청소하는 데 도움이 되는 것을 가져올 수 있나요? \\
**Model Answer** (**Correet**): Explanation: The user has spilled their coke on the table. I will throw away the coke and then bring the user a sponge. Plan: find(coke), pick(coke), find(trash), put(coke), find(sponge), pick(sponge), find(table), put(sponge). \\ \hline
**질문:** 저 사과를 퇴비화할 수 있습니까? \\
**Model Answer** (**Correet**): Explanation: The user would like me to compost the apple. I will move the apple to the compost. Plan: find(apple), pick(apple), find(trash), put(apple). \\ \hline
**질문:** 콜라가 아닌 음료를 가져올 수 있습니까? \\
**Model Answer** (**INCORRECT**): Explanation: The user asked me to bring a drink that is not coke, I will bring a sprite. Plan: find(sprite), pick(sprite), find(user), put(sprite). \(\mathcal{X}\) (Feasible answers including finding lime \\ soda, pepsi, grapefruit soda or water, because there is no sprite in the scene as defined in Table 28.) \\ \hline
**질문:** 짠 것 좀 가져다 주시겠어요? \\
**Model Answer** (**INCORRECT**): Explanation: The user would like something salty. There are several options in the objects list, so I will bring the user a lime soda. Plan: find(lime soda), pick(lime soda), find(user), put(lime soda). \(\mathcal{X}\) (Feasible answers including finding chips. The model misidentify lime soda as salty.) \\ \hline \hline \end{tabular}
\end{table}
표 19: SayCan 로봇 계획 작업에 대한 PaLM 540B에 의해 생성된 올바르고 잘못된 사고 사슬의 예.

[MISSING_PAGE_EMPTY:35]

\begin{table}
\begin{tabular}{l} \hline \hline
**마지막 문자 연결에 대한 프롬프트** \\
**Q:** "Elon Musk"에 있는 단어의 마지막 글자를 가져와서 연결합니다. \\
**A:** "Elon"의 마지막 문자는 "n"입니다. "Musk"의 마지막 글자는 "k"입니다. 그들을 연결하는 것은 "nk"이다. 답은 nk입니다. \\
**Q:** "래리 페이지"에 있는 단어의 마지막 글자를 가져와서 연결합니다. \\
**A:** "래리"의 마지막 글자는 "y"입니다. "페이지"의 마지막 글자는 "e"이다. 그들을 연결하는 것은 "예"이다. 답은 ye입니다. \\
**Q:** "Sergey Brin"에 있는 단어의 마지막 글자를 가져와서 연결합니다. \\
**A:** "Sergey"의 마지막 문자는 "y"입니다. "브린"의 마지막 글자는 "n"이다. 그들을 연결하는 것은 "yn"이다. 응답은 동기화입니다. \\
**Q:** "빌 게이츠"에 있는 단어의 마지막 글자를 가져와서 연결합니다. \\
**A:** The last letter of “Bill” is “l”. The last letter of “Gates” is “s”. Concatenating them is “ls”. The answer is ls. \\ \hline \hline \end{tabular}
\end{table}
표 21: AQuA에 대한 사상 프롬프트의 전체 체인에 대한 적은 샷 예시.

\begin{table}
\begin{tabular}{l} \hline \hline
**AQuA 대수 단어 문제에 대 한 프롬프트** \\
**Q:** John은 15개의 숫자의 평균이 40이라는 것을 발견했습니다. 각 숫자에 10을 추가하면 숫자의 평균은? \\ 답변선택 : (a) 50(b) 45(c) 65(d) 78(e) 64 \\
**A:** 각 숫자에 10을 추가 하면 숫자의 평균도 10 증가 합니다. 따라서 새 평균은 (a)입니다. \\
**Q:** a/b = 3/4, 8a + 5b = 22 인 경우 a 값을 찾습니다. \\ 응답 선택: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2 \\
**A:** a/b = 3/4인 경우 b = 4a/3입니다. 따라서 8a + 5(4a/3) = 22입니다. 이는 8a + 20a/3 = 22로 단순화되며, 이는 44a/3 \\ \(\equiv\) 22를 의미합니다. 따라서 a는 3/2와 같습니다. 답은 (b)입니다. \\
**Q:** 한 사람이 시속 20 km로 이동 하 고 2.5 시간 만에 운명에 도달 하 고 거리를 찾습니까? \\ 답변선택: (a) 53km(b) 55km(c) 52km(d) 60km(e) 50km \\
**A:** 사람이 이동한 거리는 20km/hr * 2.5시간 = 50km입니다. 답은 (e). \\
**Q:** 1에서 500까지의 숫자를 입력하려면 몇 번의 키 입력이 필요합니까? \\ 답변 선택: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788 \\
**A:** There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392: The answer is (b). \\ \hline \hline \end{tabular}
\end{table}
표 22: 마지막 글자 연결 작업에 대한 전체 연쇄 사고 프롬프트에 대한 적은 샷 예시.

\begin{table}
\begin{tabular}{l} \hline
**Coin Flip 프롬프트** \\
**Q: Q: 동전이 앞에 표시됩니다. 카가 동전을 뒤집는다. 쉐리는 동전을 던진다. 동전이 아직도 앞에 있나요? \\
**A: Ka와 Sherrie에 의해 동전이 뒤집혔습니다. 그래서 동전은 짝수인 2번 뒤집혔습니다. 동전이 앞쪽으로 향하기 시작했기 때문에 짝수 번 뒤집힌 후에도 여전히 앞쪽으로 향할 것입니다. 따라서 대답은 예입니다.** \\
**Q: 동전이 앞에 표시됩니다. 제이미는 동전을 던진다. 티레사는 동전을 던진다. 동전이 아직도 앞에 있나요? \\
**A: 제이미와 Teressa에 의해 동전이 뒤집혔습니다. 그래서 동전은 짝수인 2번 뒤집혔습니다. 동전이 앞쪽으로 향하기 시작했기 때문에 짝수 번 뒤집힌 후에도 여전히 앞쪽으로 향할 것입니다. 따라서 대답은 예입니다.** \\
**Q: 동전이 앞에 표시됩니다. 메이벨은 동전을 뒤집는다. 샬론다는 동전을 던지지 않는다. 동전이 아직 앞에 있나요? ** \\
**A: Maybelle에 의해 동전이 뒤집혔습니다. 그래서 동전은 홀수인 1번 뒤집혔습니다. 동전은 앞면이 나오기 시작했기 때문에 홀수 번 뒤집으면 뒷면이 나올 것이다. 따라서 대답은 아니요입니다.** \\
**Q: 동전이 앞에 표시됩니다. 밀리센트는 동전을 던지지 않는다. 수상은 동전을 뒤집는다. 동전이 아직 앞에 있나요? ** \\
**A: Conception에 의해 동전이 뒤집혔습니다. 그래서 동전은 홀수인 1번 뒤집혔습니다. 동전은 앞면이 나오기 시작했기 때문에 홀수 번 뒤집으면 뒷면이 나올 것이다. 따라서 대답은 아니요입니다.** \\
**Q: 동전이 앞에 표시됩니다. 샐은 동전을 던진다. 레이몬드는 동전을 던지지 않는다. 동전이 아직 앞에 있나요? ** \\
**A: Sal에 의해 동전이 뒤집혔습니다. 그래서 동전은 홀수인 1번 뒤집혔습니다. 동전은 앞면이 나오기 시작했기 때문에 홀수 번 뒤집으면 뒷면이 나올 것이다. 따라서 대답은 아니요입니다.** \\
**Q: 동전이 앞에 표시됩니다. 수상은 동전을 뒤집는다. 크리스티안은 동전을 던지지 않는다. 동전이 아직 앞에 있나요? ** \\
**A: Conception에 의해 동전이 뒤집혔습니다. 그래서 동전은 홀수인 1번 뒤집혔습니다. 동전은 앞면이 나오기 시작했기 때문에 홀수 번 뒤집으면 뒷면이 나올 것이다. 따라서 대답은 아니요입니다.** \\
**Q: 동전이 앞에 표시됩니다. 잉가는 동전을 던지지 않는다. Elanor는 동전을 던지지 않는다. 동전이 아직 앞에 있나요? ** \\
**A: 아무도 동전을 뒤집지 않았습니다. 그래서 동전은 0번 뒤집혔다. 동전이 앞면을 가리키기 시작했지만 뒤집히지 않았으므로 여전히 앞면이 표시됩니다. 따라서 대답은 예입니다.** \\
**Q: 동전이 앞에 표시됩니다. 라이언은 동전을 뒤집는다. 샤운다는 동전을 뒤집는다. 동전이 아직 앞에 있나요? ** \\
**A: The coin was flipped by Ryan and Shaunda. So the coin was flipped 2 times, which is an even number. The coin started heads up, so after an even number of flips, it will still be heads up. So the answer is yes.** \\ \hline \end{tabular}
\end{table}
표 23: 코인 플립 작업에 대한 전체 연쇄 사고 프롬프트에 대한 적은 샷 예시.

\begin{table}
\begin{tabular}{l} \hline
**Prompt for CSQA** \\ \hline
**Q:** 사람들이 만년필에서 여분의 잉크를 흡수 하는 데 사용 하는 것은 무엇인가요? 대답 선택: (a) 셔츠 주머니 (b) 서예가의 손 (c) 잉크통 (d) 책상 서랍 (e) 블로터 \\
**A:** 답은 잉크를 흡수할 수 있는 항목이어야 합니다. 상기 선택들 중에서, 잉크를 흡수하기 위해 블로터들만이 사용된다 \\ 그래서 답은 (e)입니다. \\
**Q:** 케이블이 필요한 홈 엔터테인먼트 장비는 무엇입니까? \\ 답변 선택 : (a) 라디오 판잣집 (b) 변전소 (c) 텔레비전 (d) 캐비닛 \\
**A:** 답변에는 케이블이 필요 합니다. 위의 선택 중 텔레비전만 케이블이 필요합니다. 그래서 답은 (c)입니다. \\
**Q:** 여우는 도시에서 숲으로 걸어 들어갔습니다. 무엇을 찾고 있었나요? 답변 선택: (a) 예쁜 꽃 (b) 닭장 (c) 자연 서식지 (d) 동화책 \\
**A:** 답은 포리스트에 있어야 합니다. 위의 선택 중 자연 서식지만이 숲에 있다. 그래서 답은 (b)이다 \\
**Q:** 새미는 사람들이 있는 곳으로 가고 싶었습니다. 어디로 갈까요? 답변선택 : (a) 인구 밀집지역 (b) 경주장 (c) 사막 (d) 아파트 (e) 도로블록 \\
**A:** 답은 많은 사람이 있는 장소여야 합니다. 위의 선택 중 인구가 많은 지역에만 사람이 있습니다. 그래서 답은 (a)입니다. \\
**Q:** 체크아웃 하기 직전에 포도를 어디에 놓습니까? 답변 선택: (a) mouth (b) grocery cart (c)super market (d) fruit basket (e) fruit market \\
**A:** 답변은 체크아웃하기 전에 식료품을 배치하는 장소여야 합니다. 위의 선택 중 식료품 카트는 식료품을 보관하는 데 가장 합리적입니다. 그래서 답은 (b)이다 \\
**Q:** Google Maps 및 기타 고속도로 및 거리 GPS 서비스가 대체 되었습니까? 답변 선택: (a) united states (b) mexico (c) countryside (d) atlas \\
**A:** 답변은 Google Maps 및 GPS 서비스가 하는 작업을 수행 하는 데 사용 되는 것이어야 하며, 이는 지침을 제공 합니다. 상기 선택들 중에서, 지시들을 제공하기 위해 단지 아틀라스가 사용된다. 따라서 답은 (d) \\
**Q:** 이혼하기 전에 아내는 누가 모든 작업을 하고 있다고 느꼈습니까? 답변 선택: (a) 더 힘든 (b) 괴로움 (c) 쓴맛 (d) 눈물 (e) 슬픔 \\
**A:** The answer should be the feeling of someone getting divorced who was doing all the work. Of the above choices, the closest feeling is bitterness. So the answer is (c). \\ \hline \end{tabular}
\end{table}
표 24: CSQA에 대한 사상 프롬프트의 전체 체인에 대한 적은 샷 예시. 답변 선택 사이에는 공간상의 이유로 표에 생략된 새로운 선이 있다.

\begin{table}
\begin{tabular}{l} \hline
**날짜 이해 프롬프트** \\
**Q: 2015는 36시간 후에 시작됩니다. MM/DD/YYYY에서 오늘로부터 일주일 후 날짜가 어떻게 되나요?** \\
**A: 2015년이 36시간 후에 도래하는 경우 2일 후에 도래합니다. 01/01/2015 2 일 전은 12/30/2014 이므로 오늘은 12/30/2014입니다. 따라서 오늘부터 일주일 후는 01/05/2015입니다. 따라서 대답은 01/05/2015입니다.** \\
**Q: 2019의 첫 번째 날은 화요일이고, 오늘은 2019의 첫 번째 월요일입니다. MM/DD/YYYY의 오늘 날짜는 무엇입니까?** \\
**A: 2019년 첫 번째 날이 화요일인 경우 2019년 01/01/2019년은 화요일입니다. 오늘은 첫 월요일이고, 6일 후입니다. 따라서 오늘은 01/07/2019입니다. 대답은 01/07/2019입니다.** \\
**Q: 콘서트는 1943년 06/01/01로 예정되었지만 오늘로 하루 지연되었습니다. 10일 전 MM/DD/YYYY 날짜는 어떻게 되나요?** \\
**A: 06/01/1943 이후 하루는 06/02/1943입니다. 따라서 오늘이 06/02/1943입니다. 10일 전 오늘이 05/23/1943입니다. 따라서 대답은 05/23/1943입니다.** \\
**Q: 오늘날 4/19/1969입니다. MM/DD/YYYY에서 24시간 후 날짜는 언제입니까?** \\\
**A: 오늘이 04/19/1969입니다. 24시간 후가 오늘 하루 후인 04/20/1969입니다. 따라서 대답은 04/20/1969입니다.** \\
**Q: Jane은 오늘이 2002년 3월 11일이라고 생각했지만, 사실은 오늘이 1일 후인 3월 12일입니다. MM/DD/YYYY에서 24시간 후 날짜는 언제입니까?** \\\
**A: 오늘이 03/12/2002입니다. 24시간 후 날짜는 03/13/2002입니다. 따라서 답변은 03/13/2002입니다.** \\
**Q: 제인은 2001년 2월 마지막 날에 태어났습니다. 오늘은 그녀의 16살 생일입니다. 어제 MM/DD/YYYY 날짜는 언제인가요?
**A: The last day of February is the 28th, so Jane was born on 02/28/2001. Today is her 16-year old birthday, so today is 02/28/2017. So yesterday was 02/27/2017. So the answer is 02/27/2017.** \\ \hline \end{tabular}
\end{table}
표 26: 데이트 이해를 위한 전체 사상 프롬프트에 대한 적은 샷 예시.

\begin{table}
\begin{tabular}{l} \hline
**Prompt for StrategyQA** \\
**Q: 햄스터가 동물에게 음식을 제공합니까?** \\
**A: 햄스터는 먹이 동물입니다. 먹이는 포식자의 먹이이다. 따라서 햄스터는 일부 동물에게 먹이를 제공합니다. 따라서 대답은 예입니다.** \\
**Q: Brooke Shields가 Pennsylvania 대학에서 성공할 수 있습니까?** \\
**A: Brooke Shields는 프린스턴 대학에 다녔습니다. 프린스턴 대학은 펜실베니아 대학만큼 학문적으로 엄격하다. 따라서 브룩 쉴즈는 펜실베이니아 대학에서도 성공할 수 있었다. 따라서 대답은 예입니다.** \\
**Q: 예 또는 아니요: 수소 원자 번호 제곱이 Spice Girls의 수를 초과 합니다.** \\
**A: 수소의 원자 번호는 1입니다. 1 제곱은 1입니다. 스파이스 걸스는 5입니다. 따라서 수소의 원자번호 제곱은 5보다 작으므로 대답은 아니오이다.
**Q: 예 또는 아니요: 일부 대학 시작 중에 서리를 보는 것이 일반적인가요?** \\
**A: 대학 졸업식은 12월, 5월 및 6월에 발생할 수 있습니다. 12월은 겨울이라 서리가 내릴 수 있습니다. 따라서 일부 커멘트에 서리가 내릴 수 있습니다. 따라서 대답은 예입니다.** \\
**Q: 예 또는 아니요: 베트남에서 전쟁 중 라마가 두 번 태어날 수 있습니까 (1945-46)?** \\
**A: 베트남 전쟁은 6개월이었습니다. 라마의 임신 기간은 11개월로 6개월 이상이다. 따라서 라마는 베트남 전쟁 중에 두 번 출산할 수 없었다. 따라서 대답은 아니요입니다.** \\
**Q: 예 또는 아니요: 배가 물에 가라앉을까요?** \\
**A: The density of a pear is about \(0.6g/cm^{3}\), which is less than water. Objects less dense than water float. Thus, a pear would float. So the answer is no.** \\ \hline \end{tabular}
\end{table}
표 25: StrategyQA에 대한 사상 프롬프트의 전체 체인에 대한 적은 샷 예시.

\begin{table}
\begin{tabular}{l} \hline \hline
**스포츠 이해 프롬프트** \\
**Q: 다음 문장이 그럴듯한가요? ” 카일 팔미에리는 해고 명령을 받았다."
**A: 카일 팔미에리는 하키 선수입니다. 슬래싱으로 호출되는 것은 하키의 일부이므로 대답은 예입니다.* \\
**Q: 다음 문장이 그럴듯한가요? ” 주앙 무티뉴가 NFC 챔피언십에서 스크린 패스를 잡았다."
**A: 주앙 무티뉴는 축구 선수입니다. NFC 챔피언십은 축구가 아닌 미국 축구의 일부이다. 따라서 대답은 아니요입니다.** \\
**Q: 다음 문장이 그럴듯한가요? ” Carson Wentz set the pick and roll."** \\
**A: 카슨 웬츠는 미식축구 선수입니다. 픽 앤 롤은 축구가 아니라 농구의 일부이다. 따라서 대답은 아니요입니다.** \\
**Q: 다음 문장이 그럴듯한가요? ” 조나스 발렌시우나스가 버저를 쳤습니다."
**A: Jonas Valanciunas는 농구 선수입니다. 버저를 치는 것은 농구의 일부이다. 따라서 대답은 예입니다.** \\
**Q: 다음 문장이 그럴듯한가요? ” '재멜 머레이는 라인에서 완벽했어요'
**A: 자말 머레이는 농구 선수입니다. 라인에서 완벽해지는 것은 농구의 일부입니다. 따라서 대답은 예입니다.** \\
**Q: 다음 문장이 그럴듯한가요? ” Sam Darnold pass the puck."** \\
**A: 샘 다놀드는 미식축구 선수입니다. 퍽을 통과하는 것은 미식축구가 아니라 하키의 일부이다. 따라서 대답은 아니요입니다.** \\
**Q: 다음 문장이 그럴듯한가요? ” '드레이먼드 그린이 터치다운을 던졌다'
**A: Draymond Green은 농구 선수입니다. 터치다운을 던지는 것은 농구가 아니라 축구의 일부이다. 따라서 대답은 아니요입니다.** \\
**Q: 다음 문장이 그럴듯한가요? ” 말콤 브록던이 슛을 성공시켰습니다."
**A: Malcolm Brogdon is a basketball player. Banking the shot in is part of basketball. So the answer is yes.** \\ \hline \hline \end{tabular}
\end{table}
표 27: 스포츠 이해를 위한 사상 프롬프트의 전체 체인에 대한 적은 샷 예시.

\begin{table}
\begin{tabular}{l} \hline \hline
**SayCan 로봇 계획 프롬프트** \\ 위치 = [카운터, 테이블, 사용자, 쓰레기, 그릇] \\ Object = [7up, apple, kettle chip, tea, multigrain chip, coke, lime soda, jalapeno chip, rice chip, orange, grapefruit soda, pepsi, redbull, energy bar, sponge, water]. \\ 로봇은 물건(물건)으로 물건을 집어 넣거나 물건(물건)으로 물건을 내려놓거나 물건 또는 물건(물건)으로 위치를 찾을 수 있다. 로봇은 나열된 명시적인 위치와 객체만 이해할 수 있습니다. \\
**인간**: 배가 고프네요, 칩 좀 가져다 주시겠어요? \\
**설명**: 사용자가 배가 고프고 칩을 요청했습니다. 사용 가능한 칩은 여러 종류가 있습니다. 제가 주전자 칩을 가져다 드리겠습니다. \\
**계획**: 1. find(kettle chip), 2. pick(kettle chip), 3. find(user), 4. put(kettle chip), 5. done(). \\
**인간**: 자몽 음료를 테이블에서 카운터로 이동하려면 어떻게 해야 하나요? \\
**설명**: 사용자가 자몽 음료를 카운터로 이동하도록 요청했습니다. \\
**계획**: 1. find(자몽 소다), 2. pick(자몽 소다), 3. find(카운터), 4. put(자몽 소다), 5. done(). \\
**인간**: 간식을 어떻게 가져오나요? \\
**설명**: 사용자가 간식을 요청했습니다. 두 항목을 선택하여 가져옵니다. 할라피뇨 칩이랑 사과 가져올게 \\
**계획**: 1. find(jalapeno 칩), 2. pick(jalapeno 칩), 3. find(user), 4. put(jalapeno 칩), 5. find(apple), 6. pick(apple), 7. find(user), 8. put(apple), 9. done(). \\
**인간**: 과일 아닌 음식을 어떻게 가져오겠습니까? \\
**설명**: 사용자가 과일이 아닌 음식을 요청했습니다. 에너지 막대를 가져오겠습니다. \\
**계획**: 1. find(에너지 막대), 2. pick(에너지 막대), 3. find(사용자), 4. put(에너지 막대), 5. done(). \\
**인간**: 쌀 조각을 그릇에 넣은 다음 차를 테이블로 옮기려면 어떻게 해야 하나요? \\
**설명**: 사용자가 두 가지 작업을 수행 하도록 요청 했습니다. 하나는 수행 하 고 다른 하나는 수행 합니다. \\
**계획**: 1. find(쌀 칩), 2. pick(쌀 칩), 3. find(그릇), 4. put(쌀 칩), 5. find(차), 6. pick(차), 7. find(테이블), 8. put(차), 9. done(). \\
**인간**: 빨간 불은 어떻게 버려요? \\
**설명**: 사용자가 Redbull을 버리라고 요청했습니다. 휴지통으로 이동합니다. \\
**계획**: 1. find(redbull), 2. pick(redbull), 3. find(쓰레기), 4. put(redbull), 5. done(). \\
**인간**: 음료를 가져오세요. \\
**설명**: 사용자가 음료를 요청했으며 다양한 옵션이 있습니다. 나는 그들에게 물을 가져다 줄 것이다. \\
**Plan**: 1. find(water), 2. pick(water), 3. find(user), 4. put(water), 5. done(). \\ \hline \hline \end{tabular}
\end{table}
표 28: SayCan 로봇 계획 작업에 대한 생각 프롬프트의 전체 체인에 대한 적은 샷 예시.

부록 : MWP용 대체 주석기

표 29: 수학 단어 문제에 대한 사고 프롬프트의 전체 연쇄에 대한 몇 가지 예시. 이들 예시들은 사유의 사슬들이 상이한 주석자("주석자 A" 대신에 "주석자 B")에 의해 작성되었다는 점을 제외하고는 표 20에서와 동일하다. 주석가들은 공동 저자였고 사고 사슬의 목표에 익숙했다.

**수학 단어 문제에 대 한 프롬프트**

**Q:** 숲에는 15개의 나무가 있습니다. 그루브 일꾼들은 오늘 그루브에 나무를 심을 것이다. 그들이 끝나면, 21그루의 나무가 있을 것입니다. 그 숲의 일꾼들은 오늘 몇 그루의 나무를 심었나요?

**A:** 현재 21개의 트리가 있고 처음에는 15개의 트리가 있으므로 작업자는 21 - 15 = 6개의 트리를 심습니다. 답은 6입니다.

**Q:** 주차장에 3대의 차량이 있고 2대의 차량이 더 도착하면 몇 대의 차량이 주차장에 있습니까?

**A:** 처음에는 3대의 자동차가 있고 2대가 더 도착하므로 이제 3 + 2 = 5대의 자동차가 있어야 합니다. 답은 5입니다.

**Q:** 레아는 32개의 초콜릿을 가지고 있었고 그녀의 여동생은 42개였습니다. 35개이면 총 몇 개의 조각이 남아 있습니까?

**A:** Leah에는 32개의 초콜릿이 있고 그녀의 여동생에는 42개의 초콜릿이 있으며, 총 32 + 42 = 74개의 초콜릿이 있습니다. 그들이 35살 이후, 현재 74 - 35 = 39개의 초콜릿이 있다. 대답은 39입니다.

**Q:** 제이슨에는 20개의 막대사탕이 있습니다. 데니에게 막대 사탕을 줬어요 이제 제이슨은 12개의 막대 사탕을 가지고 있다. 제이슨이 데니에게 막대 사탕을 몇 개 줬나요?

**A:** 제이슨은 20개의 막대 사탕으로 시작했지만 이제 12개만 가지고 있으므로 데니에게 20 - 12 = 8개의 막대 사탕을 주었습니다. 답은 8입니다.

**Q:** 숀은 5개의 장난감을 가지고 있습니다. 크리스마스에, 그는 엄마와 아빠에게 각각 두 개의 장난감을 받았습니다. 그는 지금 장난감을 몇 개나 가지고 있나요?

**A:** Shawn은 어머니와 아버지로부터 각각 2개의 장난감을 얻었으므로 2 * 2 = 4를 더 얻었습니다. 이제 5 + 4 = 9개의 장난감을 갖게 됩니다. 답은 9입니다.

**Q:** 서버 룸에는 9개의 컴퓨터가 있었습니다. 월요일부터 목요일까지 매일 5대의 컴퓨터가 더 설치되었다. 지금 서버실에 컴퓨터가 몇 대나 있나요?

**A:** 월요일부터 목요일까지 5대의 컴퓨터가 설치되었으므로 총 5 * 4 = 20대의 컴퓨터가 설치됩니다. 초반에 9대의 컴퓨터가 있기 때문에 지금은 20+9=29대의 컴퓨터가 있습니다. 대답은 29입니다.

**Q:** Michael은 58개의 골프공을 가지고 있습니다. 화요일, 그는 23개의 골프공을 잃었다. 수요일, 그는 2개를 더 잃었다. 수요일 말에 골프공이 몇 개 있었나요?

**A:** Michael은 58개의 골프 공으로 시작하여 23개를 잃었기 때문에 58 - 23 = 35를 가집니다. 2개를 더 잃은 후에는 35 - 2 = 33개의 공을 가집니다. 답은 33입니다.

**Q:** 올리비아는 23달러를 가지고 있습니다. 그녀는 베이글 5개를 개당 3달러에 구입했습니다. 그녀가 얼마나 많은 돈을 남겼나요?

**A:** 개당 $3의 베이글 5개는 5 * 3 = 15 달러여야 합니다. 올리비아는 처음에 23달러를 가지고 있었고, 그래서 이제 23-15 = 8달러가 남았습니다. 답은 8입니다.

\begin{table}
\begin{tabular}{l} \hline \hline
**Prompt for Math Word Problems** \\ \hline
**Q:** 숲에는 15개의 나무가 있습니다. 그루브 일꾼들은 오늘 그루브에 나무를 심을 것이다. 그들이 끝나면, 21그루의 나무가 있을 것입니다. 그 숲의 일꾼들은 오늘 몇 그루의 나무를 심었습니까?
**A:** 15개의 트리로 시작 합니다. 나중에 21개의 트리가 있습니다. 차이점은 그들이 심은 나무의 수여야 합니다. 그래서, 그들은 21-15 = 6개의 나무를 심었을 것입니다. 답은 6입니다. \\
**Q:** 주차장에 3대의 차량이 있고 2대의 차량이 더 도착하는 경우 주차장에 몇 대의 차량이 있습니까? \\
**A:** 이미 주차장에 3대의 차량이 있습니다. 2개 더 도착합니다. 이제 3 + 2 = 5대의 자동차가 있다. 답은 5입니다. \\
**Q:** Leah는 32개의 초콜릿을 가지고 있었고 그녀의 여동생은 42개를 가지고 있었습니다. 35개라면 총 몇 개의 조각이 남아 있나요? \\
**A:** Leah에는 32개의 초콜릿이 있었고 Leah의 자매에는 42개의 초콜릿이 있었습니다. 즉, 원래 32 + 42 = 74개의 초콜릿이 있었습니다. \\
35마리가 먹혔다. 그래서 그들은 여전히 74 - 35 = 39개의 초콜릿을 가지고 있다. 응답은 39입니다. \\
**Q:** 제이슨에는 20개의 막대사탕이 있습니다. 데니에게 막대 사탕을 줬어요 이제 제이슨은 12개의 막대 사탕을 가지고 있다. 제이슨이 데니에게 얼마나 많은 막대 사탕을 줬지?
**A:** 제이슨에는 20개의 막대 사탕이 있습니다. 지금 12살밖에 안 됐으니 나머진 데니에게 줬을 거예요 그가 데니에게 준 막대 사탕의 수는 20개 - 12개 = 8개였을 것이다. 답은 8입니다. \\
**Q:** 숀은 5개의 장난감을 가지고 있습니다. 크리스마스에, 그는 엄마와 아빠에게 각각 두 개의 장난감을 받았습니다. 지금 장난감이 몇 개나 있죠?
**A:** 그는 5 개의 장난감을 가지고 있습니다. 그는 엄마로부터 2개를 받았고, 그 후 그는 5+2=7개의 장난감을 가지고 있습니다. 그리고 나서 그는 아버지로부터 2개를 더 받았고, 그래서 총 7+2=9개의 장난감을 가지고 있습니다. 응답은 9입니다. \\
**Q:** 서버 룸에는 9개의 컴퓨터가 있었습니다. 월요일부터 목요일까지 매일 5대의 컴퓨터가 더 설치되었다. 지금 서버실에 컴퓨터가 몇 대나 있나요? \\
**A:** 월요일부터 목요일까지 4일이 있습니다. 매일 5대의 컴퓨터가 추가되었다. 즉, 총 4*5 = 20대의 컴퓨터가 추가되었음을 의미한다. 초반에는 9대의 컴퓨터가 있었기 때문에 지금은 9+20=29대의 컴퓨터가 있다. 응답은 29입니다. \\
**Q:** Michael은 58개의 골프공을 가지고 있습니다. 화요일, 그는 23개의 골프공을 잃었다. 수요일, 그는 2개를 더 잃었다. 수요일 말에 골프공이 몇 개 있었나요?
**A:** Michael은 처음에 58개의 공을 가졌습니다. 그는 화요일 23개를 잃었고, 그 후 58 - 23 = 35개의 공을 가졌다. 수요일에 그는 2개를 더 잃었고, 이제 그는 35 - 2 = 33개의 공을 가지고 있다. 응답은 33입니다. \\
**Q:** 올리비아는 23달러를 가지고 있습니다. 그녀는 베이글 5개를 개당 3달러에 구입했습니다. 그녀가 얼마 남았어요?
**A:** She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning, so now she has $23 - $15 = $8. The answer is 8. \\ \hline \hline \end{tabular}
\end{table}
표 30: 수학 단어 문제에 대한 사고 프롬프트의 전체 연쇄에 대한 몇 가지 예시. 이들 예시들은 사유의 사슬들이 상이한 주석기("주석기 A" 대신에 "주석기 C")에 의해 작성되었다는 것을 제외하고는 표 20에서와 동일하다.
