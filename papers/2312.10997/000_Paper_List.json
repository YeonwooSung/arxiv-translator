{
    "2312.10997": {
        "paper_id": "2312.10997",
        "abs_url": "https://arxiv.org/abs/2312.10997",
        "pdf_url": "https://arxiv.org/pdf/2312.10997.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2312.10997_Retrieval-Augmented_Generation_for_Large_Language_Models_A_Survey.pdf",
        "title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Yunfan Gao",
            "Yun Xiong",
            "Xinyu Gao",
            "Kangxiang Jia",
            "Jinliu Pan",
            "Yuxi Bi",
            "Yi Dai",
            "Jiawei Sun",
            "Haofen Wang"
        ],
        "abstract": "Large language models (LLMs) demonstrate powerful capabilities, but they still face challenges in practical applications, such as hallucinations, slow knowledge updates, and lack of transparency in answers. Retrieval-Augmented Generation (RAG) refers to the retrieval of relevant information from external knowledge bases before answering questions with LLMs. RAG has been demonstrated to significantly enhance answer accuracy, reduce model hallucination, particularly for knowledge-intensive tasks. By citing sources, users can verify the accuracy of answers and increase trust in model outputs. It also facilitates knowledge updates and the introduction of domain-specific knowledge. RAG effectively combines the parameterized knowledge of LLMs with non-parameterized external knowledge bases, making it one of the most important methods for implementing large language models. This paper outlines the development paradigms of RAG in the era of LLMs, summarizing three paradigms: Naive RAG, Advanced RAG, and Modular RAG. It then provides a summary and organization of the three main components of RAG: retriever, generator, and augmentation methods, along with key technologies in each component. Furthermore, it discusses how to evaluate the effectiveness of RAG models, introducing two evaluation methods for RAG, emphasizing key metrics and abilities for evaluation, and presenting the latest automatic evaluation framework. Finally, potential future research directions are introduced from three aspects: vertical optimization, horizontal scalability, and the technical stack and ecosystem of RAG.",
        "comments": "",
        "official_code_urls": [
            "https://github.com/tongji-kgllm/rag-survey"
        ],
        "pwc_page_url": "https://paperswithcode.com/paper/retrieval-augmented-generation-for-large",
        "bibtex": "@misc{gao2023retrievalaugmented,\n      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, \n      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Haofen Wang},\n      year={2023},\n      eprint={2312.10997},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}"
    }
}