<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '[MISSING_PAGE_FAIL:1]\n' +
      '\n' +
      '이러한 유사한 사건의 존재는 자연스럽게 두 가지 질문을 제기한다: (1) 목표를 어떻게 모델링해야 하는가, (2) 과제 간의 긍정적인 전달을 이끌어내는 가장 좋은 방법은 무엇인가. 물론 이 질문들에 대한 답은 당면한 문제에 달려있다. 본 논문에서는 트위터의 온라인 광고를 위해 클릭 후 전환율(CVR)을 예측하는 특정하지만 중요한 실제 시나리오로 초점을 제한한다.\n' +
      '\n' +
      '가장 간단한 설정에서, 광고 클릭율(CTR) 및 CVR 예측은 독립적으로 훈련된 두 모델을 갖는 별개의 지도 학습 문제로 취급된다. 이러한 작업 중 CVR 예측은 일반적으로 두 가지 이유로 더 어렵다. 첫 번째 이유는 **데이터 희소성**: 사용자에 게 표시 된 모든 인상은 CTR 모델에 대 한 학습 데이터를 생성 하는 반면 클릭으로 인한 인상은 CVR 모델에 대 한 학습 데이터를 생성 합니다. 광고 클릭 참여를 생성하는 노출의 수는 전형적으로 작은 부분이고, 때로는 1% 미만이므로, CVR 모델은 상당히 적은 데이터로 트레이닝되어야 한다. 이러한 도전은 각 서비스된 광고 인상과 관련된 기회 비용이 있기 때문에 탐사 데이터를 얻는 데 비용이 많이 든다는 사실로 인해 악화된다. 달리 말하면, 더 나은 탐사를 위해 무작위 트래픽을 제공하는 것은 상당한 재정적 저해와 함께 옵니다. 두 번째 이유는 **데이터 편향**: CVR 모델은 모든 노출에 대해 예측을 해야 하지만 클릭으로 인한 노출만 학습 예제로 사용 됩니다. 즉, 클릭을 초래하지 않은 노출에 대해, 사용자가 광고를 클릭했다면 이것이 변환을 초래했을지에 대한 반사실적 정보가 부족하다(도 1 참조).\n' +
      '\n' +
      '최근 연구(Koshelev et al., 2017)에서는 CVR 모델링에 대한 접근 방법을 소개하였는데, ESMM(Entire Space Multitask Model)은 두 가지 핵심 아이디어를 가지고 있다. (1) CVR과 CTR 문제 사이의 표현 학습을 위한 매개 변수를 공유하는 것과 (2) 모든 인상 샘플에 대해 CVR 모델을 훈련시킬 수 있는 조건 없이 CVR을 모델링하는 것이다(그들은 "전체 공간" 모델링이라고 한다). 아래에서 이러한 설명을 확장합니다.\n' +
      '\n' +
      '여기에서 절제 연구의 사용을 통해 ESMM 모델의 우수한 성능 이면의 메커니즘을 체계적으로 조사했다. 우리는 다른 산업 규모 데이터 세트에서 ESMM이 CVR 및 CTR을 별도의 모델로 모델링하는 것보다 성능이 우수하다는 (Koshelev 등, 2017)의 결과를 재현했다. 그러나 ESMM 모델의 한 측면만 통합하는 접근법으로 유사한 수준의 성능을 얻을 수 있음을 발견했다. 즉, CVR 또는 CTR 간의 매개변수 공유만 사용하거나 "전체 공간" 훈련만 사용하는 모델이다.\n' +
      '\n' +
      '### Problem Formulation\n' +
      '\n' +
      '우리는 표준 지도 학습 가정 하에서 변환 예측 문제를 고려한다. 즉, 우리는 일부 고정 분포인 \\(D\\)으로부터 i.i.d.로 그려진 광고 배치, 사용자 요청 및 광고 자체의 속성을 나타내는 \\(x\\)로 표시된 광고 _context_가 제시된다고 가정한다. 이 광고 후보가 사용자에 의해 표시되고 관찰되면("인상") 사용자는 \\(y=1\\), 확률 \\(p(y=1|x)\\)으로 표시된 광고에 대한 _클릭_을 선택합니다. 또한 사용자는 광고된 애플리케이션을 설치하거나 \\(z=1\\)로 표시된 제품을 확률 \\(p(z=1|y=1,x)\\)으로 구매하여 _변환_을 선택할 수도 있습니다. 구성에 의해, 변환은 사용자가 클릭했을 때만 가능하다. 즉, \\(p(z=1|y=0,x)=0\\). 목표는 동일한 분포에서 도출된 새로운 예제에 대해 예상되는 (교차 엔트로피) 손실을 최소화하는 분류 함수 \\(f(x;\\theta)\\rightarrow[0,1]\\을 생성하는 것이다. 즉, 모델 파라미터인 \\(\\theta\\), 여기서 \\(\\arg\\min_{\\theta}\\mathbb{E}_{D}\\)\\([L(f(x;\\theta),z)]\\), \\(L(p,z)=-(z\\cdot\\log(p)+(1-z)\\cdot\\log(1-p))\\)를 찾는 것을 목표로 한다.\n' +
      '\n' +
      '### Related work\n' +
      '\n' +
      '딥러닝 기반 모델들은 멀티-태스크 및 전이 학습에 사용하기 위해 널리 연구되어 왔다(Koshelev et al., 2017; Koshelev et al., 2018; Koshelev et al., 2019; Koshelev et al., 2019; Koshelev et al., 2020). 전이 학습에 대한 하나의 일반적인 접근법은 심층 네트워크의 최종 은닉층까지, 관련 태스크들 사이에서 신경망 파라미터들을 공유하는 것이다(Koshelev 등, 2019). 이러한 작업체로부터의 일반적인 합의는 비교적 간단한 기술들이 종종 실무에서 잘 작동하고 새로운 작업을 학습하는데 필요한 시간 또는 데이터의 양을 크게 감소시킬 수 있다는 것이다(설문 조사: (Han et al., 2017) 참조). 그러나, 전이 학습은 잘하기 어려울 수 있고, 순진하게 수행되면 쉽게 부정적인 전이를 초래할 수 있다(Han et al., 2017; Chen et al., 2018).\n' +
      '\n' +
      '온라인 광고에 대한 변환 예측의 특정 과제와 관련하여 라벨링된 변환 데이터를 얻는 비용과 성공적인 광고 주도 변환의 고유한 희귀성은 수많은 산업 맥락에서 다중 작업 학습 접근법의 개발을 장려했다. 이 출원의 비즈니스 민감성은 생산 시스템의 출판을 만류하지만 문헌에는 몇 가지 대표적인 예가 있다. 예를 들어, 빠르면 2014년 계층적 멀티-태스크 학습(MTL) 변환 모델들이 야후(Chen et al., 2018), (Chen et al., 2018)에 스케일로 배포되었고, 온라인 광고를 위한 멀티-태스크 특징 엔지니어링 접근법이 기술되었다.\n' +
      '\n' +
      '(Chen et al., 2018)에서 논의된 접근법은 이 보고서에 제시된 작업과 가장 밀접하게 관련되어 있다. 이에 저자들은 CTR과 CVR 태스크 간의 파라미터를 공유하는 다중 태스크 모델을 제안함으로써 클릭 후 변환 태스크에서 데이터 희소성의 문제를 해결하였다. 또한, 저자는 클릭 및 변환의 공동 확률을 예측하여 데이터 세트 편향 문제를 해결하는 것을 목표로 한다. 이 연구는 기준선보다 향상된 예측 성능을 보여주었다. 또한, 특히, (Han et al., 2017)은 지연 피드백의 문제에 대해 특정한 초점을 두고 이 작업에 대한 유사한 접근법을 고려한다; 흥미롭지만, 지연 피드백의 도전은 이 작업의 범위를 벗어난다.\n' +
      '\n' +
      '## 2. Methods\n' +
      '\n' +
      '상술된 바와 같이, 광고 랭킹 시스템들의 주요 관심 수량은 사용자-광고 전환율, \\(p(z=1|x)\\)이다. 이 예측을 분해하는 많은 방법들이 있으며, 이는 상이한 특성들을 초래하고 상이한 MTL 접근법들을 허용할 수 있다. 예를 들어, \\(p(z=1|x)\\), \\(p(z=1|y=1,x)\\cdot p(y=1|x)\\)의 분해를 무시하거나, 단일 예측만 남기고, 따라서 인상 공간에서 단일 작업 심층 신경망(DNN) 아키텍처 훈련을 선택하는 것이다.\n' +
      '\n' +
      '이 작업에서 방금 설명한 순진한 선택을 포함하여 6가지 다른 접근법을 테스트한다. MTL 모델은 복잡해질 가능성이 있지만 (1) 하드 파라미터 공유, (2) 훈련 공간 및 예측 헤드의 신중한 선택, (3) 조건 인식 CVR 예측의 사용으로 분석을 제한한다. 아래 1의 6가지 모델링 접근법을 설명하고 그림 2에 직접 비교하기 위한 이 정보도 제시한다.\n' +
      '\n' +
      '각주 1: 부록의 표 1은 우리의 모든 모델 디자인에 대한 체크리스트 스타일의 요약과 몇 가지 추가 구현 세부 정보를 제공한다.\n' +
      '\n' +
      '우리는 CTR과 CVR을 별도의 작업으로 처리하는 기본 접근법 _독립 예측_(IP)을 나타내며, 공유 매개변수가 없는 두 개의 다층 퍼셉트론(MLP)이다. CTR prediction, \\(\\hat{p}(y=1|x)\\) is trained on negative downsampled\n' +
      '\n' +
      '그림 1. 노출에서 클릭(\\(y\\))으로 전환(\\(z\\))으로 이벤트 흐름. 광고 클릭이 있는 표현인 \\(y=1\\)은 광고 클릭이 없는 표현인 \\(y=0\\)에 비해 훨씬 더 희소하다. 점선은 실제로 관찰할 수 없는 조건부 가능성, 즉 데이터 편향을 유발하는 반대 사실 누락 가능성을 나타낸다. 클릭된 데이터에 대해서만 학습된 변환 모델(p(z|y=1,x)\\)은 모든 인상의 공간에 대한 변환 추론에 사용될 때 희소성과 편향성의 영향을 받는다.\n' +
      '\n' +
      '클릭 데이터와 CVR 예측, \\(\\hat{p}(z=1|y=1,x)\\)은 클릭된 인상, \\(y=1\\)을 사용하여 훈련된다. 최종 예측은 \\(\\hat{p}(z=1,y=1|x)=\\hat{p}(z=1|y=1,x)\\cdot\\hat{p}(y=1|x)\\)의 곱으로 구성된다.\n' +
      '\n' +
      '[6]에서 소개된 일차적인 접근 방법은 \\(\\hat{p}(z=1,y=1|x)\\)를 직접 예측하는 모델과 \\(\\hat{p}(y=1|x)\\)을 예측하는 모델을 훈련시키고, \\(\\hat{p}(z=1,y=1|x)=\\hat{p}(z=1|y=1,x)\\cdot\\hat{p}(y=1|x)\\)로 네트워크를 구축하는 것이다. 즉, 네트워크 내에 \\(\\hat{p}(z=1|y=1,x)\\)의 예측으로 간주될 수 있는 내부 노드가 존재하지만, 이 예측을 직접 최적화하는 손실은 없다. 우리는 이 접근법을 [6]에서 사용하는 이름인 _전체 공간 멀티태스크 모델(ESMM)_이라고 부른다. 우리의 모델은 개념적으로 동일하지만 특정 아키텍처는 다르다(섹션 2.3 참조). 초기 DNN 계층에서 하드 파라미터 공유를 사용했다는 점에서 특징 임베딩만 사용하는 것이 아니라 다르다.\n' +
      '\n' +
      'ESM 접근법은 베이스라인(IP) 접근법과 구별되는 세 가지 특성을 도입한다:\n' +
      '\n' +
      '* ESMM은 CTR과 CVR 작업 간의 하드 매개 변수 공유를 사용합니다. (공유 파라미터)\n' +
      '* ESMM은 \\(\\hat{p}(z=1|y=1,x)\\)가 아닌 \\(\\hat{p}(z=1,y=1|x)\\)를 예측하여 인상의 전체 공간에 대한 설치 예측을 훈련합니다. (전체 공간)\n' +
      '* ESMM은 클릭 예측에 의한 설치 예측의 손실에 암시적으로 가중치를 부여합니다. (가중 CVR)\n' +
      '\n' +
      '이러한 특성의 영향을 분리하고 개별 및 결합된 효과를 이해하기 위해 ESMM의 여러 변형을 테스트했다. _ 전체 공간 멀티태스크 모델 - 공유되지 않음(ESMM-NS)은 ESMM과 동일한 손실을 사용한다\n' +
      '\n' +
      '도 2: 여기서 평가된 상이한 모델링 접근법. 독립 예측(IP)은 CVR과 CTR을 독립적인 작업으로 모델링하는 기준선 역할을 한다. 전체 공간 다중 작업 모델(ESMM)은 공유 매개변수, 전체 공간 예측 및 가중 CVR의 세 가지 특성을 모두 포함한다. 다른 모델은 이러한 특성 중 일부만 통합하여 성능에 대한 기여도를 연구할 수 있다. MLP 라벨(CTR, CVR)은 훈련에 사용되는 데이터의 공간을 나타낸다. CTR은 모든 트레이닝 예(전체 공간)이고, CVR은 \\(y=1\\)인 예들의 서브세트이다. (예를 들어, ESMM-NS는 두 개의 MLP를 가지며, 둘 다 CTR 데이터에 대해 트레이닝된다). 각 모델에 대한 설명은 섹션 2를 참조하십시오.\n' +
      '\n' +
      '그러나 CVR과 CTR 예측 작업 사이에는 공유 매개 변수가 없다. _ESSP-Split_ 모델은 ESMM 모델과 공유 매개 변수와 동일한 손실을 사용 하지만 \\(\\hat{p}(y=1|x)\\) 및 \\(\\hat{p}(z=1,y=1|x)\\)의 두 예측은 관계 2에 제약 없이 독립 헤드에 의해 수행 됩니다. _독립 예측 공유 매개 변수_ (IPSP)는 IP 모델과 동일한 접근 방식과 손실을 사용 하지만 (즉, 전체 공간 모델이 아님) CVR과 CTR 예측 간에 매개 변수를 공유 합니다. 마지막으로 _전체 공간 예측 (ESP)_ 은 단일 모델로 \\(\\hat{p} (z=1,y=1|x)\\)를 예측 하 여 전체 공간에 대해 학습 하지만 CTR 작업을 사용 하지 않습니다.\n' +
      '\n' +
      '각주 2: 이것은 모델이 \\(\\hat{p}(z=1,y=1|x)>\\hat{p}(y=1|x)\\)를 예측하는 것이 가능하기 때문에 두 머리의 예측이 일치하지 않을 수 있음을 의미한다. 실제로, 이것은 매우 자주 일어나지 않는다.\n' +
      '\n' +
      '### 데이터 집합 및 학습 설정\n' +
      '\n' +
      '본 논문의 평가 데이터 세트는 트위터에 제공되는 디지털 모바일 앱 설치 광고와 트위터의 모바일 디스플레이 네트워크(예: 게임 내 광고)인 MoPub에 대한 실제 클릭 및 변환 데이터로 구성된다. 이 실제 데이터 세트를 사용하면 진정한 대표적인 문제에 대한 이러한 기술의 성능을 평가할 수 있지만 데이터 세트 자체는 수많은 사용자 개인 정보 보호 및 비즈니스에 민감한 제약으로 인해 공개적으로 사용할 수 없다. 구체적으로, 2020년 중반 연속 일 수 동안 수집된 클릭 및 변환 이벤트의 고정 데이터 세트 아래의 각 평가에서 모델 훈련 및 평가에 사용되었다. 원시 데이터는 50억 개 이상의 광고 노출(이후 다운샘플링, 아래에서 논의되는 바와 같이), 5천만 개 이상의 광고 클릭 및 수 백만 개의 변환 이벤트3으로 구성되었다. 참고, 아래에서 논의되는 바와 같이, 이러한 실험에 대한 평가 보류 세트는 항상 과거 vs. 이전 14일의 데이터에 대한 훈련, 15일의 테스트 등 미래 평가. 또한 첫 번째 \\(N\\)일에 훈련할 때 예제를 섞어서 데이터를 대략 ID로 만든다.\n' +
      '\n' +
      '각주 3: 특정 데이터세트 카운트는 독점 정보의 공개를 피하기 위해 근사화된다.\n' +
      '\n' +
      '아래에 보고된 결과는 단일 평가일에 대한 것이다. 그러나 이러한 모델링 접근법의 시간 이동에 대한 견고성, 즉 모델이 재훈련의 이점 없이 미래로 예측을 더 많이 수행하도록 작업됨에 따라 예측 성능이 어떻게 변화하는지 또한 평가되었다. 이것은 특히 흥미롭고 실질적으로 관련이 있지만 이 문제의 측면은 궁극적으로 이와 관련하여 접근법 간에 주목할 만한 차이를 관찰하지 못했다.\n' +
      '\n' +
      '#### 2.1.1. Negative downsampling\n' +
      '\n' +
      '불균형 데이터 세트는 광고 데이터 세트에서 일반적인 문제이다. 우리는 부정적인 예제를 일부 요인 \\(f\\)으로 다운샘플링했으며 모델을 보정하기 위해 각 부정적인 샘플을 동일한 요인 \\(f\\)으로 가중했다. \\(y=1\\)이 유지된 모든 샘플은 변환 레이블인 \\(z\\)을 기반으로 다운샘플링이 수행되지 않았다. 평가 데이터 세트는 클릭 작업에 대한 네거티브에 동일한 다운샘플링 및 업가중 절차가 적용되어 동일하게 생성되었다.\n' +
      '\n' +
      '### Metrics\n' +
      '\n' +
      '궁극적으로, 잠재적 광고의 순위를 매기고 인상을 평가할 목적으로, 우리는 인상이 전환으로 이어질 확률 \\(p(z=1|x)=p(z=1,y=1|x)\\)에 관심이 있다. 이 작업의 경우 예측이 잘 보정되어야 하므로 교차 엔트로피 손실에 초점을 맞추었다(부록 B에서 PR-AUC를 보고한다). 우리는 점수를 기준 모델에 대한 상대적 성능 개선 백분율로 보고한다.\n' +
      '\n' +
      '### Model architecture\n' +
      '\n' +
      '모델들은 각각 약간 다른 특성을 가지기 때문에 정확한 아키텍처는 다양하지만 훈련 가능한 파라미터의 수는 모든 MLPs4에 걸쳐 유사하게 유지되었다. 다중 작업 모델(ESM-NS 제외)은 특징 임베딩 후에 두 개의 공유 레이어를 가졌고 모델 분기로서 두 개의 레이어 _퍼 헤드_가 뒤따랐다. "Weighted CVR", 예를 들어 ESMM을 사용하는 모델들은 (Beng et al., 2017)에서와 같이 \\(p(y=1|x)\\) 엔티티와 암시적 \\(p(z=1|y=1,x)\\) 엔티티5 이후에 훈련 가능한 파라미터 없이 두 개의 브랜치를 재연결하였다. 이러한 특성이 없는 모델, 예를 들어 IPSP는 각 분기의 뿌리에 단일 개체가 있었다. 네트워크의 공유 부분과 분기 부분 모두에 대해 더 넓은 층과 더 큰 깊이(더 많은 층) 측면에서 더 큰 모델로 실험했지만 이는 이점을 가져오지 않았다. 더 큰 모델은 또한 포함되거나 제외된 배치 정규화 계층으로 훈련되었다. 혜택의 부족은 충분한 훈련 데이터의 부족으로 설명될 수 있지만, 이는 더 큰 모델이 추천 작업에서 일관되게 더 나은 성능을 발휘하지 못하는 이유에 대한 더 넓은 열린 질문의 또 다른 예일 뿐이다(Beng et al., 2017).\n' +
      '\n' +
      '각주 4: IP 및 ESMM-NS는 두 개의 MLP를 가지므로 전체적으로 약 두 배 많은 파라미터를 갖는다.\n' +
      '\n' +
      '주석 5: 이 값에 대한 출력이 없지만 노드가 이 예측으로 해석될 수 있기 때문에 엔티티는 "암묵적"이다\n' +
      '\n' +
      '## 3. Results\n' +
      '\n' +
      '최상의 하이퍼파라미터를 찾기 위해 유사한 수의 실험에 대해 모든 모델을 수동으로 조정했다. 일반적으로 모델은 아래에서 논의되는 하이퍼 매개변수 값의 함수로서 약간 더 다양한 성능을 갖는 ESMM 모델을 제외하고 하이퍼 매개변수 선택에 상당히 강력했다.\n' +
      '\n' +
      '그림 3은 실험의 주요 결과를 요약한 것이다. 그들은 예측 작업의 _의미 있는 분해_가 IP보다 2% 더 나쁜 성능을 수행하는 ESP에 의해 보여지는 분명한 이점을 가지고 있다는 명확한 증거를 제공한다. 예측의 전체 공간에 대한 훈련에 대한 이러한 순진한 접근법은 긍정적인 설치 라벨이 클릭 라벨이 제공할 수 있는 유용한 신호에 의해 지원되지 않고 상대적으로 드물 때 모델을 학습 노이즈에 취약하게 만든다.\n' +
      '\n' +
      'ESP에 비해 현저한 증가와 함께 ESSP-Split 모델로 성능 점프가 있다. 이 비교는 하드 파라미터 공유의 유용성을 강조한다. 이것은 MTL의 \'고전적인\' 이점 - 종종 "공유된 표현들" 또는 추가적인 "정규화"의 관점에서 논의된다(Beng et al., 2017). 이러한 동일한 충격이 IPSP에 의해 입증되고,\n' +
      '\n' +
      '그림 3. 다중 작업 설정에 의한 성능 모델입니다. 성능 이득은 기준 IP 모델의 평균 점수로 정규화되었다. 각 모형의 성능 차이(IP 평균에 반대)에 대한 표준 오차는 최소 10번의 런에 걸쳐 계산됩니다. 결과는 긍정적인 전달을 유도하는 여러 메커니즘이 있지만 하드 파라미터 공유 단독(IPSP)이 최적일 수 있음을 보여준다. 열보다 좋은 모델은 이 모델이 \\(p<0.01\\), 2면 t-검정을 능가한다는 것을 나타낸다.\n' +
      '\n' +
      '태스크를 독립적인 헤드로 유지하면서도 통합 초기 레이어 피쳐 변환을 활용하는 최상의 성능 모델입니다. 공유 매개변수를 통한 CTR 작업으로부터의 신호의 이점은 대체 모델 설계에서 볼 수 있는 성능의 모든 이득을 제공했다.\n' +
      '\n' +
      '놀랍게도, ESMM-NS는 매우 경쟁적으로 수행되었다. 클릭 예측에 의해 CVR 헤드의 손실에 단순히 가중치를 부여함으로써 \\(\\hat{p}(y=1|x)\\) 모델은 기준선보다 더 나은 성능을 수행할 수 있었고 심지어 ESSP-Split(통계적으로 유의하지 않음)을 능가할 수 있었다. 이것이 강조하는 것은 _데이터 편향_ 문제의 범위라고 제안한다. 전체 공간에 대한 교육이 수행되면 CVR 샘플에 \'관련성\'을 할당하는 메커니즘이 있어야 합니다. 그렇지 않으면 ESP의 성능이 저하됩니다. 겉보기에 작은 세부사항인 이것은 (경험적으로) ESMM이 ESSP-Split을 능가하기 때문에 어떤 고전적인 전이 학습 주장보다 더 중요하다. 우리는 ESMM-NS가 다른 모든 MTL 설계에 비해 모델의 크기를 증가시킨다는 점에 주목한다. 왜냐하면 기준선과 마찬가지로 매우 깊은 RecSys 모델에서도 대부분의 매개변수가 존재하는 두 개의 개별 임베딩이 있기 때문이다. 그러나 추가 매개 변수가 이 경우에 실제로 도움이 된다고 제안 하지 않습니다. 사실, 편향된 데이터에 (과하게) 맞는 것이 문제인 것처럼 보일 때, 더 많은 매개변수만으로도 상황을 악화시킬 가능성이 있다.\n' +
      '\n' +
      '마지막으로 ESMM은 변동성이 더 크지만 IPSP와 유사한 성능을 보였다. 우리는 개선된 노력으로 잘 조정된 ESMM 모델에서 일관되고 더 큰 성능 이득을 얻을 수 있다고 잠정적으로 제안한다. 즉, ESMM에 대한 증가된 모델 튜닝으로 인한 한계 이익이 다른 모델보다 훨씬 크다고 가정한다. 설계가 가장 복잡한 학습 상호 작용을 허용한다는 점을 감안할 때 이것은 의미가 있을 것입니다. 그러나 더 간단한 접근법이 튜닝을 덜 필요로 할 수 있다는 점에서도 약점이다.\n' +
      '\n' +
      '대안적인 관점은 IPSP가 전체 공간에서 훈련하지 않는 것이 긍정적일 수 있다는 것인데, 이는 틀림없이 가장 어려운 훈련 목표(즉, 최악의 신호 대 잡음비를 갖는 것)인 \\(p(z=1,y=1|x)\\)을 직접 최적화하는 것을 피하기 때문이다.\n' +
      '\n' +
      '## 4. Conclusion\n' +
      '\n' +
      '우리는 간단한 MTL 방법이 변환 모델 성능을 향상시킬 수 있다는 명확한 증거를 제공한다. 우리의 실험은 하드 파라미터 공유 단독(IPSP)이 중요하고 비교적 쉬운 승리 대 팩터화(IP) 또는 나이브(ESP) 베이스라인으로 성능을 개선하는 데 최적일 수 있음을 보여준다. 또한 인상의 전체 공간에 대한 설치를 예측하려고 할 때 발생하는 데이터 편향 문제에 대응하는 것의 중요성을 확립한다. 가중 조건부 설치 예측의 놀랍도록 간단한 해는 편향을 잘 다룬다. 그러나 우리는 이 두 특성에서 얻은 이득이 결합될 때 가산적이지 않은 것으로 보인다는 점에 주목한다. 클릭과 변환의 맥락에서 이 문제를 연구했지만 데이터 희소성과 데이터 편향의 근본적인 문제에 대응하는 방법이 잘 일반화되어야 하기 때문에 이 간단한 방법론을 사용하여 조건적으로 의존하는 다른 과제를 탐색할 수 있음을 제안한다.\n' +
      '\n' +
      '## 5. 윤리적 고려 사항\n' +
      '\n' +
      '제출된 논문의 연구는 우리 조직의 연구 및 출판 과정의 일부로 검토되었다. 여기에는 필요한 모든 의무가 충족되도록 돕기 위한 개인 정보 보호 및 법적 검토가 포함된다.\n' +
      '\n' +
      '제품 및 서비스에 대한 무료 및 개방형 액세스를 지원하기 위해 광고에 의존하는 많은 회사와 마찬가지로 우리 플랫폼은 광고를 포함하여 개인화된 콘텐츠를 권장하는 알고리즘을 활용합니다. 추천 시스템은 불완전하며 자동화된 의사 결정 시스템은 모든 사람을 공평하게 취급하지 않을 수 있다. ML에서 불평등과 편향의 식별과 예방은 우리가 밀접하게 따르는 증가하는 연구 분야이다.\n' +
      '\n' +
      '편향의 알고리즘 증폭을 감지하고 방지하기 위한 지속적인 노력에도 불구하고 불평등은 여전히 사회에 존재하므로 많은 모델을 훈련하는 데 사용되는 소스 데이터에 영향을 미칠 수 있다. 이 논문의 저자는 수행된 실험이 추천 시스템에 존재하는 고유한 편향에 긍정적인 또는 부정적인 영향을 미친다는 것을 알지 못한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* A. Ahmed, A. Das, and A. J. Smola (2014)Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising. ASM International Conference on Web Search and Data Mining(WSDM)에서, 인용: SS1, SS2.\n' +
      '*Y. Bengio (2012)Deep learning of representations for nonsupervised and transfer learning. Proceedings of ICML Workshop on Unsupervised and Transfer Learning(Proceedings of Machine Learning Research, Vol. 27), K. 기연 Lemaire, G. Taylor, and D. Silver(Eds.), pp. 17-36. External Links: Link, Document Cited by: SS1, SS2.\n' +
      '* J. Devlin, M. 장광 이근 Toutanova (2018)Bert: 언어 이해를 위한 심층 양방향 변압기 사전 훈련. arXiv preprint arXiv:1810.04805. 인용: SS1, SS2.\n' +
      '* J. Kirkpatrick, R. 파스카누 Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. 밀란 Ramalho, A. Grabska-Barwinska, et al. (2017)Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of sciences114(13), pp. 3521-3526. Cited by: SS1, SS2.\n' +
      '* J. Ma, Z. 조석 이재천 Hong, and E. H. Chi (2018)Modeling task relationships in multi-gate mixture-of-experts. Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD\'18) , pp. 1930-1939. External Links: Link, Document Cited by: SS1, SS2.\n' +
      '*X. 마림 조광황 왕진 후석호 Zhu and K. Gai(2018)Entire space multi-task model: Post-click conversion rate를 추정하는 효과적인 접근 방법. The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pp. 1137-1140. Cited by: SS1, SS2.\n' +
      '* C. Perlich, B. Dalessandro, T. 오래더 Stitelman, and F. J. Provost (2014) Machine Learning for target display advertising: transfer learning in action. 마케터 Learn.95(1), pp.103-127. External Links: Link, Document Cited by: SS1, SS2.\n' +
      '*Z. 진락 양호장 Tay R. K. Pasumarthi X. 왕민 Bendersky, M. Najork(2021) 신경망 랭커들은 그래디언트 부스팅된 결정 트리들에 의해 여전히 우수한가? In International Conference on Learning Representations, pp. 11197-1120. Cited by: SS1, SS2.\n' +
      '*S. Ruder(2017) 심층 신경망에서의 멀티-태스크 학습의 개요. 외부 링크: 링크, 문서 인용: SS1, SS2입니다.\n' +
      '*C. Tan, F. Sun, T. 공원 Zhang, C. Yang, C. Liu(2018)A survey on deep transfer learning. In International conference on artificial neural networks, pp. 270-279. Cited by: SS1, SS2.\n' +
      '*H. Tang, J. Liu, M. Zhao, X. 공(2020) 점진적 계층 추출(프라임): 개인화된 추천을 위한 새로운 다중 태스크 학습(MTL) 모델. In Fourteenth ACM Conference on Recommender Systems, pp. 269-278. Cited by: SS1, SS2.\n' +
      '*Y. 왕장규 Da, 및 A. Zeng(2020) Delayed feedback modeling for the entire space conversion rate prediction. arXiv preprint arXiv:2011.11826. Cited by: SS1, SS2.\n' +
      '* J. Yosinski, J. Clune, Y. Bengio, 및 H. Lipson (2014) 심층 신경망에서의 특징들은 얼마나 전달가능한가? CoRRabs/1411.1792. External Links: Link, 1411.1792 Cited by: SS1, SS2.\n' +
      '*Y. Zhang and Q. Yang(2021)A survey on multi-task learning. 외부 링크: 링크, 1707.08114 인용: SS1, SS2.\n' +
      '*Z. 조락 홍래 위진천 앤드루스, A. 쿠메카, M. Sathiamoorthy X. Yi, and E. Chi(2019)Recommending what video to watch next: multi-task ranking system. In Proceedings of the 13th ACM Conference on Recommender Systems, pp. 43-51. External Links: Link, Document Cited by: SS1, SS2.\n' +
      '\n' +
      '모델 특성 체크리스트\n' +
      '\n' +
      '표 1은 각 모델에 대해 이루어진 설계 선택의 요약을 제공한다. 또한 모델이 구현되는 방식을 둘러싼 모호성을 제거하기 위해 아래에 몇 가지 추가 설명을 제공한다.\n' +
      '\n' +
      '우리의 기준인 IP 모델은 완전히 분리된 두 개의 MLP를 사용한다. 하나의 모델은 인상, \\(x\\)의 데이터 세트로 훈련되고 클릭, \\(y\\)을 예측한다. 다른 모델에는 클릭된 노출의 데이터 세트가 제공되며, \\(y=1\\) 및 \\(z\\) 설치를 예측한다.\n' +
      '\n' +
      '나머지 모델의 경우 _다운샘플링된 노출 및 모든 클릭_을 포함하는 단일 데이터 세트가 사용되었습니다. 그런 다음 섹션 2에서 논의된 모델 설계와 함께 필요한 훈련 체제를 생성하기 위해 각 손실 헤드에 샘플 가중치를 사용한다.\n' +
      '\n' +
      'ESMM, ESMM-NS, ESSP-Split은 양쪽 머리에 있는 모든 훈련 샘플을 사용한다. 즉, 샘플 가중치는 두 손실 모두에 대해 모든 샘플에 대해 1.0으로 설정된다.\n' +
      '\n' +
      'IPSP 모델은 일부 샘플 가중치를 0.0으로 설정해야 한다. 구체적으로 클릭되지 않은 모든 인상, \\(y=0\\), CVR 예측을 위한 샘플 가중치가 0인 \\(p(z=1|y=1,x)\\). 결과적으로, CTR 분기의 파라미터 및 (CTR 분기를 통한) 공유 파라미터만이 이러한 미클릭 샘플에 대해 업데이트될 것이다. 이것은 설정된 배치 크기에 대해, CVR 손실을 통해 구배 업데이트를 생성하는 샘플의 수가 (1) 가변적이고 (2) 배치 크기 6보다 작다는 것을 의미한다.\n' +
      '\n' +
      '각주 6: (2)는 배치의 모든 샘플이 클릭되었다는 사라지는 낮은 확률 이벤트 이외의 모든 경우에 적용된다.\n' +
      '\n' +
      'ESP 모델은 모든 샘플 가중치가 1.0으로 설정된 설치 레이블 \\(z\\)만 필요한 단일 데이터 세트를 사용한다.\n' +
      '\n' +
      '## Appendix B Pr-Auc\n' +
      '\n' +
      '많은 온라인 광고 응용 프로그램에서 모델의 보정이 중요하기 때문에 교차 엔트로피 메트릭에 초점을 맞췄다. 그러나 완전성을 위해 그림 4에 PR-AUC 메트릭을 사용한 결과를 포함한다. CE 메트릭과 비교하여 평균 이동의 순서가 변경되지만 전체 결론은 변경되지 않는다. 여러 다른 접근법이 베이스라인 IP 접근법을 능가하고, 모든 공유 파라미터 또는 전체 공간 모델이 상당히 잘 수행된다. 특히 ESP는 이 메트릭에서 훨씬 더 나은 성능을 발휘합니다.\n' +
      '\n' +
      '## 부록 C 비정상성\n' +
      '\n' +
      '우리는 모델의 예측의 성능 저하를 관찰하는 것도 흥미로울 수 있다고 생각했다. 일반적으로 우리의 평가 메트릭은 데이터의 다음 날, 즉 (트레이닝+1) 번째 날에 계산되었다. 이러한 실험을 위해 훈련과 예측 사이의 기간을 늘리면서 무슨 일이 일어났는지 관찰하고 싶었다. 실험을 동기 부여 하는 아이디어는 모델이 학습 하는 방식에 약간의 차이가 있을 수 있다는 것입니다 (예: MTL 모델이 시간이 지남에 따라 더 잘 일반화 될 수 있는 더 나은 사용자 임베딩을 학습 하도록 강요 받는 한 가지 가능성). 여기서 비교는 IP와 ESMM 모델 설계 간의 비교였다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c} Model Name & Shared Parameters & Entire Space & Weighted CVR \\\\ \\hline IP & & & \\\\ ESMM & ✓ & ✓ & ✓ \\\\ ESMM-NS & & ✓ & ✓ \\\\ ESSP-Split & ✓ & ✓ & \\\\ IPSP & ✓ & & \\\\ ESP & & ✓ & \\\\ \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1. 6개의 상이한 모델이 테스트되었고 각 모델이 캡처하는 "특성"이다.\n' +
      '\n' +
      '그림 5의 데이터는 두 유형의 10개 모델(각각 튜닝된 하이퍼파라미터 세트를 사용하여)을 학습하고 \\(n=2,3,...,6\\)에 대한 학습 후 데이터의 \\(n\\) 번째 날에 이러한 각 모델을 평가하여 생성되었다. 점 구름은 주어진 날의 각 모델에 대한 점수이고 X 표지자는 평균을 나타냅니다(분산은 크게 다르지 않으므로 이 도표에서 생략합니다). 우리는 공연 델타의 의미 있는 패턴이나 행동을 관찰하지 못했다. ESM 모델은 IP 모델에 대한 성능 우위를 유지하지만, 비록 Day 6까지는 사실상 제로이지만, 그러나\n' +
      '\n' +
      '도 4. 모델의 PR-AUC 성능.\n' +
      '\n' +
      '도 5. 모델 성능 감쇠\n' +
      '\n' +
      '두 모델의 예측 성능은 유사하게 붕괴되는 것으로 판단된다. 주목할 점은, 5일에서 6일 사이에 보이는 이득과 2일에서 3일 사이에 ESMM에 대한 작은(평균) 개선을 설명하는 성능에 상당한 일 간 변동이 있다는 것이다. 이러한 "개선"은 데이터의 변동일 뿐이며 모델링 결정의 결과가 아니다. 다르게 말하면, 그러한 패턴은 모든 유형의 분류기에서 (확률적으로) 나타날 가능성이 있다.\n' +
      '\n' +
      '## Appendix D Ctr Task\n' +
      '\n' +
      '우리는 설치 전체에 걸쳐 \\(p(z=1|x)\\)는 관심의 양이고 클릭 \\(p(y=1|x)\\)은 설치 예측과 관련이 있는 한 관심이 없다고 가정했다. 우리는 이러한 모델의 CTR 성능이 극적으로 변동한다는 점에 주목한다. 예를 들어 ESP는 CTR을 예측하지도 않으며 가중 CVR을 특징으로 하는 모든 모델은 CTR에 대해 나쁜 성능을 보인다. CCR 헤드의 기울기가 곱셈 연산을 통해 CTR 분기를 통해 부분적으로 역전파되기 때문에 이것은 놀라운 일이 아니다. CTR을 정확하게 예측하기 위한 비즈니스 또는 기계 학습 동기를 가진 엔지니어 또는 팀은 (1) 이 작업에 대해 특별히 별도의 모델을 훈련해야 하거나 (2) 특정 모델 설계에 대한 성능 페널티를 수용해야 하기 때문에 이 점에 주목한다.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>