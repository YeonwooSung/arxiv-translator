# 엄격한 Cold-start 항목 추천을 위한 Multi-task 항목 특성 그래프 사전 학습

YUWEI CAO

일리노이주립대학교

 USA

LIANGWEI YANG

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

일리노이주립대학교

 USA

USA

###### Abstract

권장 시스템은 사용자-항목 상호 작용을 완전히 사용할 수 없는 _엄격한 저온 시작(SCS)_ 시나리오에서 어려움을 겪습니다. 잘 정립된, 지배적인 아이덴티티(ID) 기반 접근법은 완전히 작동하지 않는다. 반면에 콜드 스타트 추천인은 새로운 항목을 기존 항목에 매핑하기 위해 항목 내용(브랜드, 제목, 설명 등)을 활용합니다. 그러나, 기존의 SCS 추천자들은 노이즈 또는 정보 손실을 도입하는 _coarse-grained_ 방식으로 아이템 콘텐츠를 탐색한다. 또한, 사용자의 구매 순서와 리뷰 텍스트와 같은 아이템 콘텐츠 이외의 유용한 데이터 소스는 대부분 무시된다. 본 연구에서는 기존 아이템과 SCS 아이템 간의 격차를 해소하고, SCS 아이템 추천을 위한 지식 가능한 아이템 속성 그래프를 사전 학습하는 데 있어 _fine-grained_ 아이템 속성의 역할을 탐구한다. 제안된 프레임워크인 ColdGPT는 아이템 콘텐츠에서 세밀한 속성을 추출하여 아이템 속성 상관 관계를 아이템 속성 그래프로 모델링한다. ColdGPT는 다양한 사용 가능한 데이터 소스, 즉 아이템 콘텐츠, 과거 구매 순서 및 기존 아이템의 리뷰 텍스트로부터 멀티태스크 학습을 통해 아이템을 아이템 속성 그래프로 전달한다. 긍정적인 전달을 용이하게 하기 위해, ColdGPT는 데이터 소스의 자연스러운 형태에 따라 특정 서브모듈을 설계하고, 통합된 정렬 및 균일성 손실을 통해 다중 사전 학습 작업을 조정하는 것을 제안한다. 본 연구에서 사전 학습된 아이템 속성 그래프는 암시적이고 확장 가능한 아이템 임베딩 매트릭스로 작용하여, 아이템 속성 그래프에 이러한 아이템을 삽입하고 그들의 속성 임베딩을 전파함으로써 SCS 아이템 임베딩을 쉽게 획득할 수 있다. 우리는 평가를 위한 SCS 설정을 보장하기 위해 Yelp, Amazon-home 및 Amazon-sports와 같은 세 가지 공개 데이터 세트를 신중하게 처리한다. 광범위한 실험을 통해 ColdGPT가 큰 마진으로 기존 SCS 추천기보다 일관되게 우수하며, 심지어 4개의 데이터 세트 중 2개의 데이터 세트에 대해 75-224배 더 많은 교차 도메인 데이터에 대해 사전 훈련된 모델을 능가한다는 것을 보여준다. SCS 평가를 위한 코드 및 전처리된 데이터 세트는 향후 SCS 연구에 도움이 되도록 공개적으로 사용할 수 있다.

[] **정보 시스템 \(\rightarrow\) 데이터 마이닝: 협업 필터링**

[] **정보 시스템 \(\rightarrow\) 데이터 마이닝: 협업 필터링**

[] **추가 키 단어 및 문구: 엄격한 Cold-start 권장 사항, 그래프 사전 학습, 다중 작업 학습**

[] **ACM 참조 형식:**

유웨이 조, 량웨이 양, 첸 왕, 지웨이 류, 하오펭, 첸유, 필립 S. 유 2023. 엄격한 콜드 스타트 아이템 추천을 위한 멀티 태스크 아이템-속성 그래프 사전 트레이닝. _RecSys'23: ACM Conference on Recommender Systems, September 18-22, 2023, Singapore_. ACM, New York, NY, USA, 18 pages. [https://doi.org/] (https://doi.org/)

## 1. Introduction

추천 시스템들은 잘 확립된, 지배적인 아이덴티티(ID) 기반 접근법들이 악화되는 콜드-스타트 시나리오들에서 고통받는다(Wang et al., 2018; Wang et al., 2019). 문제는 특히 Zero-shot, _strict cold-start(SCS)_(Wang et al., 2019) 설정에서 심각하다. 이 연구에서는 SCS 항목 추천, 즉 이러한 새로운 항목의 과거 등급 기록에 의존하지 않고 교육 중에 보이지 않는 새로운 항목을 추천할 것을 제안한다. 이는 _few-shot cold-start_ 항목 권장 사항 (Wang et al., 2019)과 차별화 됩니다. 새 항목의 등급 기록은 훈련 및/또는 사전 훈련 중에 액세스할 수 없지만 추론 및/또는 미세 조정을 위해 사용할 수 있습니다.

콜드 스타트 품목을 추천하는 것은 매우 중요합니다. 그림 1(a)에서 볼 수 있듯이 2017년 월간 아마존 홈 구매에서 SCS와 쇼트 콜드 스타트 품목(예: 축제 신작)은 각각 최대 4%와 22%를 차지한다. 콜드 스타트 추천은 필수적인 작업이지만, 아직 덜 탐구되어 있다(Wang et al., 2019). SCS 항목 추천을 다루는 연구는 거의 없으며, 등급 기록이 없으면 새로운 항목, 즉 가격, 브랜드, 설명 등과 같은 보조 기능에 대한 지식이 거의 없다. 본질적으로, 풍부한 정보(항목 내용 외에도 역사적 평가 점수 및 리뷰 텍스트)와 관련된 따뜻한 시작 항목으로부터 지식을 전달하는 데 의존할 것이다. 이와 같이, 기존의 SCS 추천자들(Beng et al., 2017; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019)은 사용자들 및 아이템들의 선호도 임베딩들을 그들의 콘텐츠 임베딩들로부터 재구성하기 위해 노력한다. 또한, NLP의 급속한 발전으로 인해, UniSRec(Wang et al., 2019) 및 P5(Wang et al., 2019)와 같은 최근의 방법들은 사전 훈련된 언어 모델들(PLMs)을 추천에 적응시키고(Wang et al., 2019; Wang et al., 2019) SCS 아이템들을 수용할 수 있다. 그러나 기존 메서드는 _coarse-grained_ 방식으로 사용 가능한 데이터 원본만 탐색합니다. 특히 선호도 임베딩을 재구성하는 방법은 리뷰 텍스트와 사용자의 등급 시퀀스에 포함된 항목 상관 관계를 모두 무시한다. UniSRec(Wang et al., 2019)는 PLM의 입력 길이 제한으로 인해 단순히 항목 내용을 연결하고 정보를 잘라낸다. P5(Wang et al., 2019)는 수치 등급 시퀀스를 포함한 다양한 데이터 소스를 자신의 PLM 백본에 맞도록 자연 언어 시퀀스로 왜곡한다(Wang et al., 2019). 이러한 거친 결정 처리는 유용한 정보와 잡음을 혼합하는 경향이 있으며 모델의 선호도 특성화 능력을 방해한다.

따라서 이 문서에서는 SCS 항목에 대 한 정보를 _fine-grained_ 방식으로 활용하는 방법을 조사 합니다. 구체적으로, 특히 그러한 SCS 아이템들에 대한 추천을 위한 적절한 아이템 정보를 특성화하기 위해 아이템 _속성들_ 즉, 아이템들을 기술하는 문구들을 효과적으로 활용하는 방법을 연구한다. 우리는 새로운 항목이 있지만 관찰합니다.

그림 1. 2017년 아마존 주택 구매의 분포(a)와 제안된 품목-속성 그래프(b)의 예입니다. (a)에서 'SCS', 'few-shot CS' 및 'Other'는 SCS의 구매, few-shot cold-start(각각 \(>1\) 및 \(\leq 20\)번 구매한 품목) 및 기타 품목을 각각 계산한다. (b)에서 LHS는 사전 훈련된 항목 속성 그래프를 보여주고 RHS는 SCS 레스토랑 C와 새로운 속성인 '가족 소유'가 삽입된 업데이트된 항목 속성 그래프를 보여준다.

항상 출현하는 속성은 상대적으로 안정적이다. 우리는 표 1에서 홈-SCS 데이터 세트의 \(2,867\) 테스트 항목이 하나의 \(1\) 새로운 속성만 도입한다는 것을 보여준다. 따라서 아이템의 속성을 통해 추천 모델을 학습하면 SCS 아이템을 추천할 수 있다. 도 1의 (b)에서, 예를 들어, A 레스토랑을 좋아하는 사용자는 동일한 스타일('이탈리안')을 공유하고 유사한 음식('피자')을 제공하는 새로운 C 레스토랑에 관심을 가질 수 있다. 이 직관에 기초하여, 우리는 SCS 아이템 추천을 위해 이분형 아이템-속성 그래프에 대한 모델을 사전 트레이닝할 것을 제안한다. 목표는 사용 가능한 데이터 리소스에서 속성 임베딩으로 항목 관련 지식을 전달하는 것입니다. 그런 다음, 정보적 SCS 아이템 임베딩은 이러한 아이템들의 도착 시에 쉽게 획득될 수 있다 - 새로운 속성들과 함께 SCS 아이템들을 아이템-속성 그래프에 삽입하고 그들의 이웃들의 임베딩을 전파한다. 예를 들어, 도 1(b)에서, 레스토랑 C의 임베딩은 그 속성들, 즉 '이탈리아인', '피자' 및 '가족 소유'의 임베딩들을 융합함으로써 획득된다. 첫 번째 두 번째는 기존 레스토랑과 관련된 사전 학습된 지식을 포함하고 마지막 두 번째는 레스토랑 C 고유의 정보를 도입한다. 의심할 여지 없이, 제안된 아이템 속성 그래프는 SCS 설정에서 기존의 명시적이고 고정된 아이템 ID 임베딩 매트릭스의 암시적이고 확장 가능한 대응물이다.

지식이 풍부한 항목 속성 그래프를 미리 학습하려면 세 가지 문제를 적절하게 해결해야 합니다. **1) 항목 특성 그래프의 구성입니다.* * 한편으로는 항목 내용에서 세분화된 항목 특성을 마이닝하는 것은 중요하지 않습니다. 항목 내용은 길고 시끄러울 수 있으며 전체 캡 문장, URL, 특수 문자 등이 포함될 수 있습니다. 이를 신중하게 전처리하고 명사구(2.2절에서 설명한 대로 원시 항목 내용보다 항목을 더 잘 설명함)를 추출하여 고품질 항목 속성 역할을 한다. 반면, 리뷰 텍스트는 아이템 속성에 대한 사용자의 주관적인 인식을 반영하여 객관적인 아이템 콘텐츠에 대한 가치 있는 보완책 역할을 한다. 그러나, 리뷰 텍스트의 높은 볼륨과 복잡성으로 인해, 그것들을 직설적으로 사용하는 것은 비용이 많이 들고 비효율적이다(섹션 3에서 실험적으로 검증됨). 구 단위 감정 분석[74]의 연구에서 영감을 받아 정서가 포함된 구문을 추출하고 이에 의해 반영되는 항목 상관 관계를 모델링한다. 예를 들어, 도 1의 (b)에서 '계절별 애피타이저'와 같은 주관적인 설명은 A 레스토랑과 B 레스토랑 사이의 미묘한 상관관계를 밝히는 데 도움이 된다.

**2) 사용 가능한 다양한 데이터 원본, 즉 항목 콘텐츠, 과거 등급 점수 및 검토 텍스트에서 지식을 전달합니다. 위의 정보를 보존하기 위해 우리는 추가 탐색을 위해 자연 형태에 따라 하위 모듈을 설계한다. 구체적으로, 아이템 콘텐츠는, 전술한 아이템-속성 그래프로 모델링된 후, PLM 및 그래프 신경망(GNN)[25, 53]으로 임베딩되어, 기초 자연 언어 의미론 및 고차 구조 정보를 캡처한다. 이력 평가 점수는 항목-항목 상관 관계를 추출하기 위해 트랜스포머 [52] 기반 순차 하위 모듈로 모델링된다. 리뷰 텍스트는 아이템 내용과 유사하지만 별도의 서브모듈을 사용하여 채굴된다.

**3) 모든 지식을 동시에 통합합니다.* * 이러한 하위 모듈이 항목 특성 그래프로 지식을 전달하도록 특별히 설계된 자체 감독 사전 훈련 작업을 사용하여 다중 작업 학습(MTL)[4]을 수행합니다. 우리는 다른 하위 모듈에 대해 일반적으로 사용되는 손실 항을 채택할 때 차선책으로 이어지는 작업 간의 부정적인 전달[4]을 관찰한다(섹션 3.3에 자세히 설명되어 있음). 우리는 부정적인 지식 전달이 다른 목적 함수의 불일치로 인해 발생한다고 가정한다. 따라서, 우리는 서로 다른 작업으로부터 지식을 통합적으로 통합할 것을 제안한다. 구체적으로, 일관된 _alignment_[59] 손실을 통해 상이한 태스크로부터 학습된 임베딩을 조정하는 것을 제안한다. 이러한 방식으로, 다수의 태스크로부터의 지식이 효과적으로 공유된다. 그러나 다중작업 지식의 정렬을 규칙화하지 않고 수행하는 것은 최적화 과정이 사소한 해로 변함에 따라 임베딩 붕괴 문제를 야기한다[23, 59]. 따라서, 우리는 이러한 임베딩들이 공통 하이퍼-스피어 상에 균일하게 분포될 수 있게 하는 멀티-태스크 _uniformity_[59] 정규화 목표를 고안한다. 이처럼 지식은 효과적으로 융합되어 긍정적으로 전이될 수 있다. 협력 필터링을 위해 정렬 및 균일성을 활용한다는 최근 연구[56]와 달리, 우리는 지식 전달에서 다중 작업 정렬 및 균일성의 놀라운 능력을 입증하는 첫 번째 작업이다. 또한, 다양한 사전 훈련 과제의 불일치를 해결하고 다중 작업 훈련 패러다임을 통해 항목 속성, 항목 항목 및 항목 검토 상관 관계를 동시에 특성화하는 방법을 조사한다.

제안된 통합 태스크 손실은 섹션 3.3에서 입증된 바와 같이 다중 태스크 사전 훈련에 큰 이점이 있다. 긍정적인 전달을 더욱 용이하게 하기 위해 최근 MTL 연구(Zhu et al., 2020; Wang et al., 2021)에서 이러한 접근법이 ad-hoc MTL 방법(Zhu et al., 2020; Wang et al., 2021)보다 본질적으로 더 우수함을 시사함에 따라 태스크 가중치, 학습률 및 정규화 가중치를 포함한 하이퍼파라미터를 신중하게 조정한다. 제안된 프레임워크를 아이템 속성 그래프 사전 훈련 기반 SCS 아이템 추천기, 즉 ColdGPT(GPT는 그래프 사전 훈련을 의미하며, 이는 생성적 사전 훈련 변환기(Beng et al., 2019))와 차별화된다. 우리는 ColdGPT의 평가를 위한 SCS 설정을 보장하기 위해 Yelp, Amazon-home 및 Amazon-sports와 같은 세 가지 공개 데이터 세트를 신중하게 처리한다. 광범위한 실험을 통해 ColdGPT가 기존 콜드 스타트 추천기보다 큰 마진을 통해 일관되게 우수하며, 4개의 데이터 세트 중 2개의 데이터 세트에 대해 대용량 교차 도메인 데이터에 대해 사전 훈련된 모델을 능가하는 것으로 나타났다.

우리 작업의 기여는 다음과 같다. 1) SCS 설정에서 항목 추천을 다루는데, 이는 매우 어렵고 탐구력이 부족하다. 기존의 SCS 방법에 비해 항목 내용 외에도 순차적인 항목 상관 관계 및 리뷰 텍스트와 같은 정보를 더 많이 고려한다. 2) 기존 추천인이 없는 것과 같이 세분화된 방법으로 아이템 콘텐츠를 탐색하고, 아이템 속성을 명시적으로 모델링하여 기존 아이템과 SCS 아이템 간의 격차를 해소한다. 사전 훈련된 아이템 속성 그래프는 SCS 설정에서 전통적인 아이템 ID 임베딩 매트릭스의 암시적이고 확장 가능한 대응물 역할을 하며, 그들의 속성을 사용하여 아이템을 쉽게 인코딩할 수 있게 한다. 3) 기존 아이템의 다양한 데이터 소스, 즉 아이템 내용, 평점 점수, 리뷰 텍스트의 지식을 아이템 속성 그래프로 효과적으로 전달한다. 제안된 프레임워크인 ColdGPT는 다양한 데이터 소스의 자연스러운 형태에 따라 특별히 설계된 서브모듈을 채택한다. ColdGPT의 다중 작업 사전 훈련 패러다임은 긍정적인 지식 전달에서 다중 작업 정렬 및 균일성의 놀라운 능력을 입증한 최초의 것이다. 4) SCS 환경에서 ColdGPT를 평가하는데, 이는 이전 연구에서 간과되거나 덜 탐구된 것이다. 광범위한 실험은 다양한 기준선보다 ColdGPT의 우수한 성능과 ColdGPT의 구성요소의 효과를 보여준다. 향후 SCS 연구를 돕기 위해 SCS 설정을 유지하기 위해 신중하게 처리된 코드 및 데이터 세트를 공개적으로 사용할 수 있다.

각주 1: [https://github.com/YuweiCao-UIC/ColdGPT](https://github.com/YuweiCao-UIC/ColdGPT)

## 2. Methodology

본 절에서는 SCS 아이템 추천을 해결하기 위해 SCS 아이템 임베딩을 효율적이고 효과적으로 추론할 수 있는 아이템-속성 그래프를 사전 학습한다. 그림 2는 제안된 ColdGPT 프레임워크의 전체 아키텍처를 보여준다. 우리는 먼저 2.1절에서 과제를 공식화한다. 2.2절에서는 항목-속성 그래프의 구성을 제시한다. 섹션 2.3은 아이템-속성 그래프가 다양한 이용가능한 데이터 소스들로부터 지식을 전달함으로써 사전 트레이닝되는 방법을 예시한다. 섹션 2.4에서는 사전 훈련된 항목-속성 그래프를 사용하여 SCS 항목 임베딩을 쉽게 획득할 수 있는 방법을 소개한다.

### SCS Item Recommendation

\(\mathcal{U}\), \(\mathcal{I}_{old}\), \(\mathcal{I}_{SCS}\)은 각각 사용자, 기존 항목, SCS 항목 집합을 의미하고, \(\mathcal{I}_{old}\cap\mathcal{I}_{SCS}=\emptyset\)은 사용자, 기존 항목, SCS 항목 집합을 의미한다. SCS 아이템 추천의 태스크는 특정 데이터셋에 따라 1) \(\mathcal{Y}_{old}=\{(u,i)|u\in\mathcal{U},i\in\mathcal{I}_{old}\}\), 2) \(\mathcal{C}=\{C_{i}|i\in\mathcal{I}_{old}\cup\mathcal{I}_{SCS}\}\), 항목 내용 집합인 항목 내용 \(\mathcal{C}_{i}\)에는 _title_, _brand_, _category_, _description field_ 등이 포함된다. 우리의 목표는 \(\mathcal{I}_{SCS}\)을 \(\mathcal{U}\)으로 추천하는 모델 \(f_{\mathcal{O}\)을 학습하는 것이다. 즉, \(f_{\mathcal{O}}(C,\mathcal{Y}_{old})=\hat{\mathcal{Y}}_{SCS}=\{(u,i)|u\in\mathcal{U},i\in\mathcal{I}_{SCS}\}\)을 학습하는 것이다. 즉, \(maximize(|\hat{\mathcal{Y}}_{SCS}\cap\mathcal{Y}_{SCS}|)\), \(\mathcal{Y}_{SCS}=\{(u,i)|u\in\mathcal{U},i\in\mathcal{I}_{SCS},u\text{ subsequently interactionss}i\}\)을 학습하는 것이다.

### 항목 특성 그래프 구성

제안된 항목-속성 그래프를 구성하는 주요 과제는 항목 내용, 즉 _브랜드, 범주, 설명_ 등과 같은 필드가 주어진 속성을 결정하는 것이다. 아이템 브리징에서 미디어로서의 본질적인 역할을 고려할 때 속성은 아이템의 속성을 반영하는 용어만 포함해야 한다. 그림 2의 (a)와 같이 브랜드와 같은 분야는 짧고 정밀하다. 따라서 속성 집합에 직접 추가할 수 있습니다 (\mathcal{A}\). 그러나 길고 잡음이 많은 필드에서는 전처리 과정이 필요하다. 우리는 원시 문장에 비해 명사구가 관련 없는 정보가 적은 항목을 더 잘 묘사한다는 것을 관찰한다. 예를 들어, 도 2의 (a)에서 샘플 아이템 내용의 raw description 필드에는 'whether', 'you're'와 같이 아이템과 무관한 단어들이 포함되어 있다. 해시태그 및 URL과 같은 노이즈도 있습니다. 대조적으로, 설명 분야에 포함된 명사구, 즉 '원예 용품', '휴일 장식', '흑회색 플라스틱 용기'는 훨씬 덜 중복된 정보로 아이템을 정확하게 설명한다. 따라서 명사구를 추출하여 항목 속성으로 사용하고, 이 속성들을 \(\mathcal{A}\)에 추가한다. 먼저 URL, HTML 태그, 특수문자와 같은 잡음과 사람이 읽을 수 없는 내용을 필터링한 후 명사구 추출을 위해 NLP 툴킷 2를 활용한다. 그림 2 (b)에서 볼 수 있듯이 제안된 항목-속성 그래프 \(\mathcal{G}\)의 구성은 간단해진다. 우리는 모든 오래된 항목과 획득한 모든 항목의 집합을 다룬다.

그림 2. 제안된 ColdGPT 프레임워크의 전체 아키텍처. 파란색, 빨간색 및 보라색 노드는 각각 항목, 속성 및 검토 용어를 나타낸다. (a)는 세밀한 속성의 추출을 나타낸다. (b)는 아이템-속성 그래프의 구성을 나타낸다. (c)는 PLM(회색 직사각형)의 파라미터가 고정된 아이템-속성 그래프의 멀티-태스크 사전-트레이닝을 도시한다. (d)는 미리 트레이닝된 아이템-속성 그래프를 갖는 SCS 아이템 임베딩을 도시한다.

즉, 노드 집합은 \(\mathcal{V}=\mathcal{I}_{old}\cup\mathcal{A}\)이고, 에지 집합은 \(\mathcal{G}\)\(\mathcal{E}=\{(i,a)|i\in\mathcal{I}_{old},a\in\mathcal{A},i\text{ has attribute }a\}\)이다.

### 항목 특성 그래프 사전 학습

그림 2(c)는 제안된 문항-속성 그래프의 멀티태스크 사전학습을 보여준다. 사전 훈련 과정은 사용 가능한 다양한 데이터 소스, 즉 항목 내용 \(\mathcal{C}\), 과거 평가 점수 및 이전 항목의 리뷰 텍스트 \(\mathcal{Y}_{old}\)의 지식을 항목 속성 그래프에 융합하는 것을 목표로 한다. 지식 전달을 용이하게 하기 위해, 섹션 2.3.1 - 2.3.3에 소개된 바와 같이, 정렬-및-균일성의 속성을 일관되게 고수하는 통합된 손실을 갖는 사전 트레이닝 작업들 뿐만 아니라 데이터 소스의 자연적인 형태에 관한 특정 서브모듈들을 설계한다(Srivastava 등, 2017). 이어서 사전 트레이닝은 섹션 2.3.4에 상세히 설명된 바와 같이 MTL 방식으로 수행된다.

#### 2.3.1. 작업 1: 항목 특성 상관 모델링

제1 사전-트레이닝 태스크는 속성들의 자연 언어 의미론들 및 고차 항목-속성 상관관계들을 항목-속성 그래프(보다 구체적으로, 그것의 노드들의 표현들에 통합한다. 지식 추출을 위해 PLMs, _e.g._, BERT (Devlin et al., 2017), GNNs, _e.g._, GCN (Kipf and Welling, 2017)을 채택하고 지식 전달을 위한 정렬 및 균일성 기반 손실 항을 설계한다.

그림 2(c)와 같이 속성 및 항목(각 항목은 속성의 연결로 표시됨)을 PLM에 입력하여 자연어 임베딩을 얻는다. 이러한 임베딩을 해석기, 즉 다층 퍼셉트론(MLP)에 입력하여 관련 없는 정보를 필터링하고 더 쉬운 다운스트림 모델링을 위해 저차원 공간으로 매핑한다. 그런 다음 매핑된 임베딩을 GNN을 통해 항목 속성 그래프에 전파하여 고차 항목 속성 상관 관계를 학습한다. 순방향 전파는 다음과 같다:

\[h_{1}(x)=\text{GNN}_{1}(\text{Interpreter}(\text{PLM}(x))),x\in\mathcal{I}_{ old}\cup\mathcal{A}. \tag{1}\]

태스크 1의 인코더로 지칭되는 상기 수학식의 RHS는 아이템-속성 그래프를 인코딩한다. 이는 암시적이고 확장 가능한 임베딩 매트릭스의 역할을 하며, 또한 다른 사전-훈련 작업(다음 섹션에서 논의됨)에 의해 전체적으로 또는 부분적으로 공유된다.

그래프 Pre-training(Kipf and Welling, 2017)에서 일반적으로 사용되는 InfoNCE(Han et al., 2017) 또는 BPR(Kipf and Welling, 2017) 손실을 채택하는 대신, 대비 학습에 유리하고 희소성 문제를 완화하는데 필수적인 정렬 및 균일성 특성을 고수하는 자기 감독 손실(Srivastava et al., 2017)을 갖는 첫 번째 사전-훈련 과제를 설계한다. 구체적으로 작업 1은 \(\mathcal{L}_{1}\) as:

\[\mathcal{L}_{1}=\mathcal{L}_{a1}+\lambda\mathcal{L}_{u1}, \tag{2}\]

\[\mathcal{L}_{a1}=\mathop{\mathbb{E}}_{(i,a)\sim p_{\text{pos},\text{ia}}}\parallel h _{1}(i)-h_{1}(a)\parallel^{2}, \tag{3}\]

\[\mathcal{L}_{u1}=\log\mathop{\mathbb{E}}_{(i,i^{\prime})\sim p_{\text{item}}}e^{-2\left\|h_{1}(i)-h_{1}(i^{\prime})\right\|^{2}}/2+\log\mathop{\mathbb{E}}_{(a,a^{\prime})\sim p_{\text{attr}}}e^{-2\left\|h_{1}(a)-h_{1}(a^{\prime}) \right\|^{2}}/2. \tag{4}\]

\(\mathcal{L}_{a1}\)과\(\mathcal{L}_{u1}\)은 각각 정렬 및 균일 손실 항이다. \ (p_{\text{pos}\_\text{ia}}\)는 긍정적인 항목-속성 쌍의 분포를 나타냅니다. \ (p_{\text{item}}\) 및 \(p_{\text{attr}}\)은 항목과 속성의 데이터 분포를 나타낸다. 실제로, 우리는 배치 내 \((i,a)\), \((i,i^{\prime})\), \((a,a^{\prime})\) 쌍을 사용하여 실제 데이터 분포, 즉 \(p_{\text{pos}\_\text{ia}\), \(p_{\text{item}}\), \(p_{\text{attr}}\)과 일치한다. 직관적으로, \(\mathcal{L}_{a1}\)은 각 항목의 특징들을 그 속성들의 특징들과 정렬하여 그들의 상관관계를 포착하고, \(\mathcal{L}_{u1}\)은 각 항목/속성들을 나머지 항목/속성들로부터 밀어냄으로써 그러한 상관관계를 강조한다.

#### 2.3.2. 작업 2: 항목별 상관 모델링

사전 훈련 작업 2는 이전 항목들 간의 상관 관계를 항목-속성 그래프에 융합하고자 한다. 사용자들의 이력 구매 시퀀스들은 이들 아이템들 사이의 상관들을 반영할 수 있다, 즉, 두 아이템들이 동일한 사용자에 의해 구매된 경우 상관된 것으로 간주된다. 이 직관에 따라 그림 2(c)와 같이 이전 등급 시퀀스를 모델링하기 위해 트랜스포머 기반 순차 인코더를 활용한다. 우리의 순차적 인코더의 아키텍처는 [47]과 유사하다(우리는 다른 순차적 인코더에 의해 채택된 단방향 셀프-어텐션보다 그것의 양방향 셀프-어텐션을 선택한다[24]. 전자는 최근에 적절한 구성으로 더 잘 수행되는 것으로 보여지기 때문에, [39]와 유사하다. 임의로 항목 임베딩을 초기화하는 [47]과 달리 태스크 \(1\)(섹션 2.3.1)의 인코더를 사용하여 암시적이고 확장 가능한 임베딩 행렬 역할을 한다. 순방향 전파는 다음과 같다:

\[h_{2}(u)=\text{FFN}(\text{BiAttn}(\text{mask}(h_{1}(u))+p(u))), \tag{5}\]

여기서 \(u\)는 항목의 시퀀스인 사용자의 과거 구매 시퀀스를 나타냅니다. \ (h_{1}(u)\)는 태스크 \(1\)의 인코더를 사용하여 획득된, \(u\) 내의 아이템들의 초기 임베딩들의 시퀀스이다(수학식 1). \ (\text{mask}(\cdot)\) \(u\)의 일부 항목을 무작위로 마스킹합니다. 즉, 해당 임베딩을 특수 토큰 [마스크]를 나타내는 임베딩으로 바꿉니다. \ (p(u)\)는 \(u\) 내의 아이템들의 위치 정보를 인코딩한다. BiAttn 및 FFN은 BERT4Rec에서와 동일한 멀티-헤드 셀프-어텐션 층들 및 포인트-와이즈 피드-포워드 층들의 스택을 나타낸다. \ (h_{2}(u)\)는 \(u\)에 있는 항목들의 임베딩 시퀀스로서, 시퀀스 레벨 항목-항목 상관관계로 강화된다.

그런 다음 사전 훈련 작업 \(2\)은 시퀀스에서 나머지 컨텍스트 항목이 주어졌을 때 마스킹된 항목을 예측하도록 설계된다. BERT4Rec를 포함한 기존의 순차적 인코더에서 널리 채택되고 있는 교차 엔트로피 손실을 활용하는 대신에, 정렬 및 균일성 특성을 고수하기 위해 손실 항을 설계한다[59]. 이러한 손실 조건은 태스크가 멀티-태스크 사전-훈련에서 서로 협력하는 것을 돕는 다른 사전-훈련 태스크(섹션 2.3.1 및 2.3.3)의 손실과 일치한다(섹션 2.3.4에 예시됨). 작업 손실 \(2\)은 다음과 같이 정의됩니다.

\[\mathcal{L}_{2}=\mathcal{L}_{a2}+\lambda\mathcal{L}_{u2}, \tag{6}\]

\[\mathcal{L}_{a2}=\mathop{\mathbb{E}}_{i\sim p_{\text{mask}}\parallel h_{1}( i)-h_{2}(i)\parallel^{2},\quad\mathcal{L}_{u2}=\log\mathop{\mathbb{E}}_{(i,i^{ \prime})-p_{\text{harm}}}e^{-2\left\lVert h_{1}(i)-h_{1}(i^{\prime})\right\rVert ^{2}}/2. \tag{7}\]

\(\mathcal{L}_{a2}\)은 정렬 손실항이다. 균일성 손실 항 \(\mathcal{L}_{u2}\)은 수학식 4를 따르지만, 첫 번째 항만을 속성으로 하는 것은 이 작업에 관여하지 않는다. \ (p_{\text{mask}}\)는 마스킹된 아이템의 분포를 나타내며, 인배치 인스턴스를 이용하여 근사화한다. 직관적으로, \(\mathcal{L}_{a2}\)은 구매 시퀀스 아래의 항목-항목 상관관계를 부호화하는 \(h_{2}(i)\을 항목-속성 그래프에 삽입하는 항목인 \(h_{1}(i)\과 정렬한다. 이러한 방식으로, 아이템-아이템 상관들은 아이템-속성 그래프에 융합된다.

#### 2.3.3. 작업 3: 항목 검토 상관 모델링

리뷰 텍스트에는 사용자가 수행한 중요한 주관적 관찰이 포함되어 있으며 항목의 미묘한 측면을 설명한다. 그러나 리뷰 텍스트는 볼륨이 높고 길며 시끄럽기 때문에 기존 콜드스타트 추천인[18, 64]에 의해 무시되어 탐색하기 어렵다. 우리의 사전 훈련 과제 3은 기존 항목의 리뷰 텍스트에서 지식을 효율적이고 효과적으로 전달하고자 한다. 구체적으로 그림 2의 (a)와 같이 리뷰 텍스트를 전처리하여 정서가 있는 어구를 추출한다. 먼저 구문 수준 감성 분석 [74] 도구 키트 3\({}^{,}\)4를 활용하여 (명사구, 의견 단어, 감성 점수) 튜플 세트를 얻는다(이 세트는 형식적으로 문맥 종속 감성 어휘로 지칭됨). 다양한 의견 단어로 인해 발생하는 집합의 거대한 크기와 관련하여, 우리는 튜플을 더 필터링하고 감정과 명사구만 유지한다. 예를 들어, (잠금, 열기 쉬운, 1)은 '좋은 잠금'으로 매핑되고 (힌지, 깨진, -1)은 '나쁜 힌지'로 매핑된다. 결과를 _검토 용어_ 로 참조 하 여 항목 특성과 구분 합니다. 너무 흔하거나 너무 드문 검토 용어는 그래프를 단순화하고 정보가 적은 항목 상관 관계를 도입하지 않도록 필터링됩니다. 나머지 리뷰 용어들은 그들의 상관된 항목들과 함께, 항목-속성 그래프가 구성되는 방식과 유사한 방식으로 이분형 항목-리뷰 용어 그래프를 형성한다(섹션 2.2). 항목 및 검토 용어는 태스크 1의 PLM 및 해석기와 함께 내장된 다음 GNN 계층을 통해 항목 검토 용어 그래프를 통해 전파된다. 작업 3의 순방향 전파는, 도 2(c)에 도시된 바와 같이, 다음과 같다:

\[h_{3}(x)=\text{GNN}_{3}(\text{Interpreter}(\text{PLM}(x))),x\in\mathcal{I}_{ old}\cup\mathcal{R}, \tag{8}\]

여기서 \(\mathcal{R}\)은 모든 검토 용어의 집합을 나타낸다. GNN\({}_{3}\)은 GNN\({}_{1}\)과 매개 변수를 공유하지 않는데, 이는 항목-속성 상관 대신 고차 항목-검토 항 상관 관계를 모델링하는 것을 목표로 하기 때문이다. 작업 3과 작업 1의 인코더가 동일한 PLM과 인터프리터를 사용하여 지식 공유를 가능하게 함으로써 부분적으로 중첩되는 방법에 주목한다.

과제 3의 손실은 앞의 두 과제의 손실 형태를 따르며 다음과 같이 정의된다.

\[\mathcal{L}_{3}=\mathcal{L}_{a3}+\lambda\mathcal{L}_{u3}, \tag{9}\]

\[\mathcal{L}_{a3}=\mathop{\mathbb{E}}_{(i,t^{\prime})\sim p_{\text{pos},i}} \parallel h_{3}(i)-h_{3}(r)\parallel^{2}, \tag{10}\]

\[\mathcal{L}_{u3}=\log\mathop{\mathbb{E}}_{(i,t^{\prime})\sim p_{\text{item}}}e^{-2\left\|h_{3}(i)-h_{3}(t^{\prime})\right\|^{2}}/2+\log\mathop{\mathbb{E}}_{(r,r^{\prime})\sim p_{\text{review}}}e^{-2\left\|h_{3}(r)-h_{3}(r^{\prime})\right\|^{2}}/2. \tag{11}\]

\(\mathcal{L}_{a3}\)은 정렬 손실항이다. 균일성 손실 항 \(\mathcal{L}_{u3}\)은 식 4를 따르지만 두 번째 항은 속성 이외의 검토 항과 대조됩니다. \ (p_{\text{review}}\)는 검토 용어의 분포이며 배치 내 \((r,r^{\prime})\) 쌍으로 근사됩니다. \ (p_{\text{pos}\_ir}\)는 양의 항목 검토 용어 쌍의 분포이며 배치 내 인스턴스를 사용하여 근사화된다. 직관적으로, \(\mathcal{L}_{a3}\)은 각 항목의 특징을 리뷰 용어의 특징과 정렬하여 상관관계를 포착한다. 이러한 상관관계들은 태스크 3 및 태스크 1의 인코더들의 공유된 파라미터들을 통해 아이템-속성 그래프에 융합된다.

#### 2.3.4. 다중 작업 항목 특성 그래프 사전 학습

지식적인 문항 속성 그래프를 사전 학습하기 위해 ColdGPT는 MTL을 활용하여 절 2.3.1 - 2.3.3에 소개된 사전 학습 작업을 동시에 수행한다. 항목-속성 그래프를 인코딩하는 태스크 1의 인코더는 태스크 2에 의해 공유되고 부분적으로 태스크 3에 의해 공유되며, 따라서 3개의 사전-트레이닝 태스크 모두에서 학습된 지식을 항목-속성 그래프에 융합할 수 있게 한다.

그러나 사전 훈련 과제는 서로 협력하고 자신들 사이에서 긍정적인 전이를 촉진하는 것이 필수적이다. 섹션 2.3.1 - 2.3.3에서 볼 수 있듯이 사전 교육 작업에 대한 통합 손실을 설계합니다. 대비 학습에 대한 광범위한 연구들(Zhu et al., 2017; Wang et al., 2018; Wang et al., 2019; Wang et al., 2019)에도 불구하고, 우리의 설계는 MTL 시나리오 내에서 다양한 임베딩 공간들을 정렬하고 대비하기 때문에 신규성이 두드러진다. 우리의 손실은 다양한 데이터 소스의 지식을 항목 속성 그래프로 융합하고 이질적인 작업 손실을 채택할 때 관찰된 작업 간의 부정적인 전달을 완화하는 데 도움이 된다. 긍정적인 전달을 더 용이하게 하기 위해, 우리는 MTL(Zhu et al., 2018; Wang et al., 2019)의 최근 연구에 의해 보여지는 바와 같이 태스크 손실의 가중합을 단순히 최소화하는 단일 스칼라화를 채택하여 태스크 가중치, 정규화 항 가중치 및 학습률과 같은 하이퍼파라미터가 적절하게 조정될 때 임시 다중 태스크 최적화 알고리즘을 능가한다(섹션 3.3의 하이퍼파라미터를 주의 깊게 조정한다). 상기 전체 훈련 목표는:

\[\mathcal{L}=\sum_{i=1}^{K}\mathbf{w}_{i}\mathcal{L}_{i}, \tag{12}\]

여기서 \(K=3\)은 사전 훈련 작업의 수를 나타냅니다. \ (\mathbf{w}>0\)는 태스크의 가중치이다.

### 사전 훈련된 항목 특성 그래프를 사용한 SCS 항목 임베딩

미리 트레이닝된 아이템-속성 그래프가 주어지면, SCS 아이템들의 임베딩들은 도 2의 (d)에 도시된 바와 같이, 이들 아이템들의 도착 시에 쉽게 획득될 수 있고 그들의 아이템 콘텐츠에만 의존할 수 있다. 구체적으로, 먼저 그들의 아이템 내용으로부터 SCS 아이템의 속성을 추출한다. SCS 항목 \(I_{SCS}\), 사전 훈련 중에 보이지 않는 새로운 항목 속성(\(\mathcal{A}_{SCS}\)으로 표시됨)을 사전 훈련된 항목 속성 그래프에 삽입한다. 형식적으로 항목-속성 그래프의 노드 집합은 갱신 후 \(\mathcal{V}=\mathcal{I}_{old}\cup\mathcal{I}_{SCS}\cup\mathcal{A}\cup\mathcal{A}_{SCS}\)이고, 갱신 후 에지 집합은 \(\mathcal{E}=\{(i,a)|i\in\mathcal{I}_{old}\cup\mathcal{I}_{SCS},a\in\mathcal{A} \cup\mathcal{A}_{SCS},i\text{ has attribute }a\}\)이다. 그런 다음 수학식 1과 같은 태스크 1의 사전 훈련된 인코더를 사용하여 업데이트된 항목 속성 그래프에 대한 순방향 전파를 수행하여 SCS를 포함한 모든 항목 및 속성의 임베딩을 얻는다. 학습된 아이템 임베딩들은 따라서 멀티-태스크 사전-트레이닝 동안 캡처된 아이템-속성, 아이템-항목, 및 아이템-검토 용어 상관들을 융합한다. SCS 시나리오가 SCS 아이템들의 상호작용들이 미세조정에 이용가능하지 않다고 가정하기 때문에, 이 프로세스는 임의의 미세조정을 수반하지 않는다는 점에 유의한다.

획득된 임베딩들은 SCS 아이템 추천 태스크에 대한 솔루션을 제공한다. 구체적으로, SCS 아이템에 대한 사용자의 선호도에 대한 예측은 그들의 임베딩들의 내적을 계산함으로써 이루어질 수 있다(선호도 추정을 위해 아이템들의 임베딩들과 사용자들의 임베딩들 사이의 도트 프로덕션들을 사용하는 것은 추천 연구들에서 흔히 볼 수 있다는 점에 유의한다(Kumar et al., 2018). 한편, 사용자들의 임베딩은 그들이 구매한 아이템들의 임베딩들을 평균함으로써 계산될 수 있다. 추론 동안 많은 양의 샘플링(Wang et al., 2019) 및 쿼리(Kumar et al., 2018)를 필요로 하는 콜드 스타트 추천자에 비해, 우리의 접근법은 항목-속성 그래프에 대한 간단한 업데이트 및 전파를 필요로 하므로 섹션 3.2에 나타낸 바와 같이 훨씬 더 효율적이다.

## 3. Experiment

SCS 환경에서 제안된 ColdGPT를 평가한다. 섹션 3.1은 실험 설정을 보고한다. 섹션 3.2는 ColdGPT를 상위 K SCS 항목 추천을 위한 다양한 기준선과 비교한다. 섹션 3.3은 ColdGPT의 사전 훈련 작업의 효과를 검증하고 하이퍼파라미터뿐만 아니라 손실 변화의 영향을 연구한다. 섹션 3.4는 제안된 항목-속성 그래프를 시각화하고 속성이 항목을 연결하는 데 도움이 되는 방법을 질적으로 보여준다.

### SCS Experimental Setup

#### 3.1.1. SCS Datasets

이전 추천 연구(Kumar et al., 2018; Wang et al., 2019)에서 일반적으로 채택되는 Yelp5, Amazon-home 및 Amazon-sports6의 세 가지 공개 실제 데이터 세트에 대해 실험을 한다. SCS 설정을 보장하기 위해 이러한 데이터 세트를 신중하게 처리합니다.

각주 5: [https://www.yelp.com/dataset](https://www.yelp.com/dataset)

각주 6: [https://nijianmo.github.io/amazon/#subsets](https://nijianmo.github.io/amazon/#subsets)

Yelp와 Amazon-home의 경우, 먼저 이전 작업들(Wang et al., 2019)을 따르고, 너무 적은 사용자들 및 아이템들(Yelp의 경우 \(<\)20, Amazon-home의 경우 \(<\)15) 상호작용을 필터링한다. 추천인이 SCS 항목 추천을 위해 항목 내용에 의존하기 때문에 항목 내용이 부족한 항목을 추가로 필터링합니다. 구체적으로, 5개 미만의 속성을 갖는 아이템들은 필터링된다. 다음으로, 우리는 그들의 과거 구매 기록의 길이에 따라 품목을 정렬합니다. 분류 후 훈련 및 테스트를 위해 9:1로 항목을 분할하여 따뜻한 항목을 훈련에 사용한다. 우리는 훈련 데이터의 마지막 5%를 하이퍼-파라미터 튜닝을 위한 검증 세트로 제외한다. 마지막으로, 훈련 세트에 보이지 않는 사용자를 포함하는 상호 작용은 검증 및 테스트 세트에서 제거된다.

\begin{table}
\begin{tabular}{l|l|l l l l|l l l l|l l l} \hline \hline SCS Dataset & \#Users & \#Items & Train & Val & Test & \#Attrs & Train & Val & Test & \#Ratings & Train & Val & Test \\ \hline Yelp-SCS & 4,901 & 2,639 & 2,258 & 118 & 263 & 2,087 & 2,035 & 9 & 43 & 193,320 & 185,097 & 2,731 & 5,492 \\ Home-SCS & 96,420 & 28,672 & 24,515 & 1,290 & 2,867 & 24,879 & 24,877 & 1 & 1 & 1,343,374 & 1,277,815 & 21,454 & 44,105 \\ Sports-SCS-1 & 81,778 & 28,316 & 26,483 & 1,393 & 440 & 12,154 & 12,130 & 0 & 24 & 464,335 & 456,050 & 6,745 & 1,540 \\ Sports-SCS-2 & 81,778 & 28,332 & 26,483 & 1,393 & 456 & 12,154 & 12,130 & 0 & 24 & 464,483 & 456,050 & 6,745 & 1,688 \\ Sports-SCS-3 & 81,778 & 28,344 & 26,483 & 1,393 & 468 & 12,155 & 12,130 & 0 & 25 & 464,376 & 456,050 & 6,745 & 1,581 \\ \hline \hline \end{tabular}
\end{table}
표 1. SCS 데이터셋 통계.

Amazon-sports 데이터셋은 ColdGPT를 미리 훈련된 P5 모델과 비교하는 것을 목표로 다르게 처리된다(Gupta et al., 2019). P5는 아마존 스포츠 데이터 세트 7의 이전 버전을 포함하여 3개의 대형 데이터 세트에 대해 사전 훈련되며 사전 훈련 중에 보이는 사용자의 선호도만 예측할 수 있다. 이를 위해 기존 버전과 일부 중복되는 새로운 버전의 Amazon-sports 데이터셋을 테스트 세트 구축을 위해 탐색한다. 구체적으로, 우리는 먼저 아마존 스포츠의 이전 버전이 아닌 새로운 버전의 아이템 세트를 무작위로 샘플링한다. 이들은 후보 SCS 아이템으로 간주된다. 그런 다음 새로운 버전에서 이러한 항목의 상호 작용을 추출하고 이전 버전에 존재하지 않는 사용자를 포함하는 상호 작용을 제거한다. 나머지 상호 작용은 테스트 세트를 형성하며, 모든 사용자가 보이고 모든 항목이 미리 훈련된 P5 모델에 의해 보이지 않는다. 이러한 방법으로 우리는 각각 \(\sim\)450개의 SCS 항목을 포함하는 세 가지 테스트 세트를 샘플링한다. 그런 다음 훈련 및 검증 세트는 옐프 및 아마존 홈 데이터 세트와 동일한 방식으로 이전 버전의 아마존 스포츠에서 구성된다.

각주 7: [https://jmcauley.ucsd.edu/data/amazon/](https://jmcauley.ucsd.edu/data/amazon/)

처리된 데이터 세트는 각각 Yelp-SCS, Home-SCS 및 Sports-SCS-1/2/3으로 표시된다. 표 1은 이러한 데이터 세트의 통계를 요약한 것이다. 각각의 프로세싱된 데이터세트에 대해, 검증 및 테스트 항목들을 수반하는 상호작용들이 트레이닝 세트로부터 완전히 제거됨에 따라 SCS 설정이 보장된다는 점에 유의한다.

#### 3.1.2. SCS 모델

우리는 ColdGPT를 SCS 항목을 수용하는 내용 기반 방법, Cold-start 추천자 및 사전 훈련 기반 방법과 비교한다. 내용 기반 기준선은 다음과 같습니다. 1) **BERT**(Chen et al., 2019). PLM으로, 특성의 연결을 입력으로 사용하여 항목의 임베딩을 직접 획득할 수 있습니다. 2) **BERT+R**. 순진한 방식으로 리뷰 텍스트를 활용하는 효과를 연구하기 위해 각 오래된 항목에 대해 모든 리뷰의 BERT 기반 임베딩 세트를 추가로 얻은 다음 항목의 최종 임베딩에 대한 속성 기반 임베딩 및 리뷰 임베딩의 평균을 계산한다. 3) **AFM**(Wang et al., 2019), FM 의 변형이며, 어텐션 메커니즘을 활용하여 입력 특징의 상호 작용을 모델링한다. Cold-start 권장자의 경우 다음을 고려 합니다. 4) **DropoutNet** (Wang et al., 2019)은 2층 신경망을 채택 하 고 드롭아웃을 입력 미니 배치에 적용 하 여 콘텐츠 임베딩에서 선호도 임베딩을 재구성 합니다. 5) 더 나은 재구성을 위해 무작위 트레이닝 메커니즘을 채택하는 **히터**(Wang et al., 2019). 사전 훈련 기반 방법의 경우 다음을 고려 합니다. 6) 그래프 및 메타 학습 기반 IDCF의 SCS 확장인 **IDCF-HY** (Wang et al., 2019) 및 적응에 대 한 상호 작용 이외의 콘텐츠에 의존 합니다. 7) 생성 그래프 사전 트레이닝 방법인 **GPT-GNN**(Wang et al., 2019). 8) PLM으로 아이템을 임베딩하고 순차적 추천자(Wang et al., 2019; Wang et al., 2020)를 유도성 설정으로 확장하는 **UniSRec**(Chen et al., 2019). 9) PLM 백본을 채택하는 **P5**(Gupta et al., 2019), 즉 T5(Wang et al., 2019) 및 추가로 추천 데이터를 자연어 시퀀스로 왜곡하여 사전 훈련한다. 더 나아가 10)과 비교한다. 미리 훈련 된 UniSRec의 교차 도메인 버전은 **UniSRec-PT** 로 표시 됩니다. UniSRec-PT는 다른 도메인(식품, CD, 킨들, 영화 및 홈 등 5개의 아마존 데이터 세트, 총 14,029,229개의 상호 작용)에서 전달된 지식을 활용한다. UniSRec-PT는 다른 도메인의 큰 데이터 세트(ColdGPT의 사전 훈련 데이터보다 75-220배 큰)에 사전 훈련되는 반면 ColdGPT는 대상 도메인의 데이터만 활용하기 때문에 기준선으로 간주되지 않는다.

#### 3.1.3. SCS 실험 설정

ColdGPT의 경우 배치 크기를 512로, 임베딩 차원을 64로, 학습률을 0.005로, 사전 훈련 작업의 가중치 **w**를 [0.6, 0.2, 0.2], 정규화 용어 가중치 \(\lambda\)를 0.6으로, PLM을 SBERT(Wang et al., 2019)로 설정했다(3.3절에서 하이퍼파라미터 변경 효과가 관찰됨). GNN\({}_{1}\)과 GNN\({}_{3}\)에 대해 컨볼루션 레이어의 수를 1로 설정하였다. 사전 학습 태스크 2를 위한 서브모듈의 BERT4Rec 컴포넌트에 대해 최대 시퀀스 길이를 100, 자기 주의 레이어 수를 1, 주의 헤드 수를 1, 항목 마스킹 확률을 0.2로 설정하였다. BERT4Rec 컴포넌트가 포함되지 않은 경우(3.3의 일부 절제 연구에서와 같이) 사전 학습 손실(식 12)을 지표로 하여 50에폭의 인내심을 가지고 조기 정지를 채택한다.

그렇지 않으면, 우리는 (Srivastava et al., 2017)을 따르고 200 에포크의 인내심을 가지고 조기 정지를 채택한다. 2.4절에서 언급한 바와 같이, 사용자 임베딩, 아이템 임베딩, 평가 점수를 입력으로 하여 사용자의 선호도를 예측한다. AFM의 경우, 사용자 임베딩, 아이템 임베딩, 평가 점수를 입력으로 하여 사용자의 선호도를 예측한다. DropoutNet과 Heater의 경우, 필요한 사용자/아이템 협업 임베딩을 제공하기 위해 학습 데이터에 대한 Matric Factorization(MF) 모델을 사전 학습한다. 모델 구조와 하이퍼파라미터 설정은 원본 논문과 일치한다. IDCF-HY, UnisRec, GPT-GNN의 경우, 원본 논문에 보고된 바와 같이 실험 설정을 채택한다. UnisRec의 경우, 범용 시퀀스 표현 모듈에서 사용자의 임베딩을 획득하고 MoE가 강화된 어댑터에서 테스트 항목의 임베딩을 획득한 후 예측된 평점에 대한 임베딩의 내적을 계산한다. P5의 경우, 사전 학습된 버전 8을 채택한다. 다른 두 데이터 세트에 대한 사전 학습된 P5 모델은 사용할 수 없기 때문에 스포츠-SCS 데이터 세트에 대한 P5의 성능만 보고한다. 우리는 'Z-3' 템플릿으로 P5를 쿼리한다. 하나의 질의는 하나의 상호작용만을 예측하므로 순위 매기기 전에 각 사용자에 대한 모든 테스트 항목을 질의한다. BERT와 BERT+R의 경우 Hugging Face 사전 훈련 모델, 즉 'bert-large-cased'를 채택한다. 예측 프로세스는 항목 임베딩 획득 후 ColdGPT와 일치한다. 64GB RAM과 3\(\times\)NVIDIA GeForce GTX 1080 Ti GPU를 사용하여 12-core Intel Xeon CPU E5-2620 v3@2.40GHz를 사용하고 모든 실험에 대해 5회 이상의 평균을 보고한다.

각주 8: [https://huggingface.co/makitankaze/P5_sports_base](https://huggingface.co/makitankaze/P5_sports_base)

#### 3.1.4. 평가 메트릭

이전 추천 연구(Kang et al., 2018; Wang et al., 2019)에 따라 널리 사용되는 두 가지 메트릭, 즉 NDCG 및 Recall을 채택한다. 우리는 Recall@N 및 NDCG@N을 보고하며, 여기서 N은 5, 20 및 40으로 설정된다.

### SCS Item Recommendation

Table 2는 Top-K SCS 항목 추천 결과를 정리한 것이다. 관찰 결과는 다음과 같다. 1) 제안된 ColdGPT는 가장 좋은 기준선, 즉 UniSRC보다 큰 마진을 통해 일관되게 성능이 우수하다. 예를 들어, ColdGPT는 UnisRec보다 최대 64% 더 높은 NDCG 및 최대 48% 더 높은 Recalls를 달성한다. ColdGPT는 항목 내용을 거친 방식으로 활용하는 UnisRec와 달리 세밀한 항목 속성을 추출하고 모델링하여, 세밀한 항목 속성 상관 관계가 SCS 항목 추천에 필수적이며 제안된 항목 속성 그래프와 다중 작업 사전 훈련 프레임워크가 이러한 상관 관계를 효과적으로 탐색함을 보여준다. 2) 단순히 항목 내용을 사용하는 것에 비해 기존 항목의 등급 점수 시퀀스를 통합하면 성능이 더욱 향상된다. 특히, 순차적 정보, 즉 ColdGPT와 UniSRC를 통합하는 모델이 다른 방법보다 성능이 우수하다. 이는 과거 등급 시퀀스에 포함된 항목-항목 상관 관계가 기존 항목과 SCS 항목 간의 상관 관계를 밝히는 데 도움이 된다는 것을 보여준다. 3) 간단한 내용 기반 방법들, 즉 BERT 및 AFM은 일부 콜드-스타트 및 사전-트레이닝 기반 추천자들, 즉 DropoutNet, Heater, IDCF-HY, GPT-GNN, 및 P5보다 더 잘 또는 동등하게 수행한다. 이는 이러한 추천자들이 SCS 항목들과 이전 항목들 사이의 상관관계들을 더 포착하지 못한다는 것을 보여준다. 그 이유는 사용 가능한 데이터 소스를 불충분하거나 거친 방식(예: DropoutNet, Heater, IDCF-HY, GPT-GNN)으로 탐색하고, P5는 평가 점수 시퀀스를 자연어로 왜곡하여 노이즈 및 신뢰할 수 없는 항목 상관 관계를 모델링하기 때문이다. 반면, 제안된 ColdGPT는 세밀하고 지식이 풍부한 항목 속성 그래프를 구성하고 사전 훈련하며 기존 항목과 SCS 항목 간의 격차를 효율적으로 완화한다. 이는 다시 더 많은 정보 소스를 통합하고 순진하거나 거친 방식 이외의 세밀한 방식으로 정보 소스를 탐색하는 것의 중요성을 정당화한다. 4) 리뷰 텍스트에는 귀중한 정보가 포함되어 있지만 순진한 방식으로 활용하는 것은 도움이 되지 않는다. 구체적으로,

BERT+R은 BERT와 동등한 성능을 보인다. 3.3절에서 리뷰 텍스트를 활용하는 적절한 방법에 대해 더 논의한다. 5) ColdGPT의 추론은 효율적이다. 예를 들어, 스포츠-SCS-3에 대한 IDCF-HY 및 P5의 추론은 각각 많은 양의 샘플링 및 쿼리가 필요하기 때문에 몇 시간이 걸린다. 대조적으로, ColdGPT는 SCS 항목들 및 속성들을 미리 트레이닝된 항목-속성 그래프에 삽입한 후 전파하기만 하면 되기 때문에 < 60초가 걸린다.

표 3은 ColdGPT와 76-224배 더 많은 교차 도메인 데이터에 대해 사전 훈련된 UnisRec-PT를 비교한다. Sports-SCS-3에서는 ColdGPT가 UnisRec-PT와 Sports-SCS-1, Sports-SCS-2보다 우수한 성능을 보였다. 이는 ColdGPT의 효용성과 데이터 효율성을 보여준다. 우리

\begin{table}
\begin{tabular}{l l|c c c c c c c c c|c} \hline \hline Dataset & Metric & BERT & BERT+R & AFM & DropoutNet & Heater & IDCF-HY & GPT-GNN & P5 & UniRec & ColdGPT & \(\Delta\) (\%) \\ \hline \multirow{4}{*}{Yelp} & NDCG@5 & 0.0125 & 0.0128 & 0.0132 & 0.0127 & 0.0128 & 0.0113 & 0.0032 & / & 0.0161 & **0.0265** & 64.60 \\  & NDCG@20 & 0.0391 & 0.0297 & 0.0308 & 0.0304 & 0.0301 & 0.0292 & 0.0091 & / & 0.0383 & **0.0556** & 45.17 \\  & NDCG@40 & 0.0480 & 0.0473 & 0.0504 & 0.0488 & 0.0480 & 0.0459 & 0.0157 & / & 0.0573 & **0.0863** & 50.61 \\ \cline{2-13} -SCS & Recall@5 & 0.0182 & 0.0179 & 0.0170 & 0.0172 & 0.0179 & 0.0161 & 0.0042 & / & 0.0257 & **0.0371** & 44.36 \\  & Recall@20 & 0.0756 & 0.0743 & 0.0729 & 0.0734 & 0.0743 & 0.0736 & 0.0234 & / & 0.0989 & **0.1282** & 29.63 \\  & Recall@40 & 0.1541 & 0.1504 & 0.1566 & 0.1495 & 0.1485 & 0.1436 & 0.0515 & / & 0.1816 & **0.2354** & 29.63 \\ \hline \multirow{4}{*}{Home} & NDCG@5 & 0.0010 & 0.0010 & 0.0011 & 0.0010 & 0.0011 & / & 0.0009 & / & 0.0064 & **0.0095** & 48.44 \\  & NDCG@20 & 0.0027 & 0.0025 & 0.0026 & 0.0025 & / & 0.0056 & / & 0.0112 & **0.0166** & 48.21 \\ \cline{2-13}  & DCG@40 & 0.0042 & 0.0037 & 0.0041 & 0.0041 & 0.0040 & / & 0.0121 & / & 0.0148 & **0.0215** & 45.27 \\ \cline{2-13} -SCS & Recall@5 & 0.0017 & 0.0016 & 0.0018 & 0.0016 & 0.0018 & / & 0.0019 & / & 0.0094 & **0.0139** & 47.87 \\  & Recall@20 & 0.0073 & 0.0070 & 0.0070 & 0.0070 & 0.0071 & / & 0.0179 & / & 0.0263 & **0.0383** & 45.63 \\  & Recall@40 & 0.0144 & 0.0135 & 0.0139 & 0.0140 & 0.0134 & / & 0.0483 & / & 0.0426 & **0.0609** & 26.08 \\ \hline \multirow{4}{*}{Sports} & NDCG@5 & 0.0052 & 0.0051 & 0.0044 & 0.0082 & 0.0054 & 0.0049 & 0.0000 & 0.0047 & 0.0303 & **0.0324** & 6.93 \\  & NDCG@20 & 0.0154 & 0.0154 & 0.0135 & 0.0190 & 0.0152 & 0.0147 & 0.0000 & 0.0182 & 0.0613 & **0.0663** & 8.16 \\  & NDCG@40 & 0.0264 & 0.0259 & 0.0283 & 0.0274 & 0.0244 & 0.0252 & 0.0004 & 0.0231 & 0.0830 & **0.0884** & 6.51 \\ \cline{2-13}  & Recall@5 & 0.0075 & 0.0076 & 0.0092 & 0.0124 & 0.0097 & 0.0072 & 0.0000 & 0.0080 & 0.0528 & **0.0571** & 8.14 \\  & Recall@20 & 0.0448 & 0.0446 & 0.0411 & 0.0505 & 0.0446 & 0.0446 & 0.0000 & 0.0473 & 0.1624 & **0.1760** & 8.37 \\ \cline{2-13}  & Recall@40 & 0.0981 & 0.0970 & 0.0102 & 0.0910 & 0.0889 & 0.0971 & 0.0021 & 0.0744 & 0.2666 & **0.2831** & 6.19 \\ \hline \multirow{4}{*}{Sports} & NDCG@5 & 0.0043 & 0.0046 & 0.0050 & 0.0051 & 0.0067 & 0.0039 & 0.0002 & 0.0064 & 0.0271 & **0.0297** & 9.59 \\  & NDCG@20 & 0.0121 & 0.0113 & 0.0168 & 0.0114 & 0.0158 & 0.0107 & 0.0022 & 0.0148 & 0.0636 & **0.0660** & 3.77 \\ \cline{2-13}  & NDCG@40 & 0.0203 & 0.0258 & 0.0283 & 0.0196 & 0.0269 & 0.0185 & 0.0037 & 0.0232 & 0.0828 & **0.0904** & 9.84 \\ \cline{2-13} -SCS-2 & Recall@5 & 0.0073 & 0.0071 & 0.0092 & 0.0069 & 0.0066 & 0.0088 & 0.0003 & 0.0098 & 0.0455 & **0.0504** & 10.77 \\  & Recall@20 & 0.0347 & 0.0329 & 0.0497 & 0.0303 & 0.0421 & 0.0311 & 0.0075 & 0.0386 & 0.1621 & **0.1788** & 10.30 \\  & Recall@40 & 0.0747 & 0.0706 & 0.1062 & 0.0701 & 0.0964 & 0.0688 & 0.0151 & 0.0822 & 0.2528 & **0.2974** & 17.64 \\ \hline \multirow{4}{*}{Sports} & NDCG@5 & 0.0055 & 0.0051 & 0.0032 & 0.0032 & 0.0059 & 0.0050 & 0.0000 & 0.0056 & 0.0358 & **0.0359** & 0.28 \\  & NDCG@20 & 0.0117 & 0.0112 & 0.0107 & 0.0108 & 0.0113 & 0.0110 & 0.0002 & 0.0138 & 0.0628 & **0.0692** & 10.19 \\ \cline{1-1} \cline{2-13}  & NDCG@40 & 0.0210 & 0.0195 & 0.0197 & 0.0209 & 0.0224 & 0.0192 & 0.0005 & 0.0229 & 0.0826 & **0.0924** & 11.86 \\ \cline{1-1} \cline{2-13} -SCS-3 & Recall@5 & 0.0073 & 0.0068 & 0.0056 & 0.0066 & 0.0102 & 0.0066 & 0.0000 & 0.0086 & 0.0565 & **0.0569** & 0.71 \\ \cline{1-1} \cline{2-13}  & Recall@20 & 0.0308 & 0.0298 & 0.0336 & 0.0345 & 0.0289 & 0.0268 & 0.0007 & 0.0367 & 0.1515 & **0.1758** & 16.04 \\ \cline{1-1} \cline{2-recognize, on the other hand, that cross-domain knowledge transferring may further improve ColdGPT's performance and leave the exploration to future work (Section 5).

### Ablation Study

본 연구에서는 ColdGPT의 태스크 가중치 \(\mathbf{w}\), 태스크 3 데이터, 정규화 항 가중치 \(\lambda\), 학습률 (lr), PLM, 손실함수의 변화에 따른 효과를 연구하였다. <표 4>와 <그림 3>은 결과를 제시하고 있다. 그림 3(a)와 (b)에 요약된 바와 같이 과제 1 위에 사전 훈련 과제 2와 3을 통합하는 것이 도움이 된다. 라인 1 - 14 및 라인 24를 더 비교하면, 세 개의 태스크가 멀티-태스크 사전-훈련 동안 서로 협력할 수 있고 [0.6, 0.2, 0.2]로 설정된 가중치로 가장 잘 수행할 수 있음을 알 수 있다. 15행에서는 과제 3의 검토 용어를 명사구로 대체, 즉 원래의 검토 용어에서 정서를 제거한다. 라인 15는 라인 24보다 성능이 좋지 않아 사용자의 정서가 항목 상관 관계를 더 잘 모델링하는 데 도움이 되며 주관적인 리뷰 텍스트를 탐색할 때 고려해야 함을 나타낸다. 라인 16 - 21 및 라인 24에서의 결과를 비교하면 \(\lambda\) 및 lr을 각각 0.6 및 0.005로 설정하는 것이 최상의 성능을 제공한다는 것을 나타낸다. 라인 22와 라인 24를 비교하면 PLM의 선택에도 불구하고 ColdGPT가 작동하고 ColdGPT가 PLM을 SBERT에서 BERT로 변경한 후에도 여전히 경쟁력 있는 결과를 제시한다는 것을 알 수 있다. 사전 훈련 작업 손실을 변경하면 라인 23에서 볼 수 있듯이 성능이 크게 떨어진다. 제안된 정렬 기반 손실 항을 채택하는 대신 라인 23은 작업 1과 3에 대해 그래프 사전 훈련 방법 [20; 41]에서 일반적으로 사용하는 InfoNCE 손실을 채택한다. 작업 2의 경우 라인 23은 BERT4Rec [47]의 원래 설계를 따르고 교차 엔트로피 손실을 채택한다. 라인 23은 또한 균일성 기반 정규화 용어 이외의 유클리드 규범을 채택한다. 이러한 변화는 사전 훈련 작업이 서로 충돌하고 폭발하는 기울기가 관찰된다. 도 3의 (c) 및 (d)에 도시된 바와 같이, 라인 23의 손실은 0 내지 30,000 사이에서 심하게 변동하는 반면, 라인 12의 손실은 -5 정도로 꾸준히 하락한다. 이는 ColdGPT의 단일화된, 정렬-및-균일성 기반 사전 트레이닝 태스크 손실이 포지티브 전달을 효과적으로 촉진한다는 것을 보여준다. 또한, 라인 23은 나머지 라인들이 최상의 베이스라인, 즉 UnisRec(표 2)를 능가하는 동안 파를 수행한다. 예를 들어, 라인 2, 4, 6 및 10은 동일한 데이터 소스를 사용할 때(즉, 사용하지 않을 때) ColdGPT가 UnisRec보다 성능이 우수함을 보여준다

\begin{table}
\begin{tabular}{c|c|c|c c c c c} \hline \hline  & Factor & Value & NDCG@5 & NDCG@20 & NDCG@40 & Recall@5 & Recall@20 & Recall@40 \\ \hline
1 & [1, 0.0, 0.0] & 0.0227 & 0.0454 & 0.0721 & 0.0312 & 0.1015 & 0.2102 \\
2 & [0.8, 0.2, 0.0] & 0.0242 & 0.0546 & 0.0796 & 0.0342 & 0.1223 & 0.2341 \\
3 & [0.8, 0.0, 0.2] & 0.0258 & 0.0548 & 0.0819 & 0.0335 & 0.1242 & 0.2388 \\
4 & [0.6, 0.4, 0.0] & 0.0250 & 0.0542 & 0.0805 & 0.0328 & 0.1241 & 0.2366 \\
5 & [0.6, 0.0, 0.4] & 0.0263 & 0.0538 & 0.0800 & 0.0353 & 0.1223 & 0.2331 \\
6 & [0.4, 0.6, 0.0] & 0.0246 & 0.0503 & 0.0810 & 0.0328 & 0.1143 & 0.2345 \\
7 & 태스크 가중치(\(\mathbf{w}\)) & [0.4, 0.4, 0.2] & 0.0257 & 0.0521 & 0.0768 & 0.0336 & 0.1171 & 0.2225 \\
8 & [0.4, 0.2, 0.4] & 0.0251 & 0.0522 & 0.0797 & 0.0318 & 0.1166 & 0.2367 \\
9 & [0.4, 0.0, 0.6] & 0.0261 & 0.0538 & 0.0793 & 0.0339 & 0.1231 & 0.2302 \\
10 & [0.2, 0.8, 0.0] & 0.0230 & 0.0458 & 0.0710 & 0.0311 & 0.1039 & 0.2101 \\
11 & [0.2, 0.6, 0.2] & 0.0228 & 0.0462 & 0.0714 & 0.0307 & 0.1028 & 0.2096 \\
12 & [0.2, 0.4, 0.4] & 0.0255 & 0.0523 & 0.0784 & 0.0347 & 0.1192 & 0.2301 \\
13 & [0.2, 0.2, 0.6] & 0.0213 & 0.0489 & 0.0741 & 0.0278 & 0.1158 & 0.2228 \\
14 & [0.2, 0.0, 0.8] & 0.0251 & 0.0481 & 0.0738 & 0.0335 & 0.1065 & 0.2166 \\ \hline
15 & task 3 & w/o sentiments & 0.0217 & 0.0510 & 0.0790 & 0.0293 & 0.1227 & 0.2340 \\ \hline
16 & & 0.2 & 0.0225 & 0.0498 & 0.0639 & 0.0317 & 0.0991 & 0.2005 \\
17 & 정규화 중량(\(\lambda\)) & 0.4 & 0.0258 & 0.0505 & 0.0780 & 0.0370 & 0.1152 & 0.2327 \\
18 & & 0.8 & 0.0262 & 0.0558 & 0.0853 & 0.0368 & 0.1208 & 0.2274 \\ \hline
19 & & 0.010 & 0.0221 & 0.0495 & 0.0777 & 0.0315 & 0.1194 & 0.2291 \\
20 & 학습률(lr) & 0.008 & 0.0255 & 0.0553 & 0.0851 & 0.0362 & 0.1269 & 0.2341 \\
21 & & 0.003 & 0.0246 & 0.0516 & 0.0812 & **0.0371** & 0.1232 & 0.2300 \\ \hline
22 & PLM & BERT & 0.0255 & **0.0559** & 0.0862 & 0.0370 & 0.1277 & **0.2457** \\ \hline
23 & loss function & InfoNCE + CE & 0.0146 & 0.0355 & 0.0608 & 0.0215 & 0.0990 & 0.1941 \\ \hline
24 & Default setting (Section 3.13) & **0.0265** & 0.0556 & **0.0863** & **0.0371** & **0.1282** & 0.2354 \\ \hline \hline \end{tabular}
\end{table}
표 4. Yelp-SC5 데이터세트에 대한 ColdGPT의 절제 연구. 24줄에서 기본 설정 (\(\mathbf{w}\)=[0.6, 0.2, 0.2], \(\lambda\) =0.6, \(lr\) =0.005, PLM = SBERT, 손실 함수 = 식 12) 아래의 결과는 표 2에서 복사 됩니다. 가장 좋은 결과는 굵게 표시 되 고 두 번째로 좋은 결과는 밑줄이 그어져 있습니다.

)를 포함하는 것을 특징으로 하는 방법. 라인 1은 더 나아가, ColdGPT가 훨씬 적은 데이터(즉, 단지 아이템 콘텐츠에 의존하는 것)를 사용하여 UnisRec보다 성능이 우수함을 보여준다. 이것은 다시 ColdGPT의 효과를 검증한다.

### 항목 특성 그래프 시각화

그림 4와 같이 쌍별 거리(ColdGPT를 통해 학습한 아이템 임베딩 간의 코사인 유사도를 계산하여 측정)와 아이템 쌍의 속성 유사도 간의 피어슨 상관 계수를 시각화한다. 그림 4의 (a), (b) 및 (c)에서 각각 모든 아이템 쌍, SCS-기존 아이템 쌍 및 SCS-SCS 아이템 쌍을 시각화한다. 다음을 관찰할 수 있다. 1) 모든 아이템 쌍에 대해 피어슨 상관은 0.01 수준에서 긍정적이고 유의하다. 이는 ColdGPT를 통해 학습한 아이템 임베딩이 각 쌍의 두 아이템에 대해 공유 속성이 많을수록 임베딩이 가까워짐을 보여준다. 2) SCS-기존 아이템 쌍의 경우 피어슨 상관도 0.01 수준에서 긍정적이고 유의하여 ColdGPT가 속성 관련 정보를 새로운 아이템에 효과적으로 전달하고 새로운 아이템을 이전 아이템에 연결함을 보여준다. 3) SCS-SCS 항목 쌍의 경우 피어슨 상관 관계도 0.01 수준에서 긍정적이고 유의하다. 이는 두 개의 항목이 엄밀하게 콜드 스타트 항목인 경우에도 ColdGPT가 공유 속성과 관련하여 양의 상관 임베딩을 생성할 수 있음을 보여준다. 4) 모든 아이템 쌍(0.3973) > SCS-기존 아이템 쌍(0.3541) > SCS-SCS 쌍(0.3285)에서 아이템 임베딩 유사도와 속성 유사도 사이의 피어슨 계수 순서. 이는 기존의 모든 항목이 속성과 일치하도록 명시적으로 훈련되어 모든 항목 쌍의 피어슨 계수가 더 높아지기 때문에 정당하다. 사전 훈련 중에 보이지 않는 SCS 항목은 속성과 직접 정렬되지 않아 SCS가 존재하는 항목 쌍에 대한 계수가 상대적으로 낮다. 사전 교육 단계에서 두 가지 항목이 모두 보이지 않는 경우 더욱 낮아질 것이다.

도 4. 콜드GPT 임베딩 코사인 유사도와 아이템 쌍들의 속성 자카드 유사성 사이의 피어슨 상관 계수.

도 3. 태스크 2(a)와 태스크 3(b)의 가중치를 증가시킬 때 NDCG@5의 변화, 표 4의 라인 23(c)와 라인 24(d)의 손실값을 나타낸다. (a)에서 태스크 3의 가중치를 0.0으로 고정하고 태스크 2의 가중치를 점진적으로 증가시킨다. 마찬가지로, (b)에서 태스크 3의 가중치를 점진적으로 증가시킨다. 'default'는 기본 설정(표 4의 라인 24)을 의미한다. (c) 및 (d)에서 x축은 트레이닝 에포크를 나타낸다.

## 4. 관련 작업

**Cold-start 권장 사항** 권장 방법은 잘 확립 된 지배적 ID 기반 접근 방식이 악화 되는 cold-start 시나리오에서 배포 외 문제를 겪습니다 (Zhou et al., 2018; Zhang et al., 2019). 기존의 콜드 스타트 추천자들은 주로 소수의 샷 콜드 스타트 설정을 목표로 하며 미세 조정 또는 적응을 위해 테스트 항목의 몇 가지 상호 작용을 필요로 한다. 메타-학습에 기초한 방법들(Zhou et al., 2018; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2020; Zhang et al., 2021)은 일반적으로 볼 수 있다. 테스트 항목들의 상호 작용들이 완전히 액세스할 수 없는 SCS 설정을 다루기 위해, 와이드&딥(Chen et al., 2018), 인수분해 기계(Fluxization Machines, FM)(Zhou et al., 2018) 및 그 변형들(Zhou et al., 2019)과 같은 콘텐츠 기반 방법들이 적용될 수 있는데, 이는 단지 추천을 하기 위한 사용자들 및 항목들의 콘텐츠(보조 사용자 프로파일들 및 항목 설명들)에만 의존하기 때문이다. 특정 유형의 콜드 스타트 추천인도 SCS 설정에서 작업할 수 있습니다. 이들 방법들은 전형적으로 사용자들의 선호도(협업 필터링-기반) 임베딩들 및 그들의 콘텐츠(보조 특징-기반) 임베딩들로부터 아이템들의 선호도(협업 필터링-기반) 임베딩을 재구성한다. 예를 들어, (Zhou et al., 2019)는 그러한 재구성을 위한 입력 미니-배치들에 드롭아웃을 적용한다. (Zhou et al., 2019)는 재구성의 효과를 용이하게 하기 위해 무작위 트레이닝 메커니즘을 채택한다. (Chen et al., 2018)은 회귀 태스크로서 재구성을 공식화하고 두 유형의 임베딩 사이의 MSE 손실을 최소화한다. (Zhou et al., 2019)의 SCS 확장인 IDCF-HY는 메타 학습을 사용하며 적응을 위해 상호 작용 이외의 콘텐츠에 의존한다. (Zhou et al., 2019), 반면에 대조적 학습을 활용한다. (Zhou et al., 2019), (Zhou et al., 2020), 및 (Zhou et al., 2021)은 대신 Autoencoder 또는 Variational Autoencoder(VAE)에 의존한다. (Zhou et al., 2020)은 또한 따뜻한 도메인과 차가운 도메인의 분포가 다르다는 것을 인식하고 정렬을 위해 스타인 경로를 활용한다. NLP의 발전에 힘입어 추천을 위해 PLM(Chen et al., 2018; Zhang et al., 2020)을 적응시키는 사전 훈련 기반 방법이 점점 더 주목받고 있다. 구체적으로, UniSRec(Li et al., 2020)는 PLM(Chen et al., 2018)을 아이템 인코더로서 활용하고 인기 ID-기반 순차적 추천기(Zhou et al., 2020)를 확장하여 소수의 샷 및 엄격한 콜드-스타트 시나리오 둘 다에서 작동하도록 한다. P5(Chen et al., 2020)는 PLM 백본을 채택하고(Zhou et al., 2020) 이력 구매 및 리뷰를 포함한 다양한 형태의 데이터를 자연어 시퀀스로 왜곡하여 백본을 추가로 사전 트레이닝한다(Note P5는 사전 트레이닝 동안 보이는 사용자에게만 추천을 한다). ColdGPT는 기존의 콜드 스타트 추천자들과는 1) 더 많은 정보를 고려한다. 아이템 콘텐츠 외에도, ColdGPT는 사용자의 구매 이력 및 리뷰 텍스트에 포함된 주관적 아이템 속성에 있는 순차적 아이템 상관 관계를 추가로 통합한다. 2) 다양한 정보 소스를 보다 효과적으로 활용합니다. ColdGPT는 잡음이 많은 원시 필드보다는 세밀한 속성을 모델링한다. 통합 손실 항과 이를 조정하기 위한 MTL 프레임워크를 채택하면서 다양한 형태의 정보 소스를 완전히 탐색하기 위해 특정 하위 모듈과 작업을 설계한다.

**그래프 기반 권장 사항.** 그래프는 상위 구조 정보를 캡처하는 데 표현적이므로 권장 연구에 의해 널리 채택됩니다. 최근의 그래프 기반 추천자(Zhou et al., 2019; Zhang et al., 2020)는 일반적으로 사용자-아이템 이분 그래프를 구성한 다음 GNN을 사용하여 이들의 임베딩을 전파함으로써 사용자-아이템 상관 관계를 캡처한다(Zhou et al., 2019; Zhang et al., 2020). 일부 연구는 지식 그래프(KG)로 사용자-아이템 그래프를 더욱 풍부하게 한다(Chen et al., 2018; Zhang et al., 2019; Zhang et al., 2020; Zhang et al., 2021) 및 사회적 관계(Zhou et al., 2019; Zhang et al., 2020). 또한, 사용자-아이템 그래프에 대한 학습을 강화하기 위해 그래프 사전 훈련을 활용하는 추천자(Zhou et al., 2019; Zhang et al., 2020; Zhang et al., 2021; Zhang et al., 2021)가 존재한다. (Chen et al., 2020)는 제품 지식 그래프를 사전 트레이닝함으로써 제로 샷 아이템 추천을 개선한다. (Zhang et al., 2020) 사용자 및 아이템 그래프를 사전 트레이닝하여 부가 정보를 수반한다. (Zhou et al., 2020) 미래 매칭을 위한 메타 잠재량을 결정하기 위해 암시적 사용자-아이템 그래프를 사전 트레이닝한다. (Zhou et al., 2020)는 견고성을 향상시키는 것을 목표로 사용자-아이템 그래프의 상이한 뷰를 대조한다. 제안된 ColdGPT는 기존 연구와 달리 SCS와 기존 항목 간의 격차를 해소하기 위해 세밀한 속성을 활용하려는 동기 하에 이분형 항목 속성 그래프를 사전 훈련한다.

**그래프 사전 훈련.** 그래프 사전 훈련은 보다 유익한 그래프 표현 학습을 위해 기존 레이블(Zhou et al., 2019) 또는 자체 감독 신호(Zhou et al., 2019; Zhang et al., 2020; Zhang et al., 2021)와 같이 쉽게 액세스할 수 있는 정보를 사용하여 지식을 전달합니다. 지식 전달은 동일한 도메인 내에서 일어날 수 있다(Zhou et al., 2019; Zhang et al., 2020; Zhang et al., 2021; Zhang et al., 2021; Zhang et al., 2021; Zhang et al., 2021; Zhang et al., 2021) 또는 도메인 전반에 걸쳐 일어날 수 있다(Zhang et al., 2021; Zhang et al., 2021). Word2vec(Zhou et al., 2020)에서 영감을 받은 초기 스킵-그램 기반 방법(Zhou et al., 2019; Zhang et al., 2021), 이웃 유사성을 캡처한다. 이후의 방법들은 GNN들을 사전 트레이닝함으로써 고차 그래프 구조 및 의미 지식을 전달한다. 이들은 노드 유형 예측(Krizhevsky et al., 2014), 중심성 점수 랭킹(Krizhevsky et al., 2014)과 같은 감독된 사전-훈련 태스크들, 및 마스킹된 에지 예측(Krizhevsky et al., 2014) 및 서브그래프 비교(Krizhevsky et al., 2014)와 같은 자체-감독된 태스크들을 설계한다. ColdGPT는 타겟 도메인과 관련된 다양한 데이터 소스로부터 지식을 전달한다. 그럼에도 불구하고, 우리는 교차 도메인 지식 전달이 목표 도메인에 더 도움이 될 수 있고 탐구를 향후 작업에 맡길 수 있다는 점에 주목한다. GNN들을 사전-트레이닝하는 연구들은 전형적으로 사전-트레이닝과 다운스트림 태스크들 사이의 갭들과 관련하여 이들을 미세-튜닝하는 것을 주목한다. 예를 들어, (Krizhevsky 등, 2014)는 사전-트레이닝 동안 미세-튜닝하는 방법을 학습하는 반면 (Krizhevsky 등, 2014)는 GNN들에 대한 프롬프트 튜닝(Krizhevsky 등, 2014)을 맞춤화한다. 반면에 ColdGPT는 미세 조정에 사용할 수 있는 다운스트림 작업 레이블이 없다고 가정하는 SCS 시나리오를 다루기 때문에 미세 조정을 포함하지 않는다. 또한 권장 사항에 대한 그래프 사전 교육을 활용하는 연구가 마지막 하위 섹션에서 다루어졌다는 점에 유의해야 한다.

**다중 작업 학습.** 다중 작업 학습(MTL)(Beng 등, 2015)은 서로 다른 작업과 양식 간의 지식 전달을 가능하게 하므로 사전 훈련 심층 모델(Krizhevsky 등, 2014)에서 광범위하게 채택되었습니다. MTL 연구는 태스크별 기울기(Krizhevsky et al., 2014; Krizhevsky et al., 2014; Krizhevsky et al., 2014), 결정론적 방식으로 태스크 손실을 재가중하고(Beng et al., 2015), 다목적 최적화(Krizhevsky et al., 2016)를 수행하여 일반적으로 관찰되는 부정적인 전달 문제(태스크가 유해한 방식으로 서로 간섭함)를 해결하기 위해 노력한다. 그러나, 최근의 연구들(Krizhevsky et al., 2016; Krizhevsky et al., 2016)은 스칼라화 가중치들 및 하이퍼파라미터들의 신중한 규칙화 및 튜닝을 갖는 태스크 손실들의 가중 평균을 단순히 최적화하는 것이 추가된 복잡성 및 오버헤드를 피하면서 이러한 애드-혹 방법들과 동등하게 수행한다는 것을 보여준다. 즉, 하이퍼파라미터의 조합을 경험적으로 검사하는 것이 ad-hoc MTL 방법을 적용하는 것보다 바람직하다. 따라서 ColdGPT의 과제 가중치, 정규화 용어 가중치 및 학습률을 신중하게 조정한다(섹션 3.3). 또한 정렬과 균일성의 개념을 MTL로 확장하고 이질적인 하위 모듈로 인한 사전 훈련 작업 간의 불일치를 제거하기 위해 통합된 손실 항을 설계한다(섹션 3.3에서 접근법의 유효성을 경험적으로 검증한다).

## 5. 결론 및 향후 작업

우리는 세밀한 항목 속성을 사용하여 SCS 항목 추천을 다룬다. 본 논문에서는 다양한 데이터 소스의 지식을 아이템 속성 그래프로 전달하기 위한 멀티 태스크 사전 학습 프레임워크인 ColdGPT를 제안한다. 데이터 소스를 완전히 탐색하기 위해 ColdGPT는 자연 형태에 따라 하위 모듈을 설계한다. 긍정적인 전달을 용이하게 하기 위해 ColdGPT는 통합된 정렬 및 균일성 손실을 통해 여러 사전 훈련 작업을 조정한다. 사전 훈련된 아이템-속성 그래프는 유용한 SCS 아이템 임베딩을 쉽게 획득할 수 있게 한다. 평가를 위한 SCS 설정을 보장하기 위해 세 가지 공개 데이터 세트를 신중하게 처리합니다. 광범위한 실험을 통해 ColdGPT가 기존 콜드스타트 추천자보다 큰 마진을 통해 지속적으로 우수하며, 4개 데이터셋 중 2개 데이터셋에 대해 75-224배 더 많은 데이터를 사전 학습한 모델까지 능가한다는 것을 알 수 있다. 질적 연구에 따르면 ColdGPT는 공유 속성을 통해 SCS 항목을 기존 항목과 효과적으로 연결한다. 향후, 우리는 교차 도메인 SCS 항목 추천을 위해 ColdGPT를 확장할 계획이다. 우리는 아마존과 같은 대규모 교차 도메인 데이터 세트에 대한 사전 교육이 ColdGPT의 성능을 더욱 향상시킬 수 있다는 점에 주목한다. 또 다른 미래 방향은 테스트 항목의 몇 가지 또는 풍부한 상호 작용에 액세스할 수 있는 소수의 샷 콜드 스타트 및 비콜드 스타트 시나리오에 대한 ColdGPT를 확장하는 것이다. 이상적으로, 확장된 ColdGPT는 사전 트레이닝된 아이템-속성 그래프를 풍부하게 하기 위해 이러한 이용가능한 상호작용들을 통합할 것이다.

## 6. Acknowledgments

본 논문은 보조금 2022YFB3104703을 통한 중국 국가 중점 R&D 프로그램, 보조금 62002007을 통한 NSFC, 보조금 4222030을 통한 베이징시 자연과학재단, 보조금 21340301D를 통한 허베이 S&T 프로그램의 지원을 받았다. 필립 Yu는 보조금 III-1763325, III1909323, III-2106758 및 SaTC-1930941에 따라 NSF의 지원을 받았다.

[MISSING_PAGE_EMPTY:17]

* Qian et al. (2020) Tieyun Qian, Yile Liang, et al. 2020. Attribute graph neural networks for strict cold start recommendation. _ IEEE TKDE_(2020).
* Qiu et al. (2020) Jiezhong Qiu, Qibin Chen, et al. 2020. Gcc: Graph contrastive coding for graph neural network pre-training. _Proc. SIGKDD_.
* Raffel et al.(2020) Colin Raffel, Noam Shazeer, et al. 2020. Exploring the limit of transfer learning with a Unified text-to-text transformer. _ 제이 마케터 배워 Res._ 21, 140(2020), 1-67.
* Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: siamese bert-networks를 이용한 문장 임베딩. _Proc. EMNLP_.
* 렌들(2010) Steffen Rendle. 2010. Factorization machines. _Proc. ICDM_. IEEE.
* Rendle et al. (2009) Steffen Rendle, Christoph Freudenthaler, et al. 2009. BPR: Bayesian personalized ranking from implicit feedback. _Proc. UAI_.
* Sener and Koltun (2018) Ozan Sener and Vladlen Koltun. 2018. Multi-task learning as multi-objective optimization. _ Proc. NeurIPS_.
* Sun et al. (2019) Fei Sun, Jun Liu, et al. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representation from transformer. _Proc. CIKM_.
* Sun et al.(2022) Mingchen Sun, Kaixiong Zhou, et al. 2022. Gppt: Graph pre-training and prompt tuning to generalize graph neural networks. _Proc. SIGKDD_.
* Tang 등(2015) Jian Tang, Meng Qu, et al. 2015. Line: Large-scale information network embedding. _Proc. TheWebConf_.
* Vamsi et al. (2022) Aribandi Vamsi, Yi Tay, et al. 2022. Ext5: Towards extreme multi-task scaling for transfer learning. _ Proc. ICLR_.
* Vartak 등(2017) Manasi Vartak, Arvind Thiagarajan, et al. 2017. A meta-learning perspective on cold-start recommendations for items. _Proc. NeurIPS_.
* Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, et al. 2017. Attention is all you need. _ Proc. NeurIPS_.
* Velickovic et al. (2018) Petar Velickovic, Guillem Cucurull, et al. 2018. Graph attention networks. _Proc. ICLR_.
* Volkovs 등(2017) Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017. Dropoutnet: Addressing cold start in recommender systems. _Proc. NeurIPS_.
* Wang 등(2021) Chen Wang, Yueqing Liang, Zhiwei Liu, Tao Zhang, and S Yu Philip. 2021. 교차 도메인 추천을 위한 사전 트레이닝 그래프 신경망. _2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogM)_ 에서. IEEE, 140-145.
* Wang et al.(2022) Chenyang Wang, Yuanqing Yu, et al. 2022. Towards Representation Alignment and Uniformity in Collaborative Filtering. _Proc. SIGKDD_.
* Wang et al. (2019) Hongwei Wang, Miao Zhao, et al. 2019. Knowledge graph convolutional networks for recommender systems. _Proc. TheWebConf_.
* Wang 등(2022) Shen Wang, Liangwei Yang, et al. 2022. MetaKRec: Collaborative Meta-Knowledge Enhanced Recommender System. _Proc. BigData_. IEEE.
* Wang and Isola (2020) Tongzhou Wang and Phillip Isola. 2020. Understanding contrast representation learning through alignment and uniformity on the hypersphere. _Proc. ICML_.
* Wang et al. (2019) Xiang Wang, Xiangnan He, et al. 2019. Kgat: Knowledge graph attention network for recommendation. _Proc. SIGKDD_.
* Wang et al. (2019) Xiang Wang, Xiangnan He, et al. 2019. Neural graph collaborative filtering. _Proc. SIGIR_.
* Wei et al. (2021) Yinwei Wei, Xiang Wang, et al. 2021. Contrastive learning for cold-start recommendation. _Proc. Multimedia_.
* Wu et al.(2021) Jiancan Wu, Xiang Wang, et al. 2021. Self-supervised graph learning for recommendation. _Proc. SIGIR_.
* Wu et al. (2021) Qitian Wu, Hengrui Zhang, et al. 2021. Towards open-world recommendation: Anductive model-based collaborative filtering approach. _Proc. ICML_.
* Xiao et al. (2017) Jun Xiao, Hao Ye, et al. 2017. Attentional factorization machines: attention network를 통해 feature interaction의 가중치를 학습한다. _Proc. IJCAI_.
* Xin et al. (2022) Derrick Xin, Behrooz Ghorbani, et al. 2022. Do Current Multi-Task Optimization Methods in Deep Learning Even Help? _ Proc. NeurIPS_.
* Yang et al. (2021) Liangwei Yang, Zhiwei Liu, et al. 2021. Consisrec: Enhancing gpn for social recommendation via consistent neighbor aggregation. _Proc. SIGIR_.
* You et al.(2022) Chenyu You, Weicheng Dai, et al. 2022. Mine your own anatomy: Revisiting medical image segmentation with extremely limited labels. _ arXiv preprint arXiv:2209.13476_ (2022).
* You et al.(2023) Chenyu You, Weicheng Dai, et al. 2023. ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast. _ arXiv preprint arXiv:2304.02689_ (2023).
* You et al.(2023) Chenyu You, Weicheng Dai, et al. 2023. Bootstrapping semi-supervised medical image segmentation with anatomical-aware contrastive distillation. _Proc. IPML_. 스프링거
* You et al.(2023) Chenyu You, Weicheng Dai, and other. 2023. 반지도 의료 영상 분할에 대한 재고: 분산-감소 관점. _ arXiv preprint arXiv:2302.01735_ (2023).
* Yu et al. (2020) Tianhe Yu, Saurabh Kumar, et al. 2020. Gradient surgery for multi-task learning. _ Proc. NeurIPS_.
* Yuan et al. (2023) Zheng Yuan, Fajie Yuan, et al. 2023. Where to Go Next for Recommender Systems? ID- vs. 모달리티 기반 추천 모델이 다시 검토되었습니다. _Proc. SIGIR_.
* Zhang et al.(2014) Yongfeng Zhang, Haochen Zhang, et al. 2014. Do users rate or review? 리뷰 수준 감성 분류와 함께 구 수준 감성 레이블을 높입니다. _Proc. SIGIR_.
* Zhao et al.(2022) Xu Zhao, Yi Ren, et al. 2022. Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder. _Proc. SIGIR_.
* Zheng et al.(2022) Wenqing Zheng, Edward W Huang, et al. 2022. Cold brew: Distilling graph node representation with incomplete or missing neighborhoods. _Proc. ICLR_.
* Zhu et al.(2021) Yongchun Zhu, Ruobing Xie, et al. 2021. Learning to warm up cold item embeddings for cold-start recommendation with meta scaling and shifting networks. _Proc. SIGIR_.
* Zhu 등(2020) Ziwei Zhu, Shahin Sefati, et al. 2020. Recommendation for new users and new items via randomized training and mixture-of-experts transformation. _Proc. SIGIR_.
