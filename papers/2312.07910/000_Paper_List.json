{
    "2312.07910": {
        "paper_id": "2312.07910",
        "abs_url": "https://arxiv.org/abs/2312.07910",
        "pdf_url": "https://arxiv.org/pdf/2312.07910.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2312.07910_PromptBench_A_Unified_Library_for_Evaluation_of_Large_Language_Models.pdf",
        "title": "PromptBench: A Unified Library for Evaluation of Large Language Models",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Kaijie Zhu",
            "Qinlin Zhao",
            "Hao Chen",
            "Jindong Wang",
            "Xing Xie"
        ],
        "abstract": "and will be continuously supported.",
        "comments": "An extension to PromptBench ( arXiv:2306.04528 ) for unified evaluation of LLMs using the same name; code: this https URL",
        "official_code_urls": [
            "https://github.com/microsoft/promptbench"
        ],
        "pwc_page_url": "https://paperswithcode.com/paper/promptbench-a-unified-library-for-evaluation",
        "bibtex": "@misc{zhu2023promptbench,\n      title={PromptBench: A Unified Library for Evaluation of Large Language Models}, \n      author={Kaijie Zhu and Qinlin Zhao and Hao Chen and Jindong Wang and Xing Xie},\n      year={2023},\n      eprint={2312.07910},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}"
    }
}